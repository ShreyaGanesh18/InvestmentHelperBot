{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification comparison of Random Forest algorithm with GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv(\"AllFin.csv\")## merchants's data set\n",
    "Portfolio_Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare at least one bagging based tree algorithm (e.g. Random Forest) with a boosting based tree algorithm on a classification problem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running probable algorithms within 500 s and comparing these against one another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_path'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-74defd9bcc38>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcluster\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcycler\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcycler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolorbar\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstyle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_pylab_helpers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minteractive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\colorbar.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmpl\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0martist\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmartist\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcbook\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollections\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcollections\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\artist.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdocstring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrcParams\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m from .transforms import (Bbox, IdentityTransform, Transform, TransformedBbox,\n\u001b[0;32m     18\u001b[0m                          TransformedPatchPath, TransformedPath)\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\path.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrcParams\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m from .cbook import (_to_unmasked_float_array, simple_linear_interpolation,\n\u001b[0;32m     23\u001b[0m                     maxdict)\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name '_path'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import preprocessing, cross_validation\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import make_scorer\n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "\n",
    "\n",
    "print(os.getcwd())# import h2o package and specific estimator \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321..... not found.\n"
     ]
    },
    {
     "ename": "H2OStartupError",
     "evalue": "Cannot start local server: h2o.jar not found. Paths searched:\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h2o\\backend\\bin\\h2o.jar\n    C:\\ProgramData\\Anaconda3\\h2o_jar\\h2o.jar\n    C:\\usr\\local\\h2o_jar\\h2o.jar\n    C:\\ProgramData\\Anaconda3\\local\\h2o_jar\\h2o.jar\n    C:\\Users\\Suprita Ganesh\\AppData\\Roaming\\Python\\h2o_jar\\h2o.jar\n    C:\\ProgramData\\Anaconda3\\h2o_jar\\h2o.jar\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mH2OConnectionError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\h2o\\h2o.py\u001b[0m in \u001b[0;36minit\u001b[1;34m(url, ip, port, https, insecure, username, password, cookies, proxy, start_h2o, nthreads, ice_root, enable_assertions, max_mem_size, min_mem_size, strict_version_check, ignore_config, extra_classpath, **kwargs)\u001b[0m\n\u001b[0;32m    251\u001b[0m                                      _msgs=(\"Checking whether there is an H2O instance running at {url}\",\n\u001b[1;32m--> 252\u001b[1;33m                                             \"connected.\", \"not found.\"))\n\u001b[0m\u001b[0;32m    253\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mH2OConnectionError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\h2o\\backend\\connection.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(server, url, ip, port, https, auth, verify_ssl_certificates, proxy, cookies, verbose, _msgs)\u001b[0m\n\u001b[0;32m    317\u001b[0m             \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timeout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 318\u001b[1;33m             \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cluster\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_test_connection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mretries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessages\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_msgs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    319\u001b[0m             \u001b[1;31m# If a server is unable to respond within 1s, it should be considered a bug. However we disable this\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\h2o\\backend\\connection.py\u001b[0m in \u001b[0;36m_test_connection\u001b[1;34m(self, max_retries, messages)\u001b[0m\n\u001b[0;32m    587\u001b[0m             raise H2OConnectionError(\"Could not establish link to the H2O cloud %s after %d retries\\n%s\"\n\u001b[1;32m--> 588\u001b[1;33m                                      % (self._base_url, max_retries, \"\\n\".join(errors)))\n\u001b[0m\u001b[0;32m    589\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mH2OConnectionError\u001b[0m: Could not establish link to the H2O cloud http://localhost:54321 after 5 retries\n[09:28.46] H2OConnectionError: Unexpected HTTP error: HTTPConnectionPool(host='localhost', port=54321): Max retries exceeded with url: /3/Cloud (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000021D27700198>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it',))\n[09:30.73] H2OConnectionError: Unexpected HTTP error: HTTPConnectionPool(host='localhost', port=54321): Max retries exceeded with url: /3/Cloud (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000021D277008D0>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it',))\n[09:32.98] H2OConnectionError: Unexpected HTTP error: HTTPConnectionPool(host='localhost', port=54321): Max retries exceeded with url: /3/Cloud (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000021D27700F98>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it',))\n[09:35.27] H2OConnectionError: Unexpected HTTP error: HTTPConnectionPool(host='localhost', port=54321): Max retries exceeded with url: /3/Cloud (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000021D277186A0>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it',))\n[09:37.56] H2OConnectionError: Unexpected HTTP error: HTTPConnectionPool(host='localhost', port=54321): Max retries exceeded with url: /3/Cloud (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000021D277007F0>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it',))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mH2OStartupError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-8f4a38fc112a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mh2o\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mh2o\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mh2o\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdemo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"glm\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\h2o\\h2o.py\u001b[0m in \u001b[0;36minit\u001b[1;34m(url, ip, port, https, insecure, username, password, cookies, proxy, start_h2o, nthreads, ice_root, enable_assertions, max_mem_size, min_mem_size, strict_version_check, ignore_config, extra_classpath, **kwargs)\u001b[0m\n\u001b[0;32m    259\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mH2OConnectionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Can only start H2O launcher if IP address is localhost.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m         hs = H2OLocalServer.start(nthreads=nthreads, enable_assertions=enable_assertions, max_mem_size=mmax,\n\u001b[1;32m--> 261\u001b[1;33m                                   min_mem_size=mmin, ice_root=ice_root, port=port, extra_classpath=extra_classpath)\n\u001b[0m\u001b[0;32m    262\u001b[0m         h2oconn = H2OConnection.open(server=hs, https=https, verify_ssl_certificates=not insecure,\n\u001b[0;32m    263\u001b[0m                                      auth=auth, proxy=proxy,cookies=cookies, verbose=True)\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\h2o\\backend\\server.py\u001b[0m in \u001b[0;36mstart\u001b[1;34m(jar_path, nthreads, enable_assertions, max_mem_size, min_mem_size, ice_root, port, extra_classpath, verbose)\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[0mhs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mH2OLocalServer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[0mhs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_verbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m         \u001b[0mhs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jar_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_find_jar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjar_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m         \u001b[0mhs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extra_classpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextra_classpath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[0mhs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ice_root\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mice_root\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\h2o\\backend\\server.py\u001b[0m in \u001b[0;36m_find_jar\u001b[1;34m(self, path0)\u001b[0m\n\u001b[0;32m    204\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mjp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m         raise H2OStartupError(\"Cannot start local server: h2o.jar not found. Paths searched:\\n\" +\n\u001b[1;32m--> 206\u001b[1;33m                               \"\".join(\"    %s\\n\" % s for s in searched_paths))\n\u001b[0m\u001b[0;32m    207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mH2OStartupError\u001b[0m: Cannot start local server: h2o.jar not found. Paths searched:\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h2o\\backend\\bin\\h2o.jar\n    C:\\ProgramData\\Anaconda3\\h2o_jar\\h2o.jar\n    C:\\usr\\local\\h2o_jar\\h2o.jar\n    C:\\ProgramData\\Anaconda3\\local\\h2o_jar\\h2o.jar\n    C:\\Users\\Suprita Ganesh\\AppData\\Roaming\\Python\\h2o_jar\\h2o.jar\n    C:\\ProgramData\\Anaconda3\\h2o_jar\\h2o.jar\n"
     ]
    }
   ],
   "source": [
    "import h2o\n",
    "h2o.init()\n",
    "h2o.demo(\"glm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a71858b898>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABCsAAAPNCAYAAACgceBAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzs3Xd4FMUbwPHvJCQklJBCSULvSi9KByF0RRSFFVQEFERRxALSVLAh9q4/EMWOLKiIVFGK9Cod6Z1ASCGQ3vb3x26SS3IJSbjkDnw/z5MnubvZuXfn5nK3787MKsMwEEIIIYQQQgghhHAVbs4OQAghhBBCCCGEEMKWJCuEEEIIIYQQQgjhUiRZIYQQQgghhBBCCJciyQohhBBCCCGEEEK4FElWCCGEEEIIIYQQwqVIskIIIYQQQgghhBAuRZIVQgghhItTSq1WShlKqan/xecXuVNKfW29Nl87OxYhhBDCkSRZIYQQwmUppdyVUppS6lul1CGl1CWlVJJSKkwptU4p9YZSqpGz47xeKaXuVkpNVUrd7exYioK1b4bNz8B8bLM42zY1HBzT01ZczRxZrxBCCHGjkWSFEEIIl6SUagPsB+YCg4G6QCngChAAtAcmAHuUUj8rpTydFet17G5givU7L6eAg0B4kUdUtIbl9aBSKhjoWcQxPI3Z5o5KVoRivjahDqpPCCGEcAklnB2AEEIIkZ1S6k5gHlASiADeAX42DOOw9bg70By4FxgF3IOZyEhySsA3OMMwHnJ2DNcoHPAGuimlqhqGcTqXcg8B7sAJoEbxhHZtDMOYCEx0dhxCCCGEo8nICiGEEC5FKVUX+B4zUbEfaGYYxvT0RAWAYRiphmFssw7UagK/OSdacZ2IBeZjfu8Zkke59JEXXxd1QEIIIYTImyQrhBBCuJrXAB8gAehnGMaZvAobhhFpGMbdQHT2x5RSgUqpt5VS+5RSMUqpWOvvt5RSlezVp5SqYbtegVKqtlJqplLquFIqUSl1wqZsxsKTSikPpdRzSqlt1toahlKqc7a63ZVSQ5VSy5VSF6z1Ny5atwcqpVRBG0spVVEp9bBS6hel1AGlVLRSKl4pdUQpNUsp1dDONp2VUgaZB+5Dsq3TkCX2/CywqZS6Rym1yGa/Lli3++WxTZbFIZVS/a3nilRKxSmldiqlxiilHPF9Zbb1e6i9dlZKdQDqAceAv/OqSClVXyk1Tin1p1LqqNXel5VS/yilXlNKlbezzVSrzaunx5O9zW3KFqQP2l1gUyk13ro/SSnVKpf9uF0plWaVuz+vfRZCCCGKm0wDEUII4TKsBEJ/6+YPhmEcyu+2hmEYtreVUrcBCwBf6644wAAaWD/DlVJ9DcNYl0e17YAZQBlr++RcynkBq63yKZjramRh7dtvQGubu6OB8kAP62eQUmqAYRgFmc7yFllHC1zG/Hyvbf08qJR6wDCMn23KJAEXgHJW7AnkTPbkKwZrrZBvgfusu9Js9usO4A6l1BxgiGEYubUfSqlPgCes7S9jTttoCnwAtCDvERH58TdwFLNNOpIzIWE7qsIgb8vJTDoYmPtbDnMdimaYCZGuhmEctNkmBrPNK2CeLLoMxOcj7vz2wezeArpZP3OUUs0Mw8jol0qpIMx9VcC3hmH8mM96hRBCiGIhIyuEEEK4ki5kfjb9WthKlFJVyUxU7Ac6GIZR2jCMMkAnzAUJ/YDflFKV86hqBrAPuNVm+x52yj0BNME84PUxDMMf82B9txWPJ/A7ZqJiB+ZBfGnDMHwxD0KHAGFAX+DNAu7ucczRKM2BMoZhlMOcQtMI+MH6+xtlLh4JgGEYGwzDCMRcvBRgrmEYgdl+NuTz+adhJioM4FUgwGb/p1llBlmP5aYvMAJ4FvAzDMPP2n6W9fhDSqmQfMZjl5XM+tq6+bDtY0qp0oCGmSj5mqvbBIwG6gBeVrxemImBLUBlIMvBv2EY71htnr5expjsbZ7Lc+W3D2Zh7e9gzH5VC/ifzf4qzARTBeAIZv8VQgghXIokK4QQQrgS2ykL/1xDPZMwExVRQFfDMNanP2AYxlrMg8rLgD95L04YAXQzDGObzfb2RnuUAe43DONrwzDirXIRhmFEWo+PAG7FPOjsbBjGEsMw4qxysYZhfAvcjnnAP0opVTG/O2oYxsuGYbxoGMZOwzBirfvSDMPYZxjGg8BioDTZDtAdwUr0jLFuTjcM4yXDMC5ZMUQZhjEZeM96/FnrbL49fsBIwzDeNwzjsrV9hGEYI4DtVplBDgj5G8yERH+lVBmb+zXM1/CvPBbfzGAYxkDDMD4xDONo+igYwzCSDMP4C+iKOYKihTW15Frltw/ai/M8MBSzX92vlEofnTIe8z2QDAwyDCPGAXEKIYQQDiXJCiGEEK4kwObvyFxL5cE6a6xZN/9nHbBlYa2DkX6meWAe1X2SzwO5fYZh/J7H48Ot35/ZDsXPFtN2zGSGJ+YIE0dZbP12xIFzdvdiTjlJAKbnUuY1IBHwIHOKT3anMc/027PQ+t2kkDFmsBIRf2ImbzSbh9KngHzlgOeIAdZYNx3R5vntg7nFsxR4P70updSDwCvW7Um2SRAhhBDClUiyQgghhCsp8AKTdtTEHDEB5oFpblZYvwOUUjVzKbM+l/vzXU4pVZbMA+1XlVLnc/sB6lvlqtuvLdfnaKqU+kwptdta6DF90UQD+MwqVqUgdebTLdbvrekjIrIzDCMK2JatfHZbDcNIy+Wxc9Zv/1weL6j0hTYfBlBK1cFcw+IS5tShfFFK9VFKzVVKHVPmwq22C2WmJ0Ic0eb57YN5mYg5QqUM8B1m4ugP4F0H1C2EEEIUCVlgUwghhCsJt/nbn8wD1YKwnUJxNo9ytlcZqYi59kN2Yfl8zrzKBZJ5ciC/B9yl8lkOpdSTwIc2z5G+4GOiddsb8+oqpfNbZwGkt3Ve7QyZbZ3b9Ba7o00sKdZvj/wGdRW/Yk4Paq+Uqkfmwp0/GoaRcLWNrSuTfE/WaSkpVp3pi5KmL1zqiDbPbx/MlWEYSUqpocAe665ozAVPr7aQqBBCCOE0MrJCCCGEK9ln83dzB9SX34Ox3Mql5nP7vMq52/zdxjAMlY+fqfl5UqXUzZhXy3AD5gGtsBZ8tFm08dn04vncl8K41nYuNoZhJAJzrJuPAA9Zf8+2v0UOj2AmKlIxp1PUBUoahuFv0+bzrbKOaPP89sGredTmbx/Mq5YIIYQQLkuSFUIIIVzJKswFEAH6FbIO2zPRVfMoZztE/2Ihnys/Ltj83djBdffHTIYcAAYahrHVzmVPc7vKhCOkt3Ve7QyZbV2U7VwQ6YmJpzFj21uAtRvS1ziZZRjGFMMwjtiZwlKUbV5gSqk+mFcvAfMKNQrzCjGVnBeVEEIIkTdJVgghhHAZhmFcAH62bt5vDdPPF2thTTCnc6Qvztk1j026Wb8jDMOwNwXEIaw1G/ZbN/NazLMw0pMEu/JY86FbLvdDZmKosCMAMtaiUEqVs1dAKeWLzdoWhXweh7ISE3swFzOFgi2smd7mdq9WY11lpHUe219rmxeIdQWW9OTMbMxL957AnJLzjc37RgghhHApkqwQQgjhal4AYjDXWvjFujxmrpRSfkqpnzHXCcCahz/XenikUirHWW6lVDAw0ro5J/vjRWCm9burUirPhIVSqiALSUZbvxvbO+hUSvUGOuexffqimL4FeE5bP2Ou1+CFeTlMeyYBJTEvk/lzLmWcYTzmApPvYq5BkV/pbd40l8dfBMrmsf21tnm+WetrfAeUBw4Dow3DiAbux3zdepI5TUgIIYRwKZKsEEII4VIMwzgEDMZcrLAhsFMpNd66agMASil3pVRzpdQrwDHgnmzVTMO8uoM/8KdSqp3Ntu0xrxLiizkCI7dLbjrS/4DN1t/fKaVeU0plTJ1QSpVSSnVWSn0CHC1Avcus3w2BT9MTHUqp0kqpkZhrJ0Tksf1e63dHpdRNBXheAAzDOIu5uCfABKXUy9ZICpRSvkqpV4Fx1uPvGYYRWtDnKCqGYSw1DGOs9VOQ6SnpbT5CKfWoUsoTQCkVqJR6H3ie/LV5f6WUX8EjL5DnMUcXJQODDMOIBTAMYyPwslVmmlKqRRHHIYQQQhSYJCuEEEK4HMMwFgAhwBHMs8LTgcNKqUSlVARmImMH5lnscpijI2Jttj8D3I15FrwhsF4pFaOUigHWATdjJjPutg64i3p/EoE+wErMK3FNBk4ppaKVUlGYI0lWAU9gXl4yv/X+Bfxk3XwciLDqi8ZMkBwApuZRxc+Y60j4AQeUUheVUiesnzb5DGMSoGNOa3jJiiES84D9BavMHMzX6kbwLvAv5us4A4i32vwc5hoYM4BFeWw/E3Oh0XbARaXUufQ2d2SQSqlWmAuAAkwyDGN7tiLTgNWYU2HmKKWK4moxQgghRKFJskIIIYRLMgxjPXAT5pUXfsBMXCRgDrGPxEw6vA7cbBjG/YZhJGfbfo21/buYB+1umAfUB4B3rO3WFs/egGEY4ZjrR9yFOeLhNOb0CG/MS38uBZ4EahSw6gcwD5J3Y16u1B1zPYaJQHvMREhuMUVhrmHwkxVDOaC69eOVz/1KMgzjPuBeax8iMF+jCOv2PfZen+uVYRiXMBMNH2Cu/ZCKOaViNebohceusv3fwB2Yo3uigUpktrlDKKXKYiaIPIAVmO+B7HGkYY5gigTqAZ846vmFEEIIR1ByiW0hhBBCCCGEEEK4EhlZIYQQQgghhBBCCJdSwtkBCCGEEEIIIYQQ4vqladpXmOtzhem63sjO4wpzUe7bgThgqK7rO/KqU0ZWCCGEEEIIIYQQ4lp8DfTK4/HeQF3r51Hg86tVKMkKIYQQQgghhBBCFJqu639jLtqcm7uAb3VdN3Rd3wT4apoWlFedkqwQQgghhBBCCCFEUaqMeSW0dGes+3Ila1b8Ryml5DIwQgghhBBCCJdnGIZydgxF6TFVw+WPzSIHtBqJOX0j3Uxd12cWoAp7r2Ge+y3Jiv+okY67nHuxm8FJAvt/7OwwCu38/NG0fnWFs8MotM0vdqfsbc87O4xCu7Lmres+/sr3z3J2GIV29sfhVHlwtrPDKLQz3w+T+J3ozPfDrvv+f73HL/3HOc7+OBzguo/fo9kwJ0dSOMk7zX4f0OcNJ0dSOBGLJgJct+/fM99fn/3mRmMlJgqSnMjuDFDV5nYV4FxeG0iyQgghhBBCCCGEEEVpIfCkpmk/Aa2BaF3XQ/PaQJIVQgghhBBCCCGEKDRN0+YAnYHymqadAaYAHgC6rv8PWIJ52dIjmJcuveqQGUlWCCGEEEIIIYQQTuJ+A6zIoev6oKs8bgBPFKROuRqIEEIIIYQQQgghXIokK4QQQgghhBBCCOFSZBqIEEIIIYQQQgjhJO7qBpgHUgRkZIUQQgghhBBCCCFciiQrhBBCCCGEEEII4VJkGogQQgghhBBCCOEkN8LVQIqCjKwQQgghhBBCCCGES5FkhRBCCCGEEEIIIVyKTAMRQgghhBBCCCGcRK4GYp+MrBBCCCGEEEIIIYRLkWSFEEIIIYQQQgghXIpMAxFCCCGEEEIIIZxErgZin4ysEEIIIYQQQgghhEuRZIUQQgghhBBCCCFcikwDEQ4z+Mu3aNwnhCthEbzauKezw8ni1WEd6dqiOvGJKTz96V/sOX4xR5kmtSrwwRPd8PJ0568dJ3lx9loA+rSpzVitFXUr+3P7xHnsOhaWsc3N1QJ4a2QXynp7kGZA7wk6icmpDo29Ta0AnulZDzelWLjzLN9tOJnlcQ93xZS+Dakf5MPl+GRe+GUPodEJuLspJvW5mfqBPpRwUyzZHcq3G05Qzb8Ur93TOGP7yn7ezFxzlLlbTjs0bltvje5Ljzb1iUtI5vHpOrsOn8tRplm9ynw+YQDeJT34Y9NBnv94IQATh3ZjyB2tCI+OBeCVL5bxx+aDlHB345Nx/WlaL5gS7u7MWb6d935cLfFbXnmoDSFNqxKflMIzM/5m74mIHGUa1wjg/cc64eVRgpW7TvPSt5sA8C3tyWejQ6haoQynL8bw+EcriY5Lol+72oy6swkAsQnJTJy9gQOnIqkVVI7PR3fJqLdaxbK8M38HXy7bV+j4Xx7cipCmVYhPTOHZmevYezLSbvzvPdoBL093Vu46w5TvtmTE/+mTnalavgynw2MY9fFqouOSuLtdLUbd0ciMPzGFSV9v5MCpKEp6uDN/ci88Pdxxd1Ms2XqS937ZWejYOzeuzNTBrXB3U8xZfZjPFu3J8rhnCTc+GNmRxjUDiIpJZNQnazgTHgPAE3c2ZuBtdUlNM5jy3WbW7DmXrzpfGdwarVMdbhrxQ6HjtlUU7V87qBzvjmhPoxoBvD1/BzOWmP2jVqAPnz3ZOaPeahXL8O7PO/ly+f5Cx1+c/R/gkZ4NGdSlPkrBj6sOXlPfL6r40zWtVZ6FL9/JqI9XsXjLCQBOfjeMf09HAXA2PIaH3/uz0LEXZ98J8i/FByM7UqGcN2mGwY+rDvHVHwcKHTsUTdv3aFmNcf1bkmYYpKSmMfW7zWw9dAFwbNvfCPHbeu/5++nVvjHxCUk8MuVLdv57KkeZ5jdX58uXH8GrpAfL1u/h2bd+BKBJvap8MnkwZby9OHkunIcmz+RKbAJdWzfg9af64+lRgqTkFCZ8oLN6678Oizm7aY92o1vL2sQnJjP6w8XsPnohR5mmtSvx8dN34OXpwZ/bjzJpptmGEx7oSO/WdUkzDMKj4xj9wWLOR8bQu3VdJjzQkTTDIDU1jcmz/mLz/jOFjrEo3rN51fvduO40r12BrYcuMOy9vzKe471HO9D6pkpciUsG4NmZ69h/Kmcs4r9FRlYIh9n49Xw+7jXE2WHkENK8OrWCfGk3+nvGzVjF9BG32S03fURnxs1YRbvR31MryJeQZtUAOHg6kkfeWcqmA1kPUN3dFJ881Z3xM1fR+dk53DvlV5JT0xwau5uCsb3r88ycnQz630Z6NAykRvnSWcr0bVaZywkpDPhsA3M2n+KJkDoAdL25Ip7ubjw4cxNDZm2mX4vKBJXz4lRkHA/N2sxDszYz9MvNJCSnsuZgzuSNo/RoXZ/aVcrT7IG3GfPuL7z/TD+75d5/ph9j3vmFZg+8Te0q5eneqn7GY5/OX0eH4R/SYfiH/LH5IAD9OjehpGcJ2j78AZ0e/YhhfVtTLdBP4gdCmlahZqAPHZ6bx/gv1/HGsHZ2y73xcHuen7WeDs/No2agD12aVgHgib5NWb/vHB2fm8/6fed4om9TAE5dvEL/VxfTfeKvfLhgJ2890h6AY6HR9Jy0gJ6TFtB78m/EJ6awbNtJu8+ZH12aVqZmJR86jv2F8V9tZNqwtnbLTRvahvFfbaDj2F+oWcmHzk0qAzDqzsas3xdKp3G/sH5fKKPuNJNzpy9eYcDry+gxeSEfLtjFmw+b7ZKYnMp9byyn5+SF9HphIZ2bVKZ57QqFit1NKV4b0pqH3l5ByPgF3NW2JnWDy2UpM/C2ulyKTaLj2F+YtWw/k+5rCUDd4HL0bVOTrhMWMPjtFbw+pA1uSl21ziY1A/Ap5VmoeO0pqva/FJvIlO82M3PJ3iz1HDt/mV4vmG1/+4u/E5+Yek39p7j7f/0qfgzqUp8+L/1Gj4m/0q15VWpW8nG5+MHsn5MG3sqa3Wez1JWQlJrxHr6Wg83i7jupqQav/riVkAkLuOvlxQzpdlOO91tBFFXbr9t7ju4Tf6XnpAWMnbmWt0d0yKjLUW1/I8Rvq1eHxtSpVokGd03k8de+4ZNJD9kt98mkwTz+2jc0uGsidapVomd7s8/876WhTP5oPi20l1iwagfPDekNQMSlGPo9/REttJd45KUvmf3aCIfFnF23lrWoFexHq5EzePbTZbz9uP0TeW+P6smznyyj1cgZ1Ar2o2vLWua+/bKZ2576ii5jZvPH1iOMHWj+z/l714mM+5/6aAkfjO5d6BiL6j2bV73/W7yXp2f8bfd5Xp+zLePz4L+WqHBXyuV/nOG6T1ZomrZa07RbHFTX05qmlXJEXUVN07RZmqY1sHP/UE3TPnFGTEfWbiEuMtoZT52nXrfWZN4aM2u+4/AFfEqXpKJv1pe5om8pynp7sv3QeQDmrfmXXq3MD4vDZ6M4eu5Sjnpva1qNAycj2H/SPGsRFZNAWprh0NgbBJfjTGQ85y7Fk5JmsGLfBTrVy3oQ1bFeBZbsDgVg1YEwbqnpD4ABeHu4464UJT3cSU5NIzYxJcu2t9T052xUPOejExwat63b2zdkzvLtAGzdf4pyZbyp5F82S5lK/mUpW7okW/abZ03mLN/OHR0a5lmvYRiU8vLA3d0N75IeJCenciXW8ftxPcbfo2V15q89AsCOIxfxKeVJRV/vLGUq+npTxtuDHUfMkULz1x6hZ8vq5vYtqjFv7WEA5q09TM+WZuJu++GwjDMmOw6HEeSfNXEG0KFRMCfDrnDWGilQqPhbVOPndUcB+OeoFX+5bPGX86aMtyc7jpiJtp/XHc2Is0eLahn7b+5XevwXM+L/58hFgvwy/w/EWe+NEu5ulHB3w6Bw7+Vmtctz4sIVTl2MITk1jYWbjtPDen7b/Zu/zoxv8ZYTtG8YZN7fshoLNx0nKSWN0xdjOHHhCs1ql8+zTjelmDzwFqb9tK1Q8dpTVO0fcTmBXccjSE7NvW07NAziZNhlzkbEFj7+Yu7/dYLL8c+RMBKSUklNM9h04Dy9bq3ucvEDDOvZgCVbTxB+Ob7Q8eUZezH3nbDo+IyztbEJKRw5F02gf+G/xhVV28fZfPZ6l/TAcOxXhRsmflt33tacHxZtAGDLnmP4li1FYPmsiajA8uXwKe3N5t1mn/th0Qb6dm4OQL3qgazdfgiAvzbto19XMym88+ApQi+a3+n2HT2Ll6cHnh5FM9C8d5u66CvNBNv2g+coV7oklfyyfm5W8itN2VIl2XbQPCGmr9zL7W3qAhATnzkiqlRJDwyr4WMTku3eXxhF9Z7Nq971+0OJic/6fVSI3FwXyQpN04prusrTwDUnK4ojXl3Xh+u6Xvgxsv8hgf5lOBeReeAUGhFDkH+ZLGWC7JQJzFYmu9pBvhgYzJnclz/e1BjVt7ljAwcqlC1J2OXMA9iwKwlUKFsyR5kLVplUwyAmMYVy3h6sPBBGfHIqi57uyG+jO/DDplNcTsj64dC9QSB/7Dvv8LhtBVfw4czFzCTW2YvRBFfwyVHmbB5lHu3Xlg1fPs2nz/fHt4z5YbdgzR7iEpI5/PNk9s2dyEdz/ybqiuO/gF+P8Qf6l+KczcFeaGQcgdm+IAX6lSY00rZMbMaX/PLlvAm7ZMYSdimegGxfXAAGdq7Hql05h532bVOL3zYcvbb4/UpxLpfYMsr4l8oZv5V8KO/jTVi0FX90PAE+Xnbir8sqm7PLbkqx7LW+7Px0IGv3nmPn0XDHxe6XM/b01yc1zeBKXBJ+ZUqa29q+blHmtnnVObT7Taz453TG/jpCcbR/bvq2qclvG49fS/jF3v8Pnomi9U2B+JYpiZenOyHNqhJsJ5Hn7PgD/UrR+5bqfPdnziHvJT3cWfxqXxa+fGfGgWuhYndi36lSvgwNq/vzz5HCvXfTYyuqvtPrluqsfvtevh3Xg+dmrs2431FtfyPEbyu4oh+nz2eeWT9zIZLgin45ypwJi7JbZt/Rs9zZuRkA93a/lSqV/HM8xz3dWrLz4CmSkovmwDkooCxnw69k3D4XcYWggLI5ypyzLROetcykwZ3Y9dUo+nduyPQfMtv99jb12Pj5COZMGcBTHy4pdIxF9Z7NT732PD+gBX+83pcpD9yKZ4nr4jBVFLEiPajWNK0GsAxYB7QBdgGzgZeBisADwD7gY6CxFc9UXdd/0zRtKHAH4AWUBkI0TXseGAykAUt1XZ9gPdUATdM+A3yBR3RdX2s993fWtgBP6rq+QdO0zsBUIBxoBGwHHgRGA8HAKk3TwnVdz5yAnXWfHgHGA+eAw0CirutPapr2NRAJNAd2aJr2OvAVUAuIAx7VdX23pmlTgRhd19+x6tsL9LGqXwZstuo4BDyk63pcLnGsBsbqur5N07RhwEQg1Nou0d42/1X2Ri3lOGtqr8xVMtXu7m60uimY3hN04hNT0Kfcze5jF1m3t/DzBrPLz4gr+/sHDYN9SDMM+ny4Fh+vEvxvyC1sPR7JOeuLSAk3Rcd65fl81RGHxWs3Pjv3ZW9aZadUevvP+m0Tb377F4YBLzzcg9dH3cETb82n5c1VSU1No969r+Nb1pvlHz3O6u1HOBHq2GGD12P8ecWTUcZun89f/e0aBDGwc336vbIoy/0e7m70aFmN6XO35jtWe/ITm93XJZ/1t705kPs61eWe15Zm3JdmGPR6YSE+pTz5YkwX6lfx5eCZnCOqrqaw7Wrksa2bne9rhgGVfL25o1UNtGnLChxnXoq6/XPj4e5G9xZVma5vv6Z6irv/HzkXzWe/72bOhF7EJqaw/1QEKdcwyq6o4p86uA3TftpKmp2CrZ+ay4VLcVSrUJa5k3vz7+lIToZdsVNL3pzVd0qVLMGMpzoz9YctxNicdS6oouw7y7adZNm2k7S+KZBxA1ow6A3zfeuotr8R4r96nNn2xd6GVplHp37Fe8/fz+QRfVm0ZmeOhESDWsG8/tQA7hj17jXHmhv73x8K9npM++5vpn33N2P6t2F4n5a8+eM6AJZsOsSSTYdo27AqEx/sxL0v/lS4GIvoPVuYfjZ97nbCouPxLOHG9Ifb8Xifxny4YNdVnunGIZcuta84RizUAQYAjwJbgfuBDkBfYBKwH1ip6/rDmqb5Als0TUuf9NYWaKLreqSmab2Bu4HWuq7HaZpmmyItoet6K03TbgemAN2AMKC7rusJmqbVBeYA6dNFmgMNMRMO64H2uq5/pGnas0AXXdftpuU1TQsGXgRaAFeAlZgJmHT1gG66rqdqmvYx8I+u63drmhYCfAs0u0pb1cdMtqzXNO0rYBTwTl4baJoWhJn8aQlEA6uAf3Ip+yjm60DO/PKNZWjPxjzQzZwls+tIGMEBmaMkggLKcD4y6xDj0IiYHGUuROU9DDk0IoaN+88SecUc1bByxwka16rg0GRF2OUSjfusAAAgAElEQVREKtqcWapY1ouLVxJzlKnkY97vrhRlSpbgcnwyPRoFsvFoBKlpBlFxyew+Hc3NQWUzkhVt65Tn4PkrRMYm4Wgj7m7LkD6tANjx7xmqVMgculm5QjlCwy9nKX/2YjSVc5Qxv+xcjMoc8fLN4i3obwwFQOvajD+3HCQlNY3wS7Fs2nuC5vWrOORg/3qMf0j3m7m/i7lOxq5j4QQHZJ5NC/IvxYVLWfOeoZGxWaZxBPmX5kKUWSY8Op6KvuYZtoq+3kTYnLW/uaofbw3vwOC3lnMpJmtf7NKsCntORBB+ueDTWYZ0u4lBnetlxp9LbJnxx+Ue/+V4KpYzz/ZULOdNhE08N1X14+1H2jH4nT9zxA9wOS6Jjf+ep3OTyoVKVoRGxuWMPVvbn4+MIzigNOej4nB3U5Qt5cmlmERzW9vXzS9zW3t1NqweQI1KPqx9514AvD1LsPade+g49pcCx11c7Z+XLk0rs7ew/cfJ/f+nNYf4aY055Hy81pLQSLvnGZwaf5Oa5fn0SfM8jH9ZL0KaViUl1WD59pMZ9Z+6eIWNB0JpVCMg3weczu47JdwVM5/qwoINx1i2LecCjFeNv5j6TrrN/56nekUf/MqUJCom8Zra/kaI39ZjWgiP3NMJgG37jlM1MPPbapVK/hnTN9KdDYuiis1oiyqV/DlnlTl44jx3jHoPgLrVKtG7Y5OMcpUr+jHvvSd5+MVZHDvj2DW7Hr69BYN7mmt97DwcSuXymaMkggPKcj4y6xTJc+FXCLYtU74s5yNztt/Pa/YzZ8qAjGRFuo37TlMjyBd/H28i8zm9qzjes3Y/C6Py/r+YPkIjKSUN/e8jjLw97+m04r+hOMbXHNd1fY+u62mYoyj+0nXdAPYANYAewARN03YCqzFHUqRPsFyh63r6N/duwOz0kQY29wOkfzPbbtUJ4AF8oWnaHmAeYLu+wxZd189YMe202eZqWgFrdF2P1HU92arX1jxd19MvBdEBc2QHuq6vBAI0Tbvaqk+ndV1fb/39vVXH1bQGVuu6flHX9SRgbm4FdV2fqev6LbquO2SND1f29fI9dB83l+7j5rJ06zEG3HYTAC3qVuJKXBJh2T68wy7FEROfRIu6lQAYcNtNLNua91Dk1btO0aBaAN6eJXB3U7RpUJlDZxx7Vv/AuctU9fcmyNeLEm6K7g0rsfZQ1g/WtYcucnsTc857l5srsu2EOSTyQnQCt9QwP+i9PNxoVNmHkxGZ+92jYaUimwLyxYKNGQtKLl63j0E9zbmitzaoxuXYBC5k+yC+EHmFmLhEbm1gvvUH9WzJkvXmau+260Pc2aEhB46bK2mfDrtEpxbmYqKlvDy4tUE1Dp0KwxGux/i/WXEgY5GzZdtO0r+jWXeLOhW4Ep+cMbQ3XdileGLik2lRx1wDpX/HOvyx3VzUcMWOUwzoaM6ZHdCxLn/sMA8AggNK88XT3Rjz+RqOn8+asAG4q23tQk8B+ebPfzMW1Vq+/RT3dqgNQPPaFcz3bLYvzWHR8cQmJGcshHlvh9oZca7YcTpj//t3rJM1/jFdGDNjbZb4/cuWzFig0svDnY4NgzlyrnDr7+w6Fk6NQB+qViiDh7sbfdvUZMWOrFfaWfHPafp3MOO7o1UN1u8PzYi7b5uaeJZwo2qFMtQI9GHn0fBc61y56wwtR8+l3bPzaffsfOKTUgqVqIDiaf+ruattrUJPAXF2/08f+hwcUJret9Yo8PugOOJv94xO26fNn8VbjjP56w0s336ScqU8M4Zb+5Upya31KnHobP4Tdc7uO28Pb8/hc9F8saxwM2OLo+1rVMr8HGhUIwDPEm5ExSRec9vfCPHb+p++klsHTuXWgVNZuOofHuhjLhDaqnEtomPiOB+e9f/y+fBorsQl0KqxucbYA33a8fsa83xdBT8zZqUUE0fcycz5qwEoV8ab3z5+mhc+/pmNuxw/svSrJTvoMmY2XcbMZsmmw2gh5hWoWtYP5nJcYo4TYReiYomJT6Jl/WAAtJBGLN1krhtSKygzEdOrdV0OnzHXSKsZ5Jtxf5PalfAs4Z7vRAUUz3t2xY7TV603O9u1Mnq2rFaoEwbixlMcIytsT12l2dxOs54/FbhX1/WDthtpmtYasH1HK3IfdZReZyqZ+/QMcAFoipmUSbBTPvs2V3O1ATrZ483OAFLImiTyyvZ49vL5UQxLHV3dIz9+RL3ObShT3o83Tm/k9ynvs+Er3dlh8deOk3RtXp2NHw82L+X1aeZlkla8fR/dx5n5nQlfrOGDJ7ri5VmClTtPsvIf88O7d6tavPZwJwJ8vPluYh/2nQhn0OsLiY5NZMainSydPgDDgL/+OclfOwq/gr09qYbBO8sO8uGg5ri5KRbtPMfx8FhG3FaLf89dZu3hcH7feY4pdzVk3qh2XI5P5sVfzcWc5m87wwt3NuDHkW1QwKJdoRwJMzP6JUu40aqmP9OXXNsl3vJj+aZ/6dG6Prt+eJ64xCRGvZmZ41s3awwdhn8IwDPv/8rnEzS8PT1YseVgxlUzXn3sdhrXCcIw4NT5KMa8ax6MfbFgI5+NH8Dm2c+iFHy/dBv7jjk++XI9xr9y52lCmlVh3XsDSEhK4dkZmfNcl0+7m56TFgAwafYG3hvZCS9Pd1bvOsNKaw7+J7/v5n+jQxjYuR5nw2N57CPzPfNMv+b4li3JNGuF+ZTUNO540bxEq5enO50aBTPhy6xnfQoV/64zhDSrzLp37iE+KZXnvsisc9lrfen1gvmck77eaF5KzcOdVbvPsmqXuQbFp4v28PmTtzHwtrqcjYjh8Y9XA/D03U3xLVOS14eYq5KnpqZxx5RFVPQtxfuPdsDdTeHmpvh98wn+2lm4EVKpaQYvfruJ78d1x91NMffvIxw6e4nn7mnG7uMRrPjnND+tOcwHj3Vk7Tv3cCkmkSc+XQPAobOXWLT5BCun301KmsEL32wyh+wb2K2zqBRV+1co583iV/pQxtuDtDR4pGcDQsYvICYhGS9Pdzo2DGLCVxuuPX4n9P+ZY7riV7YkKSlpTP56Q5ZLhbpK/LmpU9mXNx9pT1qagZub4tOFuzlcyP5V3H3n5mp+9O9QhwOnIln2Wl8A3py3PaO+AsdfRG1/+601ubdjHVJS00hISuXxj1cBjm37GyF+W0vX7aZXhyYcWDid+IQkhk/9KuOxrT+ZCQ2AJ6d9x5cvP4xXSU+Wr9/DsnXmZZ3v69Wax+8LAWDByh1885vZF0cN7ErtqhWZNOJOJo2409y/x9/lYtS1T13JbsW2o3S7pRZbZ44kPjE5y9oSqz4cRpcxswEY99ly69KlJfhr+zH+3H4MgBeHdqZOZX/S0gzOXLzMc5+aU2/6tKvPfSGNSE5JIyEpheFv/VboGIvqPZtXvT+/0JvaQeUo7VWCLR8OYNys9azZc46PRnUioKwXSsG+k5FMnL2x0Pt1PXLW1TZcnbqWFWSvxlo3YpGu642s219bt+enPwYsBHyA0bquG5qmNdd1/R9rzYpbdF1/0tq2F/AS5jSLOE3T/K3pIavJXLuhPLBN1/Uamqa9D5zRdf1da02Hr3RdV9aaFWN1Xe9j1fuJtc3X1iiMvrqu2z21o2laZcxpI80xp4H8BeyxWbNika7r862yHwEXdV1/1XrO93Vdb65p2oNAH13XB2qa1gJzakxt6ymOA+10Xd+oadoXwL+6rtudTJe+38BZYBPm1JTLWFNT0tstN4+pGi6R4CiMGZwksP/Hzg6j0M7PH03rV1c4O4xC2/xid8re9ryzwyi0K2veuu7jr3z/LGeHUWhnfxxOlQdnOzuMQjvz/TCJ34nOfD/suu//13v80n+c4+yPwwGu+/g9mg1zciSFk7zT7PcBfd5wciSFE7FoIsB1+/498/0wDMO4oY/mp3rXcfljs6nxR4r9NXCFZVZfxZyysdtabPJVe4V0XV+GmdjYZk0ZGXuVej8DhmiatglzLYn8XAdtJrBU07RVucRwFpiGuQjmn5jrbeQ2VngqcIumabuB6cAQ6/6fAX9rHx7HXBAz3QEr5t2Yy0p8frWAdV0PtZ5roxXTjqttI4QQQgghhBBCuLIinQai6/oJzCtupN8emstjI+1s+zXwdbb7pmMe+Nve19nm73Cs9Sd0XT8MNLEpOtG6fzXm2hjp2zxp8/fHmFcmycuPuq7PtC5P+ivwR/Z9s25HAnfZ2a94zHU6srBGmqTpuv7YVZ4/vZ7ONn/PxrzKihBCCCGEEEKI64grjCBwRdIuBTfVGhWxF3PaxgInxyOEEEIIIYQQQtxQimOBzeuSpmmbgZLZ7h6s6/rVpp8USvZRKDZx/ArUzHb3eF3XlxdFHEIIIYQQQgghhLNJsiIXuq63dnYMALqu93N2DEIIIYQQQgghioZcDcQ+mQYihBBCCCGEEEIIlyLJCiGEEEIIIYQQQrgUSVYIIYQQQgghhBDCpciaFUIIIYQQQgghhJO4y5IVdsnICiGEEEIIIYQQQrgUSVYIIYQQQgghhBDCpcg0ECGEEEIIIYQQwknk0qX2ycgKIYQQQgghhBBCuBRJVgghhBBCCCGEEMKlyDQQIYQQQgghhBDCSeRqIPbJyAohhBBCCCGEEEK4FElWCCGEEEIIIYQQwqXINBAhhBBCCCGEEMJJ5Gog9snICiGEEEIIIYQQQrgUZRiGs2MQTqCUkhdeCCGEEEII4fIMw7ihhx586FPf5Y/Nxlw+WOyvgUwDEUIIIYQQQgghnESuBmKfJCv+owL7f+zsEArt/PzRjKS6s8MotBmcpPL9s5wdRqGd/XG4xO9EZ38cTpUHZzs7jEI78/2w6z5+6T/OcyP0n+CBM5wdRqGd+2nkdd/+12v8Z74fBly/39/Ozx8NcN3+/zz743AAqg37wcmRFM6p2Q8AUGvkfCdHUjjHZvR3dgjCSWTNCiGEEEIIIYQQQrgUGVkhhBBCCCGEEEI4iVwNxD4ZWSGEEEIIIYQQQgiXIskKIYQQQgghhBBCuBRJVgghhBBCCCGEEMKlyJoVQgghhBBCCCGEk8ilS+2TkRVCCCGEEEIIIYRwKZKsEEIIIYQQQgghhEuRaSBCCCGEEEIIIYSTyDQQ+2RkhRBCCCGEEEIIIVyKJCuEEEIIIYQQQgjhUmQaiBBCCCGEEEII4STuSuaB2CMjK4QQQgghhBBCCOFSJFkhhBBCCCGEEEIIlyLTQIQQQgghhBBCCCeRq4HYJyMrhBBCCCGEEEII4VIkWSGEEEIIIYQQQgiXItNARL68OqwjXVtUJz4xhac//Ys9xy/mKNOkVgU+eKIbXp7u/LXjJC/OXgtAnza1Gau1om5lf26fOI9dx8Iytrm5WgBvjexCWW8P0gzoPUEnMTm12PbL1uAv36JxnxCuhEXwauOeTonB1isPtSGkaVXik1J4Zsbf7D0RkaNM4xoBvP9YJ7w8SrBy12le+nYTAL6lPflsdAhVK5Th9MUYHv9oJdFxSRnbNa1VnoUv38moj1exeMsJAL5/vifN61Rg66ELDH1nhUvG369dbUbd2QSA2IRkJs7ewIFTkQBs/EAjNiGZ1DSDlNQ07nhx4XUTf62gcnw+uktGvdUqluWd+Tv4ctm+fMfbuXFlpg5uhbubYs7qw3y2aE+Wxz1LuPHByI40rhlAVEwioz5Zw5nwGACeuLMxA2+rS2qawZTvNrNmz7k863zv0Q60vqkSV+KSAXh25jr2n4qkzU2BfPlMCKcvmvUu3XaSDxfsyvc+vDy4FSFNqxCfmMKzM9ex92RkjjKNawTw3qMd8PJ0Z+WuM0z5bgtgtvmnT3amavkynA6PYdTHqzP6vL16KweUZuaYLri7uVHCXfH1in/5fuXBLM/11TMhVKtYlm4Tf8v3PqQriv7T9uZAvny2O6cvXgFg6dYTfPDrTsDx/T9dUfSrd4a3p2vzKkRcTihU2xZHjLnVOaTbTQzv1YAalXxo8vgcomISAShXypN3RrSnesWyJCanMnbWeg6euVTofXplSDtCmln95/PV9vtPzfK8/1hn872w8zQvfbMBAN/SJfl8TFeqli/L6fArPPbhn0THJlGutCfvjryN6pV8SExK5bkZazh4JiqjPjelWDqtH+cjYxny9vJCx16cr0f7BkFMHnQLbkoRm5DMczPXcSLsisvG+/MLvSnt5QFAeR8vdh4LZ/gHK+nRoipj721OmgGpqWlM/WELWw+F4QhF8f2thLsb7z4WQuNaFSjhppi35iAfL9jukHizK+7/pdfitkZBTLm/Je5K8dPao3y+ZH+Wxz1LuPHe8LY0ru5PVGwiT36+njMRsQCMur0B93WsTaphMPWH7fy9LxSAYd3qM6hTbZSCOX8f5asVWT+nHu15E5Pva0Gzp37O+H/kCJ0aVOJFrSnuboq5648zY/mhHPvyztBbaFTNj6jYJJ6atZmzEXG0v7kiz9/dCI8SbiSnpDH9lz1sPGj2uefuaki/1tXwKeVJk6ev/X//jUauBmKfjKwQVxXSvDq1gnxpN/p7xs1YxfQRt9ktN31EZ8bNWEW70d9TK8iXkGbVADh4OpJH3lnKpgPnspR3d1N88lR3xs9cRedn53DvlF9JTk0r8v3Jzcav5/NxryFOe35bIU2rUDPQhw7PzWP8l+t4Y1g7u+XeeLg9z89aT4fn5lEz0IcuTasA8ETfpqzfd46Oz81n/b5zPNG3acY2bkoxaeCtrNl9Nktdny/ezZjP17h0/KcuXqH/q4vpPvFXPlywk7ceaZ+lvgGvLaHnpAXXfKBW3PEfC42m56QF9Jy0gN6TfyM+MYVl207mO143pXhtSGseensFIeMXcFfbmtQNLpelzMDb6nIpNomOY39h1rL9TLqvJQB1g8vRt01Nuk5YwOC3V/D6kDa4KXXVOl+fs41eLyyk1wsL2X8qM6mw5eCFjPsLkqjo0rQyNSv50HHsL4z/aiPThrW1W27a0DaM/2oDHcf+Qs1KPnRuUhmAUXc2Zv2+UDqN+4X1+0IZdWfjPOsNuxRPv1eW0OuFhfSduphRfRpTydc743l63VKN2ISUfMdvqyjfv1sOns/oK9m/XDuq/6crin4FMG/tEQa/de0J0aKKMa86tx0OY9D0PzIScume7NuEfaci6TF5IU/PWMfUB1sVep9CmlU1+88zcxn/xVreeKSj3XJvPNyB8bP+psMzc63+UxWAJ+5qxrq9Z+nw7FzW7T3LE32bATD6rubsOxlB9/E/M+bzVbwyJGu/HN67EYfPFj7BAsX/ekwb2oanPv+bXi8s5LeNx3jq7qY5YnKleO99bWnG/8ftR8JYutX8P79uXyg9Jpv3PzdrfY7PtsIqqu9vd7atg6eHGyHPzaHneJ3B3RtSpUJZh8ScJX4n/S8tDDelePXBWxjy/iq6vbCYvq2rUzfYJ0uZ+zrWJjo2idsm/s6XfxxkwgDzvVk32Ic7W1en+4uLGfLeKl4bbCbg6lUux6BOten72nJ6TVlK16aVqVExs52D/ErRoWEQZ8Jjrzn+rPsCUwc14+FP1tPz5T+489aq1AnK+voOaF+D6LhkQl5azuy/DjO+XyMAomISGfHZBm5/9U/GfbONd4bdmrHNX7tD6Td9lUNjFTc+l0hWaJq2WtO0WxxU19OappVyRF1Wfc00TbvdUfU5iqZpSzRN87Vz/1RN08Y68rl63VqTeWv+BWDH4Qv4lC5JRd+sTVzRtxRlvT3Zfug8APPW/EuvVrUAOHw2iqPncn4Buq1pNQ6cjGD/STNLHhWTQFqa4cjQC+TI2i3ERUY77flt9WhZnflrjwCw48hFfEp5UtHmQAqgoq83Zbw92HHEPNMxf+0Rerasbm7fohrz1h4GYN7aw/RsWS1ju2E9G7Bk6wnCL8dnqW/9vlBiE5JdOv7th8MyzpbvOBxGkH9ph8TrSvF3aBTMybArnA2PyfFYbprVLs+JC1c4dTGG5NQ0Fm46Tg+b1zw9pvnrzH1avOUE7RsGWftajYWbjpOUksbpizGcuHCFZrXL56tOR+rRoho/rzsKwD9HrTYvl63Ny3lTxtuTHUfMszQ/rzua0bY9WlTLeM3M16JanvUmp6aRlGImRz093HGzOaFRqmQJRvRqyEe/5T/ZkmVfivD9W5yKol8BbD54gUuxSThCcff9fScjM86q26pbuRzrrTOhR0OjqVq+DOV9vAq1Tz1b1mC+9frvOBJGuVz6T1lvT7YfTu8/h+l1Sw1r++rM+9s8Czrv70MZ99er4se6vWaS+ui5aKpUKEt56z0W5F+ars2rMWfVv4WKOV1xvx4GUMbbHKlQtpQnF6LiXDredKW9StCuQRDLt58CIC4xMzFaqmQJDMMx34WK6vubYRiUKumBu5vCy7MESSlpxMQ75j1t63r6X9qsVgAnwmI4fTGW5NQ0ft98ku7NqmQp0715FX7ecByAJdtO0f7mSub9zarw++aTZl8Kj+VEWAzNagVQJ8iHf46Fk5CUSmqaweaDYfRskVnnS4Na8Ma8fzBw7HfnpjX8ORkWy+nwWJJTDRZtPUO3JsFZynRrEswvG81k29IdZ2l7U0UA9p+OJiw6AYBD5y5TsoQbniXMw82dxyO5eDnBobGKG1+xJSs0TSuuKSdPAw5LVgDNgCJPVmia5l6Q8rqu367r+rWdAsmnQP8ynIvI/HIWGhFDkH+ZLGWC7JQJzFYmu9pBvhgYzJnclz/e1BjVt7ljA7+OBfqX4lxEZqY8NDKOQL+sB7aBfqUJjbQtE0ugv9n1y5fzJuySmYwIuxRPgPWFNNCvFL1vqc53f17bF1JnxW9rYOd6rNp1JuO2YcCPE3qx5LW7eKBL/esu/nR929Titw1HCxavXynOZY/FL+u/Qdt9Sk0zuBKXhF+Zkua2tvsaZW57tTqfH9CCP17vy5QHbs34IgLQsk4Flr/el2/HdqNe5Rz51ILtg3/OfcjR5lZM5X28CYu22jw6ngDrQDGveoP8S/HH633Z8sEAPl+8lwvWazauf3O+WLqP+KTCTUkryv7Tsk5F/ph2N9893yNL+zqy/2fG6Ph+5WjO6Pv2HDgVRe9bzAOkZrXKU7l8mUInU814bT5PI2MJzFZXoH9pQiNtP3Pz6D8+Zv/ZfzKC22+tacZYuwJVbGJ8+aG2vPbj5ms+YVDcr8fzs9bz7XPd2PLhAO5pX5tPf886hcPV4k3Xq2V11u8LJcbmBEGvltVY9WY/vnmuG2NnrS/QfuS6f0X0/W3RpqPEJSaz64uH2fb5EP73+z9ccuAUhHTO+F9a6Fh9vbPGERWXsy/5emf0jdQ0gyvxyRl9KTQyM9F2PiqOQF9vDp2NplW9iviW9sTL050ujYMJtvatW7PKnI+K58Bpxx8KVPLzJtQm8Xf+UjyV/LJ+jwn09SI0Kj7rvpT2zFKmV4vK7D8dnXFiQIjCuGoCQdO0GsAyYB3QBtgFzAZeBioCDwD7gI+BxladU3Vd/03TtKHAHYAXUBoI0TTteWAwkAYs1XV9gvVUAzRN+wzwBR7RdX2t9dzfWdsCPKnr+gZN0zoDU4FwoBGwHXgQGA0EA6s0TQvXdT1zEnjWfeoFTAPcgXBd17tqmtYK+ADwBuKBYcBx4BXAW9O0DsAbwKJc9rUU8DVwE3AAqAE8oev6Nk3TBgGTAAUs1nV9vBVHDPAe0BNYomlaM13X+1mPdQce13X9nlz24QRwi67r4ZqmTQYeAk4DF632cBh7U6hyZHHtlbnKmQF3dzda3RRM7wk68Ykp6FPuZvexi6zbm/MA7r9G2WnQ7O1p93W5yvfMqYPbMO2nraQ56KxNbooq/nTtGgQxsHN9+r2yKOO+fi8v4sKlOAJ8vJgzoRdHQqPZ/O/5AsWdEZsT4gfwcHejR8tqTJ+7Nd+xXkssRh7butlJZafXOX3udsKi4/Es4cb0h9vxeJ/GfLhgF3tPRNDmmfnEJabQpWllZj0dQqdxvzhsH+zN5rzabuZVb2hkHD0mL6SSrzezng5h8ZYTVPQtRfVKPrz8w1aqlM/7C3uuz1lE/WfPiQhaj5lLXGIKIU2r8OWz3ej43HzAsf3/WmKEvPuVoxV338/Np7/v4eXBrVj2Wl/+PR3FvpORpKQV7gu6shNYzvfC1ctk98nCnbzyUDv+eOMe/j0dxd4T4aSmptGteTXCL8ez53g4bW8OKlTMGXEV8+sxvFdDHnr3T3YeDWfk7Q156YFbef7LDS4bb7q72tZkzurDWe5btv0Uy7afonX9Soy9tzn3v/nH1QO5iqL6/ta8TkXS0gyaPTqbcqVLsuDVe/h792lOhV2+hmhzcsb/0kLLRzvaj9XI5XWCI6GX+d/S/fwwNoTYhBT2n44iJc3Ay9OdJ/s0ZPC7RTOlwu7KCTn+Cdl5bWz+rhtUluf7NWLoh+scGdoNTS5dal9+RzvUAQYAjwJbgfuBDkBfzIPw/cBKXdcftqYmbNE07U9r27ZAE13XIzVN6w3cDbTWdT1O0zR/21h0XW9lTbmYAnQDwoDuuq4naJpWF5gDpE8XaQ40BM4B64H2uq5/pGnas0AXXdfD7e2IpmkVgC+ATrquH7eJ4V/rvhRN07oB03Rdv1fTtJcwkwJPWttPy2VfHweidF1vomlaI2CnVT4YeBNoCUQBf2iadreu6wswkzB7dV1/SdM0BRzQNK2CrusXMZMls6/2wmia1hIYaLVHCWAHuSQrNE17FPM1BDrlWe/Qno15oFsDAHYdCSM4IPNLe1BAGc7bZI/BzMRnL3MhKu85dKERMWzcf5bIK+aQsJU7TtC4VoX/bLJiSPebud86I7rrWDjBAZlnD4L8S3HhUtbhraGRsVnO3AX5l84YAhseHU9FX/OMQkVfbyKsM85Napbn0yfNHJ5/WS9CmlYlJdVg+fb8r4/gzPgBbq7qx1vDOzD4reVZzuSk1x9xOYFl207SrFb5Ah2sOTt+gC7NqrDnRAThBRwmGRoZR3D2WLLFe3ZwWfoAACAASURBVD4yjuCA0pyPisPdTVG2lCeXYhLNbW331S9z29zqTB/BkJSShv73EUbe3hAgy1nCVbvO8voQN/zKlMx10a8h3W5iUOd6gNXmubSn7X7m2uaX46lYzhxdUbGcNxFWG9ptm2z1XrgUz6Gzl2hVvxIBPl40qRHAhvf6U8JdEeDjhT6pF9q0ZXb3IWNfiqH/xMRntu/KXWd43T2zfa+1/9tTVP3KkYq77+cmJiGZ577IPBu+4b3+nA7L/1SuId0b8EDITQDsPHbR+jy9kPn82T5PQyOzniEPCsij/1zO7D/Pzshcl2jTR4M4dfEKfdvVpkeL6oQ0q0ZJD3fKenvy0RNdeOrTgh8IFefr4V+2JA2q+bHzqPl17/fNJ/huXHeXjTedb5mSNKtVnhEf2m/fzQcvUL1S2Tz/d+alOL6/9etQj1U7T5GSmkbE5Xi2/htK09oVHZKscPb/0sI6HxWfNQ6/Uhmj9TJijYon2L8056Pizb7k7cGl2CTrsy1zFEagzbZz1x5j7tpjAIy7pynno+KoXqEMVcuXYenLvTOea/GUXtz16nKHTLM4HxVPkM2okEBfby5cSrBTxpvzl7LuS3r5zx9ry7ivt3HKwetpiP+e/E4DOa7r+h5d19MwR1H8peu6AezBHEHQA5igadpOYDXmSIr0iWErdF1PX32tGzBb1/U4AJv7AdJPv2236gTwAL7QNG0PMA9oYFN+i67rZ6yYdtpsczVtgL//z959h0VxrQEc/u0uXYqAKIIo2LvYK/ZeSFFHY2LUNBPTTbxGY0s0pkcTY3I1phuNo8k19hYb9oLYYsMI0hRBQClK2/vHLCtdQBBMvvd58kR2z5z9ZubM7Ow355xRVfVSrhicgJWKopwC5qElQvJT0Lp2AX411XkKOGEq3xbYqarqNVVV04FfuJMpyAB+My1jROtF8oQpCdIR2FiE9fED/qeqarKqqjeAAmdWU1V1saqqbVRVvev8ID9sPkmfSSvoM2kFGw//zfBu2kVUq3rVuJmcSnSuL4vo+GQSU1JpVU8bfze8W0M2Hb5U6GfsPH6ZxjVdsbWywKDX0aGxJ+fD887+/2/x49Yz5smeNh0JZZhfXQBa1XXjZkqauStjluj4FBJT0mhV1w2AYX512WJKOmwNvMxwv3oADPerx5ZAbVxsp9dVOr6m/bf+0CXe/mFfqSQq7lf8Hq6V+Oa13rz69S4uXblzUWRrbWGeYd3W2oKuzTxzzHJf0ePP8lDHOsUeAgLaBZ23uyNebvZYGvT4d/Bha2BYjjJbj4UxrIu2ToPaebP3ryhTrGH4d/DBykKPl5s93u6OBF2MKbTO7HNJ9Gtd0/zUA7dsr/vWroJeR6EXfz9uO2uebG7z0csM7VIHgJZ13LTzTEKubZ6QQtKtNFrW0bb50C51zNt2a2CYeZ8N86ub4/X86nV3tsPGUht952RnRZt6Vfk7KoGf/zxHm1dUOk1cxaOzN3Lpyo27Jirg/rSfvNtXR1zi7VJp//kpi3ZV2u532y+Io50Vlgbtkuqx7vU4eO5KjuTd3fy49S/6TvmdvlN+Z/OREIaZ9n+rulW5kZyaf/u5lUqruto48WF+9dh8NASALUdDGd5VSwIO71rffI7PHuOong05eCaKxJQ0Pvj1MG1eWkaHV5Yz4Ys/2Xs6okSJCri/+yMhKRUHOyt83LVJDP2aehCcz/wKFSXeLIPbebMtKDzHk8+yT5rYtJYLVgZ9iX8434/rt4iYRDo31eZOsLW2oHV9d4Ij7v2cA+V7Lr0Xxy/F4lPNAa8qlbA06BnSvhZbg3JOZL4tKJyhnbShWAPb1GTfWS0huTUogiHta2ltqUolfKo5EPS3Np+bq4M1AB4udvRvXYM/DoZwLiKB1q/9Tpf/rKHLf9YQFZfMoHc2ldp8ECdC4/Cuak8NVzssDToGt63BnydyTrL654lIHu2oDX0b0MrT/MQPB1tLlrzUiY9Xn+LoxbxPbhGiuIrasyL7EZyZ7e9MUx0ZwFBVVXM8T0dRlPZA9pSajoJ77WbVmZEtrtfRbi20QEus3MqnfO5l7qagGGYDO1RVfcQ0/GRnIcvnt64Fdd4prFPPLVVVsw+K/h5Yi7aeK03JjaIo0z79fwaG0qtlLfYvGK09Omrhn+b3tn48gj6TVgDw1je7mP9iL2ysLNgeFMr2Y9qXxYB2tZnzVFdcHW35ecpgTofE8Nh7a0hIus2idUFs/GA4RiP8eSyUPwNL54dzSTy97Avqd++AfRVn3g/bz9qZ89j3nVousWwPCqOnbw32fDacW6npTFwUYH5v89yH6Td1NQBTv9/HZ+O7YmNlYOfxcLab5kD4cu0J/vtyT0Z2r09ETBLPf/Fnvp+T3W/TB1HXw4lKNpYcXjCSNxcHsOtkxF2Xu5/xv/5ISyo7WDPXNCN41iMa3RxtWfJ6L0AbXrR630V2nihZ7OURP4CNlYGuTT1469vid5nMyDQy/acDLJ3UR3vM2O5gzkfE88ajvpy4FMvWY2H8uusC85/3I+CTR4lPvM2LC7U7rOcj4ll3MITtHzxMeqaRaT8e0IYJGcm3ToAvJnTF1cEGnU6bcHDK9/sBGNi2FqN7NSAj08it1Axe/KroT5fZfjycnr6e7PnkUVJSM3jjmzvbYdMcf/pP07bT1B/2a48utTSw40QEO45r+3nhupN8/VI3RnarR0RsIi8s2FlovfU8nZj+WFutOzewaONpzt7DoyZzrEsZtZ9B7bwZ3bsRGRmZ3ErLYMKX2g/K0m7/WcqkXQFfTuhKh0buuNjbcOjz4Xz6exArdl0oLJT7G2MhbX9c30a8MKgpbk62bJ37ENuPh/Ofb/dR18OJ+eP9yMg0ciEinkn3MOfAn8fC6Olbk73zR2qP21200/zelvcfpe8U7d7OlO/2mB5dasGOoDC2B2k/iBeuCeK/r/bmse4NiYhNZPx8raNrPc/KfP5CDzIyjZyPiOPNxaXz9Kfs7vf+mPztPha/0oNMo5GEpFTe/KZ458/7HS+Afwcfvso1t8aAtrUY2qUO6RlGbqWmM2Fh6eybsrp++37zSeZP6MXOzx5Dp9Px644znLlc+j9M7/e59F5kZBqZsfQIP03sgUGvQ93zNxciE5j4cDNOhFxnW1AEK3ZfZN6zndj1/hDik1J5aZHWXi9EJrD+8GW2zRlEeqaR6UvvDNf974t+ONtbk5aRyYylR7iRXDoTod9tXd5ZEcQPr3RBr9exal8IF6Ju8tqQxpwMjePPE1Goe0P4dFxbtr/bj/jkVF5doj1G/MnudajlZs9LAxvx0sBGAIz9Yg+xN28z+dGmDGnrha2VgT3vD0DdG8IX686U+fo8KOTRpfnT3W1cmumH+zpVVZua/v7B9PeqrPfQ7uY7Ai+rqmpUFKWlqqrHTHNWZB9C0R+YAfTOGgZiGh6yE3jTNL9DFeCIqqreiqLMA8JVVf1UUZRxwHeqqupMc1a8qarqYFO9X5qW+cHUC8M/q+dEPuvjhjZUwjwMxBTD/4Clqqr+pijKLGCsKYahpvrGmJafW8C6TgJqq6r6gqIojdHm9ugIRAAHuDMMZDOwwDTPRaKqqva54lsLtEIb/pLzAc05y4WgDYmpiTZXRnvuDANZpKrqJwUtC1B9+Jfl99iNe3Rl1cuMp1Z5h1FiiwjFc9SS8g6jxCKWPSPxl6OIZc9Q44m7jhCrsMKXjnvg45f2U37+Ce3HY+Si8g6jxCJ/Hf/Ab/8HNf7wpeMAcB+2oJwjKZkrq14GeGDPnxHLngGg5rhfyjmSkrn8/eMA1B5/j3NzlJO/Fw3DaDT+o3/Nr6rWpML/Nht29fR93wel9TSQ2WhDNk6YhlHMzq+Qqqqb0BIbR0zDKO72iM2vgDGKohwA6pOzl0ZBFgMbFUXJN01qmg/iOeB3RVGOAytMb30EvK8oyl60iTez7AAaK4oSpCjKCApe168AN0VRTgCT0YaBJKiqGgVMMdVzHAhUVfWPQuL/BQgrLFGRa30CTesQhDakJKDwJYQQQgghhBBCiIrtrkMnVFUNQXviRtbfYwt4b3w+y/6Adtc/+2sfAB/keq17tn/HYJp/QlXVC0DzbEWnmF7fSbZhGlk9N0z/XoD2tI7C1mkjueaDUFV1P1pCJMt00+vX0eadyC7PuqIN3XjCNBloHeBPINRUxzJgWT5x5DfVfBe0CUALpaqqd7Z/vwe8d7dlhBBCCCGEEEJULPI0kPwVdZ4HcXd2aI9MtUQbAv2CqqqpxalAUZSjaL1H3iiD+IQQQgghhBBCiAfCPzpZoSjKQcA618ujVVU9mV/5e6Gq6k3uPFa1pHW0zv3a/VwHIYQQQgghhBCiIvhHJytUVW1f3jHcq3/COgghhBBCCCGEyJ88DSR/pTXBphBCCCGEEEIIIUSpkGSFEEIIIYQQQgghKpR/9DAQIYQQQgghhBCiItPLMJB8Sc8KIYQQQgghhBBCVCiSrBBCCCGEEEIIIUSFIskKIYQQQgghhBBCVCgyZ4UQQgghhBBCCFFOdAaZsyI/0rNCCCGEEEIIIYQQFYokK4QQQgghhBBCCFGhyDAQIYQQQgghhBCinOhlGEi+pGeFEEIIIYQQQgghKhRJVgghhBBCCCGEEKJCkWEgQgghhBBCCCFEOdEZpA9BfmSrCCGEEEIIIYQQokLRGY3G8o5BlAOdTic7XgghhBBCCFHhGY3Gf/QMlJvqtKzwv836Xzx23/eBDAMRQgghhBBCCCHKiU6eBpIvSVb8S7WfvbW8Qyixg9P74DlqSXmHUWIRy55hPLXKO4wSW0QoXmN+Ku8wSizsxycf+PhrPPF9eYdRYuFLxz3w8dcc90t5h1Fil79//IHf/hJ/+ZH4y0/40nEAuA9bUM6RlMyVVS8DD3783s+uLOdISibkm+HAg7/9xb+PzFkhhBBCCCGEEEKICkV6VgghhBBCCCGEEOVEL8NA8iU9K4QQQgghhBBCCFGhSLJCCCGEEEIIIYQQFYoMAxFCCCGEEEIIIcqJTi99CPIjW0UIIYQQQgghhBAViiQrhBBCCCGEEEIIUaFIskIIIYQQQgghhBAVisxZIYQQQgghhBBClBN5dGn+pGeFEEIIIYQQQgghKhRJVgghhBBCCCGEEKJCkWEgQgghhBBCCCFEOdHJMJB8Sc8KIYQQQgghhBBCVCiSrBBCCCGEEEIIIUSFIsNAhBBCCCGEEEKIcqIzSB+C/MhWEUIIIYQQQgghRIUiyQohhBBCCCGEEEJUKDIMRNxVh9quvN6vPnqdjjVBEfy8LzTH+5YGHTP9m9CguiM3UtKY9vtJohJuYdDrmDq4EQ3cHbHQ69hwIoqf9oVQ08WOOY82My/v6WzL4l0XWXEorFTjfvfJDvRs4UVKajqvL9rNqZDYPGWaebsy7/mu2FhasP14GDN+OgBA5UpWfPVyT7zc7Am7lsgLX2wnITnVvFyL2lVY884QJizYwfpDIQAs/U8/WtZ14/D5q4z9ZGuprktRjP72I5oN7snN6FhmN+t33z8/u27NPJg1qg0GvY5fdwfz1frTOd63stAz79nONPN2IS4xlRe/3k14TBIALw5qyoiudcjINDLzl8PsPhVlXk6v07Fu1kCuxiUzbv4OAD59phPtG1TjZoq2f95Yso+/LsdVuPj3fvIISSlpZBiNZGQYGfzOBnN9Y3s3YEyvBmRkGtl+PIK5amCJ4n5ndDt6tqhByu10Ji7ew6nQ63nKNPN25bPnumBjZWD78XBm/nwI0Nr8wpe641XFnrCYRCYs2Glu8wXVO2VEa3r51gDg89XHWXswJMdnvTu6PUrXujR89pe7xm5taWDV2/2xsjRg0OvYcDiUz34PylHGw7US857rgqOdFQa9jvfVo+w4HlHk7WNloWf+eD+a+bgSl3ibCV/uIjwmkRpV7Nnx4cNcjLoBQGDwNab+sL/I9ebWrWl1Zo5qjUGn49eAi3y94a88cXz2TEea1XIhLuk2L329l/BYrf1MGNiYEX51yDAamfXLUXafjqK2uwNfPt/FvHxNN3s+W32C77aeo5FXZeaOboedjQXhMUm8ungvibfSSxx7lrJoS3WqO/Hps51p6u3Kx6sCWbThznG177NhJN1KIyPTSEZGJoNmrityrN2beTJrdDsMeh3Ld17gq3Unc7xf0H4HeHFIM0Z2q6cdrz8fZNfJyELr/G3aACrZWAJQxdGGoL9jeGb+dgA6NHRn1hPtsDDoiEu8zfD3NhV5HXIri+3/cKfaTBjUFICk2+lM/WE/Zy7HUd3Fjvnj/XBzsiXTaGTZjvN8t+VMiWMvq/gLaz/P9G/MyG71ADgbFscb3+zldlpGseMui7b0yTOd6dWyBrE3btF7yh/mul5/xJdR3esRe/M2AB+uLN75rKhmj/OjV6tapNxO57WFf3Ly0rU8ZZrXdmP+i72xsTLwZ2Ao078PAGBwhzq8qbSjnqcLA6es5Pjf0eZlGtV05aPxPXCwtSTTCAPeUku0ze937DXcHNg9/3EuRmrXCYHnrzL5m52lGjdA1ybVmDnCF71ex4o9l/jvpnM53rey0PPpuLY0reVMfFIqLy0+QERssnb9+XwHmtdy4bf9Icxcfud7cPkb3ajqZMMt03Z+cn6Auf2UhbLY/pYWej56rgct6lQlM9PI9O8D2P9X6bf7B5FengaSL+lZIQql18GbAxrw+vIgHvvvfvo2cce7SqUcZfx9PblxK53hX+1j+cHLvNizLgC9GlXFyqDnicUHGLPkII+08qS6kw2Xryfz5JKDPLnkIGO/PcittAx2nct7ArwXPVvUwMfdkS5vrGTyt3t4f1ynfMu9/1Rn/rNkL13eWImPuyM9Wmg/vF70b8He05H4vbGKvacjedG/RbZtomPqyLbsOpHz5Pr1+hO8+vWuUl2P4tj/wyoW9B9Tbp+fRa/TMWd0O8Z8tp1eU9fi396beh5OOcqM6FqXhORUuk7+gyVbzjBleCsA6nk4MaR9LXq/vZYnP93Oe0+2R6+7c/J+qm9DgiMT8nzm3BVHGTBjPQNmrL/nREVZxj/iw60MmLE+R6KiY8Nq9G3pRb/p6+j99loWbcz5w7aoerTwxKeaI35v/s7k7/Yzd1zHfMvNHduByd/tw+/N3/Gp5kj35p4ATBjSjL2no+g66Xf2no5iwpBmhdbbs0UNmnq70u/tNQyZtZ7nBzbF3vQjDqC5jyuOdlZFjv92WgYj3t9Mv7fX0H/aGro396RlHbccZV55qDnrDoUwYPpaXly4i/fG5L+OBRnZrR7xSan4vfk7Szb9xdQRrc3vhUbfpP807bPvJVGh1+mY/UQbxszbQe9p6/FvX4t6Ho45yozwq0NCUirdpqzl2y3neGu4LwD1PBwZ0r4WfaavZ8xnO5gzug16nY6/r9xk4KyNDJy1kcHvbCIlNZ3NgVpy98Ox7flgVRD9Zmxgc2AY4wc0LnHsWcqqLcUn3WbmzwdZvOFUvvUpczfRf9qaYiUq9Dodc8a058mPt9Jz8moe6uiT53gtaL/X83DCv4MPvd5azeiPt/LemA7odbpC6xw6Z6O5nRwNjmbjYS1572hnxXtjO/DUvD/pPeUPnl+ws8jrkFtZbf+wazcZ/t4m+r69hs9XH+fDp7TvxYwMI7OXHabnW6t56J31jOndMM82rAjxF9R+3J3tGNe3EYNnrKP3lD/Q63X4d/Apdtxl0ZYAVgYEM/qj/G9gLNn8l7k9lUWiomfLWtSuXplOLy9l0qIdfPBst3zLffBsdyYt2kGnl5dSu3plevrWBOBc2HWe/mQjB85E5ihv0Ov48pU+TF68g+4TlzN05v9Iy8h8IGIHCL2SQJ9JK+gzaUWZJCr0Onh3VEvGfrGHvjM349/Wi7rVHXKUUTp7k5CcSo9pm/h223neMt3Eu52WwWd/nGbuqhP51v3at4cYNHsbg2ZvK9NERVlt/8d7NdHqf2M5I2b/wawxndHJb3RRCElWZKMoyixFUd4so7p9FUUZWEp1tVEU5YsC3gtRFKVKaXwOQGMPJ8KvpxAZn0J6ppGtp6/StX7OHxB+9d3YcEK7e7zjTDRtfFwAMAK2lgYMOh3WlgbSMjJJup3zjl8bHxci4lK4knCrtEIGoG/rWqwKCAa0u6SOdlZUrWybo0zVyrbY21oSGKxle1cFBNOvdS1t+VY1WRlwAYCVARfo17qmeblx/Rqz4XAIMTdSctS393QUSbfSSnU9iiM44BDJ1/P+kL/ffGu7EnL1JpevJZKWkcnag6H0bemVo0zfll6s2nMRgA2HQ+nc2N38+tqDoaSmZxIWk0jI1Zv41nYFtAvSXi08+XV38AMZf0FG96zPV+tPkZquXejF3izZsdC3VU1+M8V07KKpzTvlavNOttjbWhEYrCUHf9tz0dy2+7aqaT5mtGOhZqH11vN04uDZK2RkGkm5nc5fYdfNPzb0Oh1vj2zD3F+PFGsdkk3nBwuDHguDHiPGHO8bjZgTIg52VlyNT87xeeveGcyW9/x5vEf9ArfRqj3aOq4/FELnJtWLFV9R+NZ2JSQ6kbBrSeb208fU+yRLn5Y1+G3fJQA2HLlM50bVtNd9a2RrP0mERCfmaT+dG1fjcnQiEbHautd2d+Tgee0cFnD6CgNa52yrJVFWbSn2xi2OX4olLSPnfr0XvnWq5Dhe1xy4RN9s52tzPPns976ta7LmwCVte18zHa91qhSpzko2FnRqXJ3NRy8D8HBHHzYdCSXS1EMm9kbJv9PKavsfvXDN3FvqWPA1qjvbARCdkGLu+ZB0K53gyATcXewqXPyFtR8LvR4bK61Xlq2VBVfjkosdd1m0JYCD564Sn5RKeejf1oeVu84CEHjhKo6VrKlaOee+rVrZDgdbK46evwLAyl1n6d+uNgAXIuK4GBmfp95uLWpyJjSWv0K1HqtxibfIzCy947osY78fWvi4EBqdSFhMEmkZRtYeDqNPC48cZfr4evDbfi3ZufFoBJ0aVQUgJTWDI8Gxpd5LpbjKavvXr+HMnpNasj32RgoJSbdpUadqWa6KeMBJsuL+8QWKlaxQFCXfYTqqqh5RVfWVUonqLtwcrInOdtEVffMWbg7WecpcNZXJMBpJvJ2Ok60l289Ek5KWwbrX/Pjj5S78cuAyN3J1T+7T2J0tp6+UetzuLnbmi0aAqOvJuDvn7BHi7lyJqOvZyySZL9CqONkSHa8lI6LjU3A1XWi5O9sxoE0tft52ttRj/qdwd7YjMvt2jUuimrNtPmW0i8mMTCM3U9JwtremmrNtrmWTcTddUM8a1Ya5KwLJNOa9IJo01JfNswcz47E2WFnc22mtrOI3GmHpm71YP2sgo0zdlQF83B1pV78qf0wfgPpWX5r7FJ7cKHLc2dqzuYyLXd42b4qviqMt0QmmNp+QgqujTaH1nrkcR/fmnthYGXC2t6Zjo+p4uGrH2Ng+Ddl6LMxcX1HpdTo2zfEnaOFIAk5FEnQxJsf7834P4tHOdTj0+XB+fLM3M346CMDI7vW4mZLK4JnrGDxzHaO618fLzT7vNsp2XsjINHIzORVne+185uVmz8bZQ1j5dn/a1S/5hZN7Zduc2zhbG8heJmubZm8/7s52RF2/8yPrSlwy7rmSrP7tarHm4J2heOcj4unjqyWJBrWtSfV7+JFpjq+M2lJhjBj5ZXJf1r87mFEFJJuKHGvu7V3Afnd3zvU9EactW5Q6+7euxd7TUSSaEtQ+7k44VbJCndqf9e8OZmjnOkVehyKtUylv/5Hd67HjRN47+TWq2NOklgvHgmPyvFeR4s/uSlwyizac4sD84RxdMIKbKansPpX3bnqJ4r7HtnQ3Y3o3Yst7/nzyTGecitETrajcXeyJjE28E1dsItVdcp4bq+dTxt0l7/kzuzrVK2PEyPK3/dnyocIE/5alGzhlFztAzaqObPloBL+/8wjtG5Z+0lr7Hrjz/XclPgX3XNcR1bKVufM9cPc28NHYNqyf3puXBzUq3aBzKavt/1doLP3a1sag1+FV1YHmtavi6epQ6DL/Fjq9rsL/Vx7+8XNWKIpSCVCBGoABmA18CLRRVTVGUZQ2wCeqqnY3LdJCUZTtgBfwkaqq3yiKUh1YATiibbMXVFUNUBSlL/AOYA1cBMapqpqoKEpb4HOgEnAb6AO8C9gqitIFeB/YCnwH1AaSgedUVT2hKMoswAPwBmKAUfmsU3fgTVVVByuK4gosB9yAQ0CptqSidM3Kr4wRaOLhSKbRyODPA3C0seC/Y9pw+NJ1Ik1JAAu9Dr/6Vfh6R+nfKdflsxmMuX7k5hv3XW4MzBrdgbm/Hs73B7PQFNQe7lrGaESXzxtGoFcLT2Ju3OJk6HU6NKyW4/0PVx4jOiEFKws9H4ztwAsDm/D5mpN56inP+AGGvreJq/EpuDrY8MukXgRHJXDofDQWej1Olax5aPZGWvi48tWErnSZ9L/SiTtX4PkdzndryQXVu/tUJC1qV2H1jEHE3rxFYHA06RmZVKtsy6B23ihziz9eP9NopP+0NTjaWfHNqz1oUKMy58Lv3Jl5qKMPKwOCWbzxNK3qujH/eT96T1lN16YeNPJyZmBbbwAc7CzxqeZI2LXEAj4p27oA0fHJtH9tFfGJt2nm7cqS13rS663V5h+ixVJA28hRpMD2k398WSwNenr7evLhb8fNr0367iCzRrXmVf9mbA0KJy393rtil1VbKsyj727Qjg9HG5ZN7svFyAQOnrt61+VKch4HLdaCltXnk+/MXedDHX1YvvOC+W8Lg45m3lUY+cFmbCwN/DFzEIEXr3Hpyo27B5NLWW//jo3cGdG1Ho/O2ZjjdTtrCxa90p1ZvxwqWdvPiu0+tx8nOyv6tq5Jp4mruJGcyn9f7sEjnWrzv31/F6uesmhLhfn5z7N8vvo4RoxMGtqS6aPa8uaSvUWKtajyP6fcfWfkPmflZjDoadfQgwFvqaTcTked+TAn/r7G36FrKAAAIABJREFUnlPh9xBtrrDKKPbouCTavPAjcYm3aF7bje8mDaT7xGUkppRez9giHQMlaDOvfXuQq/G3qGRtwdcvdOTRDjX5/cDlkgdaiLLa/su3/0U9T2c2fagQfu0mR85FkV7KQ4jEP8s/PlkB9AciVVUdBKAoihNasqIgzYEOaImGY4qirAceAzarqvqeoigGwM401GIa0FtV1SRFUSYDExVF+QAtsTFCVdXDiqI4oiUjZqAlSF4yxbEAOKaq6sOKovQEfkLrfQHQGuiiqmpRbkvOBPaoqvquoiiDgOcKKqgoynPm95sXWCyH6Bu3qZrtrkZVBxuu5RojF33jNtUctdcNOh321hbcSEmjb1N39l+MJSPTSFxyGifCEmhU3cGcrOhYtwrnrtzkeil1jxzTpxGjejQA4PjfMea7vADVXezMXcazRF1PorpL9jKVzF1HYxJSqFpZ611RtbItsaa7PM19qrDwpR4AuDjY0LOFF+kZRjYfzTnp6L9Z1PVkPLJvV+dKRMel5FPGjitxyRj0OhxsLYlPSuVKnmXtuBqXTJ+WXvRpWYMeLTyxtjTgYGPJ/Oc689riveY7cKnpmah7LjK+/72N2S+L+AGumtp97M1bbA4Mw7d2FQ6djyYqLomNpq7kxy/FYjQacXGw5noRxqKO6d2Qx7prd6GP/x2T87OztefscRfY5m+kUNVJu6NZ1cnW3I09z/bItsyCNSdYsEYbV7vgha5cunqDJrVc8a7mSMAnQwGwtbIg4JNH8Xvz97uuT5YbyansP3uF7s09cyQrRnSrx+iPtbHfgcHXsLY04OJgg04HM7JNaJflP8Na0tNXGxbRf9oabf+4Vrqz3+ysiE/UtnOq6f8nQ2IJjb5J7eqOnLiUd1Leu7kSl5JzGzvbmfd9lqi4FDxcKnElLiVH+9H2z527se65lu3erDqnQuOIydbb7eKVG4z+TJts1qeaAz1NQ3GK6360pcKYj48bt9h05DK+daoUKVmRb/vMda4vaL9HmV43L+t8Z9nC6qxsb41v7So8+/mOHHFcvxlByu10Um6nc/DcFRrXdC5ysuJ+bf+GXs58/HQnRn+yzdz2QUu2LH6lB6v3/c2mI8X/8VOe7adL0+qEXbtpPmduPBxKm3pVi52sKKu2VJDsx/GynRf44Y1exYq3IGP7NePx3tr34PHgaDxc79zpru5qz5VsvUdAuxueu8zVuJxlcouKTWT/XxFcNw1b3B4YQrPabvecrLgfsaemZ5KaqMV94u9rhF69QZ3qzjkmD71XUXEpVHe505PCvbJtnu+BK6YyV+Jzfg8U5mq8FnfS7XT+OHiZFj4upZqsuB/bPyPTyMwf95j/XjNnKJeulM9wHfFg+DcMAzkJ9FYU5UNFUfxUVb3boP4/VFVNUVU1BtgBtAMOA+NMvR6aqap6Ey2h0RjYqyhKEDAGqAU0AKJUVT0MoKrqDVVV85uavQvws6nMdsDVlEgBWFPERAVAV2CpqZ71QIGzC6qqulhV1TaqqrYpYt2cibyBl4st1SvbYKHX0adJNQLO55wMM+D8NQY217rR9WhUlSMhWghXE27Rxlubv8LGUk9TT0dCY+98efdtUq1Uh4D8uPUM/aaupt/U1Ww6EsowP22iz1Z13biZkmYe1pElOj6FxJQ0WtXV5uAY5leXLaakw9bAywz307rqD/erx5ZA7cug0+sqHV/T/lt/6BJv/7BPEhW5HL8Ui081B7yq2GNp0DOkfS22Hsv5pJetQWEM66J1kx7Ythb7zmjtYOuxMIa0r4WVhR6vKvb4VHMg6O9YPlx1jPYTf6fzm//jpa8D2HfmCq8t1u5AZR8L3a+VF+ci7u1Lryzit7WyoJKNlhu2tbLAr0l1c5xbAsPo1Eib88KnmgOWBn2REhUAP247a56cbfPRyww1xdSyjhs3k1PzDMOITkgh6VaaeeLKoV3qmNv21sAw8zEzzK9ujtfzq1ev01HZNISioZczjWo6s/tkJNuPh9P65RV0mriKThNXkZKaXqREhYuDtXlCThtLA35NPPJMphoZm0SXJtq437oeTthYGoi9cYtdJyMZ3ashFqaZtH3cHbG1tuCjVcfM2we0/TOsi7aOg9p5s/evKPNnZ02GV9NN22+Xo28WYQ/kdaf9VLrTfoJydrffFhTO0E7aBIAD29Rk31ntR/nWoIhs7aeSuf1k8W/vzZpDOc83rqZheTodvDykKb9ku9tfHPejLRXE1jrb8WFtQddmHpwLK9pxfPzvGLzdHfFy045X/w4+bA3MdbwWsN+3Bobh38FH295u9ni7OxJ0MeaudQ5u5822oPAcY8q3BF6mXYOqGPQ6bKwMtKzjlu9kwAW5H9vfw7US37zag1cXBeRJonz8TGcuRCbwzaaSTfBbnu0nIjaJlnXcsLEyANC5SXUulGCugrJoS4XJ/t3Vv03NHInZe/HD5pPmySM3Hv6b4d0aAtCqXjVtX+RKokTHJ5OYkkqrelqvxeHdGrLp8KVCP2Pn8cs0rumKrZUFBr2ODo09OR+e94kvFTF2V0cb9Kbu7DWrOuJT3YnQ6NKd7+tESBzeVe2p4WqHpUHHkLZebDselaPMtuNRDO2ozZM2oLUn+88Wniwx6HXmYSIWBh29mlfnXETxe24V5n5sf1srC2yttfN91+ZeZGRkcj783iZGF/9s//ieFaqqnlcUpTXafBHvK4qyBUjnTqIm92DI3P2XjKqq7lYUpSswCPhZUZSP0ZICW1VVfSx7YUVRmudTR34K6wVZeFqy4OVKXYbRyCebzvH5Yy3R63WsC4rkUkwSz3arzdnIGwRciGFtUCQzH2rCygmduJGSxvT/aTN1rzoSzrQhjVk2vgM6YN3xKIKjtW7Z1hZ62vm48MGGe3s8WkG2B4XR07cGez4bzq3UdCYuCjC/t3nuw/SbuhqAqd/v47PxXbGxMrDzeDjbj2t3Bb5ce4L/vtyTkd3rExGTxPNf/HnXz/xt+iDqejhRycaSwwtG8ubiAHadvH+PY3p62RfU794B+yrOvB+2n7Uz57HvO/W+fX6WjEwj05ce4uc3e2HQ61gREMz5yAQmPtKCk5di2RoUzordwcx/rgu7P3xIe2TX19r+OR+ZwLrDofw515/0jEym/XzorkNuPh/fBVcHa3Q6HacvX2fqjwcrXPxuTjYsflmbSdvCoGf1gUvmXgArdl/k46c7snXOEFLTM5i4ZF+J4t5+PJyevp7s+eRRUlIzeOObO3cuNs3xN/9gn/rDfu1xgZYGdpyIMM9Av3DdSb5+qRsju9UjIjaRF0xPMyioXksLPb9NGwBAYkoar3wdQMY9TLBWtbId857rgkGvQ6/XsfZgCH8GhfPGo76cuBTL1mNhzF52mA+f7sQz/RtjNMLExVosy3eex6uKPRtn+6PTaXfnsx4nmd2vuy4w/3k/Aj55lPjE27y4UHt6T/sG7rwx1Fd7bGamkSk/7C/xhHgZmUZmLD3CTxN7YNDrUPf8zYXIBCY+3IwTIdfZFhTBit0XmfdsJ3a9P0RrP4u09bgQmcD6w5fZNmcQ6ZlGpi+9M+TMxsqAXxN3pv50KMfn+bf35smeWmJ1U2AY6p7i3U3OT1m1JTcnW9a/Oxh7W0syM+Hpfo3pOXk1Lg7WfPNaT0C7IP9j/yV2FvHcmZFpZPpPB1g6qY92vO4O5nxEfI52U9B+Px8Rz7qDIWz/4GHSM41M+/GAtr2N5FtnFv8OPny1NudQs+DIBHaeiGDL3IcwGo0s33mhxD8+y2r7v/ZwCyrbW5ufopP1iNi29asyrEtdzly+zqY5/sC9PUbzfrefoIsxbDgcysbZ/mRkZnIq5DrLdpwvdtxl0paALyd0pUMjd1zsbTj0+XA+/T2IFbsuMHVkG5rUcsFoNBIek8hb35X8KUQF+TMwlF4ta7F/wWjtMe4L71zLbP14BH0mrQDgrW92Mf/FXthYWbA9KJTtx7Sk6IB2tZnzVFdcHW35ecpgTofE8Nh7a0hIus2idUFs/GA4RiP8eSyUPwNL98ZNWcXeoZEnk0a0Iz3DSGZmJpMX78zRy6g0ZGQambk8iJ9e80Ov17FybwgXom7wun9jTobGse14FCv2XGLe0+3YMac/CUmpvPzNnWuXgLkDsLe1xNKgp4+vB0/ODyAiNpkfX/XD0qB9R+49E82vAfd+vi9IWW1/Vydblk/zx5hpJOp6Ei8v2FZm6/Cg0Rv+DX0Iik93t7FFDzpFUTyA66qq3lIU5WFgLGAPfKqq6kZFUeYBLVVV7W7qOfEw2YaBmP5tCUSoqpquKMpraPNJvAccBXqqqhqsKIod2rwYIcBZ7gwDcQBSgIcAf1VVx5ji+gK4pqrqbNMcFPNUVW1piiFRVdVPClmn7tyZs+ILIFpV1TmKogwANgBupp4hBeowZ9sDu+MPTu+D56gl5R1GiUUse4bx1CrvMEpsEaF4jfmpvMMosbAfn3zg46/xxPflHUaJhS8d98DHX3PcL+UdRold/v7xB377S/zlR+IvP+FLxwHgPmxBOUdSMldWvQw8+PF7P7uynCMpmZBvhgMP9vY3Go3/6Iec7u3iV+F/m3XeE3Df98G/IYXTDDhkGqrxNjAHbVLMzxVFCQByPxvoELAeOADMVlU1EugOBCmKcgwYCnyuquo1tMTHckVRTpjKN1RVNRUYASxQFOU42kSaNmhDShorihKkKMoIYBbQxrTsB2jDSEriHaCroiiBQF+gbGbaEUIIIYQQQggh7pN/wzCQzcDmfN7K82w0VVVnFVDHj8CP+by+HWibz+uH0Xpk5Ja77ENFjSFXmZ3ATtO/Y9GSFFlev9vyQgghhBBCCCEqBp3hH91xpMT+DT0rhBBCCCGEEEII8QD5x/eseJApitKPvI9ZvaSq6iPlEY8QQgghhBBCCHE/SLKiAitkCIsQQgghhBBCiH8AGQaSPxkGIoQQQgghhBBCiApFkhVCCCGEEEIIIYSoUGQYiBBCCCGEEEIIUU70BulDkB/ZKkIIIYQQQgghhKhQJFkhhBBCCCGEEEKICkWGgQghhBBCCCGEEOVEngaSP+lZIYQQQgghhBBCiApFkhVCCCGEEEIIIYSoUGQYiBBCCCGEEEIIUU70ehkGkh/pWSGEEEIIIYQQQogKRZIVQgghhBBCCCGEqFAkWSGEEEIIIYQQQogKReasEEIIIYQQQgghyonOIH0I8iNbRQghhBBCCCGEEBWKzmg0lncMohzodDrZ8UIIIYQQQogKz2g0/qMfl3F0SJ8K/9us9dqt930fyDAQIYQQQgghhBCinOgN/+hcTIlJsuJfyqHbf8o7hBK7uesjPEctKe8wSixi2TN4jfmpvMMosbAfn2Q8tco7jBJbROgDH3+NJ74v7zBKLHzpuAc+/gf9+H3Qt/+DHn/Ncb+Udxgldvn7xx/47f+gxh++dBwA3s+uLOdISibkm+EAeIxcVM6RlEzkr+MBHvj286BeP0cse6a8QxDlRJIVQgghhBBCCCGEKDFFUfoDnwMGYImqqh/ker8m8CNQ2VTmLVVVNxRWp0ywKYQQQgghhBBClBOdQVfh/yuMoigGYCEwAGgMPKYoSuNcxaYBqqqqLYGRwFd32y6SrBBCCCGEEEIIIURJtQOCVVX9W1XVVOBX4KFcZYyAo+nfTkDk3SqVYSBCCCGEEEIIIYQokKIozwHPZXtpsaqqi03/9gTCsr0XDrTPVcUsYIuiKC8DlYDed/tMSVYIIYQQQgghhBDlRGeo+AMeTImJxQW8nd84kdyPY30M+EFV1U8VRekI/KwoSlNVVTML+syKv1WEEEIIIYQQQghRUYUDXtn+rkHeYR5PAyqAqqr7ARugSmGVSs8KIYQQQgghhBBClNRhoJ6iKD5ABNoEmqNylbkM9AJ+UBSlEVqy4lphlUrPCiGEEEIIIYQQopzoDboK/19hVFVNB14CNgNntJfU04qivKsoir+p2BvAs4qiHAeWA2NVVc09VCQH6VkhhBBCCCGEEEKIElNVdQOwIddrM7L9+y+gc3HqlJ4VQgghhBBCCCGEqFAkWSGEEEIIIYQQQogKRYaBCCGEEEIIIYQQ5USnL3xOiH8r6VkhhBBCCCGEEEKICkWSFUIIIYQQQgghhKhQZBiIEEIIIYQQQghRTvQG6UOQH9kqQgghhBBCCCGEqFAkWSGEEEIIIYQQQogKRYaBiCL56GV/+nZoQPKtNF74QOX4hcg8ZXzre/L1W8OxtbZky4Fz/GfBGgCmjO3NmEHtiElIAuDdbzax5eA5LAx6vpw0jBb1PbAwGFi++SifLdtZajG/+2QHerbwIiU1ndcX7eZUSGyeMs28XZn3fFdsLC3YfjyMGT8dAKByJSu+erknXm72hF1L5IUvtpOQnMojneowYUhzAJJupTHl+32cuXwdgP3zFZJupZGRaSQ9I5NB09eUOPZuzTyYNaoNBr2OX3cH89X60znet7LQM+/ZzjTzdiEuMZUXv95NeIy2fV8c1JQRXeuQkWlk5i+H2X0qyrycXqdj3ayBXI1LZtz8HQB8+kwn2jeoxs2UVADeWLKPvy7HlTj2khr97Uc0G9yTm9GxzG7W775//r2qCPG/M7odPVvUIOV2OhMX7+FU6PU8ZZp5u/LZc12wsTKw/Xg4M38+BGhtfuFL3fGqYk9YTCITFuwkITm1wHo9XSux+NUeGPR6LAw6fth6lqXbzwHw86Q+VK1si0Gv49C5aKb9eIBMo7FCxd+4pgtzx3bA3taSzEwjC9acYO3BEAA6NXZn2mNtsbLQc+JSLJOW7CUj8+7xZynt49faUs/KKf2wstBjYdCz4XAon60+AUDnRu5MHdEKvV5H8q10Ji7ZR2j0zSLHmp20n6LHn8XexpIdHz7MpqOXmf7TQQAe6uDDS/7NMRqNXI1P4ZWvdxOXeLvI+6Fb0+rMHNUag07HrwEX+XrDXznet7LQ89kzHWlWy4W4pNu89PVewmO19jNhYGNG+NUhw2hk1i9H2X1aO/8/3acBI7vWwWiEsxHxTPr2ALfTM/n82U4083EhPT2T45dimfLTIdIzit7Wszzox+79bjserpX4+OlOVHephBEY88k2wmMSzZ/17uj2KF3r0vDZX4q+E3Lp2qQaM0f4otfrWLHnEv/ddC7H+1YWej4d15amtZyJT0rlpcUHiIhN1q5/nu9A81ou/LY/hJnLg8zLWBp0vPNYSzo0cCPTaOST1afZFBhR4hjz8+6YTvT0NV27fb0z/2s3nyrMe767ti+Cwpjx4z4AKley5utXe+FVxYGwmJs8//k2EpJScapkxafju1GrmiO3UzN4Y9EuzoVr1zlP92/KqJ4N0elg2fazLNl4qtgx3+/2M3Vka3q2qIFepyPgdKS5rns990DZXDt3bOTOtxP7EHZN+27aeDiE+f+70670Oh0b5jzElbgkxn6ytVjx/pPoDPI0kPxIzwpxV33bN6BOjSr4Pv4xr376O/NefyTfcvNef4RXP/kd38c/pk6NKvRp18D83sJVe+jyzOd0eeZzthzUvjAf6d4caysLOj41n67PfcE4//bUdHculZh7tqiBj7sjXd5YyeRv9/D+uE75lnv/qc78Z8leuryxEh93R3q0qAHAi/4t2Hs6Er83VrH3dCQv+rcA4PK1mwybvZ4+U/7H56uD+OjpzjnqGz5nA/2mrr6nRIVep2PO6HaM+Ww7vaauxb+9N/U8nHKUGdG1LgnJqXSd/AdLtpxhyvBWANTzcGJI+1r0fnstT366nfeebI9ed+fk91TfhgRHJuT5zLkrjjJgxnoGzFhfLokKgP0/rGJB/zHl8tmlobzj79HCE59qjvi9+TuTv9vP3HEd8y03d2wHJn+3D783f8enmiPdm3sCMGFIM/aejqLrpN/ZezqKCUOaFVpvdHwKj7y7gf7T1uA/az0TBjejWmVbAF5YsJN+b6+h95Q/cHW0ZnB77woXf0pqOq8tCqD3lD8Y/fFWZj7RDkc7K3Q6mPecHy8u3EXvKX8QEZPIML+6RdwLZXP83k7LZOSHW+k/Yz39Z6yjWzNPWtapAsB7Y9rz6qI9DJixntUHLvGKf7Mix5qdtJ/ixZ/lzWEtOXD2qvlvg17HrNHtUOZuou/bazgTdp2xfRrdNf4sep2O2U+0Ycy8HfSeth7/9rWo5+GYo8wIvzokJKXSbcpavt1yjreG+wJQz8ORIe1r0Wf6esZ8toM5o9ug1+moVtmWcb0bMPjdzfSdsQGDXseQ9rUAWH0ghJ5T19F3xgasrQyM9KtT5FizPOjHbnm0nfnj/fjvhlP0fGs1Q2auI+ZGivm95j6uONpZ3TXuwuh18O6oloz9Yg99Z27Gv60Xdas75CijdPYmITmVHtM28e2287z1qBb37bQMPvvjNHNXnchT74sDGxF78zY9p2+mz8wtHDx/7Z7izK2nr5d27fb6CiZ/E8D7T/vlW+79p7owecluury+wnTt5qXF95Ave05F0GXiCvaciuBFf+3YePmhlpwOjaXP5N949esdvDtGuyZsUMOZUT0bMmja/+gz+Td6t6yJj7tjvp9ZkPvdflrXc6NNvar0naqdI1v4VKFDQ/d7PvdA2V07Axw6d4V+U1fTb+rqHIkKgKf7NyE4Mr5YsYp/D0lW3CeKovgrivJWCZcNURSlSiHvf6coSrSiKMVPBxfBwM5NWL75KACH/7qMk70t1VxyfulVc3HAoZI1h/66DMDyzUcZ1KVJofUajUbsbCwxGPTYWluSlpbBzaRbpRJz39a1WBUQDEBg8DUc7ayoaroQzlK1si32tpYEBkcDsCogmH6ttQu4vq1qsjLgAgArAy7Qr3VNAI5eiDZnvAMvRFPdpVKpxJudb21XQq7e5PK1RNIyMll7MJS+Lb1yrl9LL1btuQjAhsOhdG7sbn597cFQUtMzCYtJJOTqTXxruwLg7mxHrxae/Lo7uNRjLg3BAYdIvp43kfKgKO/4+7aqyW+mNnHsoqnNO+Vq80622NtaERisXWD+tueiuW33bVXTfMxox0LNQutNy8gkNT0TACtLA9kfD554Kw0AC4MOSwsDxiLcFb/f8V+6coOQq9pdnqvxKcTeuIWLgzXO9takpmdw6coNAAJORTKwba27xp+lrI7f5Nvppm2q9UTI2qRGoxF7W+2HjaOtFVfjkosca46YpP0UK37Q7i66Odmy+9SdnoY6HejQYWetdVy1t7HianzR94lvbVdCohMJu5Zkbj99fGvkKNOnZQ1+23cJgA1HLtO5UTXtdd8a2dpPEiHRieb2YzDosLEyYNDrsLWy4Gq89uN4x8k7sR//O5bqLnZFjjXLg37s3u/463k4YdDrCDD1eky+nc6t1AxAS1a9PbINc389cte4C9PCx4XQ6ETCYpJIyzCy9nAYfVp45CjTx9eD3/aHArDxaASdGlUFICU1gyPBsdxOy8hT7/DO3ny18SwARiPEJabeU5y59WvtzSrTtVdgcDROBVy7OdhacfRC1rXbBfq38TYtX4uVu88DsHL3efPr9Ws4s+eU1gPkYmQCNdwcqOJkSz3PygReiOZWagYZmUYOnImif1ufYsV8v9uP0QjWlgasLPRYWeqxNOiJuZFyz+ceKLtr58JUd7Gjl68Xy3acu2tZ8e8kyYr7QFEUC1VV16iq+kEZfcQPQP8yqhsPN0fCr935ERZxLQEPN8c8ZSIKKfPcIx3Z9+1rLPzPMCrbaye+1btOknwrjQu/vc3pFVP4YsVu4m6mUBrcXeyINHWLBYi6noy7c87EgrtzJaKuZy+ThLvpQq2Kky3Rpou56PgUXHN98QCM7F6fHcfDzX8bjbDsrf5smPMQj/dokKd8kWN3tiMye1xxSVRzts2njPYllJFp5GZKGs721lRzts21bDLuzto6zRrVhrkrAvPtTj1pqC+bZw9mxmNtsLKQ08KDKE+7ydaezWVc7PK2eVP7qOJoS3SCqc0npODqaHPXequ72LHlPX8OzR/O1+tPmX8AASyd1IdjC0eSlJLG+kOhFTL+LL61q2Bp0BMafZPrN29jYdDT3Ef7kTewnTcexUhKltXxq9fp2PjuII59MZw9p6MI+jsGgMnfH+DHiT05+NmjPNrJJ8+QkxLHLe2n0Hp1Opg+qi1zlh/O8RnpGUam/rCfre8/xJEFCvU9nfh154W7xm+OsbJtzhiztYHsZbJiyt5+3J3tiLp+58fJlbhk3CvbcjU+hcWbzrL/44c4PO8RbianEXD6So46LQw6Hu3kw86TURTXg37s3u/4a1d34kZyKotf6cHG2UN4e2Qbcw/IsX0asvVYmLm+ktLa0Z06rsSn4J7rPFQtW5k77ajgHh0OtpYATHyoCWun9WLh+A5UcbC+pzjzxO1iR2TsneEw2jbLde3mUomo69nKxBZy7eaorfNfobEMNCUhfOu4UaOKPdVdKnE2LI4OjdxxtrfGxspAT9+aeLgW7ybU/W4/gcHX2H/mCkcWjODoghHsOhlBcGTCPZ97suIsq2vn1nWrsmXuw/z8n77U96xsfn3W6A68t/xQkZLS/3Q6g77C/1ce/jVzViiK4g1sBPYAnYAI4CHTa2+qqnrE1HvhiKqq3oqijAUeBgxAU+BTwAoYDdwGBqqqel1RlDrAQsANSAaeVVX1rKIoPwDXgZZAoKIoJ4E2qqq+pChKNeC/QG1TeC+oqrpPUZTVgBdgA3yuqurioqybqqq7TetXJvIbQZX7nKLLp1TWiWfJHwf48Kc/MRph2lN9eW/CIF78aBWtG3mRkZFJ/aHvUdnBls1fvMDOo8GEROUd61f8mAuOx1wmnxUr6rmyU+PqjOzegEfeXWd+7ZF31nE1PhlXRxuWv9Wf4KgEDp69Ukgt+cs3rqKUMRrR5fOGEejVwpOYG7c4GXqdDg2r5Xj/w5XHiE5IwcpCzwdjO/DCwCZ8vuZkseMW5aso7TnfY/ke6o26nkzft9dQrbItS162SOWjAAAgAElEQVTryfpDIcTc0HpHPfHxVqwtDXzxgh+dm7ib7yJWpPhBu+M1/3k/Xl+0x/z6iwt3MfPxdlhZ6Nl9KpL0jMy7fMpdPq9IMRV8/AJkGo0MmLEeRztLFr/cnfqelTkfEc/TfRsx5rPtBP0dw/gBjZn+WGsmf3+gyPEWHlOuMvks929tP0/2asj24+E5kgOg/egf3asBA6atJTT6JrOfbM9L/s344o+8Xerz/8D8Pq8o313GAtueo50lfVt60mXyGm4kp/LVC114pIM3/zsQYi4354m2HDwfzeELxe/W/6Afu/c7foNeR7sG1RgwbQ0RsUl89VI3hnety87j4Qxq540yd9NdY76bIq1TMa+BLAw6PFzsOHoxlvdWnuDp3vWYOrw5E787XPBCxZTvObBI15uF1/vlmiDefbITW95/lLNhcZwKiSEjI5PgyHgWrjnO8qmDSLqVxl+XY8ko5pwt97v9eFd1oK6HE+1eVQFYNrkv7RtEcjQ4+t7OPZTdtfPJkFjav7qC5Nvp9GxRg28n9sbvjVX0aulFTMItTobE0rGRe5HjFP8u/5pkhUk94DFVVZ9VFEUFht6lfFO0ZIMNEAxMVlW1paIo84AngfnAYuB5VVUvKIrSHvgK6Glavj7QW1XVDFPyI8sXwC5VVR9RFMUA2Jtef8qUALEFDiuK8puqqnlntikhRVGeA57T/iq8m9uzD3dkzOB2AASeDaeG250x155uTkTF3MhRPuJaAp55ymjdNK/F3cmA/7j+EOr7Y7V4evmy7dA50jMyiYlP4sCpEFo2qFHiZMWYPo0YZerRcPzvmBzZ8eoudnm6w0VdT8oxjKO6SyVzF+qYhBSqVtYyxFUr2xKb7S5HIy9nPnqmC6M/2kx8tomLsuqPvXGLTUdC8a1dpUTJiqjryTnuBlV3rkR0XEo+Zey4EpeMQa/DwdaS+KRUruRZ1o6rccn0aelFn5Y16NHCE2tLAw42lsx/rjOvLd5rzuinpmei7rnI+P6Nix2zKB9jejfkse71AVObL6A9Z4m6nlxwm7+RQlUn7Q5PVSdbYk0/GvO0x3zqvRqfwvmIeNo1qMaGw3fugt9Oy2BrYBh9W9XM98dmecdvb2PJD2/25uNVgRy7eOdHWmDwNYbO2QhA16YexRrDXBbHb3Y3ktM4cPYq3Zt5EHMjhcY1nc29LNYeDOHnN3oVOdby3v5ZHsT207qeG+3qV+PJXg2pZGOBpYWepFvpbDwcAmCe5HTdwRDzGPSiuBKXkjNGZ7scPU4AouJS8HCpxJW4lBztR1u/O3d03U3LdmnsTlhMEtdvat9XmwLDaV23ijlZ8ap/U1wcrJmy8FCR4yzvtnOvx255xm9h0HM69DqXr2nXRpuP/p+9+w6PongDOP69uySkh/QQQgi9SwCRliCEagFFZQUboiiCBcSCIsrPBhbELtJUFFEWVARpgtTQW0JROqmEhFTS6/3+2ONIyAEhkFyi7+d58jy529m9d+dm92ZnZ2Zj6NjUm3PpuQT5urJlulY1dbCzYcv0ewh98VeL+3AlCWm51PO4eFf7Qg+b0s6a0pxNL1uOLictq4Cc/CLW7NeGU6zcG4cSEnTNsV1qRL/WPBjWEoCIU+fw93QGtHlgtDzLLpM+ITWLeh7O5tf1PK9QdzPNBZKVW8iEWZvM6+z4bDgxpskef954lJ83akMQXrm/c5leA5eN2YrlZ0iPxuw/cc48NHDDgXg6NPUmr0B7fa3nnuqoO2flFprTr4+M412DHnfnOnRu7kv/ToGEBQdodVMHOz4bcyvPzdyEEBf81/p7n1ZV9cKsLnuBoKuk36CqaqaqqueADGC56f2DQJCiKM5ovTQWK4oSAcwC6pVaf7GqquUH/WmNGTMBVFUtVlX1wviJ5xRFiQR2oPWwaHZNe3cVqqrOVlX1ZlVVb75a2jlLt5snxFwRfpjhAzoB0Ll1IOez80hMLTvbfGJqJlk5+XRurY1PGz6gEyu3at2RS89vMSikDf+c1n6EYpPS6dlRm/zK0d6Wzq0DORaTVOn9m7/2H/PkPav3RJsn1urY1JvM3EJz17QLktJzycotpGNTbwDuC23Kn3u1ivLafTEMDdWyf2hoM/7cp83F4e/pxJzxfRk3c5N5XCyAQx0bnOxtzf/3bFffPNP0tYo8nUIjXxcaeDlja9AzqEtD1u6PLZNmbUQs94VoE6Hd3rkh2/7RGkXW7o9lUJeG2NnoaeDlTCNfFyJOpfD+kv10mfArPV78jWdmbmHbP2cZP3srQJmxlQM6NuBovExyVFvMX3eEgZOXMXDyMtbsjeFeU5no0MSbzJyCcl2JkzJyyc4rpEMTrczfG9LEXLbX7os1HzP3hTYt876l7fq5O2JvawDAzdGOm5v5cCohA8c6NuYyZdDrCGsfYHFSV2vHb2vQM2d8b34JP1lumMGFbrh2NnrG3NnW/JSKiqiK49fDpQ6ujtr5pY6tgZDWfpxMyCAjuwAXB1sa+Wrn2NC2/hxPqPi8KVJ+Kh//czO30PX5JXSfsIR3ftrDL+EneU/dy9m0HJrVr4uHqXt8aFt/TlzDOfVi+XG6WH4iyj5tYV1EHPd212443H5zINtME3yujYgvVX6czOXnTGoOHRp7Ym+n5XePVr6cSNB+v4aFNuHWtvV4dta2CvcshNp/7Foz/shTybg52ZnLSI/W9Tgen8H6yDg6PbuI7hO0cpVbUFSphgqAA1FpBPk4E+DpiK1Bx6DODVgXWbbBb11kAvd20+YauK1TfbYfuXr9668DCXRtruVB95Y+nEio3JOHSpu/9m/6v/or/V/9lTV7orjPVPfq2NSH8zkFlutueQV0bKrNsXFfaDPW7I0C4M+90QztqTUiDO3ZnDWmOp2rox22pi7sD4S1ZOc/CeYL6Atlxt/Tids6N2LptqvP62XN8nMmJZsupgk1bQw6urb05cSZ9Eqfe6qj7uxdqp4Z3NgLvU5HWlY+7y3aQ+dnf6bbeJWnv9jA1r/P/KcbKnR6fY3/s4b/Ws+K0s/vKQYcgCIuNtrYXyF9SanXJWh5pwfSVVUNvsznXb151kRRlF5AX6Cbqqo5iqJstBCPVazZcYT+XVoQ+ePL5OQXMPb9xeZl4XPHETLqUwCe//g3Zr6i4GBny9pdR81P/Xj7qdtp17QeRiPEnE1j3Efaj++cpdv5auJQdn47AZ0OFqzaw+FT194TwZL1EbGEBQcQPmMoeQVFTJi15eL+TL2bAZOWAjDp223MGN0TezsDGyPjWG+ag+KL5Qf4+tkwhvVqTnxyNk999pe2j0M6UNelDlNNMyRfeESpt6sDc5/X7mgaDHqWbjvJxgOVe5xXcYmR1xfs4ocX+2DQ61i05QTHzmQwYUh7Dp5OYW1EHIs2n+CTJ0PY/P5d2iPHZmr7d+xMBn/sjuavqYMpKi5h8g+7rvrIv09Hh+DpUgedTsfhmFQmzd9Zqbiv1+MLP6N5r644e7kzLXY7y6d8zLZvVKvEUhnWjn99ZBxhwfUJn34PuQXFvDAn3Lxs9TuDGThZe0LNpO+2a49PszWw4UA8GyK1cvrlHweZ+cytDLu1GfEpWYz5fOMVt9usvhuvD++MEa2L66xVhzkSl46Xqz3fTOiDnY0evV7Htr/PVuhiv7rjv7NLEF1a+OHubM9QU+Vswuxw/o5J5anb29InOAC9XscPfx1l298VPy9VxfHr4+bAjCd6YNDrtMcP74riL9N+T/x2B7OeuZUSo5GMnAJemre9wrFaM/9re/m5nMT0XD75LZIlr91GUXEJcSnZTJh95XVKKy4x8saCPXw/oTcGvQ41/BTHz2Qw4e52HIhKZV1EPIs2n+TjJ7qzadogrfzM0rZ//EwGK3bHsO6dOygqMfL6gt2UGI1EnEph5Z5YVkwZSHGxkcMxaSzcpF2QvftIZ+JTsvnttf5aXu2N5bPl1zZXd20/dqs7/hKjkXd+2s3PrwxAp9NxMCqFhRuOXVOeX01xiZEpP0Xw/fhQ9Hodi7dGcTzhPM8Pbs3B6DTWRSawKPw0Hz9+CxveGUhGdgHPzrn4279l6m04O9hia9DTL9ifRz7ZwomETN7/5SAzHuvMG/fbkpJZwMvzb9wQEIC/9scSFhzI1k+GaY/rnLXRvOzPaffQ/1Wt/vjqN+GmR5fasCEilvURWoPwl8si+HpcX4b3akl8ShajP1kHQLP6dfl0TG+KS4wci0/jxdkXL4jnPN8Pd2d7iopLeO3bcDKu0LvEkuouPyt2RdO9dT3WTr0LI7DpQDzr9mt11+s590DV1Z3vuCWIh/u2ori4hLzCYsZ+seGa4hL/bbr/yoQmpjkd/lBVta3p9Ytowy8CgL2qqs5UFGU8ML7UnBU3q6r6jCl9lOl1culliqJsAz5WVXWxoig64CZVVSNNc1b8oarqEtP6pdf5GdihquonpmEgTkBvYJSqqoMURWkJRAADVVXdWPqzK7p/V+Paa2Kt/eIzN31A/QfmWjuMSotfOIoGI763dhiVFjv/EUZT8acj1DSziK718Qc89K21w6i0uAUja338tf34re35X9vjDxz5o7XDqLSYbx+s9flfW+OPWzASgKAnFl8lZc0UNWcoAP7DZlk5kso58/NogFpffmpr/Tl+4SiMRqOl6T/+NY4+eU+NvzZrMfvXav8O/mvDQCyZDowxNTpc9vGgV/Ag8Lhp+MZhtEk7r2Yc0Ns06eZeoA2wGrBRFOUA8DbaUJAKURTlJ2A70EJRlDhFUR6/xn0QQgghhBBCCCFqjP/MMBBVVaPQJsy88Hp6qcU3lfp/smn5d2iPBL2QPqjU/+ZlqqqexsJjQ1VVffSS16XXScRyo8Ztl4k9yNL7pZYPv9JyIYQQQgghhBA1k95Kjwat6SRXhBBCCCGEEEIIUaP8Z3pW1HaKongCf1lY1OdGPt5UCCGEEEIIIYSwNmmsqCVMDRKXe+qIEEIIIYQQQohaSCfDQCySXBFCCCGEEEIIIUSNIo0VQgghhBBCCCGEqFFkGIgQQgghhBBCCGElMgzEMskVIYQQQgghhBBC1CjSWCGEEEIIIYQQQogaRYaBCCGEEEIIIYQQVqLTSx8CSyRXhBBCCCGEEEIIUaNIY4UQQgghhBBCCCFqFBkGIoQQQgghhBBCWInOYLB2CDWS9KwQQgghhBBCCCFEjSKNFUIIIYQQQgghhKhRZBiIEEIIIYQQQghhJTqD9CGwRHJFCCGEEEIIIYQQNYo0VgghhBBCCCGEEKJG0RmNRmvHIKxAp9PJFy+EEEIIIYSo8YxGo87aMVSlqIkjavy1WdD786v9O5A5K4QQQgghhBBCCCvR62XAgyXSWPEf5XLry9YOodIyN31A/QfmWjuMSotfOIoGI763dhiVFjv/EUbT0NphVNosomt9/AEPfWvtMCotbsHIWh9/bT9+a3v+1/b4A0f+aO0wKi3m2wdrff7X1vjjFowEIOiJxVaOpHKi5gwFwH/YLCtHUjlnfh4NUOvLT22tP8cvHGXtEISVSBOOEEIIIYQQQgghahTpWSGEEEIIIYQQQliJPLrUMskVIYQQQgghhBBC1CjSWCGEEEIIIYQQQogaRYaBCCGEEEIIIYQQViLDQCyTXBFCCCGEEEIIIUSNIo0VQgghhBBCCCGEqFFkGIgQQgghhBBCCGElOr30IbBEckUIIYQQQgghhBA1ijRWCCGEEEIIIYQQokaRYSBCCCGEEEIIIYSVyNNALJNcEUIIIYQQQgghRI0ijRVCCCGEEEIIIYSoUaSxQgghhBBCCCGEEDWKzFkhhBBCCCGEEEJYicxZYZnkihBCCCGEEEIIIWoUaawQQgghhBBCCCFEjSLDQESFfPDsYPp3bUFOXiFj3lOJPH6mXJrg5vWZ+cpQHOrY8ueOo7z8+TIAXn20LyPuuIXkjGwA3pqzmj93HsXGoOeLl+6jfXN/bAwGflqzlxkLN96wmN96pCth7RuQW1DE87M2cygqpVyadkGefPxUT+xtbVgfGcsb3+8AoK6THV89G0YDb2diz2Ux5rP1ZOQUMKR7E8YOugmA7LxCXv12G//EpNK4nhszn+1t3m6gjwvTl+xj3urDlYr91nb+/O+BmzHodfy8+QRfrSi7HTsbPR8/0YN2QR6kZRXw9MzNxCVr+fv0HW25v2cTikuMTPlxN5sPJQCwdfoQsnMLKTYaKS42cuebK83be7RvC0b0aUFxiZH1kfFMVfdVKu7r8fC8D2h3ZxiZSSm83W5AtX/+9aoJ8b/58C2EtQ8gN7+ICbPDORSdWi5NuyBPZjwZgr2dgfWRcUz5YReglfkvn+lFAy9nYpOzGPv5RjJyCi673fqeTswe1xuDXo+NQcd3a4+wYP1RAH54qR8+dR0w6HXsOprE5Pk7KDEaa1T8rQM9mPpoV5wdbCkpMfL5sgMs3xkFQI/W9Xht+M3odTqy8wp5YXY4UUmZFf4ebvTxW8dWz+JXB2Bno8fGoGfl7mhmLD2gxdrKj0n3d0Sv15GTV8SEuduIvoZYS6sJ5cfezsDXz/aioY8rxSUlrNsfx3vq3hoV+wXO9rZseP9uVu+N4fXvd+Jkb8Mvk283L6/n4civW0/x5o+7ruFbKOvWtvWY8kAnDDodP285ycyVf5dZbmejZ8aobrRr6EFadj7PzNxKXIpWlsbe3pr7Q5tQbDTyvx/3svmw9lvweL8WDOvZBKMRjsSn89K8HeQXlVQ6Rqj9x251lx9/Tyc+fLw79TycMAIjpq8jLjmLD0d156ZGXuiAU2fPM2F2ODn5Rdf6dQDQs40vU+4PRq/XsSj8NF+vPlpmuZ2Nno9GdqZtQ3fSswt4ZvYO4lNytPrPU125qaEHv2yPYspPEeZ1bA063hzega4tvCkxGpm+9DCr98VXKr7LeWtEd8KCTXW3mRst190aefHxU7207yIiljfmbwOgrlMdZo7rQwMvF2KTM3nq03VkZBfg5mTHR6NvpaGvK/kFxbwwaxNH49LM29PrdKyaOoSzqdmM+HDNdcVfFWWpST03PnqiB22DPPlwyT5mrbz4mzJ9VA/6dAgg5XwefV/9/bpih6qpO3dr5ce8Cf2IPacdi6t2R/HJb1q5cnW048MnQmgR4I7RCC/M3sK+E0nXvR+1kV6GgVgkuSKuqn+XFjQJ8CL4wQ8Z99GvfPz8EIvpPn5+COOm/0rwgx/SJMCLfre0MC/7ckk4IaM+JWTUp/y5U/vBHNLrJurY2dDtsU/o+eRnjBzchUA/9xsSc1j7ABr5uRLywmImzgtn2sjuFtNNe6wHL8/dSsgLi2nk50rv9gEAPD24PVsPnyH0hSVsPXyGpwe3ByDmXCb3vb2Cfq/+xqdLI/jg8R4AnErIYMCkpQyYtJTbXvud3PwiVu+JrlTsep2Odx6+hREz1tNn0nIGdwmimb9bmTT392xKRk4BPSf+ztw//+HVoR0BaObvxqAuDen72nIe+Wg97z7SBb1Od3G999dy2xsryjRUdGvpS/8ODRjw+h/0fW05s1aVrQxXl+3fLeHzgSOs8tk3grXj792+Po18XQl98VcmfrOdqSO7WUw39dGuTPxmG6Ev/kojX1d63VQfgLGD2rH1cAI9X/qVrYcTGDuo3RW3m5Sey5C3VjJw8jIG/28FY+9sh29dBwDGfL6RAa8to++rv+PpWoc7uwTVuPhzC4oYP2sLfV/9nYc/XMuUh27B1dHO/BnPzdzMwMnL+H37KZ67u31FvgKgao7f/MIShr2/loFvrGDgG39wa7v6dGjiBcC7I7owblY4t72xgqU7TvPc4HYVjrW0mlR+Zq08TO+Jv3Hb5OV0bu5j/oyaEvsFL97XgR1HEs2vs/OKGDh5mfkvLjmr0r8DoJWltx+6mREfb6Dv5BUM7tKQZv6uZdLcH9qEjOwCbn11OfP+PMorQ4MBaObvyqAuDen3+gpGzNjAOw9rF/C+dR0Y2bcFd761hv5vrMSg1zGoS8NKxwi1/9i1Rvn5ZHQoX688RNgrSxk05Q+Sz+cC8OaC3Qx4bRn9X1vGmZRsHu3X6qrxW6LXwVsPdODRz8LpP2UNgzs3oGk9lzJplB5BZOQU0HvyauatO8Yr92hx5xcWM+P3w0xdcqDcdp++vRUpmfmEvb6GflP+ZOexc5WK73LCghtodbfnFzFxzhamPR5qMd20x0KYOHczIc8vMtXdGmjx3RVM+KF4QiYsIvxQPE8P1o6HZ+/qwOHoFPpN/IVxMzfw1oiydcJRt7XleHz6dcdfVWUpPTufKT/sZPbKQ+W2tXjLCR7+YO11xw5VV3cG2HX0rLmefKGhAuDNh7uyMTKOXi/9Qv9Xf+PEmev/HsS/izRWVBNFUQYrivJKJdeNUhTF6zLLGiiKskFRlH8URTmsKMq464u0vNt7tOGnNdqdrd1/x+Dm7ICvR9kfPV8PF1yc6rDr7xgAflqzlztC2lxxu0ajEUd7WwwGPQ51bCksLCYzO++GxNy/U0OWbDkBwL4T53B1tMPHVBG+wKeuA84OtuYW3CVbTjCgk1Zp698xkMVbjgOweMtxBnQKBGDv8STzHZN9x5Oo5+FU7rND2voTnZRJfHJWpWIPbuxJVGImMeeyKCwuYfnOaPp3aFB2/zo0YEn4SQBW7o6mR2s/8/vLd0ZTUFRCbHIWUYmZBDf2vOLnPRzWnK9WHKLAdGctJfPGfAfX6sSWXeSkZljls28Ea8ffv2Mgv5jKxP6TpjLvdkmZd3PA2cGOfSe0CuYv4SfNZbt/x0DzMaMdC4FX3G5hcYm5zNjZGtBfbBMjK68QABuDDlsbA8YK9Kqo7vhPnz1PVKJ2lycxPZeU83l4uNQBwAg4O9gC4OJoR2JazlXjv6Cqjt8Ld1dtDFpPhAtZajQacXbQLtRcHa4t1jIx1ZDyk1dQzPZ/zgJQWFzCwagU6nk41qjYQbuz6O3mwOZD5XsZAgT5uuDl6sDOo4kWl1dEcGNPopKyiD2XbS5L/YIDyqTp1yGAX7adBmDlnhh6tPLV3g8OKFWWsolKyjKXJYNBh72dAYNeh4OdDYnpuZWOEWr/sVvd8Tfzd8Og17HF1OsxJ7+IvIJi4OK5E8DermLnTkvaN/IgOimL2ORsCouNLN8dS7/2/mXS9Av255ftWmPaqr3xdG/lA0BuQTF7TqSQX1hcbrtDewTx1aojABiNkJZVUKn4LmdApyCWmOpe+04k4XaZupuLgx17j1+oux1n4M1BpvUbsnjzMQAWbz5mfr95gDvhh7QeICfPZBDg7YKX6Tuu5+FEnw6B/LThyHXHX1VlKeV8HpGnUygsLl8edh5NJD37xnwPVVV3vhxnB1u6tPTjp43ad1ZYXML5nBtbpkTtJ8NAqoGiKDaqqi4DllXB5ouAF1RV3acoiguwV1GUtaqq3rDb4/7ersSdu3gRFn8uA39vVxJTM8ukibeQ5oInh3RjeP+O7D8ax2tfrSA9K5elmw5yR0gbjv/yGg517Hj1y+WkZV5fpekCPw9Hzpi6wgIkpObg5+5EUqlKmZ+7EwmppdNk42eqFHu5OZjTJqXn4nnJjw3AsF7N2RAZV+79wV0b8/u2k5WP3d2RM6XjSssmuLGXhTRaJay4xEhmbiHuznXwdXdg/8nkUuvm4Oeu7ZPRCAte7APAjxuOs3CT9oPSyM+VW5r78NK9HcgvLOadRXs5cLp8tz9Rs5UrN6bynJRRqsx7OJYv86by4eXqYE6blJGLp6v9Vbdbz8OR+S/0JcjXlXd/3lPmomfBS/1o38SLjZHxrNh19bvL1oj/guDGXtga9ObhEy/P3cr3L/Qlr7CYzNxC7vrfiqvGf9n9uEHHr16nY8WbtxPk48L3fx0l4pSWbuK3O5g/IYy8giKycgu56+3VFY71inFbufyA1j24b4cGfLPmyj9n1R37ufO5vP5AZ8Z9vZmQNmUvAC+4q1tjlu88fcW4r8avrkPZmNNy6HBpWarrYI6xdFnyc3csU5bOpuXgV9eBfSeTmb36CNs/vIu8wmK2HDrLlsNnry/OWn7sVnf89TycOJ9TwOznetPA25nwwwlMW7TXPFTuoyd60Lt9AMfj03lr4e6rxm9xn+o6kJB6Mf6z6bkEN/Iok8a3VJqLZcfusg0QLqZGoAl3taFrC29izmUzZeF+kjPzKxWjxbg9HDmTcvFGj5Znl9TdPJxISC2VJuUKdTdXre72d3QKt3duxO6jiQQ38SbAy5l6Hk4kZ+Ty5iPdeGfhTpztba8//ioqS9WlKuvOnZr68OfUu0lMz+HtH3dxLD6dQB8XUjPzmDE6lNaBnhw8ncwbP+wgt5JDn2o7nV76EFjyn2msUBQlCFgFhAPdgXjgLtN7L6qqusfUe2GPqqpBiqI8CtwNGIC2wEeAHfAwkA/crqpqqqIoTYAvAW8gB3hCVdUjiqJ8B6QCHYB9iqIcBG5WVfUZRVF8ga+Bxqbwxqiquk1RlKVAA8Ae+FRV1dlX2y9VVROABNP/mYqi/APUB25YY4XOwnuXNvbrLKS6cEdg7u87eP/7vzAaYfJj/Xl37B08/cESOrVqQHFxCc3vfZe6Lg6s+WwMG/eeICqh/Pi+a4/58vGY01jYsYrexOjeuh7DerVgyFt/lHnf1qCnf6dA3ltUuQrGZeOqSBqjEZ2FBRfWvffd1SSm5+LpYs+PL/XhREIGu44lYaPX4+ZUh7veXkX7Rp58NbYnIS/9Vun4hXVUpDxbPJavY7sJqTn0f20ZvnUdmDs+jBW7okg+r/XMeejDtdSxNfDZmFB6tPEz30WsSfGDdpfrk6dCeX5WuPn9UQPb8MhH64g4mczo29vwxoOdeXnetqt80hU+r0IxXfn4LTEaue2NFbg62jL72V40r1+XY/HpPN6/FSNmrCfiVDKjb2vN68M7MfHbHRWK9eoxXZLGwnpVVX4Meh1fjO3Jt3/+Q8y5K/dSq+7YH+nTkvWRcSSkXv6u/eCujRj/9ZarfMLVAiDnzJgAACAASURBVLD0+RX5HTNethy6OtrSv0N9QiYu43xOAV+NCWFI1yB+2xFV+TBr+bFb3fEb9DpuaeHLbZOXEZ+SzVfP3MrQnk1ZZLqB8MKcrdoQoEe6MLhLI1TTne5rUaF9usY6kI1Bh7+HI3tPpvDu4gM83rcZk4bexIRvKl/fuZTFc2CF6ptX3u4XyyJ465Hu/DntHo7EpnEoKpni4hL6dggk+XwuB08n061VvesJXYutispSdamquvPBqBS6jFtETn4RYe0DmDehL6EvLMFGr6dtkCevz9/O/pPnePPhrjw96CamL6n+edNEzfWfaawwaQYMV1X1CUVRVODeq6Rvi9bYYA+cACaqqtpBUZSPgUeAT4DZwFOqqh5XFKUL8BUQZlq/OdBXVdViU+PHBZ8Bm1RVHaIoigFwNr3/mKkBxAHYrSjKL6qqVvgWt6lBpgOw8zLLnwSe1F41uuK2nri7GyPuvAWAfUfiCPC+OOa6vrcbCcnny6SPP5dB/XJptDsd59IuVjTnr9iFOu1RLZ4+wazbdZSi4hKS07PZcSiKDi0CKt1YMaJfKx7orc2TEXkqGX/Pi0M06nk4kphetmKZkJpdZhhHPQ8nc5fR5IxcfOpqLcQ+dR1IKdUq3qqBOx+MCuHhD9aQnlX2jkLv4AAORqWYK9yVkZCag3/puNydSErLtZDGkbNpORj0OlwcbEnPLuBsuXUdzft04a5lSmYea/bFEtzYi13HkkhIy2bVXm34TuTpFIxGIx4udUi9gXdLRNUY0bclw3s1B0xl/jLl+YKE1JzLl/nzufi4aXd1fNwcSDGV4XLl0cJ2E9NzORafzi0tfFm5+2IvivzCYtbui6V/x0CLjRXWjt/Z3pbvXuzLh0v2sf+k1iXXw6UOrQPdiTDdlV6+M4ofXupXLvbLqarj94LzOYXsOJJIr3b+JJ/P1WI9VSrWF/pUOFZr5/8FlsrP+49153TieeZdpleFNWPv1MybW5r78kifljjZ22Broyc7r8g8EWirQHds9DoOWpiY7lqcTcstG7O7Y7neJwlpufh7OHE2LbdMWdL29+LwGT/TuiGt/YhNzjaf31fvi6NTU69rbqywdtm53mPXmvHbGPQcjk41N8Kt2RtDx6beLNp08fNKjEaW7zzN6NvbVqqxIiEtl3oeF+9q+9V1KFd2zprSnE0vW3YuJy2rgJz8Itbs14ZTrNwbhxISdM2xXWpEv9Y8GNYSgIhT5/D3dAa04VNanmWXSZ+QmkU9D2fz63qeV6i7meYCycotZMKsixm847PhxJzLZHD3JvTv2JCw4EDq2BpwcbDjs6d789yXGyoefzWUpapUHXXnrNyLw5vWR8bxrkGPu3MdElKzSUjNNh/DK3ad5ulBFZ8jSvw3/Nf6m5xWVfXCrC57gaCrpN+gqmqmqqrngAxguen9g0CQoijOaL00FiuKEgHMAko3zS5WVbX8oD+tMWMmgKqqxaqqXhg/8ZyiKJHADrQeFs0qumOmWH4Bxquqet5SGlVVZ6uqerOqqjdfbXtzlm43T4i5Ivwwwwd0AqBz60DOZ+eVGQICkJiaSVZOPp1ba+PThg/oxMqt2mzFpee3GBTShn9Oaz9CsUnp9OzYFABHe1s6tw7kWEzlZwCev/Yf8+Q9q/dEc1+otu2OTb3JzC0s040NtC5qWbmFdGzqDcB9oU35c69WUV67L4ahoVr2Dw1txp/7tIt5f08n5ozvy7iZmzh9tnw239WtyXUNAQGtwaCRrwsNvJyxNegZ1KUha/fHlkmzNiKW+0KaAHB754ZsM43xXrs/lkFdGmJno6eBlzONfF2IOJWCg50NTvZa26SDnQ2hbepx1DSZ1J/7YuneShsz38jXBVuDXhoqaon5646YJ/NbszeGe01lokMTbzJzCsp0PQWtW2l2XiEdmmhl/t6QJuayvXZfrPmYuS+0aZn3LW3Xz90Re1sDAG6OdtzczIdTCRk41rExj9E16HWEtQ/gxBnLc3lYM35bg54543vzS/jJMsNUMrILcHG0o5GfNowttK3/NU34VRXHr4dLHVwdtS7KdWwNhLT242RChhargy2NfF3MsR5PqPi8KTWx/AC8dF8HXBxt+d+Cyz9Fw5qxPzdzC12fX0L3CUt456c9/BJ+sswTS+7q2pjfd1zfEBAoXZacLpaliLJPXlgXEce93bWbD7ffHMg204SfayPiS5UlJ3NZOpOaQ4fGntjbaXnfo5UvJxIsVhmuqLYfu9aMP/JUMm5OduZ5Nnq0rsfxeK3sB/lcrC/17dCAk9dwPJd2ICqNIB9nAjwdsTXoGNS5AesiyzYYr4tM4N5u2lwDt3Wqz/YjV69//XUgga7NtTzo3tKHEwmVe/JQafPX/k3/V3+l/6u/smZPFPeZ6l4dm/pwPqfAct0tr4COTbU5Nu4LbcaavVEA/Lk3mqE9tYaDoT2bs8ZUp3N1tMPW9KSFB8JasvOfBLJyC3nv593c/MxCuj73E2M/+4uth+OvqaECqqcsVaXqqDt7lxoOEtzYC71OR1pWPucycjmTkk3jetrNzpA2/hyPT+O/SmfQ1/g/a/iv9awofQVWDDigzflwIfcvHRxWOn1JqdclaHmnB9JVVQ2+zOdlX+b9chRF6QX0BbqpqpqjKMpGC/Fcbl1btIaKH1VV/bWin1lRa3YcoX+XFkT++DI5+QWMfX+xeVn43HGEjPoUgOc//o2Zryg42NmydtdR81M/3n7qdto1rYfRCDFn0xj3kRbinKXb+WriUHZ+OwGdDhas2sPhU9c3dvaC9RGxhAUHED5jKHkFRUyYdbE77pqpdzNg0lIAJn27jRmje2JvZ2BjZBzrTXNQfLH8AF8/G8awXs2JT87mqc/+0vZxSAfqutRhqmmG5KLiEu54XZuKxN7OQM+2/rwyL/y6Yi8uMfL6gl388GIfDHodi7ac4NiZDCYMac/B0ymsjYhj0eYTfPJkCJvfv0t75NhMbf+Oncngj93R/DV1MEXFJUz+YRclRiPebvbMfvZWQJugb+mO02w6qE0Mt2jzST58vBtr3xlEQVExE+ZWrLv7jfb4ws9o3qsrzl7uTIvdzvIpH7PtG9UqsVSGteNfHxlHWHB9wqffQ25BMS/MuVgOV78zmIGTtXI66bvt2iPTbA1sOBDPhkjt4ufLPw4y85lbGXZrM+JTshjz+cYrbrdZfTdeH94ZI1q31lmrDnMkLh0vV3u+mdAHOxs9er2ObX+fNT/StCbFf2eXILq08MPd2Z6hpsrZhNnh/B2TysR525j9XG9KjEYysgt4cU7Fj+mqOH593ByY8UQPDHodep2OP3ZF8Zdpvyd+u4NZz9yqxZpTwEvztlc4Vmvm/+XKj5+7I8/d1Z7j8emsenswAN+t/YefTV3ka0LsV3NnlyBGTF9XobRXUlxi5I0Fe/h+Qm8Meh1q+CmOn8lgwt3tOBCVyrqIeBZtPsnHT3Rn07RBWlmapcV4/EwGK3bHsO6dOygqMfL6gt2UGI1EnEph5Z5YVkwZSHGxkcMxaSzcdO137kur7cdudcdfYjTyzk+7+fmVAeh0Wg+chRuOodPBjNEhuDjYodPB3zGpTKrEkC7Qys6UnyL4fnwoer2OxVujOJ5wnucHt+ZgdBrrIhNYFH6ajx+/hQ3vDCQju4Bn51zslLtl6m04O9hia9DTL9ifRz7ZwomETN7/5SAzHuvMG/fbkpJZwMvzb9wQEIC/9scSFhzI1k+GaY/+nLXRvOzPaffQ/1Wt/vjqN+GmR5fasCEilvURWoPwl8si+HpcX4b3akl8ShajP9GOw2b16/LpmN4Ulxg5Fp/Gi7M3lfvsG6GqypK3mwMr3rrT9LheeHxAa8ImLiUrr5Avxvakays/PJzt2fXpUD76NcI8pOia46+iuvMdtwTxcN9WFBeXkFdYzNgvLjYIvf79dj4feyt2NgaikzJ5YdbmSsUu/r10lZ1puLYxDZH4Q1XVtqbXL6INvwgA9qqqOlNRlPFoPRMuzFlxs6qqz5jSR5leJ5depijKNuBjVVUXK4qiA25SVTXSNGfFH6qqLjGtX3qdn4Edqqp+YhoG4gT0BkapqjpIUZSWQAQwUFXVjaU/28J+6YD5QKqqquMrmh+uvSbW2i8+c9MH1H9grrXDqLT4haNoMOJ7a4dRabHzH2E01/eoO2uaRXStjz/goW+tHUalxS0YWevjr+3Hb23P/9oef+DIH60dRqXFfPtgrc//2hp/3IKRAAQ9sfgqKWumqDlDAfAfNsvKkVTOmZ9HA9T68lNb68/xC0dhNBotTfnxr3Hu4+dr/LWZ9/MfV/t38F/rWWHJdEBVFOVhYH0l1n8QmKkoymTAFvgZiLzKOuOA2YqiPI7Ww2MMsBp4SlGUA8BRtKEgFdEDbdLPg6ahKACTVFVdeW27IYQQQgghhBCiullrmEVN959prFBVNQptwswLr6eXWnxTqf8nm5Z/B3xXKn1Qqf/Ny1RVPQ0MtPB5j17yuvQ6iWhPIrnUbZeJPcjS+6Zl4VieXFgIIYQQQgghhKiVpAlHCCGEEEIIIYQQNcp/pmdFbacoiifwl4VFfa7l8aZCCCGEEEIIIWoOnV76EFgijRW1hKlB4nJPHRFCCCGEEEIIIf41pAlHCCGEEEIIIYQQNYo0VgghhBBCCCGEEKJGkWEgQgghhBBCCCGElegNBmuHUCNJzwohhBBCCCGEEELUKNJYIYQQQgghhBBCiBpFhoEIIYQQQgghhBBWojNIHwJLJFeEEEIIIYQQQghRo0hjhRBCCCGEEEIIIWoUGQYihBBCCCGEEEJYiQwDsUxyRQghhBBCCCGEEDWKNFYIIYQQQgghhBCiRpFhIEIIIYQQQgghhJXo9NKHwBLJFSGEEEIIIYQQQtQo0lghhBBCCCGEEEKIGkVnNBqtHYOwAp1OJ1+8EEIIIYQQosYzGo06a8dQlTK//1+NvzZzeeR/1f4dyJwV/1H1H5hr7RAqLX7hKAIe+tbaYVRa3IKREr8V/RviH01Da4dRabOIJm/DAmuHUWn2vR+q9eVn54De1g6j0rqs2UD+5p+sHUal1ek5vNaXn9xVs6wdRqU53Daa/PBF1g6jUuqE3A/U3vpb/MJRALW2/MctGAlI/NZyIX7x3yPDQIQQQgghhBBCCFGjSGOFEEIIIYQQQgghahQZBiKEEEIIIYQQQliJziB9CCyRXBFCCCGEEEIIIUSNIo0VQgghhBBCCCGEqFFkGIgQQgghhBBCCGElOr30IbBEckUIIYQQQgghhBA1ijRWCCGEEEIIIYQQokaRYSBCCCGEEEIIIYSV6PQGa4dQI0nPCiGEEEIIIYQQQtQo0lghhBBCCCGEEEKIGkWGgQghhBBCCCGEENYiw0Askp4VQgghhBBCCCGEqFGksUIIIYQQQgghhBA1igwDEUIIIYQQQgghrEUvfQgskVwRQgghhBBCCCFEjSKNFUIIIYQQQgghhKhRpLFCCCGEEEIIIYQQNYrMWSEu661HuhLWvgG5BUU8P2szh6JSyqVpF+TJx0/1xN7WhvWRsbzx/Q4A6jrZ8dWzYTTwdib2XBZjPltPRk4BQ7o3YeygmwDIzivk1W+38U9MKo3ruTHz2d7m7Qb6uDB9yT7mrT5c4Xh7tavP/x6+BYNex08bj/PVHwfLLLez0fPJ6FDaNfIkLSufsV9sIi45C4CnB7Vj2K3NKC4xMuWHnWw6eOaK25zxZAhdWvqSmVMIwITZ4fwdk0rXln7Mez6M2HPadlftiebTpZEV3oc3H76FsPYB5OYXMWF2OIeiU8ulaRfkyYwnQ7C3M7A+Mo4pP+wCtDz/8pleNPByJjY5i7GfbyQjp+CK2331/k70CQ4A4NOlkSzfGVXms956uAtKz6a0fOLHGhd/fU8nZo/rjUGvx8ag47u1R1iw/igAP7zUD5+6Dhj0OnYdTWLy/B2UGI3/+vivx8PzPqDdnWFkJqXwdrsBVfpZlRV+6ATvq2soKSnhnpAOPD4wpFyaNXsOM/OPTejQ0TzAl/dH3cOR2LO88+MKsvMK0Ot1PHFbKAM7t6myOKvzXPThqO7c1MgLHXDq7HkmzA4nJ7+oSvbLrVNnAsc8g06v59zqlSSoP5XdL28fGr84EYOTMzqDnthv5pKxeyeuHTrR4LEn0NnYYCwqImbuLDIj91dJjFcSfug47/+0iuISI/eEdmTU7aHl0qzefYiZyzai00HzAD8+ePI+AJ76+AcOnIqjQ7NAvnzuwSqPtSrORU3qufHREz1oG+TJh0v2MWvlxd/XbTPuIzuvkOISI8XFJdwx5Y8bvk9b/znN+79uoKTEyJCubXm8X5dyadbsP8rXq7aBTkcLf2/eG3EHZ1LPM2He75QYjRQWlzA8tANKSPsbHt/VhB88zvsLV1BsNHJPaCdG3dGzXJrVuw4y8/cNWvlp4McHoxUAnpoxnwMnTeVn/MNVGmdV1N26tfJj3oR+xJ7LBGDV7ig++S2Ceh5OfDqmJ95ujpQYjSxcf5R5aypeb7OkOst+HVsDS14biJ2tAYNex8rd0cz4NaJGxHyl7f7wUj86NPFm97FERs74q9xnXWvdrar35e7ujRl7R1sAsvOLmPTddv6JSbth+f9voTPIo0stkcYKYVFY+wAa+bkS8sJiOjb1ZtrI7gyasrxcummP9eDluVvZdyKJH17uT+/2AWyIjOPpwe3ZevgMXy4/wNODbuLpwe2Z+vNuYs5lct/bK8jIKaB3+wA+eLwHg6Ys51RCBgMmLQVAr9Ox54thrN4TXeF49Tod74zowgPv/0lCag5/vHUna/fFcPxMhjnNsFubkZ5dQOiLvzK4ayMm3d+JsV9uopm/G4O7NqLPK0vxdXfkp4n96fnSbwBX3Oa7P+1h5e7yMe46avnH42p6t69PI19XQl/8lQ5NvJk6shuD/7eiXLqpj3Zl4jfb2HfiHN+/2JdeN9Vn44F4xg5qx9bDCXz1x0HG3tmOsYPaMW3R3stuN6x9AG2DPBnw2jLsbA0smTSQDZHxZOVpDTA3NfLE1dGuxsaflJ7LkLdWUlBUgmMdG9ZNu5u1+2JITM9lzOcbzfsx67le3NkliGU7Tv+r479e279bwsYv5vPo9zOq9HMqq7ikhKk/rWL2+IfwdXdl+LS59LqpBU38vc1pohNTmLd6K9+/NBJXJwdSzmcDYG9ny7sj76ahrydJ6ZkMe3cO3ds0wdXR/obHWd3nojcX7DaXlTce6Myj/VqVaxy5MTump+HT4zg66SUKks/R5rOZpO3YRl7MxXOg//CHSN28iaQVy7APbEiLt6cROeIBis5ncGzKaxSmpuDQMIgW735AxEPKjY/xCopLSnj3xxXMnvAIfu6uDHtnNr2DW9DE38ecJjoxhXkrt/D9K4/j5uRAyvks87JHB/YgL7+QxZv3VHmsVXUuSs/OZ8oPOxnQKdDi5ypTV5OWlV8l+1RcUsLUxX8xa+x9+NZ14YGPfqRXu6Y08fM0p4lOSmPe2p3MHz8cV0d7UjJzAPB2deL754djZ2NDTn4B9743n17tmuDj5lwlsV4u/ncXLGf2C4/i5+HKsLe+pndwS5rUv7T8bOb7SU9YKD8h5BUUsnjj7iqNs6rqbgC7jp7l0elry2ynuKSEt37cxaGoFJzsbVn1zl1sPhTP8fj0SsVf3WU/v7CY+6etISe/CBuDjl9fv50NkfHsP3nO6jFfabtfrziEQx0DD/ZuUe5zrrXuVh37Ensuk6HvriYjp4BeN9Xn/ce6M/h/K25I/ot/PxkGUkmKovRSFOWG3XpQFCXr6qkuu+7biqIcUBQlQlGUPxVF8b/eePp3asiSLScA2HfiHK6OdvjUdSiTxqeuA84Otuw7kQTAki0nGNCpobZ+x0AWbzkOwOItx80/EHuPJ5lbjPcdT6Keh1O5zw5p6090UibxyRXPkuAmXkQlZhJzLovC4hKW7ThN/0t+lPp3DGRJuLZPK3ZF0aNNPdO+BrJsx2kKikqIPZdFVGImwU28KrTNG6l/x0B+CT8JwP6Tpjx3uyTP3RxwdrBj3wntRP5L+Elz3vbvGGj+zrTvIvCK221W342dR85SXGIkN7+Iv2NT6XVTfUC74Hpt2M1M/bniFfPqjr+wuISCohIA7GwN6HUXP+fCxZuNQYetjQFjBXol1Pb4r9eJLbvISc24ekIrOXQ6nkAfdwK83bG1MTDw5jZsiDxaJs0v4fu4v9fNuDpp35unq3Z+CfL1pKGvdlHkU9cFD1cn0jKzqyTO6j4XXSgrAPZ2VVdWnFu0JD8hnvyzCRiLikjZtB73bt0vSWXE4OgIgI2TEwUp2h3dnJMnKEzV/s+NjkJvZ4vO1rZK4rycg6fjCfTxoIG3B7Y2Ntx2S1s2RBwpk+aXzXsZ1vsW3Mzl5+LFcNdWjXGyr9wFwLWqqnNRyvk8Ik+nUFhc9eeTSx2KPksD77oEeNXVjt+OLdh48ESZNL9uP8Cw0GBzI6Kni1aWbG0M2Nlo99YKioopKan++A+eiiPQx5MGPqby06UdGyL+KZPml017GBbWxXL5ad0EJ/s6VR5nVdXdLicpPdfccyM7r5DjZ9Lxc3esfPxWKPsXeqLZGPTYGPQYubbyVd11B4CtfyeQlVu+B11l6m7VsS97j58z1/33nzhHvVJl5HrzX/z7Sc+Kf4cPVVV9HUBRlOeAN4CnrmeDfh6OnEm5WJlPSM3Bz92JpPTci2ncnUhILZ0mGz8P7QTk5eZgTpuUnovnJSc7gGG9mrMhMq7c+4O7Nub3bSevLV53R85cEkuHJt5l05Tap+ISI5k5Bbg718HP3dF80gVISMs2/9heaZsvD+3I+Lvbs/XvBKYt2mu+8OzU1Js17w4mMS2Hd37aw7EK3mGwtA9+Ho4kZZTKcw/H8nluitXL1cGcNikjF09X+ytu95+YNMYPac/sVYdxsLOhW6t6HI/XLlYf7deStftjy3x2TYs/KSOXeh6OzH+hL0G+rrz78x4SS5XPBS/1o30TLzZGxrNi19V76dT2+P/tEtMz8XV3M7/2dXfl4On4MmmiE7Xuqo988A3FJUbG3HkrIW2blklz8HQ8hUXFNPD2qJI4rXEu+uiJHvRuH8Dx+HTeWlg1d25tPb3IP5dkfl2QnIxzi1Zl0sQvmE+Ldz/Ad/AQ9Pb2HHn1xXLbcQ/pSfbJExgLC8stq0pJaefxK1N+3DhwquzvT1SidtH18LS5lBiNjBnci5C2zao1Tqi6c9GVGDHy48T+GI1GftxwjIUbjt2o3THFkYVfXRfza5+6LhyMTiiTJvpcGgAjPvlJO35v60aPVo0AOJt2nmdm/UZscjrP39WzWntVACSln8fP42rlJxmAh6fOoaSkhDF3hRHSrnrLT1XW3To19eHPqXeTmJ7D2z/uKle3CfBypm1Dz+u6K26Nsq/X6Vj59iCCfF2Yv+4IESeTa0TMFdnupSpTd6uOfSltWK9mbDhw8bf7evP/X0Uvw0AsqZWNFYqiLAUaAPbAp4ABaKSq6sum5Y8CnVRVfVZRlNeBB4FYIBnYq6rq9Mts9zm0i/wi4G9VVYcpinIL8AngAOQCI1VVPXrJek7A50A7tDz9n6qqvyuK0gb4FrBD68Vyr6qqx6+yb87A74A7YAtMVlX1d9Myi/uiqur5UptwgutvltShK/fepXfsdOWTUNGbet1b12NYrxYMeats5xRbg57+nQJ5b9G1VbgrG4vxCutaetzxhW2+t2gvSRm52Nnoee+x7oy5sx2fLo3kUFQKXZ9fQk5+Eb3b12fu+DB6vvTrDdsHC0mu+mVfbrubD52hfWMvlr5xBymZeew7kURRcQm+dR2445YglKmrKxT31T6nTBoL61U2ftAqYv1fW4ZvXQfmjg9jxa4oks/nAfDQh2upY2vgszGh9Gjjx5ZDCeU39C+K/7/o0qwtLikhJimVeS+MIDHtPI9++B2/ThljvlN7LiOTSd8u5Z1H70Kvt/Rt3oCYqvlcBPDCnK3odTrefqQLg7s0Qt1yovwK16sCO+bZK4zktWs4++tinFu1pslLr3LwqcfN6RwaBtHgsSc5+trLNz6+q7D0FVy6S8UlJUQnpfDNSyNJTDvPiA++4bc3x+LqWL6xvSpV1bnoSu55ayWJ6drFxcKJ/Tl5JoOdRxOvY4uXxGbhILh0H4qKjUSfS2fuswqJ6VmM/PRnfnllBK6O9vi5u7LklREkZWQxfu7v9Gvf3NxzqjpYOobLlZ/iEqITU/jm5ce08vPeXH57+5lqLT9VVXc7GJVCl3GLyMkvIqx9APMm9CX0hSXm5Y51bJg9vg//+2EHWbmVb4i0RtkvMRoZOHkZro52zBnXmxYBdTkaV/FhLNaoO1hS2brbtX7m9eR/t1Z+3N+zGfe8s8r83vXmv/j3q5WNFcBjqqqmKoriAOwG+gBbgQs1oPuBdxVFuRm4F+iAtq/7gL1X2O4raI0e+Yqi1DW9dwToqapqkaIofYGppm2W9hqwXlXVx0zr7VIUZR1aw8enqqr+qCiKHVqjytXkAUNUVT2vKIoXsENRlGVApyvti6Io7wKPABlA73Jb1dI8CTwJgG35CfRG9GvFA6bxb5GnkvH3vFgRqOfhSGJ6Tpn0CanZZYZx1PNwIjFNS5OckYtPXa2F3qeuAymlWmVbNXDng1EhPPzBGtIvGR/bOziAg1Ep5gu2ikpIzcH/0lguifdsag7+nk6cTcvBoNfh4mhHela+tm7pfXW/uO7ltnmh5bigqAR18wlG365N1le6S/aGyHjeHaHH3bnOZccBj+jbkuG9mgOmPL9Mfpbez8vm+flcfNy0Vm0fNwdSTHloMW9M63y+7ACfLzug/T+mJ6cTz9OmoSdBvq5sma4Vcwc7G7ZMv4fQF8s3ulg7/gsS03M5Fp/OLS18y8wjkl9YzNp9sfTvGGjxYr+2x/9f4lvXhcS0i8NUEtPO413qTi1ovS1ualQfW4OBFTm+VgAAIABJREFUAC93gnw9iUlKoW1QfbJy83n685949q7etG8cUGVxVve56IISo5HlO08z+va2VdJYUZh8jjreF8fn23l5UZBa9g6Y14DbOfbaRACy/vkbnZ0dNq5uFGWkY+vlRbPX3+TU9GnkJ5y54fFdja+7K2fLlJ8MfCyVn8YB2NoYCPB2p5GvJzGJqbRtVL/K46uOc9GVXOjVlXI+j9V7Yghu4nVDGyt867pwNj3T/DopPbNc7wjfus7cFFRPO3493Qjy8SDmXDptG/qZ0/i4OdPEz5N9p+LpF9z8hsV31fjdXTmbepXy4+FWtvz4eRGTmELbRlV3voHqqbuVboBYHxnHu4aLdRsbg47Z4/vw29aTrLqGucbM8Vu57F9wPqeA7UfO0uum+le9WK4pdYfSrqXuVt37AtCygTsfPt6dh6evK1f3h2vLf/HfUlvnrHhOUZRIYAdaD4tGwClFUboqiuIJtEBrvAgBfldVNVdV1Uyg/CxDZR0AflQU5SG03hUAbsBiRVEOAR8DlqaQ7w+8oihKBLARrcdHILAdmKQoykSgoaqqFemXpQOmKopyAFgH1Ad8r7Yvqqq+pqpqA+BH4BlLG1ZVdbaqqjerqnqzpeXz1/7DgElLGTBpKav3RHNfqNZ9umNTbzJzC8t0IwSti2BWbiEdm2rdke8Lbcqfe7UfqrX7YhgaqnV/HBrajD/3xQDg7+nEnPF9GTdzE6fPnudSd3Vrcs1DQEA7wQb5udLA2xlbg57BXRuxdl9smTRr98dyX4i2T3fcEsTWvxNMscYyuGsj7Gz0NPB2JsjPlYiTyVfcZukxfAM6BZpPrN6l3g9u7IVexxUnLJu/7ggDJy9j4ORlrNkbw70hTQDo0MSbzJyCcl35kjJyyc4rNHcBvzekiTlv1+6LNX9n94U2LfO+pe3qdTrqOmtjaFs2cKdVoDubD55hfWQcnZ5dRPcJS+g+YQm5BUWX/bGzZvx+7o7Y22rtf26OdtzczIdTCRk41rExfz8GvY6w9gGcOGN5LobaHv9/SZug+kQnpRKXnEZhUTGr9xymV/uyFyu927dg19EoANKycohOSiXAy53ComLGz1zEoK430b9T6yqNs7rPRUE+Fy+Y+nZowMmEqikrWUePUMe/Pna+fuhsbPC8NYz0HdvLpClISsS1Q0cA7BsEorezoygjHYOTEy3emkbst3PJ+vv6nhRQWW2D/IlOTCXuXBqFRUWs2nWIXu1blkkT1qElu49oE9mmZWYTlZhCgLd7tcRXHeeiy3GoY4OTvY35/57t/Dkae2MvFtoE+hFzLp24lAzt+N13lFvbNimTJuympuw+rpXrtKwcos+lEuDlRmJ6JnkF2sXy+Zw8Ik6fIciner6XC9o2qk90YsrF8rPzIL2CLy0/rcqWn7PJBFTRcLPSqqPuVr5uozPXbaY/EcqJ+HTmrDpUufitWPY9XOqYJ6O0tzUQ2sa/Qr+31qw7XM611N2qe1/8PZ2YM64342ZtKVP3r2z+/2vpDTX/zwpqXc8KRVF6AX2Bbqqq5iiKshGtcWARoKD1hPhNVVWjoijX2s/3DqAnMBh43TSM421gg6qqQxRFCUJrjLiUDm2Ix9FL3v9HUZSdpu2uURRllKqq668Sw4OAN9owlkJFUaJM+1fRfVkIrACmVDC9ResjYgkLDiB8xlDyCoqYMGuLedmaqXebn9wx6dttzBjdE3s7Axsj41hvmoPii+UH+PrZMIb1ak58cjZPfaY9HeP5IR2o61KHqSO1idmKiku44/VlgDY5XM+2/rwyL/ya4y0uMfL69ztY8FI/DHodizaf4Fh8Oi/cE8yB0yms3R/Lz5uO88lToWyZfg/pWfk8/eUmAI7Fp/PHzijWv3c3RSXGi4+JNGJxmwCfje2Jp4s9Oh0cjk7l1W+1SvvtnRvycJ8WFJcYySso5umvNlU8zyPjCAuuT/j0e8gtKOaFORfzYfU7gxk4WcunSd9t1x4ZZWtgw4F4NkRqY/++/OMgM5+5lWG3NiM+JYsxn2+84nZtbfT8Mvk2QLtr8tzMLRRfx8Rl1R1/s/puvD68s9Z9Hpi16jBH4tLxcrXnmwl9sLPRo9fr2Pb3WfMjQf/N8V+vxxd+RvNeXXH2cmda7HaWT/mYbd+oVf65FWVj0DNp2G2M+fRHikuM3P1/9u47PIqiD+D49+6SkIQQEgIkEEpCUXoRpIN0Il2EEQsCdkUREeUFUbDhqyKCigiiomJhKC9SBERBeu9FlE5CC6QAaYTk7v1jL0cqCWmX4O/zPDzk9mZnf7M7t7c7NzPbuhE1KpZn2uI11KlakQ4N76R13epsPnSMvhM+x2wyM/L+zvh4ebJ0yz52HTnN5dh4Fm82HiX89pA+1KockM1Wb11hnotMJpj8dBtKebhhMsGh05GM/WZLvpcJAKuVU59/Sq133wezhYu/LSf+1EkCBw0h9sg/RG/ZxOkvvyD4xZcJuK8/NpuN4x99AIB/7/soUbEiFR8aRMWHjMc2/j32VZIuF96vZy4WC2Mf6s4zU74n2WrlvtaNqRFYns8WraZuUEU6NKpF67o12HTwGH1e/wyz2cTLA7ri42WMxR78/lecOHeJuGuJdHrlI94a3IfW6eZDyS8FdS4qV9qDZW/1xMvDFasVHu9Wh46jF1GmVAm+HNERMBpIf9l8gj/3p50PJq9cLGbG3N+RZ6cvwGq10rdFPWpUKMu0XzdSt7I/7evXoFWtIDYdPsV9E7/BbDbzUp978CnpwebDJ/lo0VpMJhM2m43BHZtSs2K57Dear/FbGPtIT56Z/K1Rf9rcRY1Afz773x9G/Wlcm9b1arDp4FH6vPaJUX9Utxv1571ZnDh30ag/L3/IW0P70roA5kMpqGu3Hs2CGNS5NsnJVhKuJ/PcZ2sAuPsOf/q3rclfpyNZObEvAO/P3eHI75bjL+S6X97Hk4+faoPFbMJsNrFk60n+2HNrsRf2tQPAgnH3Ur1CaUq6u7Bt6gBembXR8ZjrvCiosozo2xAfrxK8O7glgOPxyPmx/8Xtz1QYs8znJ6VUH+AJrXUvpVQtYA8QAuzFGBZxChittd6mlLobmAG0wmiY2Ql8mdmcFUopM1BFa31SKeUKhGH00PgGmKO1XqCUmgAM0VoH2RtNRmmteyqlJgLewAv2RpLGWuvdSqlqwAn7sinASa31lCzKFaO19lJKvQjUsM+30QFYjdFzpFxWZVFK1UyZC0Mp9QJwj9a6/832Y6WHvypeBz6VMz8+QaVHvnF2GLkWNmeoxO9Et0P8T1PV2WHk2gxOkbBmjrPDyDX3Do8U+/qztVumIwWLheYr13Bt3U/ODiPXSrR7sNjXn/jlM5wdRq553Ps01zbMdXYYuVKizQMABD40y8mR5M6ZH58AKLb1P2zOUEDid5awOUOx2WwFM9lUERG/dFqRvzfz6Dms0I9BcRwGsgJwsQ+TeBtjKAha6yjgEMZwi232ZduBxRgNGQuBHRhzOmTGAsxRSu0HdgMfa62jgQ+A95RSG8l6zom3MSbD3GcfLvK2ffkDwAH78JBawHc5KN8PQFOl1A6MXhaHc1CW/yqlDtj3SVfgxRxsRwghhBBCCCGEk5nM5iL/zxmK3TAQrfU14N4s3uuZyeJJWusJSilPYB3wURbrXseYFyL98s1A6oHRr9uX/4l9SIh9LoqnM1n3PeC9rEuTJq2X/f9LQMsskmVaFq11+gk/hRBCCCGEEEKIYqvYNVbkwkylVB2MeR++1VrvcnZAeXA7lUUIIYQQQgghhMjUbd9YobV+KP0ypdQ0oHW6xVO11gU6kMv+pJI/Mnmrk9Y6Irv1MyuLEEIIIYQQQohizElP2yjqbvvGisxorYc5absRQCNnbFsIIYQQQgghhCguiuMEm0IIIYQQQgghhLiN/St7VgghhBBCCCGEEEWCDAPJlPSsEEIIIYQQQgghRJEijRVCCCGEEEIIIYQoUqSxQgghhBBCCCGEEEWKzFkhhBBCCCGEEEI4icksfQgyI3tFCCGEEEIIIYQQRYo0VgghhBBCCCGEEKJIkWEgQgghhBBCCCGEs8ijSzMlPSuEEEIIIYQQQghRpEhjhRBCCCGEEEIIIYoUGQYihBBCCCGEEEI4iwwDyZT0rBBCCCGEEEIIIUSRIo0VQgghhBBCCCGEKFJMNpvN2TEIJzCZTHLghRBCCCGEEEWezWYzOTuGgpS4/ucif2/m1nZgoR8DmbPiX6rSI984O4RcC5szVOJ3IonfucLmDCVhzRxnh5Fr7h0e4WmqOjuMXJvBqWJff3aHRTk7jFxrXMlX6o8Thc0Zykfrjjo7jFx7uV0NXjAHOTuMXPnUehKAigNnODeQXDr789NA8b3+DJszFJD4nSUlfvHvI8NAhBBCCCGEEEIIUaRIzwohhBBCCCGEEMJZzNKHIDOyV4QQQgghhBBCCFGkSGOFEEIIIYQQQgghihRprBBCCCGEEEIIIUSRInNWCCGEEEIIIYQQzmK2ODuCIkkaK4QQQgghhBBCCJFrSqkQYCpgAWZprf+bSRoFTABswF6t9UM3y1OGgQghhBBCCCGEECJXlFIWYBpwL1AHeFApVSddmprAGKC11rouMCK7fKVnhRBCCCGEEEII4SSm4j8MpBlwVGt9HEAp9TPQBziUKs2TwDStdRSA1jo8u0ylsUIIIYQQQgghhBC5FQiEpnodBjRPl+YOAKXURoyhIhO01itulqk0VgghhBBCCCGEECJLSqmngKdSLZqptZ5p/9uUySq2dK9dgJpAe6ASsF4pVU9rHZ3VNqWxQgghhBBCCCGEcBZz0Z9K0t4wMTOLt8OAyqleVwLOZpJmi9b6OnBCKfU3RuPF9qy2KY0VQgghhBBCCCGEyK3tQE2lVDBwBhgIpH/SxyLgQWC2UqosxrCQ4zfLtOg34QghhBBCCCGEEKJI0lonAc8DK4G/jEX6oFLqLaVUb3uylUCEUuoQsAZ4RWsdcbN8pWeFEEIIIYQQQgjhJLfB00DQWv8K/Jpu2Rup/rYBI+3/ckR6VgghhBBCCCGEEKJIkcYKIYQQQgghhBBCFCkyDEQIIYQQQgghhHCW22AYSEGQxgqRpTcHNaNjw0rEX0ti5MwNHDgVmSFN/SA/Jj/VBnc3C6v3hjH++20A+JR0Y9rz7alc1ovQSzE89+mfXI5LpG+rajzXox4AsdeSGDt7M3+djqKEq4X5r4Xg5mrBYjbx6/ZTTF64p0jEnFW+gX4lmfliByxmMy4WE7NXHWbO6r/TbOvrlzpSpXwpOo/5JdvYc7IPKvqV5OOn2uDt6YbFbOI9vZM1e8/keP+4uZiZ8nRb6gf7ERVzjec+W0vYpRgqlfVizft9OXbuCgC7jl5k7OzNOc43RWHu/zpVyjBxSAu8PFyxWm18ungfS7aeBKBVnQDGPXg3bi5m9p2I4JVZG0m2pn/Uc9GNv3WdCrz2YFPMJhOxCdd5eeYGToZfveXjkd6GA0d5X6/EarXSr01jHg9pkyHNyh0Hmb50LSZM3FHJn/ef6Mfh0PO888MyYhMSMZtNPHlvW0LurpvnePLToK8+oH7PjlwNj+Dt+t2cHU6RqUv5ac+2zcz+bDJWq5WO3XvT96HBad5ftXghK3+Zj9lsxt3Dg6dGjqFSUDXH+5cunGfk0IEMGPwEvR54JN/jy4t/Q/2pXqE0Hz3ZmnpBfnw4fxczfj3oyGvT5P7EJlwn2WojOdlKj/FL871Mpw/sYNNPM7BZrdRq243G3VWa9/f9tpC/1q/EbLbgXqo07YeOoJSfP1cjLvDbtHex2axYk5Oo17EXddr3yPf4slO7Wzv6fTwes8XM5q/m8vsHX6R537dKIA/Neh+vcn7ERUbz/aMvEX3mPAC93xtNne4dAFj57qfs1ssKLM63BreiY6PKxCcm8dL0PzlwMuPcdfWDy/LxM+2NurMnlDe+3QSAT8kSTH+xE5XLliL00lWemfo7l2ONc0/L2hV489GWuLiYibyaQP+3jDry5L31ebDjndhscDg0kpFfrOXa9eRbirkwz5ctawcw/uFmjnyrVyjN85+vZeXO0zf24aDmqHY1qPXkD7dUjsIq280+y8Ut3sI494jiTYaBiEx1aBhIsL83bUctZPTXm5k4tGWm6SYOacHorzfRdtRCgv29ad8gEIDnetVn48FztHtlIRsPnuO5XvUBCL14lQHvrqDra4uZumgv7z/WCoBr15N54L2VdHttMSHjFtO+QSCNq5crEjFnlW94dDz3vfUrIeMW03vCMp7rWR9/Hw/HdkKaViE2ISnH8edkHwzv04Cl205y7+tLGDZtLe8OzryMWRl4T02iYxNpO2ohs1YcYuwDTRzvnQq/Ssg4Y9u5aago7P0fn5jEiBnr6TzmFwZ9uIrxjzTD29MNkwk+fqotw6atpfOYXzhzKYb+bWsUm/hTtjF8+jpCxi3ml83HGd63YU4PQ5aSrVYm/rSc6S88xKIJz7F8+0GOnb2YJs2pCxF8tWIj370ylP9NeJZXlXHT5u7myrtD+/K/Cc8yffjDfKBXciUuIc8x5afNs+fzacjg7BMWgqJUl/KLNTmZr6d+yJj/TmHyNz+zcfVvhJ1M+7Sx1p26MumrH/ngyzn0fmAQ302fmub9bz//mEbNbu2cVVj+DfUnOvYa47/fysxfD2San5q4gpBxiwvkZsFqTWbjD5/TfcRbqLe/4Oi2tUSdPZ0mjV+V6vQbN5UBb35OtSZt2DLvawA8S5eh75iP6D/+M+4b+zG7l88jNvqmk8fnO5PZzIBP3+KLHkOYWK8rTQb2JqB22u+Vvh+OZfuchbzf+F5WvPMJvSa+CkCd7h2odFc9PrirB5Nb3kenl5/CvZRXgcTZsVFlggO8afPSXEZ/uZ73Hm+babr3HmvD6FnraPPSXIIDvOnQsDIAw/o0YsOBM7QZOZcNB84wrHcjALw93Zj4WBuGTFpJx1fm8/SU3wEI8PXksZC6dB/7Pzq9Oh+L2USfltVvKebCPl9u/uu841pn4HsrSEhMYu3+Gz/6NAj2y7fzp7M+y8Ut3oI894ji71/dWKGUmqCUGlUE4mivlMr1J1QptUIptVcpdVAp9YVSKs/9iLreVYUFG44BsPvYRbw93Shf2iNNmvKlPfDycGPXUeOGZ8GGY3RrUsWx/vz1RwGYv/6oY/nOIxcdLd67j16kgq+nI7+4a8aNvYvFjIvFjI3sfwkvjJizyvd6spXEJCsAbq4WzKYb2/Es4cKTIXX55Je9t1SG7PaBzQZe7q4AlPJ040J0HABmk4nXBjZl6Zs9+e3d3jzc4Y4s99H8DUYZl207Seu6FW4pvpsp7P1/4vwVTl4wehtciI4n4koCZUqVwNerBIlJyZw4b/QSWX/gLN3vrlps4gewAV4eqY5zVFy28WfnwIkzVCnvS6Vyvri6WAhpWpc1e9P2BFqwYRcPtG+Kd0mj3H7eJQEI8vejqr+fsQ98SlHGuyRRV2PzHFN+Orp+G3GRl50dBlC06lJ+OXr4EP6BlfCvGIiLqyutOnZh+6Z1adJ4lrxxA3YtIR6T6cZJcfuGtfhXCKRyqp4WRcm/of5EXElg74kIriff2ndrfgg/8Q/e5SviXa4CFhdXajRrx8k9aRvFA2s1xLWEOwD+1WsRG3UJAIuLKxZX43yYnHTd+CIsZFWbNeTisVNEnAgl+fp1ds1dQv3eXdKkCahdg3/+MHooHFmzmfq9O9uX1+To2q1Yk5NJjIvnzL6/qB1yT4HE2a1JEPPXHwFg19FwSnu6Ud4nXd3x8aCUhxs7j4QDMH/9EUKaBtnXr8q8df8AMG/dP47l97WuwfLtJzgbYZz3I67caKx2sZhxd3PBYjbh4ebC+ahb+24o7PNlat2bBbFmXxgJiUZPkJRrqYk/77ilMhR22Qrqs1zc4r3tmM1F/58zdotTtlqIlFImpdTtXk6ltW4I1APKAQPymmGArydnI2984ZyLjCWgjGfaNGU8OZc+jb3xoay3B+GX4wEIvxyPn7d7hm0MbF+TNftutGabTSZWvNObPdMGsv7AWfYcu1QkYr5ZvhXKePLbu73ZNmUA05cd4EK0sf4r/Rvz5fKDxCfeWlfI7PbBxwv30K91dbZNHcC3ozrzxndbAWNfXo1PpOf4pfQcv5SH2t9B5XIZf7kJKOPpuNhIttq4GpeIr5dxU1O5nBfL3+7FvNdCaHZH+VuKG5yz/1M0qlYWV4uZU+FXibx6DReLmQbBxs1192ZBVCxTstjED/DqrI1893Jntk0dQL/W1Zm2ZH+28WfnQvRV/H1LO177+3oTHp12aMmpC5GcuhDBox98zcP//YoNB45myGf/iTNcT0qmcrkyeY7pdlWU6lJ+ibwUjl95f8drv7Llibp4MUO6lYvmMfzhfvww8zOGPG88mSwhPp5ffv6O/oOfyNeYbleF8f2bng0bP4zuyrK3evJQFo3deREXFYGXb1nH65K+ZYmNyrp3xOH1K6lSv6njdUzkReaNf44fXh1Mw5D+lPTxy/cYb8YnMIDo0HOO19FnzlM6MCBNmjP7/qJhvxAAGtzXDXfvUniW8eHsvr+oE3IPrh7ulPTzpWb7lvhUyr8fClIzvuNjHK+NulMyXZqSnItMlSbiRv0qW9qDcPt1THh0PH7exo1qtQqlKV2yBPNe78nyd++jf9uaAJyPiuOLpfvY9tlD7J7+CFfiElm3P+dDU8G558veLYL5ZfMJx+shXWqxaneoI7+8csZnubjFW9DnHlH85eucFUqpRUBlwB2YCliAYK31q/b3hwBNtNYvKKVeBx4GQoFLwE6t9aQs8v0T2AM0A7yBx7TW25RSE4CYlPWUUgeAnvbVlgNrgJZAX6VUbWCiPaZLWutO9nR17PlXAaZorT/JrCxa65n2HgtfAU0xfvz8Wmv9sVKqOjANo6EgDnhSa31YKTUAGA8kA5e11u1ysA+bAVMADyAeGKq1/lsp5QnMBmoBfwFBwDCt9Q6t9RX76i6Amz22PEn1g5hD+h8zMkmS4w23rB3AA+1q0u+d5Y5lVpuNkHGL8fZ048sXO3BnJR/+Dot2esw3y/dcZBxdX1uMv48Hs0Z0ZNm2k5T38aSqvzdv/rCdSmVvratndvugT8tg5q0/yszlB7mrRjmmPNOWzmMW0a5eRWpX9qX73UEAlPJ0Jdjfm9CLMVlsKVVZgPDoOJqPmE90zDXqB/kxa0RHOv1nETEJ13McuzP2Pxit/FOeactLMzY4lg+btpbxDzfDzcXMugNnSUq2ZrOVohX/EyF1efSj39lz7BJPd6/LGw/fzatfbcpmS7cufWjJViunwyP56uXBXIi6wpAPZ7Nw/LN4exoXHBcvX2XsN4t4Z0gfzObM9oaAolWX8kum+WUSULe+A+jWdwAb/ljJwjnfMOw/45k3eyY9+j+Iu4dnJpmI9Ar6+zcz/d76lQvRxs3Fj6O7cuzsZbb+fSEPOaaPLZPoMiso8M/m1Vw8dYTer3zgWOZVphwD3vyc2OgIVn72NtWatMGztG++xZetTGK1pTsoi16ZyIBP36T54P4cXb+N6LBzWJOSObxqPVWaNuClDQuIuRTJyS27sCblfIjorYWZWZzp0mRSe7I7X1jMZhoEl0W9uwx3NwtL3uzLriPhRFyNp1vTqrQY/hNX4q4x48Uu9GtTg4UbMjZ0Zx1zxmWFdb6sVcnXMQTE38eDHs2CUBNXZJNzzjnjs5wXt+O5RxR/+T3B5mNa60illAewHegEbARetb//APCuUqopcD/Q2B7DLmBnNnmX1Fq3Ukq1A77G6EVwM3di3Og/p5QqB3wJtNNan1BKpf5JsBbQASgF/K2Umq61vp6+LEqpBRgNBIFa63oASikfex4zgWe01keUUs2Bz4GOwBtAN631mVRps3PYHmeSUqozRgPL/cBzQJTWuoFSqh5G442DUmolRmPOcmB+ZhkrpZ4CngKgRPcM7w/uXIsH2xutmnuPX0rza3SFMiUzdEU/FxlHhSzSXLoST/nSRgtr+dIeaboM1qrsy4ePt2LQpN+JjrmWIY4rcYlsPnye9g0Cs22sKIyYz0XGZZvvheh4/jkTTbM7/fHzdqdBkB+bJvfHxWLCz9sdPTbklr4As9oHD9xTk0EfrgKMSTBLuFooU8odkwne+H4ra/efTZPPq/0b07GRMRY1ZNxizkfGUdGvJOej4rCYTZTydHMcg0T7//tPRnAq/CrVKniz78TNxwU7e/97ubsye1RnPpy/i93HbvzKu+voRe63N4S1q1eR4ADvYhN/mVIlqFPF19GrZsnWk3z/Struxrnh71OKC1E3urlfiLpCOZ9SadP4etMgOBBXi4VKZX0J8vfjdHgE9YICiYm/xrBPf+KFPh1oWK1SnuO53RTFupSf/MqVJyL8xgVkxKVwfMuWzTJ9qw5dmDXlfQCOHj7I1nVr+GHGZ8TGXMVkNuPqVoKQ+/LcCfC2UVjfv1lJ6RUYcSWBFTtO06h62Xy9YSjpW5aYqBs9BWOjLlHSJ2PvrLBDu9m9bC69X33fMfQjTT4+fvhWrML5Iwep1jTjBMEFJTrsHD6Vb/SG8AkM4MrZtPvnyrlwvur/LABuJT1p1C+EhCtGD6ff3pvGb+9NA+DROVO4ePRkvsU2uEsdHu5YC4A9xy9S0c8LMGIz6kXaYRnnImOoUObGDykV/FLVncvxlPcxeleU9/Eg4kq8Y53IqwnEX0si/loSWw6fo05V4/idDr9K5FWjji3ffoKmd/hn21jh7PMlQM/mQazYeYok+9CEulX9CPL3Zv2k+wHwcHNh/aR+tB218KZlcUbZ8pOz4y3oc48o/vJ7eMRwpdReYAtGr4Rg4LhSqoVSyg+jAWEj0Ab4RWsdr7W+CizJQd4/AWit1wHeObj5P6W13mL/uwWwTmt9wp5H6qltl2mtr2mtLwHhQEo/1/RlqQkcB6oppT5VSoUAV5RSXkArYJ4r0s/tAAAgAElEQVRSag8wA0j5RtsIzFZKPYnRoyMnStvzOgB8DKRMud8G+Nke/wFgX+qVtNbd7NstgdFQkoHWeqbWuqnWumlm73/7+2HHpEMrd57m/jbGJEmNq5fjalxihm5x4ZfjiU247pgE8v421fltlzFh1qpdoY5JDfu3reFYXtGvJF++2IEXZ6x3zCkAxg1ayoRG7q4W2tatyNGz2Y8fLoyYV+0KzTTfAF9P3F2Nw1ra042mNctz/Nxlvv/jb5oO17QaOZ9+by/nxPkrOWqoyMk+OBsRS5u6FQGoUbE07q4WIq4ksHb/WQZ1qoWLxWjzDg7wxqOECx/M3+3YPwCrdofSv41Rxh7Ngth46Jxj22Z7k3qVcl4E+5fidA66kTtz/7tazHw5ogMLNhxj2bZTabaT0vXQzcXMsz3rZXhKS1GO/3JsIqU83RwNLG3rVeTo2Zz3MMpK3aBAToVHEnYpiutJyazYcZD2DdN2uezQ8E62/X0SgKiYOE6FR1KprC/Xk5IZMX0uvVo0oGuTOnmO5XZUFOtSfqpeqzbnz4QSfu4sSdevs2n1Kpq2TNtZ8FzYjQkTd2/ZSIVAo6H0zakz+eynRXz20yK63z+Q+x4aLA0V6RRG/cmKRwkXSrq7OP5uV78if4fm/ZyTWvmgO7h84SxXLp4nOek6R7eto2rDFmnSXDp9jPXff0rIC2/g4X3jEi8m8hJJiUZj+rXYq1w4dojSAYH5Gl92Tm/fR7kaQZQJqoTF1ZW7HujF/iW/p0lT0s/X0bOhy3+eY8s38wBjck7PMkZ5KtavRcX6tTj82/p8i+3bVYfoOmYhXccsZOWOk44hGnfVKM+VuETHsI4U4dHxxCQkclcNY7hn/7Y1WbnzJAC/7TzFgHbG98KAdnewcqdxPlm54xTNawVgMZtwd7PQuEZ5jpyJ5sylGO6qWR53N+NaqE29QI6cyb7uOPN8maJPy2pphoCs3htGkxfm0mrkfFqNnE98YtItN1QUVtny0+1+7ilOTBZLkf/nDPnWs0Ip1R7oDLTUWsfZh1a4A3MBhdFj4H9aa5tSKjf9h9P3MrIBSaRtcEk9OCp1U7Ipk/VTpP5pPxlwyaosWusopVRDoBswDKNcI4BorXWj9BlrrZ+x97ToAexRSjXSWmc3hfXbwBqt9X1KqSDgz1RluCmtdYJSajHQB1iVXfqbWb03jI6NAtkwqR/xicm8/OUGx3sr3untuPkdO3uz8fgiVwtr9p1xPEZz2tL9TH/+HgbeU5MzETE8+6lRjBF9G+LjVcLxFIuUxxSV9/Hk46faYDGbMJtNLNl6kj/2hBWJmLPKt2ZgaV5/8G5sGAdnxvKDHL6FYSvpZbUPXu7XiH0nIli1O5S3f9zO+4+34omQOthsMHKmEctPf/5D5bJeLH+7NyaT0UL9xJTVGbbx89ojTHmmLesn9SM65hrDpq0FoPmdAbx8fyPj0VFWG2Nmbyba/riynCrs/d+zeRDN7wzA18udAfYvx5EzN3DodCTPdK9Hp0aVMJtNfP/H32w6dL5YxT/6q03MHN4Bq83G5dhERqWKJbdcLGbGDryXZ6f+QLLVRt/WjahRsTzTFq+hTtWKdGh4J63rVmfzoWP0nfA5ZpOZkfd3xsfLk6Vb9rHryGkux8azeLMxaezbQ/pQq3JANlstPI//+Al3tG+BV1lf3gvdzJLxH7Ppa+2UWIpSXcovFosLj70wiomjh2NNttL+3l5UDq6G/mYG1e6oTdPW7Vi5aB77d27H4uJCyVKleG70+HzbfkH7N9SfcqU9WPZWT/sjbuHxbnXoOHoRZUqV4MsRxm8cFrOJXzaf4M9bnHcgO2aLhTYPPcuvU8Zhs1q5s3VXygRWZfui7ykXVJOgRi3YMu8rricksOqL9wBj6EfIC+OJPneazXqW0UfdZqNB1/vxqxScr/Flx5qczPzh43lu+XeYLWa2fDOP84eO0H3CS5zeuZ8DS36nZvsW9Hz3FbDBsfXbmPf8GwBYXF0YsdaoSwlXYvj+0ZewJt/afFY59cfuUDo2qsLGKQONR0/O+NPx3m/v9aPrGOPme8zXG+yPLnVhzZ5QVu8JBWDa4j188WJnHmxfizMRMY6nfhw9G82avaH8/n5/rDYbP605zN9hUQAs23qClRPvJ8lq5eDJCH74469birmwz5cAlcp6UbGMJ1sOZ39tkBeF/Vm+laG7RSHewjj3iOLPlH7MXW4ppfoAT2iteymlamEMUwgB9mIM8TgFjLbPNXE3Rg+EVhgNJjuBL7OZs+Kw/ea/DTBda11fKfUI0FNrPVApdRfG0JOUZyYtTTVcoxzGUBPHMBD7EI8JZD7nRcMsynIASNRaX1FKNQJma60bKaU2AR9rrefZG2IaaK33KqWqa62P2fPejTEsJc3wDft77YFRWuueSqn/AXO01gvs8Q3RWgcppV4Bqmmtn1VK1bHv15YYjUCltNbnlFIuwA/Aeq31Zzc7XpUHzS62U/KGzRlKpUe+cXYYuSbxO9ftEH/CmjnODiPX3Ds8wtNk/3SWomoGp4p9/dltv8kojhpX8pX640Rhc4by0bqcz0dQ1LzcrgYvmIOcHUaufGo9CUDFgTOcG0gunf35aYBiW//D5gwFJH5nCZszFJvNdltPlpV84I8if29mqdep0I9Bfg4DWYHRK2EfRu+ALQBa6yjgEFBVa73Nvmw7sBjjhnshsAPIrs9/lL1R4AvgcfuyBUAZ+/CLZ4F/MltRa30RY66GhfahHXNzUxYgEPjTvr3ZwBj78oeBx+15H8To2QDwoVJqv70RZJ29vNn5AHhPKbWRtENHPgfK2WMajTEM5DJQElhsX74XYyjLFznYjhBCCCGEEEIIZzNbiv4/J8i3YSBa62vAvVm81zOTxZO01hPsT7lYB3yUzSYWaK3HpF6gtY4HumaRvl66tMsxJp9MvWxCutep18m0LMBd6RfY58IIyWR5vyzySJ/uT+zDPbTWm4HUA8lft/+fADxiH+pRHfgDY16ORODunGxHCCGEEEIIIYQoDvL7aSC3YqZ9OIM78K3WepcTYykOPIE1SilXjCkSnrU3VAghhBBCCCGEELcVpzVWaK0fSr9MKTUNaJ1u8VStdftCCaqAKaW6Ae+nW3xCa31fduvan5qS6VM8hBBCCCGEEEIUU04aZlHUObNnRQZa62HOjqEgaa1XAiudHYcQQgghhBBCCFGU5ecEm0IIIYQQQgghhBB5VqR6VgghhBBCCCGEEP8mJrP0IciM7BUhhBBCCCGEEEIUKdJYIYQQQgghhBBCiCJFhoEIIYQQQgghhBDOIk8DyZT0rBBCCCGEEEIIIUSRIo0VQgghhBBCCCGEKFKksUIIIYQQQgghhBBFisxZIYQQQgghhBBCOItJ+hBkRvaKEEIIIYQQQgghihRprBBCCCGEEEIIIUSRIsNAhBBCCCGEEEIIZ5FhIJmSvSKEEEIIIYQQQogiRRorhBBCCCGEEEIIUaSYbDabs2MQTmAymeTACyGEEEIIIYo8m81mcnYMBSn5xK4if29mCb6r0I+BzFnxL1XpkW+cHUKuhc0ZSuBDs5wdRq6d+fEJqgz9wdlh5Nrpbx6m8uDvnB1GroV++2ixj7+4f36Le/xPU9XZYeTaDE4V+/1f3OO/OHWks8PItXIvTi72+7+4xh82ZygAF6JjnBxJ7vj7eAHF9/ozZf8X1+uH0G8fBYr//hf/PjIMRAghhBBCCCGEEEWK9KwQQgghhBBCCCGcRZ4GkinZK0IIIYQQQgghhChSpLFCCCGEEEIIIYQQRYoMAxFCCCGEEEIIIZzFdFs/7CTXpGeFEEIIIYQQQgghihRprBBCCCGEEEIIIUSRIo0VQgghhBBCCCGEKFJkzgohhBBCCCGEEMJZzNKHIDOyV4QQQgghhBBCCFGkSGOFEEIIIYQQQgghihQZBiKEEEIIIYQQQjiJzSR9CDIje0UIIYQQQgghhBBFijRWCCGEEEIIIYQQokiRYSBCCCGEEEIIIYSzyDCQTMleEUIIIYQQQgghRJEijRVCCCGEEEIIIYQoUmQYiBBCCCGEEEII4SwyDCRT0lghMtW+fiATBjXDYjbx059H+Hzp/jTvu7mYmfJ0W+oH+xEVc43nPltL2KUYAIb1qs/Ae2qSbLUx/vutrN1/Nkd5vjWoOapdDWo9+UO+lOGtR1vQsWFl4hOTeGnGOg6cjMiQpn6QHx8/0w53VxdW7w3lje+2AOBT0o3PX+hI5XJehF6M4dlPVnM5LpGWtQP4amQXQi9eBWD59pNM+d8eADZPUcQmXCfZaiMp2UqP1xfnOvZ76lVg/ENNsJhM/Lz+GNN/PZTmfTcXM5OfaEn9qmWIir3G89M3EhYRC8Bz3evwQNvqJNtsTPhhJ+sOnqNaQCk+e6aNY/0q5byYvGgfX6/6m9qVfZg4qBme7i6EXYrlxZkbiUlIynXsAPfUr8iEh5piMZv4ed1RPl92MEP8Hz/ZmvpBZYiKSWTY9HWEXTLiH9ajHg+0q27Unx+2s+7AOUq4mpk3phtuLmZcLGZ+3X6KyYv2AdC6dgBjH7gLs9lEXEISI2dt4lT41X91/IX5+f3wiVY0CC6LCTh+/gojZ24g7lre6g/Am4Oa0bFhJeKvJTFy5gYOnIrMkKZ+kB+Tn2qDu5uF1XvDGP/9NsD4/E57vj2Vy3oReimG5z79k8txiVnmW6dKGSYOaYGXhytWq41PF+9jydaTeS7DrRj01QfU79mRq+ERvF2/W6FuO73iWn/6tqrGcz3qARB7LYmxszfz1+moDOla1Qlg3IN34+ZiZt+JCF6ZtZFkqy3H28mqfrWoFcBXL3Uk9KKxL5bvOMXURXtzVZbsuFa9k5Lt+mIymUk4uJX4navTvF+ybW9cK9UAwOTihsnTi8gZ4woklsKsL58825YGwWVJSray59gl/vPNJpKSbTzdvS73taoOgIvFRI2KpWn03M9ExyYW2bIM7lyLJ0LqEOTvTYNnfyIq5totxXqrtm7eyNSPJmG1JtOzz308MnhopunW/PE7b4x5lS9nz6FWnTpcjo7m9TGvcvjQQe7t2YuXXvlPvsdWmOf7FF7urqx5vy8rdp7m9e+2AqDHhlDex4OExGQAHv7gNyKuJOS4HPl97ZDCbDKxdEJ3LkTFMXTKGgCmPt2GBkFlSEq2sef4JcZ8u4Wk5Jyfx7JSEMeieoXSfPRka+oF+fHh/F3M+NXYLxXKeDLl6baUK+2B1WbjxzX/8PVvf+W5DOL2Ik04IgOzycQ7g5vz6Ier6Dh6EX1aBlOzYuk0aQbeU5Po2ETajlrIrBWHGPtAEwBqVixN7xbBdPrPIgZ9uIp3B7fAbDJlm2eDYD+8Pd3yrQwdG1YiOMCbNi/PY/RXG3hvaKtM0733WGtenbWRNi/PIzjAmw4NKwEwrHdDNh48S9uX57Px4FmG9W7oWGfb3+fpNnYR3cYucjRUpBjwzq90G7soTw0VZpOJtx9pyuCP19B53DJ6N69KzYreadI80LY6l2MTuWfMEr767W/+M6ARADUretOreVW6vL6MwZPX8M6gpphNJo6fv0r3CcvpPmE5Pd9cQXxiEit3hQLw/pDm/Hf+Hrq98Ssrd4Xy9L11ch17SvzvDGrG4Mmr6TR2Cb2bB2WoPw+0q8HluETajf6FWb/9xZgBd9njL02v5lXp/NoSHv1oNe8+2hyzycS161YGvr+KkDeWEfLGUu6pH0jj6mUBeHdwc16csYF731jGoi0nGN67vsRfiJ/fN+dsp9tri+n62mLORsQypEvtPMUP0KFhIMH+3rQdtZDRX29m4tCWmaabOKQFo7/eRNtRCwn296Z9g0AAnutVn40Hz9HulYVsPHiO53rVv2m+8YlJjJixns5jfmHQh6sY/0izfD0f5cTm2fP5NGRwoW4zM8W5/oRevMqAd1fQ9bXFTF20l/cfy3jeN5ng46faMmzaWjqP+YUzl2Lo37bGLW0nq/oFsO3vC4SMW0zIuMUF1lCByYRX+35c+eVLouZ8QIk7GmMp458mSez6xUT/NJnonyYTv3cDiUf3Z5FZ3hR2ffnfpuO0f/V/dB7zC+5uFh5sfwcAM3496Njv/9U72XL4wi03VBR2WXYcCefB//7maNwqSMnJyUz+4H0mTf2U7+cu4PeVKzhx/HiGdHGxsSyY+xN16tVzLHMrUYInnn6W54a/VCCxFfb5PsWo/o3ZcvhChu0Mn77OUZdupaGiIK4dUjzWtRZHz15Ok9eizcfpMGYxXcYtwd3NwsB2NXMca1YK6lhEx15j/PdbmfnrgTT5JCfbePvH7XT8zyL6vLmMwZ1rZdhnQji1sUIp1V4p1SrV62eUUo86M6acUEoNUUpVTPX6pFKqbB7yC1JKHcg+ZZbrf6WU2quU2qeUmq+U8sptXgCNqpfl5IWrnL4Yw/VkK4u3nKBrkypp0nS9qwrzNxwFYNm2k7SuW8FY3qQKi7ecIDHJSujFGE5euEqj6mVvmqfZZOK1gU2Z+POOvISdNr4mVZm/3ohv19GLeHu6Ud7HI02a8j4eeHm4sutoOADz1x+lW5OqjvLNW38EgHnrj9AtXfkLUqNqfpwMjyH0YizXk60s2XqKLo0qpUnTpXElFmw6AcCvO07TurZxodqlUSWWbD1l7P9LsZwMj6FRNb8067au48/p8BjORMQBUC3Am63/GPtg/cHz3Nukct7jT3Wsl2w9RdfGafPs2rgy8zccM+LfforWdQIcy2/Eb68/9vhTfm11sZhxsZiw2X9AsNlseHkYN5beHm5ciIr7d8dfyJ/fmITrjnzd3SzYbHn/ZafrXVVYYN+/u4/ZP7+l031+S3vg5eHGrqMXAViw4Zjjc9r1riqOz7/xua5y03xPnL/CyQtGb5YL0fFEXEmgTKkSeS7HrTi6fhtxkZezT1jAinP92XnkouMX1d1HL1LB1zNDGl+vEiQmJXPi/BUA1h84S/e7jfO+RwkXJj3RmqVv9mT5273oelfm58Ks6ldhcfGvQnJ0BNYrkWBN5tqR3bhVq5tl+hJ3NubaP7sLJJbCri9r9p5x5Lvn+KVMj3GfFtX4ZXPGG/GiVpaDpyIdvTIK2l8HDxBYqRIVAyvh6upKp67d2LDuzwzpZs34nAcHDcbN7cb5z8PDgwaNGuNWomAacAv7fA9Gz4BypT1Yd+BsvpWjoK4dAnw96dQwkJ/XHU2T15p9N2LfczyCCmUyfhZuVUEdi4grCew9EcH1dD0/wi/HO3puxCYkcfTsZQLyoRzFlslc9P85gbN7VrQHHI0VWusvtNbfOS+cHBsCVMwuUSF6SWvdUGvdADgNPJ+XzAJ8PTkbGet4fS4yloB0FwQBZTw5ax92kGy1cTUuEV+vEsa6EanWjTLWvVmeQ7rUYtXuUMIvx+cl7CzjM7YXR4BvyXTlLMm59DHZT5JlS3sQHm3EEx4dj1+qk3WTGuX5bWJfvn+1K3cE+jiW22zw439C+PWdPjzc4c7cx+7jkTauqLiM+9/Hw7E/k602rsZfd+z/c5E3bnbPR8URkK6Rpnezqizeesrx+p8z0XRpZLSK97i7Sp6/8DIc66hY/H09MkkTlyF+f1+PdOveKLvZZGL5Wz3Y/ckANhw8x57jlwAY/c0Wvh3Zka2T+9GvVXCGbpf/+vgL+PML8NGTrdn12QNUr1Cab1blvQtnptsrk7EMGT6/9pjKens4zifhl+Px83bPcb6NqpXF1WLO81Cc4up2qD8AA9vXZM2+MxmWR169hovFTINg40age7MgKpYxvhuG927AxkPn6Dl+KQ+8t5LXBjbFo0TG0bJZ1S+AJjXKsfLd3nw3qnOa74f8ZPYqjTUm2vHaGnMZc8nMf400l/LF4l2G62FHCiQWZ9QXMIZ69GtdnT/THWN3NwvtGwSyfPspbpWzylIYLl68SHn/AMfrcuXLc+lieJo0//x9mPALF2jdtl2hxlbY53uTCV5/6G7e+Wl7pvF89GQbVrzTmxf7NMhbOfLp2mHCQ02ZOHcX1iwacl0sJvq1CnYMO8qLgjoWOVGprBd1q5Zh99FLeSmCuA0VyJwVSqlFQGXAHZiqtZ6plAoBJgIW4BLwOPAMkKyUegR4AegExADLgG+11s3s+QUBi7XWDZRSTYDJgJc9nyFa63NkQin1J7AbaAKUAx4FxgD1gbla63H2dCOBx+yrzdJaT7FvczmwAaNB5QzQB+gBNAV+UErFAyl9pF5QSvUCXIEBWuvDSql7gKn2921AO631Ta+A7dv9Hki5s35ea71JKWUGPgPuAU5gNDR9rbWer7W+Yl/XBHjYt5VrqXqeOeTkxy7bTdY1Z9IsZrOBv48HPZoFoSauuOU4b8ZExkDS/2KXm3LuPxlB8xfnEnctiY4NK/HVyM60fXk+APe9uZQL0XH4ebvz039COHruMlsPn89N8LmM3Zb58lR/u1rMdG4UyPsLbnRPfuXrrUx4qAkv9q7Pqj1hXE+y3nrM2cWWkzQ2G6ZM3khZ12qzce8by/D2dGXmC+25I9CHf85E83jX2gyevJo9xy/x9L11eP3BJoz+ZovEnya27NfLzec3xctfbjSGLz3anN7Ng9Hrj2Zc4RbkpAyZJMn2xJddvuVLezDlmba8NGNDjvbZ7eh2qD8tawfwQLua9HtneabvD5u2lvEPN8PNxcy6A2dJSjbOee3qVaTLXZV5urvRBb6Eq4VAv5IZul9n5cDJCFq8NJ+4a0l0aBjIrBEdaffKwjyVJa9K3NGIa0f35ewg5oIz6gvAu4NbsvXwBbb9k/aGu0vjymw/En7LQ0C4STzZyWtZCkWmG70RtNVq5dOPP2LsG28WXkwpURTy+f7RTrVYvTcszQ87KYZPX8f5qDhKurswc3gH7m9dnQUbj2WzpZtsL0cxZX3t0KlhIJeuJLD/VCQtavlnXBl499HmbPsnPMNnITcK6lhkx7OECzOGt2fCD9vS9LYTAgquZ8VjWusmGDf1w5VS/sCXwP1a64YYN/MngS+Aj7XWjbTW61NW1lr/BbgpparZFz0AaKWUK/Ap0N+e/9fAu9nEkqi1bmff1i/AMKAeMEQp5Wdv/BgKNAdaAE8qpRrb160JTNNa1wWi7fHPB3YAD9vjTukOcElrfRcwHRhlXzYKGKa1bgS0BXLSdSAc6GLP6wHgE/vyfkAQRkPLE9xoJAFAKfUNcB6oZd9HGSilnlJK7VBK3XS8xbnIOMcvTQAVypTkQnTak/r5yDgq+hlpLGYTpTzdiI65Zqzrl2pdX2PdrPKsW9WPIH9v1k+6n02T++Ph5sL6Sf1uFl6WBnepzcqJfVk5sS8XotPFUcYzQxnORcZSIX1M9i74ly7HO4aNlPfxIMLeUhwTf93RnX/13jBcLGZ8vYzukin5R1xJYMWOUzSqlruRQeej4tPG5evJhei0VedcVLxjf1rMJkp5uBIdm8i5yLg0PSMC0q3bvn4FDpyK4lKqcZjHzl9h0OQ19HxrBYu3nuJUeN66pWY41r4lCY+KzySNZ4b4z2dY1zPDsIgrcdfZcvgC7etXpEypEtSp4uvopbBk60ma1ign8RfS5zc1q83Gkq0nuNfepf5WDe5cixXv9GbFO725kKp+O7YXlf7zG5f15/dKvKPravnSHo5xx5mWw76Ol7srs0d15sP5u9h97GKuynA7KG71J3W98ffxoFZlXz58vBWPT1lNdBYTFu46epH731lOrwnL2Hr4AicuGENCMMFTU9c4xqu3eGk+R89e5qMnW7Pind58O6ozkHX9ikm48f2wZu+ZNN8P+ckacxmz141eG2av0lhjM29QKXFHY679XTBDQMA59WXEfQ3x83bnrR+3ZYind4tgFudiCIizylJYypUvT/iFGz+eXAwPp2y5G981cXGxnDh2jOHPPsmAPj04dGA//xk1gsOHDmWWXZ4583zfpGY5hnSuxabJ/Rn3YFPub1Od/yhj7pHz9jxjE5JYtPkEjarn/DquIK4dmtYsT5fGldg46T4+e7YtrWoHMOWp1o50I/o0oEwpd976KffDqAvjWNyMi8XEzOEdWLTpOCt2nM51OW4HNpO5yP9zhoLa6nCl1F5gC0YPi6eAdVrrEwBa64xTy2akAWX/+wFgLnAnRkPDKqXUHmAcUCnz1R1SZjrcDxzUWp/TWl8DjttjawP8T2sdq7WOARZiNCwAnNBap8yguBOjsSArCzNJtxGYrJQaDvhorXMyxbkr8KVSaj8wD0iZ7bANME9rbdVanwfWpF5Jaz0UY2jKXxj7KwOt9UytdVOtddObBbD3+CWCArypXM4LV4uZ3i2CWWWfjDHFqt2h9G9jTErWo1kQGw8ZnVtW7Qqld4tg3FzMVC7nRVCAN3uOXcoyz9V7w2jywlxajZxPq5HziU9Mou2o3P0S9e2qvxwTX67YccoxadpdNcpxNf66Y1hHivDoeGLir3OX/eawf9sa/LbzlL0cpxnQ1pisaEDbmvy2yziBlks1HKRRtbKYTSaiYq7hUcKFku6ugDHuuV39QP4OyzgLfU7sPRFBsH8pKpctiavFTK/mVVm1J21X19/3hHF/q2AAujetwib7JFGr9pyhV/Oqxv4vW5Jg/1LsOX7jKSi9mwexeFva7rF+9rH5JhO80KseP/yZt+7CN+L3uhH/7nT1Z08o/dsYM7d3v7sqm/4yLqJW7Q5NFb+XI/4ypUrg7Wns3xKuFtrUCeDYuctcjk2klIcrwf6lAGhbryJHzuVt3H+xj78QP78AQeVLOfLt3Lgyx3IZ/7e/H3bcJK7ceZr77fu3cfVyXI1LzDBMLPxyPLEJ12lc3fj83t+muuNzumpXqOPz379tjTTLM8vX1WLmyxEdWLDhGMvSfT7+bYpb/UldbywWM1++2IEXZ6x3zEmRmZSuyW4uZp7tWY85q/8GYN3+swztemOCz7pVywBGz4+QcYsZPOl3Rzkzq18Zvx8okCc8JF0Ixfxe6fEAACAASURBVOJTFrN3GTBbKFGzMYnHMw4fs/iUw1TCg6TzJ/M9hhSFXV8G3lOTe+oH8vy0tRl+8S3l4UqLWgGOyaOLelkKU606dQkLDeXsmTNcv36dP35bSZu29zje9/IqxdJVq5n3yzLm/bKMOvXq899JU6hVJ28TbmfFmef74dPX0+Il45rznZ92sGDDMf6rd2IxmxyNiy4WE50aVeLvsGhyqiCuHd6fv5vmIxfSetT/eH76ejb9dZ4RMzcCMLBdDdrVq8Dz09fnqbdOYRyLm/nwidYcOXuZL1cUTMOYKP7yfRiIUqo90BloqbWOsw/F2IvR0HAr5gLzlFILAZvW+ohSqj5Gg0Pm09NmLuVKwZrq75TXLmTeoyn9ugDJGEMsskubbM8XrfV/lVLLgO7AFqVUZ6314WzifQm4ADTEaExKaZa8WZzYt5eslJoLvAJ8k136rCRbbbz+3RbmvNIFi9nE3HVH+edMNC/3a8S+ExGs2h3Kz2uPMOWZtqyf1I/omGsMm7YWMOY/WLr1JKv/25ckq41x324xxtnZyDTPgrJ6TygdG1Viw+QBJCQmMXKGo+MOKyf2pdvYRQCM/WYTk59uh7ubhT/3hrF6bxgAny3ZxxcvdGRg+zs4cymWZz75AzAuTgZ1rk1yspWE68k895nRZlTO24NZL3UCwGIxs2jTsQxjaXMq2WrjjTk7+G5kByxmE3rDcY6cvczIvvXZdzKS3/ecYe66Y3z8ZCvWvteL6NhEnp+xAYAjZy+zbPtpfn+nB0lWG6/P2e4Y5+juZqFt3QDGfpf216jezYN4tKPRMLNiVyh6Q+5+lUod/+tztvH9qE7GsV5/lH/OXmbkfQ3ZfyKCVXvCmLvuKFOeasO69/sY8U83js8/Zy+zdPsp/pjYm6RkK+O+34bVZqN8aQ8mP9kai9mYXX3ptpP8YZ9obfQ3W5jx/D1YbTYuxyXyylebJf5C+vyaTDD56TaU8nDDZIJDpyMZm4chLClW7w2jY6NANkzqR3xiMi9/ucHx3op3ehMyzmiDHjt7s/H4NFcLa/adcUy+N23pfqY/fw8D76nJmYgYnv30z5vm27N5EM3vDMDXy50B9gutkTM3cOh0TtrV88fjP37CHe1b4FXWl/dCN7Nk/Mds+loX2vZTFOf6M6JvQ3y8SvDuYOMSITnZSo/xSwH4dlRnXp21kQvR8TzTvR6dGlXCbDbx/R9/s+mQccMwddFexj/SjFUT+2AyQejFGIZO/iPDdrKqX93vrsqgTneSbLWRkJjMsM/X5rosN2WzEvPnQkr3eQrMJhIObiM58gKezbuRFB5G4gmj4cKYWHNPNpnlTWFfL7w3tCVnLsWwaHwPIO3jYUOaVmXdgbPE5/LRt4VdlqFda/Nsj3qUK+3Bqol9WL03jFe/2pSn45EVFxcXXnplNC8PH4bVaqVHr94EV6/OrBnTqVW7Dm3a3XPT9Qf06UFsbCxJ16+zfu2ffPTJ5wRXq3bTdXKqsM/3WXFztTDn1S64WsyYzSY2HDzHj2v+yXE5CuLa4WYmDm7OmYhYFr0eYuyrHaeZujhvT/0pqGNRrrQHy97qaX88ODzerQ4dRy+idhVf+repwV+nI1nxTm8A3p+3M81EukKY8mPm9tSUUn2AJ7TWvZRStYA9wCCMeSbaaa1PKKXKaK0jlVIvA95a6/H2dScAMVrrSfbX24HDwH6t9QdKKTfgEDBIa73ZPizkDq11pjPS2RtKRmmtd9gbUUZprXumfg+j0WI2xhAQE7DVHm8UsFRrXc+efhTgpbWeoJRaAkzWWq+xv3cSaKq1vqSUagpM0lq3V0pV11ofs6dZBMzWWi/KJM6glG0ppT4GwrTWHymlhmLMS2FSSg0ABgO9Mebf+Aujx8oCoLrW+qh9zooPAbTWo9JvJ7XKg2YX2xHZYXOGEvjQLGeHkWtnfnyCKkN/cHYYuXb6m4epPLg4zIObudBvHy328Vd6JNdtkU4XNmdosY//aXI31KUomMGpYr//i3v8F6eOdHYYuVbuxcnFfv8X1/jD5gwF4EJ04TxBJL/5+xgPqivu+7+4Xj+Efms8bLE473+bzZbtD7fF2fXzx4r8vZlrQPVCPwYFMcHmCuAZpdQ+4G+MoSAXMW6sF9onigwHugBLgPn2Bo4XMslrLsbNdzCA1jpRKdUf+EQpVdoe/xQg19Pna613KaVmAyk/N8/SWu+2NyBkZTbwRboJNjMzQinVAaO3xSGMCTuz8zmwwN44sQZImXJ3AcYEpAeAfzAaVS5jNLB8q5Tytv+9F3g2B9sRQgghhBBCCOFsTpoToqjL98YK+3wQ92bx9vJ0af8BUj8baH269ycBk9It2wPk6LlKWuv2qf7+E/gzi/cmY/T8SL3uSYz5MVLHkvL3AozGgxRBqd7bgfFIVrTWmTXAZBanY1ta6yOk3Sdj7MutSqlRWusYpZQfRuPKfq21FWiN+D979x0eRbXGcfy7aSQkJISEHkpoooKAKNIvBCkqTYURCyJWBNu1IYqCDSyooIgXRLGg6AERUBRE6b33Ip2EFggJkBBKkr1/7BISsiExJNkN/j7P4yOZOTv7ntmzszPvnHNGRERERERErhAF8uhSKTC/WpZVEvAD3nROtCkiIiIiIiJyRbkikhWWZX1K1t4FI4wxHjUwyzlB6LcXLT5jjLkpN6/P2BtERERERERErgC2K3pKjjy7IpIVxph+7o4hN4wxG4D67o5DRERERERExJNpJg8RERERERER8ShXRM8KERERERERkSJJTwNxSXtFRERERERERDyKkhUiIiIiIiIi4lE0DERERERERETETewaBuKS9oqIiIiIiIiIeBQlK0RERERERETEo2gYiIiIiIiIiIi7eKkPgSvaKyIiIiIiIiLiUZSsEBERERERERGPomSFiIiIiIiIiHgUzVkhIiIiIiIi4i56dKlL2isiIiIiIiIi4lGUrBARERERERERj2Kz2+3ujkHcwGaz6YMXERERERGPZ7fbbe6OoSCdTYj1+Gszv5JlCv0z0JwV/1IR941zdwh5FjO+t+J3I8XvXjHje7OsfWt3h5FnN82cw5qYeHeHkWcNIkKLfPt5jCruDiPPRrNX7ceNYsb35nX/6u4OI88Gnd7Jyn1Fs/3cUDkUgIr3jHVzJHmz//uHgaJ7/hkzvjdQ9OMv6u1H/n00DEREREREREREPIp6VoiIiIiIiIi4i54G4pL2ioiIiIiIiIh4FCUrRERERERERMSjaBiIiIiIiIiIiJvYNQzEJe0VEREREREREfEoSlaIiIiIiIiIiEfRMBARERERERERd9EwEJe0V0RERERERETEoyhZISIiIiIiIiIeRcNARERERERERNzFZnN3BB5JPStERERERERExKMoWSEiIiIiIiIiHkXJChERERERERHxKJqzQkRERERERMRd9OhSl7RXRERERERERMSjKFkhIiIiIiIiIh5Fw0BERERERERE3MSuYSAuKVkh2Xq9ZyOi6kWQfCaFZ8csZOPeY1nK1K0axoePNsffz5vZ62IY9O1yAEoG+vHpE62oFB5E9NFE+n4yl+OnzlK9fAgfPNKMOlXDeH/Sakb/tgmAauWCGfVEq/TtVi4TxAc/reWLmZsvux6t6lZkcM9GeHvZmDB3O6N+3ZBpvZ+PF8Mfa0HdyDDiE8/Qd+Q8Yo4mAtCvU116/KcmqWl2Bn27jHkbDgAw7OFmtGkQQdyJ09w8YOplx+hKYe5/gMUfdiPp9DlS0+ykpqZx26BfPSLm7LZbMSyQMU+3xtvLCx9vG1/N2sr42dsA+PaFtpQpGYC3l43l22IZ+PVS0uz2IhG/v583/3uyFVXKBJOalsafa2J4x6z6x5+FKyENb6Ty409g8/LiyIzfOGgmZFrvV7oM1Z7vj3dgEDZvL6K/HMvxFcsIbtCQSg8+gs3HB3tKCvvGjubkujX5EtM/sXb5Er4a+SFpaWlE3dqZrvf0yrR+1rTJzJw6CS8vL/wDAnj02QFEVK2Wvv7o4UM827sH3Xs9TKe77iuwOAvimJPdNt9/uCnXRYZjA3YdOsGzYxZy6kxKgdUtOz2/eI+6HaM4GRvHm3XbF/r750ZRaT9QuMcigAF3NaRN/QgARkxZxy/L9uR7naq3bUn7YQPx8vZmzVeGRcNGZ1ofUrkCnf/3DsXDS5Ecf5yfH3yOk/sPARBcqTydRg0lOKIc2OH7rg9xfN/+fI/xUtYtX8I3oxztp/Utnel8d+b28+cvk5k1dRJe3l4U8w/g4WcHEFElc/t54aEe3Hn/w3S0Crb9vHF/Y6LqVSL5bAr/HT2fjXvispSpWzWMj/q0xN/Xh9nronntm6WAo/2MejKKSqWDiD6SyOMfz+b4qbO0a1iZF7o1JM1uJyU1jcHfLmPF34epGB7E58+0wdvLho+3F+P+2Mz4v7bmOtbCPF6m75+eN2G1rEHtR74DYNC9N9Lk6vIABPh5ExYcQJ0+3+e6DoX9fQUI8vdlzrtdmbFqH69+syzfzh0Kou3c3rQ6fTtdB0DS6XMMGLeYLfuOUa18CJ892Tp9u5XLlGDYpNV8MWNTlveUfy+lcMSl1vUqElk2mBbPT6b/l0sY0ruJy3JDHmhM/y8X0+L5yUSWDabVdRUB6NupLos2HaTlC5NZtOkgfTvVBSAh6QyDvl3GmN82ZtrOrkMn6DBwGh0GTuPWV38h+UwqM1buvex6eNlsvNXrJu5/fxZR/afQpUkkNSuEZCrT4z81SUg6S4vnJzN2xmZevqshADUrhNC5cSRtXppCz/dn8XavxnjZbABMXLCDnu/Nuuz4slPY+/88a8gMOgyclqdERUHFnN12YxOSuf2N3+gwcBqdB0+nb8e6lC0ZAMDjn8yl/SvTuHnAVMKCi9HxpqpFKv7Rv22idf+fuWXgL9xYq0z6e1wWLy+q9Huavwe+xIZHexPWKgr/ylUyFalw930cmz+PTU88xo6hb1H1iacBSDlxnL8HvcLGxx9m17B3qP7CgMuP5x9KS03lyxHvM+Cd4Xw47gcWzf6DmD27MpVp1qYdw774nvc+H0/nu3ryzWcjMq3/etRH1G/k+nPNLwVxzLnUNl8fv4L2r0yj3SvTOBCXxANtry7Q+mVnyVeT+KRDr5wLuklRaT9Q+MeiqHoR1KkaRvtXptFp8HT63FqHIH/ffK2TzcuLW4YP5vsuDzGqQQeu7d6R8No1MpVpO3QA6777mdGNOjJ/yCe0eeP59HVdxw5jyUef81mDDoxtcQdJR7JeQBWktNRUxn3yPi8OGc77X/zA4jl/ELM3c/tpGtWOd8d+z9DR4+l0V0/GX9R+vv3sI+oVQvuJqhdBZLlgmj83kf5fLGRo76Yuyw19sBkvjl1E8+cmElkumNb1HMmqfp3rsWjTAVo8N4lFmw7Qr3M9ABZuPEDbAT/T/uUpPD9mAe8/0hyA2PhTdB38C+1fnkKn16bRr9N1lC1ZPFexFvbxEuC6yDCCi/tleo/Xv1uRfg46btaWf3T+Wdjf1/Oe79aApVsPZ1p2uecOBdV29h05Sbc3p9N2wM+MmLKW9x5qBsCug8dp//IU2r88hVtemUrymZR8OfeXK4uSFXlgWVYry7L++dVc9ttLvMzXP2lZ1jbLsjZZlvVefsTU7vrK/LRwJwBrdh4huLgfZUICMpUpExJAUIAfq3ccAeCnhTtp37By+usnLdgBwKQFO9KXx504zbrdcZxLzf4ud/Nry7M39gT745Iuux71q4ez5/BJ9h1J5FxqGtOW7qadM5aMdZ200BHr9OV7aHatI7vermFlpi3dzdmUNKKPJLLn8EnqVw8HYNm2wyQknb3s+LLjzv3vaTFnt91zqWmcTUkDwM/XGy/bhfdJPH0OAB9vG74+3thz0avCU+I/fTaVJVscdxPPpaaxYU8c5Uvl7sTvUoKuqs2Zg/s5c+gg9pQU4ubNJrTJxScidryLO97LJzCQs3GOC4JTO3dw7pjj38l79+Dl54vNN38vZnKyY+tmylaMoGyFivj4+tI0qi0rFs/PVKZ4YFD6v8+cTsZmu9AoViycR9nyFamU4U55QSiIY86ltnm+rQP4++WurReEHQuWc+rYcbe8d24UlfYDhX8sqlkxhGVbD5GaZif5TAqbo4/lT4I0g4o31iN+514S9kSTdu4cmyZO56qON2cqE167BrvnLgFgz7yl6evDa9fAy8ebXbMXAXAu6RQpyafzNb6c7Ni2mbIVLrSfJq3asmrRP2g/i+ZRpnzFTD0tCkq7hlXSP//VO5yfc8mL2k/JAIICfFm9IxY4304cyet211dm4oLtAExcsD29/WTssRVQzJfzh5qsv2UZfoxzUNjHSy+bjVd63MCQH1ZmG1OXJtWYunRXtusvVtjfV3D0bCgdEsD8jQfS3yM/zh0Kqu2s2h6b3ltk9fZYypcKzPLezetUYG/sSfYfvaxLoqLN5uX5/7mBkhVFnGVZrYEuwHXGmGuBYfmx3XKhxTlw7EKy4OCxJMpddNArV6o4By8uE+ooEx4cQOzxZABijycTFuyf6/fu3DiSqUt2X074F2J0VY/QrPU44EyMpKbZOXnqLKFBxRyvzZAwORif9bUFxR37346d7/q3Y/obHbmndS2PiflS2y1fqjh/vN2Z5cO789n0jRxOSE4vN/6Ftqz5tAdJyeeYvjznTL2nxQ8QXNyPmxtUYtGmgznGnxPfsHDOHIlN//vs0aP4hZXOVGb/+K8Ji7qZ+t/+SK03hrJ31MdZthPavCVJO3dgP3cuy7qCdOxoLGFlyqb/HRZehvgjR7KUmzllIk/dewffjRnJA088C8Dp5GSm/vAN3Xo9XOBxFsQxJ6dtfvBIM1aPvIvq5UMYN2tLQVWtSCsq7QcK/1i0ZV88ra6riL+fN6FBxWhydXkqhGW9mLgcJSqU5XjMhePYif2HKFGxbKYyhzds4equjiFEtbu0o1hwEAGlShJWsyqnE07Q/YdPeWTJNG4e0h+bV+GevsZf1H5KlS7Dsbis7eePqRN5pucdfP/5SO7vd6H9/PLDN9x5fyG1n1IXHUeOnaJcaObPs1xoYNb242xj4SEBxDp/i2ITkgnLcOHd4YYqzH3/Tr55oR3PjVmQvrx8qUBmDb2dFR/3YNSv6zmccCp3sRby8fKBtrWZtSY6/ftxsYphgVQqHcSiTYdyFX+2dSjA76vNBq/ecyNvTViRbUx5PXcoyLZzXo9WtZizLibL8s6NqzF18c5/FK/8OxS5OSssy5oCVAL8gRGANxBpjHnRuf4BoKEx5knLsl4F7gWigaPAKmOMy4t5y7KeAvoAKcBmY0wPy7IaAcOBACAZ6G2M2XbR6wKBT4C6OPbnYGPMVMuyrgXGAX44kkJ3GmO251C3IGAqEAr4AgONMVOd67Kry+PAO8aYMwDGmFhX2/6nXCXGL75h5yp3frn39Hy9vWh7faV8G6Ofm3q4Yr+M1+YHd+z/O974jcMJjh/K7/u3Y+eB4yzbdjjnF56Pp4BivtR2Dx47RbtXplG2ZABjn4li+vI9HD3huON23/uzKObrzcePt6DZteVYsPHSP9qeFr+3l42RfVsy7o8t7DuSD3caclHBsFZRHJ01k0OTJxJ09TVUf2EAG/o8lF4uoEpVKj34KNteefHy4/mHXH73XNSpfdfutO/anYV/zWTy+HH0e2kQE78aw23d7sY/oOCTjQVxzHF1XZZxm899vggvm40377+JzjdFYpx3xuSCotJ+sgmrQI9F8zceoF61cKa8dhtxJ0+zekcsKalpuQ03d3JRqVkD3uGWjwZR77472bdoOSf2HyItJQUvHx8qN7uRMY07czz6AN3Gj6BezztZ+/XE/I3xEly1H5uLT6Fdl+6069KdRX/NZMp343i8/yB++mYMt95ZiO3HRVwX97jK63Fqxsq9zFi5l5tql+OF7tdz99AZgOOCte2AnylbsjhfPHsz05ftTv8tu2SshXi8LFsygNsaVcUaMiPb7XZuHMlvy/fmao6r8wr7+3p/m9rMXhfDwWOuE0KXc+5QkG0HoOk15enR6ipufyNz53Rfby/aNazMOz9mn4CRf68il6wAHjTGHLMsKwBYAbQBFgHnz57vAt62LOsG4E6gAY56rgYudQX8Eo6kxxnLsko6l20FWhpjUizLuhkY4txmRq8As40xDzpft9yyrD9xJD5GGGO+syzLD0dSJSengduNMScsywoHllqWNQ1oeIm61AJaWJb1tvP1zxtjXH7bLct6FHgUgGK3Zlnf6+ba3N3KcUd93a6jVMjQTat8qUAOx2c+MB48dipTV66MZY6eSKZMiCNbXCYkgLhc/GiBY4zexj1xufqRy42Dx05lrcdFGf9Dx05RISyQQ/Gn8PayUaK4HwmJZxyvzXB3qXxo1tfmJ3fv//N39eNOnGbGyn3Urx6eY7KiMGJ2+RletN3DCcn8vT+BRleV5bcVF3pRnDmXyqzV0bS7vrLLZIUnx//ug03ZffhEvkwyC3Du6BGKlS6T/rdfeDhnjx3NVCa8/a38/Up/ABK3bMbm54dPcAgpxxPwDQ+n5quvs2vYUM4cPEBhCytdhrjYC+0x7mgsoeHh2ZZv2rotY4e/C8COrZtYNn8O340eSVLiSWxeXvj6FaPD7d3zPc6COubktM00u51flu3msVvrKFnhgqe3H3cfiz6Ztp5Ppq13/Pvxluw+fCLf6gZwcv8hQiLKp/8dXLEcJw9kvreSeDCWiT36AeAbWJyru3bgzIlETuw/xKF1m0nYEw3A1ml/EtGofqEmK0pd1H6OHYklNCz79tOkdVu+HOFsP1sc7ef7z0dyKkP7ad81H9tP26u5p/VVgLP9ZDyOlCqe5Xhx8FhS9u3neDJlSjrukJcpGUCci14Iy7YeokqZYEKDihGfeCZ9+eGEU2yLieem2uWYvnxPjnEX5vHy2iphVC0bzIJhjtP4AD8fFgy7gxbPT04v27lxJAOdk0Veiju/rw1rlqZRrbLc36Y2gf4++Pp4kXQ6Jf0m3z89dyistnN1pVDee7g5Pd+bSUKGNgPQun4EG/Lx3L+osv+DIVT/JkVxGMhTlmWtA5bi6GERCeyyLKuxZVlhwFU4khfNganGmGRjzEnglxy2ux74zrKs+3D0rgAIASZalrUR+Ai41sXr2gEvWZa1FpiLo8dHZWAJ8LJlWf2BKsYY133OMrMBQyzLWg/8CVQEyuZQFx8cPTEaAy8AxrIsl63dGDPGGHODMeYGV+u//nNr+gRDM1ft487m1QFoUL00J0+dzdJtLvZ4Mkmnz9GguqMr+Z3Nq/PH6n0AzFodTbcWjsmzurWokb48J12aVMu3ISDgOPBWLRdMpdJB+Hp70blxJLNWR2cqM2tNNN2aO2K9rVFVFm0+mF6Hzo0j8fPxolLpIKqWC2btzqNZ3iO/uHP/BxTzIdDfJ/3fLetWYFt0gkfEPGt1tMvtlgstjr+vIwcYUtyPG2qWYdfB4xQv5pM+rtPby0ZUvQh2HHA9lt4T4wd4oVsDShT3ZfD45Tl+BrmVuG0rxSpUxK9sOWw+PoT9J4qEpUsylTkbe5jgBtcD4F+pMl5+fqQcT8A7MJCr3hhK9LixJG52zyzd1WtfzaH90cQePEDKuXMsnj2LG5q0zFTmYMyFdr5m6SLKV6wEwOsjxjBywhRGTpjCrXf24PZ7ehVIogIK5phzqW1WLVMifbs3N6jEzoOeO2+EO3l6+3HnscjLZqNkUDEAalcK5erKoczfkL8Jyf0r11OqRhVKVonAy9eXa7vfxt/T/8pUJiAsNP22bfMX+qQnIw6sXI9/yWCKh5cCILJVY45sLdyEXPWrMrefJXNn0bDpJdrPskWUi3C0n0HDx/Dxd1P4+LspdLijB13u7pWviQqAr2dtSZ+ocMbKvemf//U1SnMy+Vx61/zzYhOSSUw+x/U1HO2nW4sa/LHKkSiftXof3VvUBKB7i5rp7adq2QvHmjpVw/Dz8SI+8QzlS2X+LbuxVtlcH4cK83g5e10MDZ/8kabPTqLps5NIPpuSKVFRrVwwIYHFWLU96/CeLPvbjd/Xpz5bQOP/Ourw1oSV/LRwZ3qiIi/nDoXRdiqEBfL5Mzfz9Gfz2H0oayK0S5PqGgIi2SpSPSssy2oF3Aw0McacsixrLo7kwI+AhaMnxM/GGHt2F+yXcBvQEugMvOocxvEmMMcYc7tlWVVxJCMuZsMxxGPbRcu3WJa1zLndmZZlPWyMmZ1DDPcCpXEMYzlnWdYeZ/0uVZcYYLIxxo6jV0caEA7kfLS9hNnrYoiqX5GFw+4g+Wwqz32+MH3djLc602HgNABe/mqJ41FMvt7MWb+fOescjxL79NcNfPbEf+jxn5rsj0vk8U/mAlA6JIDpb3QkKMCXtDR4qP01RPWfQuLpc/j7edPi2vK89OXiywk9k9Q0O69+s5TxL7TF28vGj/N38Pf+BJ67oz7rd8cxa000P8zbzvA+LVgw7A4SEs/Q79N5APy9P4Ffl+1h9jtdSUmzZ3r85ci+LWl8dTlKBfmzfER3Ppi8lh/nXXKUzz9S2Pu/VIlifP5MFOC4wJ+6ZDdzN/yzx8IVVMzZbbdmxRBevftGR3dQYPTvm9gak0B4sD9fPtsGPx8vvLxsLN58KP2RpkUh/nKhxXmqSz2270/g9zc7A/DVrC38cLntKy2NvaM+ofbb74KXN0f++J3kvXuo2PMBkrb/TcLSxez7/H9EPv0c5W7vht1uZ9cHjvl6y3a+nWIVKlDhnp5UuKcnANtefpGU4zkntPKLt7cPDz75PEP6P0VaahqtbulEpchqmHGjqVbram5o1pKZUyayYdUKvH18CCxRgr79BxVafOcVyDHHjstt2mzw4WPNKRHgh80Gm/cd4+VxOd8VLAgPff8xtVo1Jig8lKHRS/hl0Ecs/tK4JRZXikr7gcI/Fvn6ePHTwFsASEw+x1OfLSA1DeXFTwAAIABJREFULX/HPNpTU/n9v69z7y/jsHl7s/briRzZsp1Wrz7NgdUb+Xv6X1RteRNRbzwPdjt7F67g92cGO16blsafA96h52/fgM3GwTUbWf3lj/kaX068vX144Mnneeelp0hLS6NVh05EVK3GxK8c7adh05b8MXUiG1evwMfHh8CgEjz+opvaz9pooupHsPDD7pw+m8Kzoy/MLTFzSFfavzwFgJfHLebDx1ri7+fN3HUxzHbOIzDyl/X878koerSqxf6jSfT52JFUuvXGSO5sUYOU1DROn03l8U/mAFCjQkleu/cm7HY7NpuN0dM3sDU6PlexFubxMiddmlRj2tJ/frOssL+v2cmPc4eCajv/vb0BJUsUY4jz6SIpqWnc9qpjv/j7edOyTgVe+uLS9ZN/L5u7Zg7PC8uyugAPG2M6WZZVG1gLdADW4RgWsRfob4xZblnWjcBooCmOpMwq4HNXc1ZYluUFVDbG7LEsyxdHAuAqHHNOjDfG/GRZ1mDgAWNMVWfS5HljTEfLsoYAwcCTziRJA2PMGsuyqgG7ncuGA3uMMcOzqVeiMSbIsqyngRrO+TZaA7Nx9BwpnV1dLMvqA1QwxrxmWVYt4C9nXS75wVbq+VXR+eAvEjO+NxH3jXN3GHmm+N3rSoh/WfvWORf0UDfNnMOamNydyHqiBhGhRb79PEaVnAt6qNHsVftxo5jxvXndv7q7w8izQad3snJf0Ww/N1QOBaDiPWPdHEne7P/eMcFoUW3/MeN7A0U//qLcfux2+xU9TuJU8mmPvzYrHuBf6J9BURsGMgPwcQ6TeBPHUBCMMfHAZhzDLZY7l60ApuFIZEwGVgLZ9UvzBsZblrUBWAN8ZIxJAN4DhlqWtYjs55x4E8dkmOudw0XedC6/C9joHB5SG/gmF/X7DrjBsqyVOHpZbM1FXb4Eqjnf+wegV06JChERERERERFPVqSGgTifeHFLNus6ulg8zBgz2LKs4sB84INsXnsOx7wQFy9fgmMCy/NedS6fi3NIiHMuisdcvHYoMDT72mQqG+T8/1GgSTbFXNbFGHMWuC837yMiIiIiIiJSFBSpZEUejLEs6xoc8z58bYxZ7e6ALsOVVBcRERERERGRbF3RyQpjzD0XL7Ms61Og2UWLRxhjCnQQmvNJJX+5WNXGGBOX0+td1UVERERERESKtrQiNI9kYbqikxWuGGP6uel944D67nhvERERERERkaKkqE2wKSIiIiIiIiJXuH9dzwoRERERERERT6FBIK6pZ4WIiIiIiIiIeBQlK0RERERERETEo2gYiIiIiIiIiIibpGkciEvqWSEiIiIiIiIiHkXJChERERERERHxKBoGIiIiIiIiIuImdrvGgbiinhUiIiIiIiIi4lGUrBARERERERERj6JhICIiIiIiIiJuoqeBuKaeFSIiIiIiIiLiUZSsEBERERERERGPomSFiIiIiIiIiHgUmx6T8u9ks9n0wYuIiIiIiMez2+02d8dQkOJOnvL4a7OwEsUL/TPQBJv/UhXvGevuEPJs//cPE3HfOHeHkWcx43srfje6EuI/M3+Cu8PIs2It7+Yxqrg7jDwbzd4i337WxMS7O4w8axARqvbjRjHje/PB/B3uDiPPnmtZo8i2n9HsBaBCj9FujiRvDvzwGECRbf8x43sDit9dzscv/z4aBiIiIiIiIiIiHkU9K0RERERERETcRI8udU09K0RERERERETEoyhZISIiIiIiIiIeRcNARERERERERNxET+h0TT0rRERERERERMSjKFkhIiIiIiIiIh5Fw0BERERERERE3CTN3QF4KPWsEBERERERERGPomSFiIiIiIiIiHgUDQMRERERERERcRM9DMQ1JStEREREREREJM8sy+oAjAC8gbHGmHeyKdcNmAjcaIxZealtahiIiIiIiIiIiOSJZVnewKfALcA1wN2WZV3jolwJ4ClgWW62q2SFiIiIiIiIiJuk2T3/vxw0AnYYY3YZY84CPwBdXJR7E3gPOJ2b/aJkhYiIiIiIiIjkVUUgOsPfMc5l6SzLagBUMsb8mtuNas4KEREREREREcmWZVmPAo9mWDTGGDPG+W+bi5ek98ewLMsL+Ah44J+8p5IVIiIiIiIiIpItZ2JiTDarY4BKGf6OAA5k+LsEUAeYa1kWQDlgmmVZnS81yaaSFSIiIiIiIiJuYi/6zy5dAdS0LCsS2A/0AO45v9IYcxwIP/+3ZVlzgedzehqIkhWSrTfub0xUvUokn03hv6Pns3FPXJYydauG8VGflvj7+jB7XTSvfbMUgJKBfox6MopKpYOIPpLI4x/P5vips9zetDp9O10HQNLpcwwYt5gt+44B8FD7a7m79VXYbPD9nG18MWPTP4q3Vd2KDO7ZCG8vGxPmbmfUrxsyrffz8WL4Yy2oGxlGfOIZ+o6cR8zRRAD6dapLj//UJDXNzqBvlzFvw4FLbrPXzbV5uMM1VC0bzHWPTyA+8QwAIcX9GPZIM6qUKcGZc6k8P3YR22ISPC7+nwbeQqC/LwDhwf6s3XWUh4fPBqBx7XIMvq8RPt424hPP0P3tGbn+DF7v2YioehEkn0nh2TEL2bj3WJYydauG8eGjzfH382b2uhgGfbsccLSZT59oRaXwIKKPJtL3k7kcP3U2x+0G+fsy592uzFi1j1e/cUws3KVxJE90vg673c7hhGSe+mx++mfk6fEH+vvw08Bb09eXL1WcyYt28fp3y3OMPycLN27n3Qm/k5pm544W1/PwrS2ylJmxYiOfTZuLzQa1Isrx3qPdAOjz0bes3xVDg5qV+fSpey87lvzW84v3qNsxipOxcbxZt71bYujatBp9b6sDQNKZFF7+aglb9sVnKdf0mnIMvPtG/Hy8WL87jhfGLiI1FzNXnZddW2tcuxxf/DeK6COO48LvK/cyYsq6/KkcsHb5Er4a+SFpaWlE3dqZrvf0yrR+1rTJzJw6CS8vL/wDAnj02QFEVK2Wvv7o4UM827sH3Xs9TKe77su3uPKDJ7SfjAriWFS9fAgfPNKMOlXDeH/Sakb/duE3dvGH3Ug6fY7UNDupqWncNijXw4lzbd/GlSyeMBp7Whq1W7Snwa1WpvXr/5jMlgUz8fLyxr9ECK16P0OJsLKcjDvMH5++jd2eRlpqCnWiOnFNq9vyPb7L4Unt541eTYmq7zx3+2yu63O3yHA+6tPK0XbWRvPa14sBKBlYjM+ebkOl8BJEHz1JnxF/cjzpLCUCfPmkXxQVw4Pw9rbxv1/XY+b9TdNryjO4Z5P07VavUJK+n/zFzJV7860+hf1dKErxli9VnOGPtaB0SABpdjvfz/mbL//YUmTiP8/LZmP6Gx05FH+K3h/+dVnxi/sYY1Isy3oCmInj0aVfGmM2WZb1BrDSGDMtL9vVBJviUlS9CCLLBdP8uYn0/2IhQ3s3dVlu6IPNeHHsIpo/N5HIcsG0rhcBQL/O9Vi06QAtnpvEok0H6Ne5HgD7jpyk25vTaTvgZ0ZMWct7DzUD4KqIUO5ufRUdX5tKuwE/c3ODSkSWDc51vF42G2/1uon7359FVP8pdGkSSc0KIZnK9PhPTRKSztLi+cmMnbGZl+9qCEDNCiF0bhxJm5em0PP9WbzdqzFeNtslt7lyeyx3v/NH+kXBeU90vo5N+47R7pVpPDN6IYPva+SR8d/51u90GDiNDgOnsWpHLL+vcJxYBBf34+0HGvPgR39x84Cp9Plkbq4/g9b1KhJZNpgWz0+m/5dLGNK7ictyQx5oTP8vF9Pi+clElg2m1XWOuXf6dqrLok0HafnCZBZtOkjfTnVztd3nuzVg6dbD6X97e9kY3LMR1pAZtHtlGluij/FA26uLTPxJp1PSP5sOA6cRczSRGflw4pealsbb301n1DP3MfXNfvy+fAM7D8RmKrP3cBxf/LaAb156iClvPEH/Hh3S1z3QoRlDHrrjsuMoKEu+msQnHXrlXLAARR85Sfe3He1uxJR1vPtg1uOmzQYfPdqCfp/O4+YBU9l/NJFuLWr8o/fJrq0BLN92OL3t5GeiIi01lS9HvM+Ad4bz4bgfWDT7D2L27MpUplmbdgz74nve+3w8ne/qyTefjci0/utRH1G/kevvlbt5Qvs5r6CORQlJZxj07TLG/LbR5fasITPoMHBagSQq0tJSWfTdKG595g2sN//HjuXziD+wL1OZsMrVuWPgCLq/PopqDZuzdOKXABQPKUXXAR/QbdBIbn/5I9b8PpGkhKwX4O7kKe0nqn4lx7nbf3+k/+cLGPpQ1oQ0wNAHm9N/7Hya//dH57mbo+d2vy71WbhxP82f/ZGFG/fTr3N9AB5ody1/74+n7Us/0e2NX3ntvsb4enuxePNB2g2YTLsBk7Hemk7y2RTmrY/Jt/q467tQVOJNTbXz5vcriHppCl1en06vm2tnOXf05PjPe6j91ew4cDzPcYvnMMb8ZoypZYypbox527nsNVeJCmNMq5x6VcC/PFlhWdZgy7Ke94A4WlmWleezA8uy/CzLGmNZ1t+WZW21LOvOy42pXcMqTFqwA4DVO44QXNyPMiUDMpUpUzKAoABfVu9wXPBMWrCD9g2rOF5/fWUmLtgOwMQF22nfsDIAq7bHpt9tXr09lvKlAgGoUSGENTtiOX02ldQ0O0u3HKLDjVVyHW/96uHsOXySfUcSOZeaxrSlu2nnfM/0Ol1fmUkLHXWavnwPza4t76xrZaYt3c3ZlDSijySy5/BJ6lcPv+Q2N+09lt6rIaOaFUNYtOkgADsPHqdSeBDhwf4eF/95gf4+NL2mPDNXOU4auzaJZMbKvRyISwIg7kSuniqUHt9PC3cCsGans82EXNRmQgIICvBj9Y4jAPy0cGd622h3feX0NudoS5Vz3G7dqmGUDglg/sYLQ+JsNrBho3gxR8exIH8/DiecKjLxZ1S1bAnCgwNYtu2wy/X/xIbd+6lcphSVSpfC18eHWxrVYc7arZnK/DR/FT1aNyIk0BFfWHBQ+rrGV1cj0N/vsuMoKDsWLOfUMfee7KzafiT9+LZmxxHKhxbPUiY0qBhnU1LZfegEAAs2HuBW57EuoJgPwx5uxq+vd+T3NzvR7vpKWV4P2be1grRj62bKVoygbIWK+Pj60jSqLSsWz89UpnjghfZy5nQyNtuFubZWLJxH2fIVqZShp4Un8YT2c15BHYviTpxm3e44zqUWflfj2N1/E1ymAsGly+Pt40uNRi3Zs3ZJpjIVa9fDt5jj97Js9dokxR8FwNvHF29fR0/A1JRz4IFdpT2l/bRvWJVJznOv1TtiCcnm3K1EgB+rtp8/d9tOhxuqOl9fhYnz/wZg4vy/05fbgaAAx2cQ6O9LQuIZUtLSMm33tpsimbM2mtNnU/OtPkXtu1DY8cYeT07v+ZB0OoUdB45TrlTW3x1PjR+gXGhxoupHMGHe33mO+0qRVgT+c4crPllhWZbNOfvolewVINYYUwu4Bph3uRssV6p4+gUrwMFjpygXGpi5TGggB49lLJOUfpAMDwkgNiEZgNiEZMIuOtgB9GhViznrHBn4bTHx3FS7HCWDiuHv501U/UpUKBWY5TXZxhtanAMXx3LRhULGOqWm2Tl56iyhQcUcr81Y13jHa3OzzYtt2RfPLTc4LjzqVwunYnhQekLGE+Pv0LAKizYdJPH0OQAiy4UQEuiHebkD09/oyJ3NqucY+yXrUCprHbK0GWdM4cEBxB53tpnjyYQ5kzzZbddmg1fvuZG3JqzI9B4pqXZe/moJs4Z2YeUnFrUqhvDD3O1FJv6MujSpxi/LducYe27Exp+gXOiFOy5lQ0M4HH8yU5k9h+PYeziOnkPHcu+Qz1m4Mef9Jq71aFWTOev3Z1l+7OQZfLy9uC4yDIBbG1VNP9Y91fk6Fm0+SMdBv3LX0Jm80uMGAoplHa2ZXVsDaFijNDPf7sw3z99MrYol860+x47GElambPrfYeFliD9yJEu5mVMm8tS9d/DdmJE88MSzAJxOTmbqD9/QrdfD+RbPlaygjkWXYsfOd/3bMf2NjtzTulZ+VCOTU/FxBIWmD1UmMDScpPjse0dsXTCTynVvSP878dgRJg7qy3cv9qJeh24ElgzL9xivBI7zhAs3Uhxt56Jzt1KBHDyWoUzcJc7dgh3nbuNmbqJmhVBWj7qPv97rxqBvFmfJGXVpWp2pi3fmb33c8F0oqvFGhAdxbZVSrNlxtEjFP/i+Rgz5YRVp7roSFo+Xr3NWWJY1BccsoP7ACBzjVSKNMS861z8ANDTGPGlZ1qvAvTiex3oUWGWMGZbNducCa4FGQDDwoDFmuWVZg4HE86+zLGsj0NH5st+BOUAToKtlWVcDQ5wxHTXGtHGWu8a5/crAcGPMx67qYowZY1mWN/AFcAOORPOXxpiPLMuqDnwKlAZOAY8YY7ZaltUdGASkAseNMS1zsQ8bAcOBACAZ6G2M2WZZVnHgK6A2sAWoCvRzdp950LkcY0yac39eFpuLp89cPPGLzcUDanJ7w6PpNeXp0eoqbn/D0aFkx4HjjPplPRNe6kDSmRQ274sj5R+M4c5rLPZLvNbLRYorp21++ssGXu/ZiBlvdWZrdDyb9h7LcvfBFXfF36VJJBMyXMj7eNuoWzWcHu/MxN/Xm6mDbmP1ziPpd4EvJTd1uOQzjf7hdu9vU5vZ62I4eCxzrwkfbxs921zFLQN/YW/sSd68/yae6FyXj6euLxLxZ9S5cSTP/G9BDu+QO67ivDi21LQ09sbG8eULvTkcf4Je733Jz6/3Jbh41mSjZK/J1eW4q2VN7njrd5fr+306j0H3NsLPx4v5Gw+Qkuo4RrSsU4G211fisVsd814U8/WmYlhgrrvHbtwTR+P/TuLUmRRa16vI2GeiaPnC5Hypk8vjkYvG3b5rd9p37c7Cv2Yyefw4+r00iIlfjeG2bnfjH5D3O37/JgV1LLqUO974jcMJjouL7/u3Y+eB4/nSo+tCbC6ic1VR4O8lszmydzudX3gvfVlQqdJ0f30USQlxzBz5JtUaNqd4SGi+xXelsLnYp1nbTs5lLtbqugg27Y2j+1u/UrVsMBNevpVlW38iMdlxo6NMyQBqVyrF3PXReY7dFXd8Fy6Hu+ItXsyH0U+1YvB3y9NvPuVFYcffpn4EcSdOs2FPHI1rl8vjVuRKl98TbD5ojDlmWVYAjhlB2wCLgBed6+8C3rYs6wbgTqCBM4bVwKocth1ojGlqWVZL4Escjz65lKtwXOj3tSyrNPA50NIYs9uyrFIZytUGWuN4nMo2y7I+M8acu7gulmX9hCNBUNEYUwfAsqzzt63GAH2MMdsty7oJGAVEAa8B7Y0x+zOUzclWZ5wplmXdjCPBcifQF4g3xlxnWVYdHMmbjDG8aVlWK2An8IQxJstZRqZn4/pmnQCqV9uruaf1VQCs23WUCmEXsvHlSxXP0pX+4LGkTL0GypcK5HC8o8zR48mUKenI0JcpGUCcM9MKcHWlUN57uDk935tJQoZJD3+Y9zc/OLuB9bcaXvIi7mIHj53K1BOjfKnALPEeOnaKCmGBHIo/hbeXjRLF/UhIPON4bca6hl54bU7bvFji6XM89/mi9L8Xf9iN6Nisw0U8If6SQcWoXy2cR0bMyRTHsZP7ST6TQvKZFJZtO8Q1lUOzTVb0urk2d7dy3IVbt+to1veLv7jNnMq+zZxIpkyIIytfJiQgfQiKy30Tf4qGNUvTqFZZ7m9Tm0B/H3x9vEg6ncLvK/YAsDfW0Wvg12V7Mo3p9/T43zGOQ+HVlUPx8bKxwcXkaHlRNjSYQ/EXLnoPxx+nTMkSWcpcVy0CXx9vIkqHElk2jH2Hj1EnsmK+xHAlytiGeg2bRWgJf95/qCk9h/2Z6fiW0eodR7jTmchoWacCkeWc8/PY4NERc9h10fftg0eacW2VMA4nnKLXsD+zbWsZT1LnrNvP2728CA0qlqvJZXMSVroMcbEXflbijsYSGh6ebfmmrdsydvi7AOzYuoll8+fw3eiRJCWexOblha9fMTrc3v2y47pSFMax6FIOO++mx504zYyV+6hfPTxfkxWBoeEkxl+4j5IUf5TAkqWylIvZvIY103+k84vvpg/9yLSdkmGEVqjMoe2bqHZD83yLryjr1fYa7o2qDcDaXUeoEBYEOD47R7tIylT+4LFEype6MGSrfNglzt1OONrFXa2uYuTUtQDsOXyC6CMnqVGhJGt3OnpXdWpcnd9X7CElH4ZVuPu7UNTi9fG2Meap1kxZvIsZK/flWN6T4r+hVhnaXl+J1vUiKObrTYkAX0b0acHT+XSTpqjxwBFuHiG/h0c8ZVnWOmApjl4JkcAuy7IaW5YVhiOBsAhoDkw1xiQbY04Cv+Ri2xMAjDHzgeBcXPzvNcYsdf67MTDfGLPbuY2MU9tON8acMcYcBWKB8/1cL65LTWAXUM2yrE8sy+oAnLAsKwhoCky0LGstMBoo79zGIuAry7IewdGjIzdCnNvaCHwEXOtc3hz4wRn/RuD8bWIfHM+xXWSMuR5YArjsoWKMGWOMucEYc4Or9V/P2kL7l6fQ/uUpzFi5N33St+trlOZk8rn0roHnxSYkk5h8jutrlAagW4sa/LHKMRHgrNX76N6iJgDdW9Tkj9WOA2iFsEA+f+Zmnv5sXpYL4PPdxSqEBXLLjVX/UXfCdbuOUrVcMJVKB+Hr7UXnxpHMWp05wz9rTTTdmjvqdFujqizafNAZazSdG0fi5+NFpdJBVC0XzNqdR3O1zYsFF/fD19vxtbq7VU2WbTuUqyy3O+Lv2Kgqf66N4cy5C+NL/1i9j0ZXlcHby4a/nzcNqpe+5F3dr//cmj6Z38xV+7izuWPYSIPqpTl56mx6d8DzYo8nk3T6HA2qO9rMnc2rp7eNWauj09tctxY1Mi13td2nPltA4/9Ooumzk3hrwkp+WriTd8wqDsWfombFkpQqUQyAFnUqsGO/6yeyeGL853VpXI2pS/NnCAhAnaoV2Hv4GDFH4jmXksLvyzfSql7tTGWiGtRmxVbHe8afTGLP4TgiSuvu5aVkbEPe3l58/nRrnh694JK9kc4f6/x8vHi8Yx3Gz94GwPwNB+jd7sJksNdWcVzMPff5IjoMnEavYX8C2be10hmG29WvFo6XjXxJVABUr301h/ZHE3vwACnnzrF49ixuaJK5s+DBmAsnymuWLqJ8RcecG6+PGMPICVMYOWEKt97Zg9vv6aVExUUK41iUnYBiPgT6+6T/u2XdCmyLzt1TrHKrTNVaHD98gBNHDpGaco4dy+dTpV7jTGWO7tvJgm8/ocOTrxEQfOEUL/HYUVLOOtrxmaSTHN65mZBySqCe9/WszemTXM5cuYduznOv62uU4cSps67P3U6f5foaZQDo1qImM1ftAeCPVXvp3tJx4dq9ZS1mOs/p9h9NpHkdxz4PDwmgWvmS7I29cIzr2rQ6UxfvyJ/6uPG7UBTjff/hZmw/cJzPZ2wucvG/a1bT6OmJNH12Ev0+nceizQf/tYkKyV6+9axw3tW/GWhijDnlHFrhD/wIWDh6DPxsjLFbluW679+lXZxvsgMpZE64ZBwclTGVbHPx+vMynsmlAj7Z1cUYE29ZVj2gPdAPR72eARKMMfUv3rAxpo+zp8VtwFrLsuobY3K6TfomMMcYc7tlWVWBuRnq4EocjqEnPzv/ngg8lMN75Gj22mii6kew8MPunD6bwrOjLxw8Zg7pSvuXpwDw8rjFfPhYS/z9vJm7LobZzjkoRv6ynv89GUWPVrXYfzSJPh87HkX039sbULJEMYY4ny6SkprGba86Jogd83QbQksUIyUljVe+Wpw+UV1upKbZefWbpYx/oS3eXjZ+nL+Dv/cn8Nwd9Vm/O45Za6L5Yd52hvdpwYJhd5CQeIZ+nzqm9vh7fwK/LtvD7He6kpJmZ+DXS0mz28GOy20C9G53NY/fVofSIQHMGtKF2etiePGLxdSoEMLwx1qQmmZn+/4EXhi76FJhuy1+cAwxGPVL5sej7jhwnLnr9/PHkC7Y7XYmzN2e60evzl4XQ1T9iiwcdgfJZ1N57vOF6etmvNWZDgMdn/PLXy1xPPLK15s56/czZ51jXP+nv27gsyf+Q4//1GR/XCKPO59EcqntunI4IZnhP69j0iu3kJKaRkxcEs+OufRrPCn+8zreVDX94jQ/+Hh78/I9t9Jn+LekpqVxe7MG1KhYhpFTZnNt1Qq0rl+bZtfWYPGmnXR5dSReXjae696OkkGOrvu93v2C3QePcurMWdq88AFv9OpCszr/7CkWBemh7z+mVqvGBIWHMjR6Cb8M+ojFX5pCjeGZrvUoGVSMt3s5ZlDP+AjIr5+/mRfHLuJwQjJ9bq1Dm/oReHnZ+PavbSzefAiAEVPWMei+Rswa0gWbDaKPJLp8jFt2be3WG6vQs81VpKbZOX02lX6jLnv6onTe3j48+OTzDOn/FGmpabS6pROVIqthxo2mWq2ruaFZS2ZOmciGVSvw9vEhsEQJ+vYflG/vX9A8of2cV1DHotIhAUx/oyNBAb6kpcFD7a8hqv8USpUoxufPRAGOpylNXbKbuRuyzrdyOby8vWl+z+P8Nnwg9rQ0rmrWjlIVq7BiyreUrlqTqvUbs3TiF5w7fZpZ/xsKOIZ+dHhyEAkH97HEjHX0Ubfbua7dnYRFROZrfJfLU9rPX2uiiapfmUXDezgePTl6bvq6P4beQbsBjmFhA75c6Hx0qQ9z1kYze63jRsan09byv6dv5u5Wtdkfl8hjwx2/QcN/Xs1HfVrx57vdsNlgyIRlxJ90nD5HhAdRPiyIJVsO5nt9Cvu7cDlDKNwR79WVQ+nWvAZb9h1jxludAXh34qr07Xl6/Je7v+XfwXbxPAR5ZVlWF+BhY0wny7Jq4xim0AFYh2OIx16gv3OuiRtx9EBoiiNhsgr4PIc5K7Y6L/6bA58ZY+palnVK0jq3AAAgAElEQVQf0NEY08OyrOtxDD05PyPgrxmGa5TGMdQkfRiIc4jHYFzPeVEvm7psBM4aY05YllUf+MoYU9+yrMXAR8aYic5EzHXGmHWWZVU3xux0bnsNjmEpa13UrxXwvDGmo2VZPwPjjTE/OeN7wBhT1bKsF4BqxpjHLcu6xrlfmxhjVlqW9QMwxhgz2zkvyG3GmEvetoq494si29lo//cPE3HfOHeHkWcx43srfje6EuI/M3+Cu8PIs2It7+Yxcv+kH08zmr1Fvv2siYl3dxh51iAiVO3HjWLG9+aD+flzB90dnmtZo8i2n9E4ejlU6DHazZHkzYEfHgMosu0/ZnxvQPG7S8z43tjt9rzc7C4ydh896fHXZpHhJQr9M8jPYSAzcPRKWI+jd8BSAGNMPLAZqGKMWe5ctgKYhuOCezKwEshpBrF4Z1Lgf1zoOfATUMo5/OJxwOVzb4wxR3DM1TDZObTjx7zUBagIzHW+31fAAOfye4GHnNveBHRxLn/fsqwNziTIfGd9c/IeMNSyrEVkHjoyCijtjKk/jmEg5/dZf2Cwc11P4LlcvI+IiIiIiIiIR8q3YSDGmDPALdms6+hi8TBjzGDnUy7mAx/k8BY/GWMGZFxgjEkG2mVTvs5FZX/H8YSQjMsGX/R3xte4rAtw/cULnHNhdHCx/I5stnFxubk4h3sYY5YAGZ8b9qrz/6eB+4wxp51PH/kLR28VjDF7gRyfNCIiIiIiIiJSFOT300D+iTHO4Qz+wNfGmNVujKUoKA7MsSzLF8f8FY8bY3I/qYOIiIiIiIh4HI8fA+ImbktWGGPuuXiZZVmfAs0uWjzCGNOqUIIqYJZltQfevWjxbmPM7Tm91vnUFJdP8RARERERERG5krizZ0UWxph+7o6hIBljZgIz3R2HiIiIiIiIiCfLzwk2RUREREREREQum0f1rBARERERERH5N0nTpBUuqWeFiIiIiIiIiHgUJStERERERERExKNoGIiIiIiIiIiIm9g1DMQl9awQEREREREREY+iZIWIiIiIiIiIeBQNAxERERERERFxkzQ0DsQV9awQEREREREREY+iZIWIiIiIiIiIeBQNAxERERERERFxEz0NxDX1rBARERERERERj6JkhYiIiIiIiIh4FA0DEREREREREXGTNA0Dcclm1wCZfyWbzaYPXkREREREPJ7dbre5O4aCtPnQCY+/NrumXHChfwbqWfEvVfGese4OIc/2f/8wFXqMdncYeXbgh8eIuG+cu8PIs5jxvanc+zt3h5Fn+8bdW+TjL+rtp6jHf2TEs+4OI89KP/1hkd//RT3+x6ji7jDybDR7i/z+L6rxx4zvDcDOZ+52cyR5U334BIAiv/+L6vnDvnH3AkV//8u/j5IVIiIiIiIiIm6iwQ6uaYJNEREREREREfEoSlaIiIiIiIiIiEdRskJEREREREREPIrmrBARERERERFxkzQ0aYUr6lkhIiIiIiIiIh5FyQoRERERERER8SgaBiIiIiIiIiLiJnp0qWvqWSEiIiIiIiIiHkXJChERERERERHxKBoGIiIiIiIiIuImaRoH4pJ6VoiIiIiIiIiIR1GyQkREREREREQ8ioaBiIiIiIiIiLhJapq7I/BM6lkhIiIiIiIiIh5FyQoRERERERER8SgaBiIiIiIiIiLiJnoaiGvqWSEiIiIiIiIiHkU9KyRbb9zfmKh6lUg+m8J/R89n4564LGXqVg3joz4t8ff1Yfa6aF77ZikAJQP9GPVkFJVKBxF9JJHHP57N8VNn019Xr1o4017vRN9P5jB9+R4A9n7bm63R8QDsP5rIgx/+eXnx92pKVH1n/J/NdR1/ZDgf9WmFv583s9dG89rXi53xF+Ozp9tQKbwE0UdP0mfEnxxPOktIoB8fPPYfqpQN5szZVJ4bPY9tMfHp2/Oy2fh9yO0cOpZEr/dnXlb8r/dsRFS9CJLPpPDsmIVs3Hssa/xVw/jw0eaO+NfFMOjb5c74/fj0iVZUCg8i+mgifT+Zy/FTZ+natBp9b6sDQNKZFF7+aglb9sVTvlRxhj/WgtIhAaTZ7Xw/52++/GNLnmP/T53yDLqnId42Gz8s2Mlnv23OtN7Px4sPH25C3SqliE86wxOfLSImLgmAvrdew10tqpNqtzP4u1XM33QQgIfaXkWPltWx22Hr/gRe+GIpZ1LSGPFIU+pGliIlJY11u+MY8M1yUlLzLztdmHXJTwXRfqqXD+GDR5pRp2oY709azejfNqVva/GH3Ug6fY7UNDupqWncNujXf3X8OfGtchWBLbtis3lxetMyklfNzrQ+sEVnfCNqAGDz8cNWPIhjowcWaEwZFcT+v9R2B9zVkDb1IwAYMWUdvyzb43Hxe1L7uVjPL96jbscoTsbG8Wbd9oX63lD47WXP1/ezNToBgANxiTz4keP70+ya8rxy9w142WwknT7Hc2MWsif2pNvrkl3bKebrzaRXOuDn6423l43fVuzlw8lr/1G8uRVQ+zrCbr8fm82LE8vmcPyvXzKtD+t6H/41rgHA5lsM7xLB7H35EQC8S4ZRuscj+JQMA7udQ2PeIyX+aL7E1apuRQb3bIS3l40Jc7cz6tcNmdb7+Xgx/LEW1I0MIz7xDH1HziPmaCIA/TrVpcf/2bvv8CiKN4Dj37tLAgkhHQgQQleQXlQEAgFpFkBBRiyIKD+xYgFFEMWCYEUsqCh2LAyIgIIgSu+9gxBKCAmQQgJpkOTufn/s5UjgAiGkHPh+nsdHsjs7+87e3N7u7Mxsx/pYbXbG/LCWpdvjLprnC3e14LYbamG12flh0b9889duurWswfC+LbDZwWq18eqP61i/N/6Sy1Lc1wt1QivyyaPtnduHV/JlwqxtfL3wX25tXYNnezehXlV/eo1dwPZD59fTwijN41/Q9/N/Pa6jf+Q1WK02klJPM/zLlcQ6josQ0rNCuNS5WRi1Q/1oP2w6I75awfhBbV2mG/9QO16YspL2w6ZTO9SPTs2Mi80nejVj5c44IobNYOXOOJ7o1cy5jdlkYlT/61m6LTZfXqezrHQfNYvuo2ZddkNF5+Y1jPifncaIL5cz/uGIAuJvz4gpy2j/7DRH/DWM+Hs3Z8WOWNo/N40VO2J5oldzAJ7q3YKd0Ul0HfErT3+2mNcH5j8ug29pzL7YlMuKHaBTs+rUruJHxPCZjPh6NeMG3eQy3bgH2zDi61VEDJ9J7Sp+RDatDsDjPZuwcudROjw/k5U7j/J4zyYAxCSk0u/N+XR7aQ4fztrK2w8Z8Vutdt74aT2dX5xF79fmMrBLA+pX8y9S7GaTiTfub83ADxbTZfRcet1Yk/rV/PKluTuiLifTs+g48ne++utfXuxnHN/61fzoeWNNur48l4ETFjN2gPGjViXAm0FdruX21xfQ7ZV5WMwmet5YE4BZaw7RedQfdHtlHuW8LPSPqFukuN2hLMWlpOpPSvoZxvywli/m7XCZnxo3nx6j51z2jdqVHv9FmUz4Rvbh1OwvSZ76DuWuaYElqEq+JOnL55Dy8wRSfp5A5tYVZEVtLyCz4ldSx7+gfDs3C6NxrWC6vzSHnq/O5dFbG+Nb3tPt4neb+uPC6m9n8HGPgaW+Xyj9+gLG9UKP0XPoMXqOs6Eidx9DP1tGj9FzmL36AEPvaMalKO26cybbyt3jF9D9JaMskU2r06JupUuKuVBMJkL6DuLYF+8Q8/bz+LZoi2eV6vmSJM2aSux7o4h9bxSnViwgY9t657rK9z3GyUV/cOSt54n94GWsaaeKJSyzycTYgTfywLsL6TxiFr1vqn3etUf/jvVJSc8iYvhMpszfxai7WwFQv5o/vdrU5uYXZzHg3YW8ObANZpPpgnmqiHpUDa5A5Ijf6PziLOasOQjAip1H6eb4DIZNWck7D7crUlmK+3rhwLFUbn31T2599U9uf20+mVk5LNgUA8De2JMMmbSctUVoVMkbc2ke/4K+nzuiT3DbK7/T7aU5zFsfzUv9Wxe5TOLqU6aNFUqpSKVU2zx/P6qUeqAsYyoMpdSDSqlqef4+pJQKuYz8aimlXF/9FG57k1LqTaXUXqXUbqXU0KLmlatbq5rMWB4FwKaoBPx8vKgc4J0vTeUAb3y9PdkUZZwoZyyPonsr46arW8twpi/fB8D05fvo3ircud2g7tcxb/0hEk9lXm6YBereqhYzHPvfFBWPfwHxV/T2YuO+3Pj30aN1Lcf2NZm+bK8R/7K9zuXXhAWyYofRyLI/7iRhlSoS4m/kWzWoAje3COfnxXsuO/5uLcP5dcV+ADbvdxx//3Pi9/fG19uLTVEJAPy6Yr/zOHdrGe78/IzPxVi+cV+C84nV5qgEqgb6ABB/MtP59Cj9dA5RcScJDfIpUuzN6wRzKD6NmIR0sq02fl8bTVfHE9NcXVuE8esq4yJh3obDtGto3Kh1bR7G72ujycqxEZOYzqH4NJrXCQbAYjFR3st4+uTt5cHxFKP+LHa05ANsPZBE1SLG7Q5lKS4lVX+STp1m68Eksoux58rVGP/FeFQJx5qShO3UCbBZObNvM151GhWYvty1LTizd3OpxVdSx7+gfOtX92ftnmNYbXYyz+SwK+aE8+bPneJ3l/rjStTydWScOFkm+y7t+nIhdsDX22joqujjxfHkDLcoy4XqTsaZHAA8LGY8LGbsFH/9Khdej+zE4+QkxYPVSvrm1VRo3KrA9L4t2pK2yehp6lmlOiazhcy9xmWqPesM9uysAre9FM3rhnDoeCqHE9LIttqYs+Yg3fJcL4LjmK4wjuncdYdo16iqsbxVOHPWHDR+YxPSOHQ8leZ1Qy6Y54Cbr+XD37aSOzVA0qnTwNnPAMCnnAf2IswdUFLXC7naXVeFw/FpxCYZdTrq6CkOHLu0XkPnxVzKx7+g7+fq3cc4nWUFjHuOol5/Xumsdrvb/1cWyrpnRSTgbKzQWn+utf6+7MIptAeBahdLVIoeBGoADbTWDYFfLjfD0CAf4vJ0wTp6IoPQwAr50wRW4OiJvGnSnSeYEH9v4h03YPEpmQQ7fuxDA324pXVNfvj7/Bv6cp4W5r7Rizmv9XQ2elxe/GnnxHZO/EEVOHoiT5qkC8TvZ8S/KzqJW6+vDUDzupUIC/GlqiPf1x64ibE/rcVmu/wvc2igD3EFHNu8ZTzv+DsaH0L8vIk/6Yj/ZCbBfuXP20f/yPosPqd3C0BYiC+NagaxOapoXTxDA7zzx5Wc4Ywrb5rc8lltdlIzswn0LUdooA9HT5y9uDyWnEFogDfHUzL5Yv4eVr/bm/Uf3ElqRjbLdx7Ll6eHxUSftrVZsv1okeJ2p7JcdtylUH/OZcfOjyO6Mff127m30zX/6fgvxuzrjy3tbA8sW9pJzBVc92QyVwzE4hdE9pF9JRpTXiV1/AvKd/fhZCKbVqe8l4VA33Lc1LAq1YLzn6/dIf4LKc36425Ku76A43rhtduZPea2fA9DXpiyku+HdWHdh/3o064uk36/tB5JZVF3zCYT88f2Ysuk/izfEceW/cUzvCIvj4BAclLODoXNOXkCi3+Q67SBIXgEVyJznzFUxbNSVayZ6VQZ9AzVh40jqOe9YDIVS1wuj/e5v7F5rketNjupGVnO39h816nJxrYXyrNm5Yr0bFObua/dzvfDu1CrSkVnuh6twln89p18N6wLw6esvPSylMD1Ql69bqjJnLXRlxzXBWMu5eNfmO9n/471WeLi2lT8d5XInBVKqVkYN8/lgQ+11l8opXoA4wALkAg8DDwKWJVS9wNPATcDacBc4Dut9Q2O/GoBc7TWTZVSrYAJgK8jnwe11i7vTpRSS4DNQCugEvAAMBJoAkzTWo92pHsOeMix2RSt9UTHPv8EVmA0qMQCvYHbgNbAj0qpTCC3j+BTSqmegCfQT2u9RynVEfjQsd4OdNBaX7AZ1LHfH4DcK7UntdarlFJm4BOgI3AQo6Hpa631DOAx4F6ttQ1Aa130PmEOJs7/ITq3pdnVb9XFGt1eHdCGcb+sdznj7Y1Dp3E8JYPwShWZ9tIt7Ik5QfQljjU9G5ur+M9J47KMF873kzlbeP2Btvw1vg97YpLZcSgRq9VGlxbhJJ7KZPvBRG5qWLVIMeeLrRDH1tWlQmGbSW5qGMrdHerTZ+yf+Zb7lPNg8tBIXv1xHWmnswuZ2zlcxl6YumN3vRzw8/GkW4vqtB8xh1MZWXz6WHvubFOL39YccqYbe//1rN0bz/p9CUWL25UyKsvlKun640qf1+dxPMW4OP9pRDf2x51k7b/Hi5TXlR5/cSp3TXPORG27+MmpGJXU8S8o32U74mhWJ4RZr9xGUuppNkXFk2Mt+hwuUn9KV2nXF4A2z0zneEom4ZV8+WVkD/bEJBMdn8rgHo144P2/2bI/kSG3NuKV+67nha9WFaYYF92nM42L7S6n7tjsdnqMnoOfjxdfPt2Ja8MC+PfI5Q8nza/wUVdocRPpW9c5C26ymPGu04Aj748iJzmRKg8MpeINHUldu+TyoyrCdSQYkRe0rdnFY9jcPL08LZzJtnLbmD/o0Tqc9//Xnr6O66D5Gw8zf+Nhbry2CsP7tuDet/8qfEGgRK4XcnlazHRpXp23f916aTFdRGkf/4t9P+9sW4emtUPo9+af52ci/rNKqmfFQ1rrVhg39UOVUlWAL4G+WutmGDfzh4DPgQ+01s211stzN9Za7wa8lFJ1HIvuBrRSyhP4GLjLkf/XwJsXiSVLa93Bsa/ZwBNAY+BBpVSwo/FjEHAj0Ab4n1KqhWPb+sAkrXUjIMUR/wxgA3CfI+7c/tuJWuuWwGfAcMey4cATWuvmQARQmL7e8UBXR153Ax85lvcBamE0tAzmbCMJQF3gbqXUBqXUn0qp+q4yVko94kizwdX6gV0bsmDcHSwYdwfHUzLyPdmqGuTD8ZT83SmPnkh39iow0lRwdulKPJnpHHZROcCbJMeThqa1Q5j0ZCdWT1TcdkNt3nywrbMXRW7+hxNSWb37KI1r5e8CdzEDu17HX+P78Nf4PhxLTqdasO85seWfrOfoiTSqBuVJE3yB+B1DVtIys3lu8lK6jZzJ0E8XE+znzeGEVFpfW4VuLWuy5qN7+HTozbRrVJ2Pnuh0afF3acD8sb2YP7YXx5MzqVbAsT0bf0bBx/9UprPramV/b2dXR4AGNQJ59+G2PDxxESlpZ5zLPSwmvhjaiVmrDjB/w+FLij2vY8mZ+eMK9DlvmMPRPOWzmE1U9PYkJT3LUaazrfqhjm3bXxdKTGI6J1LPkGO1M3/TEVrVOzvy6ulejQmqWI43ftlU5LjdpSxFVVr1pyC5xyXp1GnmbzhM87qXVqYrPf5LYUs7idk3wPm32dcfW7rrLvzlrmnBmX9LfghIaRz/oycyCsz34znb6DF6Dve9/RcmTBw8fmlj4v9L9ccdlHV9yT3ehxPSWLPnGI1qBhFUsRzXhQc6eyb8vvYQrepXdouyFMapjCxW7zl2WUOgCpKTcsKYHNPBwz8I68lkl2l9W9zkHAKSu+2Z2EPGEBKbjfQdG/AKq1Uscbn8jM+51jx24uz1qMVsoqKPFylpZ4xt816nBhrbXijPoycymLfe6J0wf8NhGtQIPC+mtf8ep2aVigT6lrukspTE9UKuyCZV2RGdTOIl1KfCKM3jf7HvZ/tGVXmqV1Me+uAfsop5wvErhc1ud/v/ykJJNVYMVUptBdZg9LB4BFimtT4IoLUuzJS1GlCOf98NTAOuxWhoWKiU2gKMBsJcb+40x/H/7cBOrfVRrfUZ4IAjtvbAb1rrdK11GjATo2EB4KDWOnda5o0YjQUFmeki3UpggmMOiQCtdY6rDc/hCXyplNoOTAeucyxvD0zXWtu01seAxXm2KQec1lq3xmgU+tpVxlrrL7TWrR3pzvPdwt3OCS7nb4jmrghjJvqW9SqRmpntHBaRKz4lk7TMbFrWMyaDuiuiHn9tNH4EFm46TL8Io82kX0R9/tpk3Py2fVZz0zPGf3PXHeSlb1exYGM0/j5eeHkY1THQtxzXX1OFvZc4UeV3C3fRbeRMuo2cyYINh7jLsf+W9SpzKiPLdfyns2hZr7Ij/vos2HgIgL82RtOvg9GVt1+Ha1jgKJefjxeeFiPOezs3YO3uo6RlZvPWL+tp/eRPtBn6M49/9A8rd8YydNJiLsV3f+9xThi2YONh+rY3JopsUbcSqRlZzq6lzvhPZpJ+Ots5GVff9nWdx3nhphjn53dXRD3n8mrBFfjy6U48PXk5B4/lvxl4d3A79sWd5Mv5+WevvlRbDyZRu0pFaoRUwNNipueNNVm4JX+Xvr+3HKFvW2M4za2tw1m1x3gCuXBLLD1vrImXh5kaIRWoXaUiWw4kEXcigxZ1ginvZQGgXcMqRB014u8fUZeOjavy1ORVxf7wubTLcjlKo/4UxLucBxXKezj/3aFJNf6NucTv7xUe/6XIOR6DJSAEs18QmC2Uq9+CrAM7z0tnCaiEqZw3OccOlVgsuUrj+C/cFOMyX7PJRIDjxqBBjUAahgeyLM9cNO4Sf0FKu/64g7KsL+deL7SuX5l9sSmcTM+ioo8XtUONSQ0jGlcjKu7in0NZ1p2giuXw8/ECoLynhYhG1YiKK/65R87E7MezUigeQZXAYjF6T+zceF46z0pVMftU4Myhs8POzhzej9m7AuYKxpAJ73qNyD5WPN30tx5IpFaoHzUq+eJpMdOrTW0WOiaQzLVwcwx3tTeO6W031GLlLqMz9cJNMfRqU9v4ja3kS61QP7bsT7xgngs2HqbddaEAtGkQ6rwOqlX57HCQxjWD8LKYSc7zMKdQZSmB64VcvW6sxZx1xTsEBEr3+F/o+9moZhBvDbqJhz7455Ia+MR/Q7EPA1FKRQJdgJu01hmOoRhbMRoaLsU0YLpSaiZg11rvU0o1wWhwcD09s2u5Zxtbnn/n/u2B675x524LYAUuNLPTmTzpPAC01m8ppeYCtwJrlFJdtNYXm33xWeA40AyjMSn3W3uhOI8Avzr+/RvwzUX2cVGLtsTQuXkYKyb043RWDs9NdnZ8YcG4O+g+ahYAo75ZxYQhHSjvZWHJ1iMs2noEgE9+38bnT3Wmf+Q1xCam8+hH/1xwf/WqB/D2w+2w2eyYzSYmzdl2WW/V+GdzDJ2bh7NyYn/j9WOTlzjX/TW+D91GGm1LI79e4Xh1qQeLt8SwaItxkp40ZwufP92FeyIbEJuUxpCJxttJ6lcP4MPHOmG12dkbm8zwL5YWOcYLWbT1CJ2bV2fFe33IzLIy7MsVznXzx/aix2ijDW7Ut6uN16d5Wli8LZbFW40fxkl/bOezJzvSv2N9YpPSeOxjo/zP3NGMAN9yvDnQ+ArlvmLv+msqc1f7euw+fIL5Y3sB8Pb0jc78LoXVZueVqRv4/rlOWMwm9IoD7Is7yXN3NGHboRP8vSWWacv288H/2rJ0fE9S0rN4crJRvn1xJ5m7/jB/j72NHJudl6caQ4a2HEhi3oYY5o7pgdVqZ+fhZH5aakz49OYD1xOblM5vL3Uzjs/GGD76vcjz1ZZpWYpLSdWfSv7ezH39dny9PbHZ4OHu19F5xCyCKpbjy2c6A8aTl9mrD7Jke9EvZq/0+C/KbiNtyUz8ez8CZhOnd67DeuI4Pjd2Jyf+CFkHHa81vLYFZ/aWzGsML6Skjn9B+Xp6mPl19C2A0Xtt6GfLsV7G3D9Xff1x4eGfPuKayDb4hgQyPmY1v4/5gFVf61LZd2nXl3rV/XlrUFtsdjtmk4lJf2xnn+MGf8RXq/hiaCdsdjsn07MYnieWsixLQXWncoAPHzzSHovZhNls4ve1h/hny5FL/AQKwWYj8ddvCR3yIiazmdS1S8g+Fktgj7s4E3OAjJ1Gr0Tflm1J37w6/7Z2Oyfm/EjVx1/CBJw5cpBTaxadv48isNrsvPz9GqY+3xWL2cS0ZVHsjU1hWJ/mbDuYxMLNMfyydB8TH41g+Xt9SEk7wxOTjOuuvbEp/LH2EIveuoMcm53R360xnvzacZknwKd/bOejxyIY3KMR6aezef4rY26KW66vSd/2dcmx2jmdlcPjky792q4krhcAyntZiGgUyqjv1+XbX/eWYbx2b2uCKpbjm6c7sismhQcmXNpDstI+/gV9P1/q3xqf8p58/pTRIznv64iFMBVlxtsLUUr1BgZrrXsqpRoAW4ABGPNMdNBaH1RKBWmtTyilhgF+Wusxjm1fBdK01u85/l4P7AG2a63fUUp5AbuAAVrr1Y5hIddorc9/JIVzzorhWusNjkaU4Vrr2/Ouw2i0+BZjCIgJWOuINxn4Q2vd2JF+OOCrtX5VKfU7MEFrvdix7hDQWmudqJRqDbyntY5UStXVWu93pJkFfKu1nuUizlq5+1JKfQAc0Vq/r5QahDEvhUkp1Q8YCPTCmH9jN/CI1nqGUuotYK/W+mtHOd/VWl9/oc8p7L6v3G8680KK/Wkw1fpPLuswiizulyGE3X/Z7Ull5sjUQYQP+rGswyiyw9/cd8XHf6XXnys9/oQPnyvrMIqs0tMTrvjjf6XHP4TifVVxaZpM9BV//K/U+I9MHQTA/mfuKeNIiqbuxJ8Brvjjf6VePxz+5j7gyj7+dru9eGZ2dVPLDyS5/b1ZRJ3gUv8MSmIYyHzAQym1DXgDYyhIAsZQkJmO4SHTHGl/B+5USm1RSkW4yGsacD/GkBC01lnAXcDbjny2kOdtIkWhtd6E0VixDqOhYorW+mIDhL8FPnfEfaHeFs8opXY4Ys3EmLDzYj4FBiql1gDXALkTLfyK0YNiBzDZEWtuX8G3gL6OoSPjMea0EEIIIYQQQgghrkjFPgzEMR/ELQWs/vOctHuBpnkWLT9n/XvAe+cs2wJ0KGQskXn+vQRYUsC6CRg9P/Juewhjfoy8seT++1fODruAPHNZaK03YLySFa31U4WM07kvrfU+8h+TkY7lNibCflMAACAASURBVKXUcK11mlIqGKNxZbtjXQrGW0qEEEIIIYQQQogrXom8ulSUmD+UUgGAF/CGY6JNIYQQQgghhBBXqLJ624a7uyoaK5RSk4B25yz+UGvtVgOzHBOE/nDO4jNa6xsLs33e3iBCCCGEEEIIIcTV6qporNBaP1HWMRSG1no70Lys4xBCCCGEEEIIIdzZVdFYIYQQQgghhBBCXImsMgzEpZJ4G4gQQgghhBBCCCFEkUljhRBCCCGEEEIIIdyKNFYIIYQQQgghhBDCrcicFUIIIYQQQgghRBmxyZQVLknPCiGEEEIIIYQQQrgVaawQQgghhBBCCCGEW5FhIEIIIYQQQgghRBmxyjgQl6RnhRBCCCGEEEIIIdyKNFYIIYQQQgghhBDCrcgwECGEEEIIIYQQoozY7DIMxBXpWSGEEEIIIYQQQgi3Io0VQgghhBBCCCGEcCsyDEQIIYQQQgghhCgjVhkF4pLJLuNj/pNMJpN88EIIIYQQQgi3Z7fbTWUdQ0n6Y/dxt783u71hlVL/DKRnxX9U2P3flHUIRXZk6iCJvwxJ/GXryNRBZP45uazDKDLvW4bw/rKosg6jyIZ1qHfF15/Xytct6zCKbMzp/VJ/ytCRqYMYQs2yDqPIJhPNO0v2lXUYRfJCZH3gyr1+OzJ1ECDxl5Xc+KvfO6WMIyma2J8Gl3UIooxIY4UQQgghhBBCCFFG5G0grskEm0IIIYQQQgghhHAr0lghhBBCCCGEEEIItyLDQIQQQgghhBBCiDJitckwEFekZ4UQQgghhBBCCCHcijRWCCGEEEIIIYQQwq1IY4UQQgghhBBCCCHcisxZIYQQQgghhBBClBF5dalr0rNCCCGEEEIIIYQQbkUaK4QQQgghhBBCCOFWZBiIEEIIIYQQQghRRqwyCsQl6VkhhBBCCCGEEEIItyKNFUIIIYQQQgghhHArMgxECCGEEEIIIYQoI/I2ENekZ4UQQgghhBBCCCHcijRWCCGEEEIIIYQQwq3IMBAhhBBCCCGEEKKM2GwyDMQV6VkhhBBCCCGEEEIItyI9K0SBXhtwA52bhZF5JofnvljBjugT56VpUiuYCY+0p7yXhUVbjzDmh3UABFTwYtKTkdQI8SUmMY3HP17CyYws6lb15/3/taNxrWDenbGJyfN2AlA1yIeJQyKo5O+NzW7np8V7+fqv3UWOPbJJdV4dcAMWs4mfl+zj0z+251vv5WFm4pAImtQOJjntDI9/spQjiWkAPNGzCf071sdqszPmh7Us3R53wTzbXVeVl+5pjdlkIv10NsO+WMGh+NQix56rNI8/wOAe19G/Y30A9sQkM+zLlZzJtpZ5zAXle114EOMebIOvtyc2m52P52zj97WHAGh7XSij77keLw8z2w4m8fyUlVgL0WLtLvGXVJ1aufsgb89cjM1m5842jXm4643npVmw+V8+/3MVmExcW60Sbw28jbgTp3juq9nY7HayrTbuiWiBat/ssuO5VId3bGDVz5Ox22w0iOhOi1tVvvXb/prJ7uULMJstlK/oT+SgZ6gYXIXUpOP8NelN7HYbNmsOjTv35LrI24otrtI833z0WARNa4eQY7WxZX8iL36zihyrnSG3NuLOtnUB8LCYqFfNn+aP/0JKelaxlbNu1w50f280ZouFzd9qVr43Od96//Bq9Pr8LXxCgshMPslvDw0jNfYYAH41qtLz0/H4hYWCHX6642FOHo4tttgKw13rD5TuuQfg0HcPsCcmBYC4pDQe+mARUHLnnosZ8NU7NLm9M6nxSbzRpHuJ768oYnZsYM20L7DbbFzbvhvNbslff7Yv/I1/VyzAZLbgXdGfiIHPUDG4MqlJ8fz92VjsNhs2q5VGnXvSsOOtJRZnSdSlO9rW4fHbGgOQfiaHUd+uZvfhZMp5WpjxUg+8PC1YzCbmrY9mwswtRY69JM6l7w1ux80twkg6dZouI2eft88htzZi9D3X0/Sxn0lOO1OkuN3l+zvhkfbc2KAKqRnZADz3xQp2HT4/lgt5/YE2dG5Wg8ysHJ6dvIwdh5JcluWDRztQ3tODRVtjeOX7Nc6yfPpUZ2pU8iUmIY3HPlrEyYws7mxbl8d7NgUg/XQ2I79ZxW5HXKsnKtJPZ2O12cmx2rjt5TmXFK+4+knPCuFSp2bVqV3Fj4jhMxnx9WrGDbrJZbpxD7ZhxNeriBg+k9pV/IhsWh2Ax3s2YeXOo3R4fiYrdx7l8Z5NAEhJP8OYH9byxbwd+fKxWu288dN6Or84i96vzWVglwbUr+ZfpNjNJhNjB97IA+8upPOIWfS+qfZ5efXvWJ+U9Cwihs9kyvxdjLq7FQD1q/nTq01tbn5xFgPeXcibA9tgNpkumOe4B9sw9LNl9Bg9h9mrDzD0jsu/iSvt4x8a6MOgbg25/ZU/6DJyNmaziV5tartFzAXlm5mVwzOTl9Nl5GwGvLuQMfffgJ+PFyYTfPBIBE9MWkqXkbOJTUzjroh6V0z8ufso7jpltdkYN/0fPh3Sh99GPsj8Tf+y/1j+i5Do+GS+WriW7565h99GPsjzfToBUMmvAt8/ew/6hQf48bl7+eafdcSfTLvsmC6FzWZl5Y+fcuszr6Pe+JyodUtJjjucL01weF36jP6Qfq99Sp1W7Vkz/WsAfPyDuGPk+9w15hPuHPUBm/+cTnrK+RdgRVHa55vfVh0g8oXf6DJyNuW9LNwTeQ0Ak+ftpMfoOfQYPYe39EbW7DlerA0VJrOZWya+yk+9H+bTFj1o1O92Qhrk/151HT+SrT/+xuQbbmfZuI+5+fXhznV3THmP1R98yWctejAlog/pCcVz/AvLXesPlP65B+B0ltVZX3JvdHL3UdznnsJY/e0MPu4xsFT2VRQ2m5VVP31G96Gv0fe1z9i/ftn59adGHe4YNZG+YyZRq2U71v2aW38C6TXiffq88gm9R05g6/zirT95lVRdiklIpd+b8+n20hw+nLWVtx9qC8CZbCt3j19A95eMuhTZtDot6lYqUuwlcS4FmL48igHvLHS5z6pBPkQ0quZs8CgKd/r+Arz58wbnukttqOjcLIzaoX60HzadEV+tYPygti7TjX+oHS9MWUn7YdOpHepHp2ZhADzRqxkrd8YRMWwGK3fG8UQv4/xxOCGVu96YS9eRv/HhrC2883C7fPn1GzuP7qNm/ecbKqx29/+vLEhjxQUopSKVUn8UY35FPhsqpfoppXYqpWxKqdZ5lndVSm1USm13/L9zccTarWU4v67YD8Dm/Qn4+XhR2d87X5rK/t74enuxKSoBgF9X7Kd7q3Dn9jOWRwEwY3mUc3nSqdNsPZhE9jk1Pv5kprPFOP10DlFxJwkN8ilS7M3rhnDoeCqHE9LIttqYs+Yg3Rz7z1u+GSuM+OauO0S7RlWN5a3CmbPmIFk5NmIS0jh0PJXmdUMumKcd8PX2BKCijxfHkzOKFPe58ZXm8QfwMJsp72U8HfH28rjkcpRUzAXle/DYKQ4dN574HU/JJOnUaYIqliPQtxxZOVYOHjsFwPIdcdx6fc0rJn4omTq1I/oYNSoFEBYSgKeHhR4tr2XJ9qh8aWau3kb/iOb4+ZQHILii8R309LDg5WF0xMvKsZbJuMr4g3vxq1wNv0pVsXh4Uu+GDhzasjpfmuoNmuFZzoi9St0GpCcnAmDx8MTiaRxPa042FOPrwUr7fLN469neCFsOJFI18PzzZO82dZi9+kCxlRGg+vXNSN4fTcqhGGzZ2eycPpdrb++SL01Ig3ocXGJ8JoeWrnGuD2lQD7OHhQOLVgKQnZ5BTubpYo3vYty1/kDpn3supCTOPYURtXwdGSdOlsq+iiLhnPpT5/oORG9dky9NtQbN8HDUn8p1Cq4/9hI8f5ZUXdq4L8H5tH9zVEK+807GmRwAPCxmPCxm7BStfCVxLgVY+2/BDbdj7ruBN6dtuKyvtDt9fy9Xt1Y1nbFsinLsM+CcsgR44+vtyaao+Dwx13TGPH35PgCmL9+Xp/7EO+vPpn3xVA2qUKLlEFcXGQZy5dgB9AEmn7M8EeiptY5TSjUGFgDVL3dnoYE+xJ1Id/599EQ6oUE+xJ/MPJsmyIej56Zx/ICF+Hk708afzCTYr3yh9x0W4kujmkFsjkosttjPbekPDfIhLslIY7XZSc3IItC3HKGBPs4fE4CjyWfLVFCeL0xZyffDunA620pqZja9X51bpLgvVoaSPP7HkjOYPG8Hayb243SWlWU7Ylm2I84tYi5Mvs3rhOBpMRMdn4rdblw0Na0dzLaDSdx6Qy2qFeKH0V3ih5KpU/En0wgNqOj8u3JARbZHH82XJjohGYCBE3/GarPz2C030a6h0cPmWPIpnpz8GzGJKTzbuwOV/X0vO6ZLkZGchG9giPPvCoEhxB/4t8D0e5YvILyJs12XtBMJ/PnhGE4lHOXGux6iQkBwscRV2uebXB4WE33a1eXVH9bmW17ey0Jk0+q8/H3+G6nLVbFaFU4eOVtfTsUeo/oN+Z+6H9++m4Z3dGfdpO9o0Lsb5fx88Q4KILh+LU6nnKLfL5MIqFmDg4tX8s/od7HbbMUa44W4a/2Bsjn3lPO0MPe128mx2fn0j+0s2Gj0EiiJc8/VICMliQpBeepPQAgJBwuuP3tX/EWNxvnrz4KPX+VUfPHXn7xK49qhf2R9Fm8722hqNpmY90ZPalWpyHd/72HLfve6ditI1xY1OJacwe7DyUWK90Jxl9X3F+CFfi155o5mrNx1lPHTNpKVU/jzbN7ja+wzg9DACsSn5ClLYIXzy+J4uBji7+1MG5+SSbCLxpX+kdeweOsR5992O/z0Yg/swI//7OHHxQV/r8R/k9s2ViilZgE1gPLAh4AFqK21fsGx/kGgldb6KaXUy8B9QAzGzftGrfV7BeQ7FHgUyAF2aa37K6VuACYC3kAmMEhr/e8521UAPgaaYBy3V7XWs5VSjYBvAC+Mnip9tdb7LlI2X2A2EAh4AqO11rMd61yWRWu927E+X15a6815/twJlFdKldNaF23gnYOj91w+57Y8u0hSxPb0s3zKeTB5aCSv/riOtNPZRcqjMLG7Yr/AtmYXfZBy8xzcoxEPvP83W/YnMuTWRrxy3/W88NWqS4r5XKV9/P19vOjWKpy2z83gVEYWnz/ViTvb1uG3VYV/OltSMV8s38r+3kx8NIJnJ69wLn9i0lLG3HcDXh5mlu2II8d68R9rd4q/JOqU3cWX4NzQcqx2ohNSmPKU4nhKGoM+/IVfXxyIn095QgP9mPHiQOJPpvHMlNl0bXYNwX6l93TE5dM6VwcX2Lt6EQnR++j1/DvOZb5Blej32qekpySx4JM3qNOqPT7+gZcdV2mfb3K9OfAm1u45zrq98fmWd21Rg/X74ot1CAhQqIIuHPkWt3wwhmb39+XwynWcij2GLScHs4cH4e2u54s2vTgZE8ddUz+k2YC+bPluevHGeAHuWn8KCqOkzz1tnpnO8ZRMwiv58svIHuyJSSY6PrVEzj1XA1fnT5cfCrBvjVF/bh/+tnOZb1Al+o6ZRHpKEn9/OpZardrh41c89SdfSCV87XBTw1Du7lCfPmP/dC6z2e30GD0HPx8vvny6E9eGBfDvkZRCx+yMqwTOpQUp72Xhqd5Nue/tvwodX0Hc6fv71rSNxJ/MxMvDzFsPteWx25vw4aythSmGI87zd3pu3S/q5wTQ9rqq9I+8ljtfP9tp/c7X/uB4SgbBfuX5+cUeRB09ydo9xwods7j6uW1jBfCQ1vqEUsobWA/cDKwEXnCsvxt40zEkoi/QAqM8m4CNF8j3RYxGjzNKqQDHsj1AB611jlKqCzDOkWdeLwGLtNYPObZbp5T6G6Ph40Ot9Y9KKS+MRpWLOQ3cqbU+pZQKAdYopeYArS6xLOfqC2wuqKFCKfUI8AgA5c6f3GlglwbO8c9bDyTmexpdNajCed1Bj57IyNeVK2+axFOZVPY3Wosr+3uTdOriXX49LCa+GNqJWasOMH/D4YumL8jRExnnx56SP/ZjJzKoFlyBY8kZWMwmKvp4kZJ2xtg2OM+2gWe3dZVnUMVyXBce6HyS8PvaQ/zwfNcixV2Wx79946rEJKRyItWoOn+uj6Z1/coXbawojZhdfp6ObXzLe/Lt8C68O2MTm/effaqyKSqBvo6LqQ6Nq1E71O+Kib8461ReVQIqcizl7ER58Smp5/WOqBLgS9NaVfG0WAgL9qdW5SAOJ6TQuGaoM01lf1/qhgaz6UAsXZtfc9lxFVaFwBDSks8+sUtPTqRCQNB56Y7s2szmudPo9cLbzq7X+fIJCCawWjjH9u2kTuv2lx1XaZ5vcj1zZzOC/crz4of5xyoD9GpTmznFPAQEIDX2GP5hVZ1/+1UPJTUuf0NJ2tF4pvd/AgDPCj40vKMHZ06lcSr2GMe27iLlUAwAe+b8TdgNzUu1scLd6k9Zn3uOO55+Hk5IY82eYzSqGURqZlaJnHuuBhUCQ0g/kaf+pCTi46J3ROyuzWyZN43bhxdcfwKqhXN8305qt7r88w+U3rVDgxqBvPtwWwa89zcpLiaiPJWRxeo9x4hsWr1IjRUldS51pVblitSo5MuCN3s79uXDn2/0pOerc0nI0yOiIO74/Y2OT3X20MjKsaGXRTHk1kYXL0vXhtzb6dqzZcl7HIN8zjuOR0+kF1yWk5lUDjB6V1QO8CYpz7FsWCOQdwa3Z8A7C/LVn9z8k06dZv6GaJrXCfnPNlbYinmI4dXCneesGKqU2gqswehhURs4oJRqo5QKBq7FaLxoD8zWWmdqrVOB3y+S7zbgR6XU/Ri9KwD8gelKqR3AB4Crb3c34EWl1BZgCUaPj3BgNTBKKTUCqKm1vvhZzmhkHaeU2gb8jTFso0oRyuLk6OHxNjCkoDRa6y+01q211q1drf/u7z3OSXkWbDxM3/bGzPIt6lYiNSMrX5c2MLqrpZ/OdnbT69u+Ln9tMhoZFm6KcU5qeFdEPefyC3l3cDv2xZ3ky/m7Ll7gC9h6IJFaoX7UqOSLp8VMrza1WbgpJl+ahZtjuKu9Ed9tN9Ri5a6jzrh7tamNl4eZGpV8qRXqx5b9iQXmeTI9i4o+Xs6b4YjG1YiKu/QfaSjb4x+bZHS3LO9ltLW1a1SVfYUoR2nEvHBTjMt8PS1mvnymE7+u2M/cddH59pPbjdLLw8xjtzdm6iLX3QrdMf7irFN5NQoP5XBCCkeSTpKdY2X+pn/p2LhuvjSdm9Zj/T7ju5KclkF0wgnCQvw5npLK6Syjp9OpjNNsORhHrcrF/1TwQirXuoaTx+M4lXAMa042UeuWUbNZm3xpEg/vZ/kPH9PjqVfw9gtwLk87kUhOlnFxdCY9leP7d+Efetmj5YDSPd+AMcFcxybVeXLS0vOeZlX09qRNg1AWnLP/4hC7YRtB9WoSUDMMs6cnjfrdxt65/+RL4x0c6Hzs1v75R52NEXEbtlE+wA+fEKNxoHZkGxL25J8vpaS5W/0py3OPv48XXh7G5V+gbzla16/MvtiUEjv3XA0q1bqGU/GxpCYa9efA+mXUbJb/bUqJh/ezYuondHsif/1JTz6n/kTtwr9KWLHFVhp1qVpwBb58uhNPT17unA8KjMb13Imhy3taiGhUjai4os09UhLn0oLsOZJCiyem0fa5GbR9bgZHT2Rwy8u/F6qhAtzz+wvkm9Oie6vwQjUafbdwN91HzaL7qFnM3xDtjKVlvUqkZmbnGwICxvCOtMxsWtardDbmjdGOmA/TL8J4q1y/iPr5688zXXj6s6X56o93OQ8qlPd0/rtDk+r8e+TyhuWIq49b9qxQSkUCXYCbtNYZSqklGI0D0wCF0RPiN621XSlVQEe8At0GdAB6AS87bvLfABZrre9UStXCaIw4lwljiMe5dz27lVJrHfkuUEoN1lqf/7grv/uAShjDWLKVUocc5bvUsgCglAoDfgMe0FrvL0oe51q09Qidm1dnxXt9yMyyMuzLFc5188f2osdoY8beUd+uNl7F5Glh8bZY5+Rvk/7YzmdPdqR/x/rEJqXx2MdLAKjk783c1293vK4RHu5+HZ1HzKJheCB3ta/H7sMnmD+2FwBvT9+YbzK5wrLa7Lz8/RqmPt8Vi9nEtGVR7I1NYVif5mw7mMTCzTH8snQfEx+NYPl7fUhJO8MTk5YCsDc2hT/WHmLRW3eQY7Mz+rs1RkunHZd5Aoz4ahVfDO2EzW7nZHoWw/Mcq6Iq7eO/ZX8i89ZH8+cbvbDabOw4dIKfFu91i5gLyvf2G2tx47WhBPqWp5/jxzX3NV2P3tqYm5uHYTab+OGff1m16+Kt9O4Uf0nUKQ+LmZF9O/PYZ79is9m4o01j6lUNYdK8lTSqUYXIJvVo26AWq/ZEc+e4bzCbzTzbuyMBFbxZvecQ789aislkwm63M7Bza+pXK9qM70Vltlhof+9jzJs42nh1YLtuBFWvyfpZP1CpVn1qNW/DmulfkX36NAs/Hw8YXa97PDWGlKOHWa2nGDfSdjtNu/UlOOzS3nZTkNI+34wfdBOxiWnMGmO8OvPPDdHObr49Wtdk2Y44Ms/kuA72MtitVv589jXu+/0bTBYLW76bTsLufUS+/DRxm3awd+4/1OpwI51fHw52O9Er1vPnM68a29ps/D3yLQbM+x5MJo5u3sGmr6cVe4wX4q71B0r/3FOvuj9vDWqLzW7HbDIx6Y/t7HPcYJbEuacwHv7pI66JbINvSCDjY1bz+5gPWPW1LpV9F4bZYqHtPY/x58SXsdtsXNOuK4HVarJx9g+E1KxPzeZtWDfjK7LPnOafyWfrT7cnx5B8NIa106c4z59Nu/UhKKxWicRZUnXpmTuaEeBbjjcHGm+ksFpt3DbmDyoH+PDBI+2xmE2YzSZ+X3uIf7YcoShK5FwKfPJ4B9o0DCXItzzrPuzH+zO3MG3pBUdrXxJ3+v5+9HgHgiuWx2SCndEnGPlN/kmEL1qWLTF0bh7Gign9OJ2Vw3OTlzvXLRh3B91HzTLK8s0qJgzpQHkvC0u2HmGRYw6KT37fxudPdaZ/5DXEJqbz6EdGg/azd7YgoGI5xjneLpL7itJKft5MefZmACwWM7NW7WfJttJ9pbVwfyaX4/DKmFKqNzBYa91TKdUA2AL0ALZiDIuIBkZordcppa7HmHSyLUbjy0bgS1dzViilzEC41vqQUsoTOILRQ+MbYKrW+lel1KvAg1rrWo5Gk+Fa69uVUuMAP+ApRyNJC631ZqVUHeCgY9lE4JDWemIB5UrTWvsqpZ4G6jnm2+gELMLoOVLpYmVxNNwM11pvcPwdACwFXtda/1rYY1xjwLfu98EX0pGpgwi7/5uyDqPIJP6ydTXEn/nnufPsXjm8bxnC+8tK96l6cRrWod4VX39eK1/34gnd1JjT+6X+lKEjUwcxhIu/XcldTSaad5YU341qaXoh0nhifaXWnyNTBwESf1nJjb/6vVPKOJKiif1pMHa7vUgPda8UX2847Pb3Zg+1Di/1z8Bdh4HMBzwcwyTewBgKgtY6GdiFMdxinWPZemAORkPGTGADUFAfNAswVSm1HdgMfKC1TgHeAcYrpVZS8JwTb2BMhrnNMVzkDcfyu4EdjuEhDYDvC1G+H4HWSqkNGL0s9lysLEqpO5VSR4CbgLlKqQWOvJ4E6mH0Etni+K9yIWIQQgghhBBCCCHcklsOA3FMEHlLAetud7H4Pa31q0opH2AZ8H4B22ZjzAtx7vLVQN6Z4l52LF+CY0iIYy6K8+aD0FqPB8YXXJp8aX0d/0/EaHRwxWVZtNa/YQz1ODfPscDYwuxfCCGEEEIIIYS4ErhlY0URfKGUug5j3ofvtNabyjqgy3A1lUUIIYQQQgghxAXYbG4/CqRMXBWNFVrre89dppSaBLQ7Z/GHWusSHWzmeFPJPy5W3ay1TrrY9q7KIoQQQgghhBBC/JdcFY0Vrmitnyij/SYBzcti30IIIYQQQgghxNXgqm2sEEIIIYQQQggh3J1VRoG45K5vAxFCCCGEEEIIIcR/lDRWCCGEEEIIIYQQwq3IMBAhhBBCCCGEEKKM2OwyDsQV6VkhhBBCCCGEEEIItyKNFUIIIYQQQgghhHArMgxECCGEEEIIIYQoI1YZBuKS9KwQQgghhBBCCCGEW5HGCiGEEEIIIYQQQrgVaawQQgghhBBCCCGEW5E5K4QQQgghhBBCiDJitcmcFa5IzwohhBBCCCGEEEK4FWmsEEIIIYQQQgghhFuRYSBCCCGEEEIIIUQZkWEgrpns8k7X/ySTySQfvBBCCCGEEMLt2e12U1nHUJImLN/v9vdmz0XULfXPQHpW/EdVv3dKWYdQZLE/DSbs/m/KOowiOzJ1kMRfhq6G+M+smFbWYRRZufZ385S5VlmHUWQf2w5d8fVnw+Hksg6jyFqHBzKEmmUdRpFNJvqKrz/vLNlX1mEU2QuR9a/Y+jOZaACq9Z9cxpEUTdwvQwCu2Pp/ZOogQOIvK7nxi/8eaawQQgghhBBCCCHKiAwDcU0m2BRCCCGEEEIIIYRbkcYKIYQQQgghhBBCuBUZBiKEEEIIIYQQQpQRGQbimvSsEEIIIYQQQgghhFuRxgohhBBCCCGEEEK4FRkGIoQQQgghhBBClBEZBuKa9KwQQgghhBBCCCGEW5HGCiGEEEIIIYQQQrgVaawQQgghhBBCCCGEW5E5K4QQQgghhBBCiDIic1a4Jj0rhBBCCCGEEEII4VaksUIIIYQQQgghhBBuRYaBCCGEEEIIIYQQZUSGgbgmPSuEEEIIIYQQQgjhVqSxQgghhBBCCCGEEG5FhoEIIYQQQgghhBBlRIaBuCaNFUIIIYQQQgghhCgypVQP4EPAAkzRWr91zvrngMFADpAAPKS1jr5QntJYIQr0+gNt6NysBplZOTw7eRk7DiWdl6ZJrWA+eLQD5T09WLQ1hle+XwNAQAUvPn2qMzUq4ZUpjwAAIABJREFU+RKTkMZjHy3iZEYW3VqF8/xdrbDZ7eRYbbz6w1rW7z0OQPQPg9gTkwxAbGIaD034+5LijWxSnVcH3IDFbOLnJfv49I/t+dZ7eZiZOCSCJrWDSU47w+OfLOVIYhoAT/RsQv+O9bHa7Iz5YS1Lt8ddMM9fR99ChfKeAIT4lWfLgUQGT1xEt5Y1GN63BTY7WK02Xv1xHev3xl9SOUqqLO8NbsfNLcJIOnWaLiNnO/N69s7m3BtZn6TUMwC8PX0ji7fGXnLMAK8NuIHOzcLIPJPDc1+sYEf0ifPSNKkVzIRH2lPey8KirUcY88M6wKgzk56MpEaILzGJaTz+8RJOZmRdMN9qwRV49+G2VA2qgB0Y+N7fzuMA8PqAG1Ed6tHgfz9eUfG/O7gtTWuHYAIOHDvFc1+sIONMTqHKcCErtu/j7Z/mYrXb6RPRisG3dTgvzfx12/ls9mJMJrimRijvDFEAPDrhO7btP0KL+uFMembAZcdSFA27d6DPB2MwW8ys/moaf7/zeb71geHVuXfK2/hWCibjRAo/PPAsKbHHAOg1fgTX3doJgAVvfsxmPbfE4izNc9HALg0Y3OM6alXxo+ljP5OcdqbEyrV13Wq+/3QCNpuNTrf0otc9A/Ot//v3mSycPQOzxUy58t4Mfm4kYTXrONcnHj/G8w/3p+8Dg7ld3V9icRbFgK/eocntnUmNT+KNJt3LOpwSORfVrerP+/9rR+Nawbw7YxOT5+0EoJynhRkv9cDL04LFbGLe+mgmzNxS7GWK2bGBNdO+wG6zcW37bjS7ReVbv33hb/y7YgEmswXviv5EDHyGisGVSU2K5+/PxmK32bBZrTTq3JOGHW8t9vguhzvVn9cHtqVzc8e122dLXF+71Q7hg0cjjbqzJYZXvlsFQECFcnz29M3UCKlITGIqj374NyfTs/Cv4MX7QzpSs4ofZ7KsDJu8lH+PGNdr7w/pSJcW4SSeyuTmF2YUKebS/u0d1b8VnZuFYTaZWL4zzplXrq+f7Ux45Yr5rpXKsiyl+d0tzfgB/Hy8eOfhtlwbFojdbmf4lJVsikq4rDKIsqGUsgCTgK7AEWC9UmqO1npXnmSbgdZa6wyl1GPAO8DdF8pX5qwQLnVuFkbtUD/aD5vOiK9WMH5QW5fpxj/UjhemrKT9sOnUDvWjU7MwAJ7o1YyVO+OIGDaDlTvjeKJXMwBW7Iij68jf6D5qFsO/WM67/2vvzOt0lpXuo2bRfdSsS26oMJtMjB14Iw+8u5DOI2bR+6ba1K/mny9N/471SUnPImL4TKbM38Wou1sBUL+aP73a1ObmF2cx4N2FvDmwDWaT6YJ59h37Jz1Gz6HH6DlsjIrnz/VGo+CKnUfp9pKxfNiUlbzzcLtLKkdJlQVg+vIoBryz0OU+pyzY5SxPURsqOjWrTu0qfkQMn8mIr1czbtBNLtONe7ANI75eRcTwmdSu4kdk0+oAPN6zCSt3HqXD8zNZufMoj/dsctF8Jw6J4PN5O+j84ix6jvmDxFOZznVNawfj5+N1Rcb/2tT1dH9pDt1emkNcUjoPdm1Y6HIUxGqz8ebU3/n02QeYPfYp/ly7jf2x+RvSoo8n8dW8ZXw/6n/MGjuUEfecvSF4sEd7xv2v72XHUVQms5l+H7/O57c9yLjG3WjVvxehDevlS3PHu6NYP3Umb7e4hfljP6LnuBcAuO7WToS1bMw7LW9jwk13cvOwRyhf0bdE4iztc9GGffHc89ZfxCSknRdLcbJZrXzz8bu8MG4i7371C6sW/8WR6AP50rTt3I23p/zE+MlT6Xn3AKZ+9mG+9T989gHNbnD9vSprq7+dwcc9Bl48YSkoqXNRSvoZxvywli/m7ciXz5lsK3ePX0B3x29XZNPqtKhbqVjLZLNZWfXTZ3Qf+hp9X/uM/euXkRx3OF+a4Bp1uGPURPqOmUStlu1Y9+vXAPj4B9JrxPv0eeUTeo+cwNb500lPOf8GvCy5S/3p3LyGce327DRGfLmc8Q9HuEw3/qH2jJiyjPbPTnNcu9UA4InezVmxI5b2z01jxY5YnujVHICnerdgZ3QSXUf8ytOfLeb1gWevCfXSf7nvrXlFjrm0f3tb1a9E6/qV6TZqDl1GzqZZ7RDaNAh17qdH63DSTxft4cCV/t0t7fgBXr3/BpZsi6XTiN/o/tIcouJOFjn+K53VZnf7/y7iBiBKa31Aa50F/AL0zptAa71Ya53h+HMNEHaxTK/6xgql1KtKqeFuEEekUuqPy9j+TaVUjFIq7Zzlzymldimltiml/lFK1bz8aKFbq5rMWB4FwKaoBPx8vKgc4J0vTeUAb3y9PdkUZdzwzFgeRfdWxu67tQxn+vJ9AExfvo/urcIB8j0d9i7nib2Yhmc1rxvCoeOpHE5II9tqY86ag3Rz7NNZppbhzFhhlGnuukO0a1TVUdZw5qw5SFaOjZiENA4dT6V53ZBC5VmhvAdtr6vKgo2HzyufTzkP7EUoYEmUBWDtv8dJSc+65HgKq1vLcH5dsR+Azfsddcb/nDrj742vt5ez1fzXFfuddaNby3BnnTPqUvgF861fzR+L2cTyHUcB49ifzrICxg3jS/1bM+6XDVdk/Gmns537LO9lKVI9Otf2A0cIrxxMjcpBeHp4cMuNTVi8ZXe+NL8u3UD/zjfiX8Eod7Df2Rv6NtfVpUL5cpcdR1HVvKEZCfujSToYgzU7m03TfqdJr6750oQ2rMfef4wnhPsWr6ZJry6O5fWJWroWm9VKVkYmsdt207BHxxKJs7TPRTujT+TrTVRSov7dRZVqYVSpVh0PT09uiuzKxpXL8qXxqXC2vpw5nYnJ0VAKsH7lUipXrZ6vp4U7iVq+jowT7nGRXFLnoqRTp9l6MIls6/nnk9zfLg+LGQ+LGTvFO3Y64eBe/CpXw69SVSwentS5vgPRW9fkS1OtQTM8ypU3ylenAenJiQBYPDyxeBo9Ga052djdcFy3u9Sf7q1qMcNx7bUpKh7/Aq7dKnp7sXFf7rXbPnq0ruXYvibTl+0FYPqyvc7l14QFsmKH8SBjf9xJwipVJMRRJ9fuOUbKZfToKu3fXrvd6JHg5WHGy9OMp8XsfFDgU86D//VoxEezt7pVWUrru1va8fuW9+TGBlX4ZalRZ7OtNk5llNx1qrh8SqlHlFIb8vz3SJ7V1YGYPH8fcSwryMPAnxfb51UxDEQpZQJMWmtbWcdSgn4HPgH2nbP8krvTFEZokA9xSenOv4+eyCA0sALxKWefXIcGVuDoibxp/s/efYdHUfwPHH/fpUBCCCEhBQgkVAHpvYOhqhQLDIoCoiIiVgQRLGD5ggURBVRAxYKFoYiA9N47oXchJCGUNCAFQnL3+2OPI+VoIfXn5/U8POR2Z2c/uze7tzs7M5tIgLc7AKVKuNnTno9Pxifdya5zwyDe7tWQUp5u9P18mX16ERcn/vmoG2kWK5Pn72Xpzlt2YcoYb0l3zmSKJXPtcvptSrNYuZyUQkmPIgSUdM/Q5CwqLpGAksZ23C7Pzg2C2HggKsPNZecG5RmuGlDKsyj9vri7FiK5uS230q99dR5vUYm9J2P46Pft9iaU9xp3gLc75y+mKzPe7lnLjC2+Up5u9rTnLybj41n0lvmW9i7GpaQUpr76AOV8PdhwIIqxM3disVp5pkM1lu8Oz7DuwhQ/wBcDWvBAnUCORcbz4e/b73g7buZ8/CUCvG884fcvWYK9/0ZkSHPqnHFz0GfMNCwWC4O6h9CyVpV7XndO8CobQHx4lP1zfORZghrXzZAmcu8h6jzWmbUTf6L2o50o6lkcd28vzuw9ROf3XmX1l9/j6u5GlbbNOHvweK7EmV/notwWF30eHz9/+2dvXz+OHz6QJd2yv2exaPYfpKZe453PJwNwJTmZBX/+wsjPJrJQ31mXrP+y3DoX3YrZZGLRR10J9i/OzysOE3oiOqc2B4Ck+BiKeZeyfy7mVYoLJ4/cNP3RDcsoV7Oh/XNC7AWWThzNpfNRNOnxLMW8fHI0vv8vjHPLjcpLo+xkunbzLkZUbLo0Mbe4dvM0rt0OhsXwUKMKbD9yjrqVfAks5UFp72JE38Vv7E1jzuPf3l3HL7D50Fl2TOyFyQQ/Lz9kf5o/rEc9pi0+QLLtwUFB2ZZbycljN6/jL+9XnNhLVxj/QkuqlyvJvlMxjJqxjeQc6PYqcofWeiow9SazTQ6mOaw9U0o9DTQEbvvk6K4rK5RS84ByQFFuDKBRQWv9lm3+M0ADrfUrSqn3gKcwalmigZ1a63E3yXcNEIrRhMQTY8CNbUqp0UDC9eWUUvuBLrbFFgOrgWbAI0qp6sAYW0zRWut2tnQ1bPmXByZorb92tC1a66m2/jY/YOxAK/Cj1vpLpVQljH44vkASMEBrfVgp1RMYBaQBF7XWWTuBZ93WxsAEwA1IBvprrY8opdyBn4BqwCEgGBistd6htd5iWzZDXlrr1ek+bgFypCOwyUF5y/x01+SgSN7JA+AlO8JYsiOMJtUCGNazPk+OXQJAk1dnci4+ifK+xZn5zoMcDo8l7PzlO4s3m7FYb7Gs2UG7o8x5dm9WgT/WZKw/WrLzNEt2nqbJff4MfbwevT9dxt3IjW25lV9XHuareXuwYmXY4/V4r3cjhn6/8Y5iTe9O1n3HZ7E7yNfJbKLxff48+O58ImMS+eblNvRsXZk1eyJ4uHEwasySOw39luvJkMbBcjkd/0zbE4Y3p23EbDLxUd8mdGtSAb3+3m6uHZWDzLGlpVkIOxfDj289y7m4S/T75Hv++uhlPN3dsi6c1xzsyMznpHnDxtBz4gc06deD4+u3ER8RhSU1jcPL11O+YW3e2DCHhOhYTm3ZhSU1dy6G8utclNsclh8HR0TH7j3p2L0nG1cuZd5v0xk0fBRzfpnKQ48/SVG321ecitw7F92KxWql87vz8XR3ZdprD3BfoBdHIuLvIcdMsTkuQA4d27KKC2HH6DL0U/s0D29fHh81mcT4GFZ88zHBDVrg7lkyx+L7/8Lk8DyZKY3D67tb5ztpfigf9m3OsrGPcTg8jv2noklLy5nng3n92xvsV5zKZUrQ+DUNwO/DO9LkvjNcTr5GkL8nH/y2ncBS2esmWNiP3byO39nJRM1gH977dSuhJ6IZ/XRjBnepxbg5u7OZY+H2/+BtIBEY99XXBQJnMidSSrUH3gHaaK1v2ywrOy0rntVaxyql3IDtQDtgI/CWbX4v4H9KqYbA40A923p2ATtvk3cxrXVzpVRr4Eeg5m3S34dxo/+SUsoXmAa01lqfVEp5p0tXDXgAKA4cUUp9q7W+lnlblFJzMCoIymqtawIopbxseUwFXtRaH1NKNQG+AUKA94FOWuvIdGlv57AtzlTbFzYGY1+9BMRprWsrpWpiVN7cjVs2p7E11TGa67hkHQCqX4fq9H7gPgD2/BtNGZ9i9nmlvd05F5+UIX1UbCKlvdOnKca5OCNN9MVk/LyMGno/LzdiHNS+bz18liA/T0p6FCEu4ao9/9MXLrP5UBQ1g33uuLIiKjaJMpljyRTv2dgkyvgU42xcEk5mE8XdXYlPuGosm35bS95Y9lZ5enkUoW7FUgz4Kn19UbrtO3KOIP/i9u27U7m1LTcTfemK/e/f1xzjpzfb3SJ1Rv3aV+PJtlUBW5m5SXlIv203LTOXkvErYdTK+5VwI8YWl8P9EZeEs5OZA2GxnLb11V+68zT1K/tyIT6ZYH9P1o8zxldwc3Vm/bjHaDV0bqGIf+baG+uzWK0s2HqSgQ/VvOfKCv+SnpxN10z5XNxF/LyKZ0zjXYLaFQNxcXYi0LckFQJKcfpcDDUr3LZLYa6Lj4jCq1xp+2evsgFcOnMuQ5pLUef5occgAFyLuVP3sc5cuWScQ5aNncyyscaT/r4zJnDh+KlciTM/zkV5wdvXj5jzN/Z37IXzlPQpddP0zR7owI9fGTebxw8dYOu61fw+bRJJCZcxmc24uBah0yM9cz3uwiIvzkV34lJSCpsPn6Vt7bI5WllRrGQpEmNvPPFNjI/G3UHriMiDuwldNJMuQz+1d/3IkI+XD15lynPu2AEqNGiZZf5/Ub8ONXgqpBoAof9eoIyPB2Acq0a5SMyQPio2gdLeN27GS/vc4trN1j0iIfkaQ6bc+HHa8vWTnL5wZ9dnDmPOx9/eR1tUZPfxC/buE6v3RlKvsi+JV65RO9iHTeN74OxkwsezKHpk59s++Cjsx25+xh8Vm0RUbJK9Nciibafs41yIQmk7UEUpVQGIBJ4AeqdPoJSqB0wBOmut7+gNBNkZs+JVpdQejKf45YAKwL9KqaZKKR+MCoSNQEvgb611stb6MkY3htv5A0BrvQ7wvIOb/7DrLQ6ApsA6rfVJWx7ph6/9R2t9VWsdDZwHrrdlzbwtVYB/gYpKqYm2169cUkp5AM2BWUqpUIydfP2qeSPwk1JqAEaLjjtRwpbXfuBL4H7b9JYYg5Ggtd4P7L3D/NI3p/n8Zmm01lO11g211g0dzf95+SH7AJdLdoTRo5UxeF39yr5cTr6WoRkhGE0EE5KvUb+y0Ry5R6vKLLN13Vi+6zQ9WxnNx3u2qsKyXcaYDsH+N26Oagb74OpsJi7hKiXcXXF1NopjSY8iNKrqz9HIOz/Z7vk3muAAT8r5euDiZKZb0wos3xWeIc3y3eH0aGls08ONg9l4MMoWazjdmlbA1dlMOV8PggM8CT0Rfds8uzQOZkVoBFev3WguGOyXbvuCvHF1Mt/16Py5sS234pehi075u/qR+3nFYfvAnEt3nubxlpUAqFfJl8tJKVm6YZy/mEzilWv2JuyPt6xkLxvLd4Xby1yPVpUzTHeU755/oylRzBXv4sY4Ci1qlOZY5EVW7YmgwSszaT5kNs2HzCY5JdVhRUVBjR8ylqP29cpxIure+0LXrFCWsHMxRFyI41pqKou37qNt3WoZ0oTUq872wycBiLucyKmz0QT6ejvKLs+d3r4X38rBeAcH4uTiQv1eXdm3IGM3q2I+Je1PFju8/RJbps8CjME53b2Nn5MytapRplY1Di9bnytx5se5KC9Uuq86ZyPDOR91htRr19i8ZjkNmmdsSBgVcWPAxN1bNxIQaDxgGTVhKl//No+vf5tH58eeoPuT/aSiIpO8OBfdjHfxIvbBiIu6ONHq/jI5Psidb3BVLp2P5HL0WdJSr/Hv9nUE1WmSIU306RNsmDGJjoPfx83zxuVfYlw0qSnG7+jVxMucO36QEv75X4FaUPy8/CAdR8yl44i5LN1xih62a6/6lf24lJTi+NrtSgr1K/sB0KNVFZbuPAXAsp1h9Gxt3Lj2bF3V3h3X090VFyfjGq13SDW2HooiIfka2ZWfv71nYhJpUi0AJ7MJZycTTav5c/xMPL+uPELDVzXNh8zmsY8Wc/LspTtqoVnYj938jP/CxWSiYhOpGOAJQIv7y9ivg0Tho7VOBV4GlmL0ENBa6wNKqQ+VUt1syT4HPLDdUyul5t8u37tqWaGUagu0B5rZxkhYg9GFYiagMFoM/KW1ttrGkbhbmdu/WDHew5q+UiV9B6j01cUmB8tfl/5uMQ1wvtm2aK3jlFJ1gE7AYIzteh2I11pn7CANaK1ftLW0eBgIVUrV1Vrfbpjqj4DVWutHlVLBwJp023DX7rY5zZ1YFRpOSN1ANozvyZWUVIZMuXFhv3TMI3QaOQ+AkdM3MX5ga4q6OrFmTwSr9hh94Cct2Mt3r4TwRNuqREYn8uLXKwF4qFEFHm9VmdQ0C1dS0hg00WiVULmsF58+1wKLxYrZbGLy/L0cu4vKijSLlfd+2cKMYR1wMpuYue44RyPjefOxuuw9GcPy3eH8ufYYE15sxfpxjxGfcJXBk42nBEcj41m49RSrPnmEVIuVd3/eYowbYMVhntd1a1qBbxZkfCXhg42CeLxlJVLTrFxJSeWlyWu5W7myLcCkl1rTtHoA3h5F2fZVT76YG8rMtccY+URD7g/yxmq1EhGdwNs/br7rmAFW7YkgpG5ZNox7jOSUNN6ctsE+b8nH3ej8rnE+GvnTZuOVVy5OrN4baX/7yOSF+/j25TY80aYKkTEJDJq45pb5WqxWPv5jO3++3QmTycS+UzH8vvpotmIvSPGbTDB+YEuKu7liMsHB07GMnJ5xILrscHZyYuTTXXhx/M+kWSw82rI+lcv6M+mvldwfXIYH6lWnRc3KbDpwnO7vfI3ZbOJN1QkvD6Ppfr+x33My6gJJV1No9+bnfNj/EVrUzLvxLCxpacx+dRQvLf4Fs5OZLdNncfbgMR4a/Qand+5j/4IVVGnblC7/GwZWOLF+G7Nefh8AJxdnXl9rNPm9cimBX/u+gSUte32Sbyevz0X9O1Zn0MM18S3hxvIx3Vm1J4K3ftiU49vl5OTMM68M5ZO3X8VisdC2c1cCgysy66cpVKxanQbNW7Ps71ns37UdZ2dninkUZ9Bbo3I8jtzy3O9fU7VtUzxKlWRs+GYWjPqSTT/qfIklt85FviXc+OfDLni4uWCxwHOdahAyfB5+Xu58+UJLnMwmzGYTC7aeYmVoRJa47oXZyYnmTw5i8YT3sFosVG3RgZJlgtj596+UCqpCUN2mbJv9A9euXmHllLGA0fWj48ujiIsKZ+us7zGZTFitVmp3fAzvwOAcje9eFZTys3J3OCF1y7NxwhPGqyenrLHPWzb2MTqOMCruR/y4wfbqUmdWh4azKtSo/Jw8P5TvXmvPk22rERmTwMAJRoVwlbJefDXoAdIsVo5GxjF06o1rm8mvhNCsehm8ixdlx6TejJu9kz/X3Hw8kszy+rf3n21hNK9RmuVjumMF1u6NZMXunCnvhf3Yzev4E65c471ftjJxUGtcnM2cvpDAm1M3ZIlLFB5a60XAokzT3k/3d/u7zdN0N6PMK6W6A89rrbsqpaphdFPoDOzB6OIRBgy3jTXRCKMFQnOMSpGdwLTbjFlx2Hbz3xL4Vmtdy9ZioIvW+gmlVH2MJiaVbIstTNddwxejq4m9G4iti8doHI95Uecm27IfSNFaX1JK1QV+0lrXVUptAr7UWs+yVcTU1lrvUUpV0lqfsOW9G6NbSpbuG7bKkaFa6y5Kqb+AGVrrObb4ntFaByulhgEVtdaDlFI1bPu1mdZ6R7p8ErTWHuk+1wNmYzSnyTz45k0FPvVDoe0YFfn78wQ+PT2/w8i2iBn9Jf589P8h/qsbZuZ3GNlWpGUvXjEH53cY2TbRcqrQl58dp+PyO4xsa1i+JAPJkZde5YsphBX68vPZmju+1Chw3mpbpdCWnykYrRzKPDElnyPJnjN/DgQotOU/YkZ/QOLPLxEz+mO1WrP1ULewGPL3/gJ/bza+e808/w7uthvIEoxWCXsxWgdsAdBaxwEHgSCt9TbbtO3AfIwb7rnADuB2bXvibJUC32GMvwAwB/C2db8YBDh8dKq1voAxHsNcW9eO213NO9wWjFesrLGt7ydghG36U8BztrwPcOO9sZ8rpfbZKkHW2bb3dj4DxiqlNpKx68g3gK8tpuEY3UAuAiilPlNKRQDuSqkIWyUHZKM5jRBCCCGEEEIIUZDdVTcQWxeDB28yr4uDyeO01qNtb7lYB3xxm1XM0VqPSD9Ba50MdLxJ+pqZ0i4m0wCTWuvRmT6nX8bhtgD1M0+wjYXR2cH0x26SR+Z0a7B199Babwaqppv9nu3/K8DTWusrtrePrMRorYLtbStvkUl2mtMIIYQQQgghhBAFWXbeBnI3ptq6MxQFftZa78rl9RV27sBqpZQLxvgVg7TWKfkckxBCCCGEEEKIXPL/4NWluSJXKyu01r0zT1NKTQZaZJr8lda6bW7GkleUUp2ATzNNPqm1fvR2y9remuLwTR1CCCGEEEIIIcR/RW63rMhCaz04r9eZl7TWSzFe2SKEEEIIIYQQQohsyPPKCiGEEEIIIYQQQhikG4hjd/s2ECGEEEIIIYQQQohcJZUVQgghhBBCCCGEKFCkG4gQQgghhBBCCJFP0qzSDcQRaVkhhBBCCCGEEEKIAkUqK4QQQgghhBBCCFGgSDcQIYQQQgghhBAin8jbQByTlhVCCCGEEEIIIYQoUKSyQgghhBBCCCGEEAWKdAMRQgghhBBCCCHyiXQDcUxaVgghhBBCCCGEEKJAkcoKIYQQQgghhBBCFChSWSGEEEIIIYQQQogCRcasEEIIIYQQQggh8omMWeGYyWqVHfNfZDKZ5IsXQgghhBBCFHhWq9WU3zHkpmd+31Xg781+6l0/z78DaVnxH1W29/f5HUK2Rf7+PAE9JuZ3GNl2dvYrhT7+4AGz8juMbDs1rWehj7+wH79lnpiS32Fk25k/B3IuPiG/w8g2fy8PKT/56MyfAznx+pP5HUa2VZrwB4FPT8/vMLItYkb/Qlt+zvw5EICBBOVzJNkzhTAAyvX7JZ8jyZ7wn/sCUL7/b/kcSfacnv4UQKE9fiNm9M/vEEQ+kcoKIYQQQgghhBAin6RZLPkdQoEkA2wKIYQQQgghhBCiQJHKCiGEEEIIIYQQQhQo0g1ECCGEEEIIIYTIJ/I2EMekZYUQQgghhBBCCCEKFKmsEEIIIYQQQgghRIEi3UCEEEIIIYQQQoh8It1AHJOWFUIIIYQQQgghhChQpLJCCCGEEEIIIYQQBYp0AxFCCCGEEEIIIfJJqnQDcUhaVgghhBBCCCGEEKJAkcoKIYQQQgghhBBCFChSWSGEEEIIIYQQQogCRcasEEIIIYQQQggh8om8utQxaVkhhBBCCCGEEEKIAkUqK4QQQgghhBBCCFGgSDcQIYQQQgghhBAin0g3EMekZYUQQgghhBBCCCEKFGlZIW7qw75NCalTjuSUVN6Yso79p2KypKkV7MOXL7amqIszq/aE8/4vWwDwKubKN6+EUM7Xg/ALCQz6ehUXk1Lo2KA8w3o0wGK1kppmYfSvW9l+9BwAYb/l50FZAAAgAElEQVT253B4HACR0Qk8O35Fjm3LR/1b0a5+EMlXU3l98kr2nbyQJU3tir5MGNyeoq5OrNwVxnvT1wPQpWklhqrGVCnrzUMjZrHn3/MAODuZ+eLFEGpV9MXZbGLW2iNMnLczx2LO7fgBqpf34bOBD1DczQWLFR58W3P1WlqOxt76fn9G9aqL2Wxi5oaTfLfkSIb5rs5mvujfiJpBJYlPTOHlqVuIjEkyytCLTakd5M2czacY9UeofRkXJxMfPFmPpvf5YrFaGTfvAEt2ReZo3IU9/tw4fptVD+CHIR0Iv3AZgMXbTzHhr1BKexfjq0Gt8S3hjsVq5fdVR/hh6YF7i79fc0Lq2uL/do3j+CuU4ssX21LU1YlVoeG8//MmW/xF+Pa1dpQrVZzw6Mu8+NUKLiamANCsemk+6NsMZ2czsZev0OPDhQAMeLAWT4bch9UKh8NjGfLd2hw/FrZu3shXX4zDYkmjS/dHebpff4fpVq9cwfsj3mLaTzOoVqMGF+PjeW/EWxw+eIAHu3TljWFv52hcjuTl+b9sKQ+mvd4OJ7MJZycz05cdZMbKw/cWfy6Un+JuLkwcHELZUh44OZn4buFe9NqjNK9RmtF9mtnzrVTGi5cmrmTpjrB72obM3KrVxufRvphMZi5tXc3FlQsyzPd55GmKVq4BgMmlCE7FPQkbOQAAJy8ffJ8YgLOXD1itnJ36Galx0TkaX3of9GlMSJ1Akq+mMmTqBvaHxWZJUyvYh/EvtDT2/54IRv26DTDKz+SX21KulAfh0Qm8NHENF5NSeKR5RV56uCYAiVdTGfnTZg6djqOIixOz3+mMq4sTTmYTi7aHMX5uaJb13ancKDslirnyxcA2BPl7cjUljTenrOVIhHG988XANrSvV57oS8m0e2t2tuO+F31++IxaXUK4fD6Gj2p1ypcYANrUKsPo3g1xMpv4c91xvvkn4++Iq7OZLwe0oFawN3EJKQz+dh0R0YkADH64Jr1aVyLNYmXUb9tZtz/KvpzZZGLh6Ic4F5dE/wmrM+T5wdONUC0rUf3FP+89/pqlGdW7AU4mE3+uP8G3iw5miX/8882oFeRNXOJVXv52IxExRvwvPVSDXq0qkWa1Mvq3naw7EEXFgOJMerGlffnyvh6Mn7eXH5cf4aGG5Xijey0qly5Bt4+Xsu9U1mMsO3Lj2K1UugRfDGhBzWAfPp+9iymLbnyvz3euwRNtqgBwODyON6dtzPHfXlG4ScsK4VBInUAqBHjS8s1ZDP9hA2P7N3eYbuyzLXjr+420fHMWFQI8eaBOIACDu9Vh44EztHpzNhsPnGFwtzoAbNh/hg4j/qLTyHkMnbqezwfcOAlfSUmj08h5dBo5L0crKkLqBVGxtBfNX5nBsCmr+WRAG4fpPhnQlmFTVtP8lRlULO1FSN3yABwJj+W5cYvZcuhMhvRdm1XG1cVMyJt/0Gm4pk+H+wn0LZ5jced2/E5mE5Ne7cDwqatpO+QPHh/1F9fSLDkau9kEH/auxzNfb6DjqKV0a1SOyqUz7iPVIpiLSSk88O4SflhxlLcfqwXA1WtpjP/7AGNm782S7+CHqhNz+Soh7y2lw6hlbD2atfLmvxx/bh2/ANuOnLUfpxP+Mm4I0iwWPvxtGw+8NYduoxbQr0N1qpT1yn78dcsZ8b8xk+HT1jP2uVY3ib8lw79fR8s3ZtriL2fE370uG/ZH0nLITDbsj2Rwt7oAeLq7MubZljwzbikhw2YzcIJxngko6c6zne/noZF/0e6t2TiZTXRvVinb8TuSlpbG+M8+ZdxXE/l15hxWLF3CyX//zZIuKTGROTP/oEbNmvZprkWK8PzAQbz06hs5GtPN5PX5/3xcEo+MXkCnkfPo+v58Bnetjb+Xe/bjz6Xy80zH+zkaGUeHt+fQ48OFvP90U1yczGw6GEXHEXPpOGIu6uN/SE5JZe3eiGzH75DJRKnH+3N26meEfzoMj3rNcfEvmyFJzLwZRI4bSeS4kVzasJSkvdvt8/yeGsTFVQuJ+GQYkV++R1rCpZyNL50H6pSlgr8nrYbOZfiPmxnTv5nDdGOeacrwHzfRauhcKvh70ra2sT0vda3FxgNRtB42l40Honipq3FODb9wmZ7/W0LHd+bz1bw9fPqsUS6vXkuj19ildHpnPp3fnU/b2mWpV8k3W7HnVtl5pXs9DoTF0GH4HF77djUf9rtxTOm1R3jqk0XZijenbP5pNhM798vXGMwmEx/3aUy/8atoN3IB3ZoEU6VMiQxperWuzMWkFFoP/5vvlx1iRM/6AFQpU4KuTYJo/84C+n6xiv/1bYLZZLIv92zHahw/czHLOmsHe1PC3TXH4v/o6Yb0+3I17d/9h25NgqhSxjNj/K0qcTExhTYjFvDDsiO83bOuLX5PujYJosN7/9Bv/Go+7tMQs8nEv2cv89DoxTw0ejFdPlhCckoqS3eFA3A08iIDJ69n69HzWWLJrtw6duMTrzLq161MXbQ/Qz4BJd3p37E6Xd5fSPsRf2M2m+jWtEKObU9hk2axFvh/+SHXKyuUUm2VUs3TfX5RKdU3t9d7r5RSzyilyqT7fEopVeoe8gtWSu2/fcqbLv+yUuq4UsqaPg6l1FNKqb22f5uUUnVulc+d6tggiNnrjwOw6/gFPN1d8fNyy5DGz8sNDzcXdh03TpSz1x+nU4MgY/n65Zm1/hgAs9Yfo1MD48Y56WqqfXm3Ii5Y86Dcd25UgVlrjad0u46dw7NYEfwyXQj7eblT3M2VnUfPGjGvPUznxhUBOBYZx4kz8VnytVqtuBdxwclsoqirMympFhKSUwpN/G3qlOdQWAwHw4ynRnEJV7Dk8ImoTgVvws4nEB6dyLU0Kwu2h9OhTpkMaTrULcOczcYTyMU7I2le3Q+A5JQ0dhyPcVjD3rNFMN8sNvaJ1QpxCTm/3wtz/Ll1/N7M+fhk+9PHxCvXOHYmnoCS2b/Z7NQgmNm29e86fp4SN4m/uJsrO49dj/8YnRsG25YPYta6o0b8647apz/aojKLt5/kjO1JVsylK/b8nJ3MFHV1xslsws3VmbNxidmO35FDB/ZTNjCQMmUDcXFxoV3HTmxYtyZLuu+nfMOTffrh6lrEPs3NzY3adevhWiRnLqpvJ6/P/9fSLKSkGhWlri5OGW4ysiO3yo8V8HBzAaBYURfiE66SaslYwftwkwqsDg3nSkrOPhksUr4y16LPkRpzHtLSSNy9mWI1G9w0vUe95iTsMp72u/iXxWR2IvmocQliTbmK9VrunDPB+P7nbDgBwO4TtvJTItP+L+GGh5sru44bFbVzNpywl5OO9cvby59RrozpO49d4GKSEffu4xcone4cc71sOTuZcXYyYyV7v2W5VXaqBpZkw36j9dyJMxcJ9C1OKds+2Xr4LPEJV7MVb045vn4bSbFZb+bzUt2KPpw6d5nTFxK4lmZhwdYwOtYrlyFNx3rlmG0rW4u2h9GiRoB9+oKtYaSkWgiPTuDUucvUregDGDfE7eqU5c91xzPkZTaZGNmrAWNm7sq5+M8nEH4h0R5/h7qBGdJ0qBfInE0njfh3nKZFdX9jet3AdPEncup8gj3+61rU8Of0+QQiY5IAOB51iX/PXs6R2K/LrWM35tIV9pyM4Vpa1uPS2WymqKuT/bf3XFxSjm6TKPzyohtIWyAB2ASgtf4uD9aZE54B9gNnbpMur2wEFgJrMk0/CbTRWscppR4EpgJN7nVlAd7u9gt6gKjYJAJKFuN8fPKNNCWLERWbPk0iAd7GxUOpEm72tOfjk/FJd7Lr3DCIt3s1pJSnG30/X2afXsTFiX8+6kaaxcrk+XtZujNnmtAGeHtwJibhRpwxCZT29uB8/I0TYmkHaQK8PW6Z78ItJ+jUqAJ7pj2Lm6szo37ekCsXHLkVf6XSXlix8sc73fDxLMq8jcf4Zv7unI3dy42o2Btl5mx8MnUreGdI458uTZrFyuXka5T0cL3pDXxx283CkO730/Q+X05fSGTU77uJvpwL+76Qxp+bx2+Dyn4sG/MI5+KT+Oi3bRyNzFgRFljKg5pBPuw+kf3WIkb86cpzbCIB3pni9y5GVGz6Mn+L+D2N+CuWLoGzk5lZ73XBo6gLPyzZz+z1xzgbl8R3C/eybVJvrtieiq/bl7Pdci5cuICff4D9s6+fH4cOZKy/PnrkMOfPnaNFq9b8+duvObr+u5Ef5//S3sX4ZVhHgv09+fiPbZyLz/4Fa26Vn+lLD/DT0E7s+uZpPNxcGPT1iiwV7t2bV2LqP/uyHfvNOHuVJDX+RneE1IuxFClf2XHakqVw9vEl+ZjR1NrFtzRpyYn4938dZ28/ko/uJ3bhH+TW04KAku6ccVA2zl9Mv//ds5YfW+VDKU83e9rzF5Px8SyaZR1PtK3C6r03jlGzycSij7oS7F+cn1ccJvRE9rq45FbZORgWw0ONKrD9yDnqVvIlsJQHpb2LEZ1un/zXZSk3cYnUrVjKQRrj3HDj97YI/iXd2J3uO4+KS7KXp9G9GzJm5i6K2X57r3um/X0s3x2RoVzeU/xebhnLdFwS9TLH7+Vm38b08QeUdM8Q/9m4JAIyVZJ1axzE/K0527Uss7w4dtM7G5fElEX72TKhJ1dS0li3P5J1+wvKbZcoKLJdWaGUmgeUA4oCX2mtpyqlOgNjACcgGngOeBFIU0o9DbwCtMOovPgH+Flr3diWXzAwX2tdWynVABgPeNjyeUZrHYUDSqk1wG6gAeAL9AVGALWAmVrrd23phgDP2hb7Xms9wbbOxcAGoDkQCXQHHgYaAr8ppZKB6+2gXlFKdQVcgJ5a68NKqTbAV7b5VqC11vqWVZ229f4KFLNNellrvUkpZQYmAW0wKiHMwI9a69la6922ZTPkpbXelO7jFiBjNW42mcj6ZMua6cLG0cOvO7n2WbIjjCU7wmhSLYBhPevz5NglADR5dSbn4pMo71ucme88yOHwWMLO33utscM4Mz91cbgtt96YepX9sFis1H1hOiWKFWHeR4+xbm84p8/nbPPa3IrfyclM42plePBtTfLVVPSoR9j77wU27M+55st3Ukbuthw5O5ko4+3OzhMx/G/WXp5rX4WRPWsz5MftN18omwpr/Ll1/O47FUOT12aSdDWVkDqB/DCkPa3evNHH2r2IM1Nfb8foX7eQkHwtW7EbsTmKP1Mah9t463ydzGZqVyiF+t8/FHV1YsEHj7Dr2HliLifTqWEQTV/9g0tJV5nyWgcea1mZuRuO3zrDu+EwuBvbYLFYmPjlF4x8/4OcW2c25cf5Pyo2kQ4j/sLfy50fhrTnn60niU7X8uWu4s+l8tO2diAHwmLo+fFCgv09+WPkQ2w9PMde1v283KhWzps1e8OzFfetOWpt4jjgYvWakbhnm32DTE5m3CpWI+KLkaTGRePf91WKN27D5a1rciHOOzxvOljuTqtOmlUPoFfrKjz28WL7NIvVSud35+Pp7sq01x7gvkAvjkRkbVF4O7lVdibND+XDvs1ZNvYxDofHsf9UNGk53O2ysHN8rXMHaaxWx98b0K5OWaIvXWFfWCxNq/nb5/l7ufFwoyDUJ8uyLJdtd3AddvP4HUxP97eLk5n2dcvy6Zw99xbjbeT2sZtZCXdXOjYoT/Mhs7mUlMJ3rzzAo80r8temrF0k/wvkbSCO3Us3kGe11g0wbupfVUr5A9OAx7XWdTBu5k8B3wFfaq3raq3XX19Ya30IcFVKVbRN6gVopZQLMBHoYcv/R+B/t4klRWvd2rauv4HBQE3gGaWUj63yoz9Gi4OmwAClVD3bslWAyVrr+4F4W/yzgR3AU7a4r1cpRmut6wPfAkNt04YCg7XWdYFWwJ1U0Z4HOtjy6gV8bZv+GBCMUdHyPDcqSe7UcxiVLw4ppV5QSu1QSu1wNL9fh+osHfMIS21PTcv4FLPPK+3tnuVJV1RsIqW906cpZm++FX0x2d500s/LjRgHNddbD58lyM+Tkh5Gc+fr+Z++cJnNh6KoGeyTZZk79UynWiz/vBfLP+/FudhEyvjcaGVQ2seDs7EZm3hHxSRkSXPuNs3AH21ZldWhp0lNsxBzKZnth6OoU8kv2zHndfxRMQlsPhhJ7OUrJKeksmrXKWpVzF4/35uuIy6Z0t43ng4EeLlxLj5jWTibLo2T2URxNxfiE2/eRDkuIYWkq6ks3W08VVu0M4L7y2d/fIRbKUzx58Xxm5B8zd7cetWeCJydzPbj19nJxNTX2/HXxhMszsbAgv061GDZ2MdYNvYxzsZlKvPexbKU56hYo4WRPY3PLeK/lGxfZvWeCJKvphJ3+SpbDkdRI8ibVjXLcvr8ZWIvXyE1zcri7SdpWNWfnOTr58f5c2ftny+cP08p3xvHW1JSIidPnODVQQPo2f1hDu7fx9tDX+fwwYOOsstx+X3+v+5cfBJHIuJoUi0gyzK3jj/3y0+vtvexaJvRhPvUuUuEX7hM5TI3jt2uTSuxePspUh00db5XqfGxxuCYNs4lvEm7GOcwrUe9ZvYuINeXvRp5yuhCYrGQuH8HroHBORpfv/bVWPJxN5Z83I1zccmUuUnZuC4qNunm5edSsr3puV8JtwzdtaqVK8nnzzXnuQmrHLZkvJSUwubDZ+196O8o9jwoOwnJ1xgyZS0dR8zl1W9W4+PpxukLOduEv7CLik3KWG5KFuN8XLKDNMZT/PS/t2ezLOvOubgkGlbxo0O9QDaOe5RJg1rRvHoAE15owf1B3gT5F2fdZ4+wcdyjuLk6s+7T7vcUv3EtkCmGTNcLUemOjfTxG8fDjW5NAZmWbVurNPvD4rJdgXsreXXsOtKyZmnCL1wm9vJV229vGA2r5Mx1tPj/414qK15VSu3BeJpfDngBWKe1Pgmgtb6TYWk1cL2pQC9gJnAfRkXDcqVUKPAut28tMN/2/z7ggNY6Smt9FfjXFltL4C+tdaLWOgGYi1GxAHBSa3192OidGJUFNzPXQbqNwHil1KuAl9Y61dGCmbgA05RS+4BZQA3b9JbALK21RWt9Flh9swwyU0o9gFFZMfxmabTWU7XWDbXWDR3N/3n5IfvAeUt2hNGjldHEtH5lXy4nX8vQDBKMJo4JydeoX9m44O7RqjLLbF03lu86Tc9Wxui+PVtVYdmu0wAE+98YnLBmsA+uzmbiEq5Swt0VV2ejOJb0KEKjqv5ZmpffjZ+W7qPDsJl0GDaTxdv/pWebasa2VPHnclJKhi4UxrYkkZCcQv0qxg1KzzbVWLL95C3XERmdQIuaRtF0K+JMg6oBHI90fPFYEONfs+c0Ncr74Gbrp9+0RlmORuTMaNLX7T0VR7CfB4E+7rg4mejaqBwr9mRsJLViTxSPNzP6uj/YoCybD99+sKiVe6NoWtUod82r+XE8Kncu+gpT/Hlx/Pqma85ft2IpzCYTcbYbhnEDWnE8Mp5pi7M3NM/Pyw/aBylcuuMUPWzrr1/Zj0tJKY7jv5JC/cp+tvirsHTnKQCW7QyjZ+uqRvytq9q7lC21PdE3xplxol5lP45FxhMZnUD9Kn4UdXUCoGXNshy7h/OPI9Vq3E9EeDhnIiO5du0aK5ctpWWrG4PlengUZ+HyVcz6+x9m/f0PNWrW4pNxE6hWo8Ytcs05+Xn+L+3tTlEXY9+XcHelUVV/TkTdXf/5vCg/kdEJtKxp3ASXKuFGxdJehKVrSfdI80r8vSkHW+OkczX8BC6+ATh7+4KTk9F64kDWt0+5+JbG7F6Mq6eO3Vj29AnMbsUwFzP2v1vl+7l2Nme7Of284jCd3zUGuFy68zSPtzQGqK1Xydf4zcpUYXX+YjKJV67ZB8J8vGUlezlZvivcXv56tKpsn17GpxjTXnuA16as5+TZG/vdu3gRPG2DJBZ1caLV/WUcDqZ409jzoOx4urvi4mRc4/QOqcbWQ1H31Prs/6M9J2Oo4F+ccqU8cHEy07VJEMt3Z2yltDw0nB62svVQoyA2HTIqgJfvDqdrkyBcnc2UK+VBBf/ihP4bw6ezd9NkyFxaDP2Ll79dz6ZDZ3l96kZW7Ymk4WuzaTH0L1oM/YvklFRaD/87h+IvdiP+0IzH2YrQCB5vbgwg+VDD8mw6fM62XZHp4i9mj/+6bk2Cmb8td7qA5MWxezORMYnUq+Rr/+1tcX9pjjkYY038t2WrG4hSqi3QHmimtU6ydcXYg1HRcDdmArOUUnMBq9b6mFKqFkaFw920KrhevW5J9/f1z844brWUeVmANMDtZgnTpU2z5YvW+hOl1D/AQ8AWpVR7rfXt3rn2BnAOqINRYXS96jFbo4oppWoD3wMPaq2zvmMrG1aFhhNSN5AN43tyJSWVIVPsjWJYOuYROo2cB8DI6ZsYP7A1RV2dWLMnglV7jC4Ekxbs5btXQniibVUioxN58euVADzUqAKPt6pMapqFKylpDJpo1MdULuvFp8+1wGKxYjabmDx/b47dLKzcFUa7ekFsntjHeBXZ5JX2ecs/70WHYTMBeHvaWiYMbkdRV2dWhYaxarfxw/Bg44p8/GxrfDzd+HVEFw6ciubJ/81n+tJ9THipHWvGP4nJZOLP1Yc4dDpHdn+exH8x8SpTFoay+JOeWK2wcncYK3fl7I9hmsXKqD9C+eX1VpjNJmZtPMWxqEu80a0G+8LiWLEnipkbTvLlc41Z/XFnLiam8Mq0rfbl1495EA83F1yczHSoW4a+E9ZzPOoyn87Zx/hnG/F+LxdiLqfw1s853wWkMMefW8fvw42D6dO+OmlpFq5cS+OlScbx26iqPz1aVeHQ6ViWjnkEgE9n7rDnd7dW7g4npG55Nk54wnh92pQ19nnLxj5GxxFGvfGIHzfYXh/ozOrQcFaFGhe2k+eH8t1r7XmybTUiYxLsb/04fiae1XvCWfFpDyxWK3+sPmx/feA/W0+ydMzjpFosHDgVw28rD2Ur9ptxdnbmjWHDefPVwVgsFh7u2o0KlSrx/ZRvqVa9Bi1bO37Lz3U9uz9MYmIiqdeusX7tGr74+hsqVKx4y2WyK8/P/2W8eP+pJvbm3FP+2Wd/jXV25Fb5mfDXLr58sS0rPu2ByQRj/thKnG2smcBSHpT28WDzIYc9Vu+dxUL0nJ8IGPg2JrOZy1vXcO1sJCU79+Bq+L8kHTAGCfSo35zE3ZszLmu1Ejv/N0q/9A4m4GrESS5tWZU7cWK0ugqpW5YN4x4jOSWNN6dtsM9b8nE3Or9rPF8a+dNm4/WHLk6s3hvJ6j3Gjd3khfv49uU2PNGmCpExCQyauAaA1x+pg5dHEf7Xz7g8TEuz8PCohfh5ufPlCy1xMpswm00s2HqKlaEF69xTpawXXw16gDSLlaORcQydutae7+RXQmhWvQzexYuyY1Jvxs3eyZ9rMr4iO7c99/vXVG3bFI9SJRkbvpkFo75k0486T2NIs1h5b8Y2fh1qvMZ45vrjHD1zkSGP1mHfyRiWh0Ywc91xJrzQknWfdjdeFf6tcW46euYiC7eHsXJMN1LTLLz76zYseTGCe6b435+xg1+GPICT2YTe8C/HzlxkyCO12HsqlhWhkcxcd4IvBzRn7diuRvxTjGPj2JmL/LP9NCs+fphUi5X3Zmy3x1/U1YlW9wcw8pdtGdbXqX4gH/RuiHfxIkx/rQ0Hw+PpO/6On3E6lFvHrm8JN/75sAsebi5YLPBcpxqEDJ9H6IloFm0PY/FH3UizWNh/KpbfVx+9p20ozKQbiGOm2/Vrd0Qp1R14XmvdVSlVDQgF+mCMM9Faa31SKeWttY5VSr0JeGqtR9mWHQ0kaK3H2T5vBw4D+7TWnymlXIGDQB+t9WZbt5CqWusDWQLBPmbFUK31DlslylCtdZf08zAqLX7C6AJiArba4o0DFmqta9rSDwU8tNajlVILgPFa69W2eaeAhlrraKVUQ2Cc1rqtUqqS1vqELc084Cet9TwHcQZfX5dS6ksgQmv9hVKqP8a4FCalVE+gH9ANY/yNQ8ALtm4p1/Oxx2H7XB5YBfTNNH7FLQU+9UOhPSIif3+egB4T8zuMbDs7+5VCH3/wgFn5HUa2nZrWs9DHX7b39/kdRrZF/v48ZZ6Ykt9hZNuZPwdyLj7h9gkLKH8vDyk/+ejMnwM58fqT+R1GtlWa8AeBT0/P7zCyLWJG/0Jbfs78ORCAgQTlcyTZMwXjYUi5fr/kcyTZE/6z8SLD8v1/y+dIsuf09KcACu3xGzGjP1ar9d5eFVXAtZ+0ocDfm614uWWefwfZ7QayBHBWSu0FPsLoCnIBoyvIXFv3kJm2tAuAR5VSoUopRy+sngk8jdElBK11CtAD+NSWTyjG4JfZprXehVFZsQ2jouL76wNW3sJPwHe2uG/V2uJ1pdR+W6zJ3GLMiHS+AfoppbYAVYHrHSLnABEYbyGZYov1IoBS6lWlVARGl5i9SqnrV5vvAz7AN7ZYHY5HIYQQQgghhBBCFBbZ6gZiGw/iwZvMXpwp7VGgdrpJ6zPNHweMyzQtFGh9h7G0Tff3GtK92jPTvPEYLT/SL3sKY3yM9LFc/3sORuXBdcHp5u3AeCUrWutX7jBO+7q01sfIuE9G2KZblFJDtdYJSikfjMqVfbZ5X3NjIM70+T6PMRinEEIIIYQQQohCxirdQBzK9qtLRa5ZqJTyAlyBj2wDbQohhBBCCCGEEP8ZhaayQik1GWiRafJXWusC1fnKNkDor5kmX9VaN7mT5dO3BhFCCCGEEEIIIf6LCk1lhdZ6cH7HcCe01vuAuvkdhxBCCCGEEEIIUVgVmsoKIYQQQgghhBDi/xuLjFnhUHbfBiKEEEIIIYQQQgiRK6SyQgghhBBCCCGEEAWKdAMRQgghhBBCCCHyidUq3UAckZYVQgghhBBCCCGEKFCkskIIIYQQQgghhBAFinQDEUIIIYQQQggh8olV3gbikLSsEEIIIYQQQgghRIEilRVCCCGEEEIIIYQoUKQbiBBCCMuIXMsAACAASURBVCGEEEIIkU8s0g3EIWlZIYQQQgghhBBCiAJFKiuEEEIIIYQQQghRoEg3ECGEEEIIIYQQIp9YLfkdQcEkLSuEEEIIIYQQQghRoJisVhnM47/IZDLJFy+EEEIIIYQo8KxWqym/Y8hNLT9dXeDvzTYMfyDPvwPpBvIf5VK3f36HkG3XQqdTtvf3+R1GtkX+/jwBPSbmdxjZdnb2K5R5Ykp+h5FtZ/4cWOjjD3x6en6HkW0RM/pL/PlI4s9fEn/+KszxR8wwrtvK9fslnyPJnvCf+wIwkKB8jiR7phAGQPn+v+VzJNlzevpTAHg+MCKfI8meS6vH5ncIIp9IZYUQQgghhBBCCJFPpLeDYzJmhRBCCCGEEEIIIQoUqawQQgghhBBCCCFEgSLdQIQQQgghhBBCiHxisUg3EEekZYUQQgghhBBCCCEKFKmsEEIIIYQQQgghRIEi3UCEEEIIIYQQQoh8YpVuIA5JywohhBBCCCGEEEIUKFJZIYQQQgghhBBCiAJFuoEIIYQQQgghhBD5RLqBOCYtK4QQQgghhBBCCFGgSGWFEEIIIYQQQgghChTpBiKEEEIIIYQQQuQTi1W6gTgiLSuEEEIIIYQQQghRoEhlhRBCCCGEEEIIIQoUqawQQgghhBBCCCFEgSJjVgghhBBCCCGEEPlEXl3qmLSsEEIIIYQQQgghRIEiLSvEHRn/Vm86t6hF8pUUnhv1A6GHT2dJU696ED988BxFi7iwZOM+hnz2OwC1q5Zj0jt98HArStiZaPq+M5XLiVdo16QG/3u1B64uzqRcS+XtCZo12w/nSvwf9m1KSJ1yJKek8saUdew/FZMlTa1gH758sTVFXZxZtSec93/ZAoBXMVe+eSWEcr4ehF9IYNDXq7iYlEKz6gH8MKQD4RcuA7B4+ykm/BWaK/F/1L8V7eoHkXw1ldcnr2TfyQtZ0tSu6MuEwe0p6urEyl1hvDd9PQBdmlZiqGpMlbLePDRiFnv+PQ9AoG9x1k14ihNn4gDYdfQcw6etybGYP+zXnJC6tn3+7RrH+7xCKb58sS1FXZ1YFRrO+z9vAsCrWBG+fa0d5UoVJzz6Mi9+tYKLiSmUKObKFwPbEOTvydWUNN6cspYjEUb8z3WuSe+QaphM8Puqw3y/eH+hih/AbDKxeMyjnI1NpN/nS+8p/g/6NCakTiDJV1MZMnUD+8Nis8Yf7MP4F1oa8e+JYNSv22zxuzL55baUK+VBeHQCL01cw8WkFCqVLsEXA1pQM9iHz2fvYsqiAwAUcXFi9judcXVxwslsYtH2MMbPvftjITdivlm+zaoHMOqpxvZ8K5UuwcvfrGXpzhvntg/7NEG1rky1Ab8VuPiv8yjqwupPH2HJztO898tWAPTIzvh5uXElJQ2Apz5bRsylKzeNu22tsozu0xgns4k/1hzjm4X7Msx3dTYzYWAralXwIS7hKi9NWktEdAIAg7vW4ok2VUizWBn161bW7jtzR3lm3rejnmpEs+qlAXBzdcLH042aL/5+R/v9dvLyWMiOvN7/b/Wox8ONg0mzWPl11RGmLztEx/rlGPp4PSxWSEuzMPq3bWw/er5AbMu451vQrl4gMZeu0H7E31nWOfCh+3n3yUbUHvQHcQlX7zpmyPtjd+QTDQipE4jZZGL9gTP2vK778Y0QyvsVd7i9t9KmVhlG926Ik9nEn+uO880/Gculq7OZLwe0oFawN3EJKQz+dh0R0YkADH64Jr1aVzL2/2/bWbc/yr6c2WRi4eiHOBeXRP8JqzPuu6cboVpWovqLf95VrDmpzw+fUatLCJfPx/BRrU75FkebmqUZ1bsBTiYTf64/wbeLDmaY7+psZvzzzagV5E1c4lVe/nYjETHG/n/poRr0alWJNKuV0b/tZN0BY//3b38fT7auhMkEf6w7wY/Lj9jze6ZdVfq2q0pamoVVe88wdlbOXoN++nIXOja5j6QrKbz02Rz2HDuTJU3dKmX4ZngP3Iq4sGzrEYZPWgjA2/3a0e/hhkTHG9v34Q/LWL71KOX9vdj20xscCzeuY3ccDOeNCXdXzsV/i7SsELfVuWUtKpf3p0b3EQz6+GcmjezrMN2kkX0Y9PHP1Og+gsrl/enUohYA373/DO98PZv66n3mrd7Fm/0eBCAmPoFHX/+a+up9nnv/B6Z/PCBX4g+pE0iFAE9avjmL4T9sYGz/5g7TjX22BW99v5GWb86iQoAnD9QJBGBwtzpsPHCGVm/OZuOBMwzuVse+zLYjZ+k0ch6dRs7LtYqKkHpBVCztRfNXZjBsymo+GdDGYbpPBrRl2JTVNH9lBhVLexFStzwAR8JjeW7cYrYcyvojE3b2Ih2GzaTDsJk5WlERUrecsc/fmMnwaesZ+1wrh+nGPtuS4d+vo+UbM237vBwAg7vXZcP+SFoOmcmG/ZEM7lYXgFe61+NAWAwdhs/htW9X82E/47u8L7AkvUOq8fC7f9Fh+Bza1ytPhQDPQhP/dc8/WJNjkfHZjvu6B+qUpYK/J62GzmX4j5sZ07+Zw3RjnmnK8B830WroXCr4e9K2dlkAXupai40Homg9bC4bD0TxUlfjWI5PvMqoX7cydVHGiqCr19LoNXYpnd6ZT+d359O2dlnqVfItEDHfLN/Nh87S+V0j3ifGLuFKSipr90Xa11O7gg+e7q4FNv7rhvaox5bD57Ks59Vv19m371YVFWaTiY/7NaHv58sJGT6P7s0qUKVMiQxpnmhThfjEFFoNncv3Sw4yslcDAKqUKUG3phVo9/Y8+ny+nP/1a4rZZLptno727Qe/bbfHO335IZbsCLtpzHcjr4+Fu5XX+1+1qkxpn2K0Hf4XIW/PY/6WkwBsOBBFR9vx++b3G/nsuRYFYlsAZq0/Tp/PljtcZ2lvd1rdX8Ze4ZEdeX3sNqjiS8MqfnQcOZ/2I/6mToVSNK0WYF9P54blSbySetfbYTaZ+LhPY/qNX0W7kQvo1iQ4y/7v1boyF5NSaD38b75fdogRPesDxv7v2iSI9u8soO8Xq/hf3yb2/Q/wbMdqHD9zMcs6awd7U+IuzpO5ZfNPs5nYuV++xmA2mfjo6Yb0+3I17d/9h25NgqhSJuN1SK9WlbiYmEKbEQv4YdkR3u5pXBtUKeNJ1yZBdHjvH/qNX83HfRpiNpmoWrYET7auRLePl9J51GLa1SlLsF9xAJpV86NDvUA6v7+IDu8tYuqSQzm6PR2aVKVSWR/q9fmC18bPY/zr3R2mG/9Gd14b/xf1+nxBpbI+tG9c1T7vm9kbafXCJFq9MInlW4/ap588E2ufLhUVN1gt1gL/Lz9IZUUeU0q9qJTqa/v7GaVUmWzms0gp5eVg+mil1NB7jTO9rm3q8dtC44nxtn3/4lXcnYBSGX8AA0qVwLOYG1v3ngDgt4Wb6Na2HgBVgwJYv9M4Sa3ccoBH2xkXJ6FHThN1wbgxO3AikqKuLri65Hxjn44Ngpi9/jgAu45fwNPdFT8vtwxp/Lzc8HBzYddx40nS7PXH6dQgyFi+fnlmrT8GwKz1x+jUoHyOx3grnRtVYNZao8XJrmPn8CxWBD8v9wxp/LzcKe7mys6jZ4041x6mc+OKAByLjOPEmXu/Ab4bnRoEM9u2z3YdP0+Jm+zz4m6u7Dx2fZ8fo3PDYNvyQcxaZ5SZWeuO2qdXDSzJhv3GDeWJMxcJ9C1OqRJuVCnrxa5j57mSkkaaxcqWQ1F0blSh0MQPUNq7GO3qleeP1ffeuqhj/fLM2WAci7tP2Mp8iUzxl3DDw82VXceNpxtzNpywl+2O9cvbjxnjWDCmx1y6wp6TMfwfe/cdHkXxP3D8fZdCElJIAun0IkUg9I50IlVRFiyoqOBPRPSLKFL8gorYEbtgwYIiKyKidAUh9JqAgECoqYR00ki5+/2x4ZJLjpBcygW/n9fz8Dzkbnb2M7Nzu3uzM3O5+SUvWJnXtJtrezs99nZ6jJTvolZVMZcl32FdG7HtaJRpJIJep2PO+M4s/PFgjY6/bSNv6nk4s+Pvkh2RZRXctC4XLl/l0pV0cvMNrN17niHFznFDOjZg1U4ttnX7L9CrjTYCYkinBqzde56cPAORV9K5cPkqwU3rlppnWep2dI8m/Lr3nNVlKh57dX8WyqO663/CwNt4/5dwjAVhX+/Iuv75BXCpZY/RWP5yVUVZAPadukxKRo7Ffc57oCuvrTyIFeGaxVSdn12jURuN5mivx9FBj4OdnoS0LECr+0khbfjg1/BylyO4ibdZ/f+27yJDOtQ3L2uH+qwqiGn9gYv0au1nev23fRe1+k8oqP8m3gD4ebowsH0gP+6IMMtLr9Mxe1wnFq48XO5YK1tE6H4yk0p2plSn4CbeXIhPJ/JKhqn+BwcHmaUZ3CGIn3drHYTrD16iVytf7fXgoCL1n8GF+HSCm3jTzN+dI+cSTPc2+07FM7SjlueD/Zvzyfrj5OQZAEi8at2oohsZ3rM1K7YcAeDgyUg8XJ3w9XIzS+Pr5YabixMHTkQCsGLLEUb0al2pcQghnRXVTFXVz1RV/bbgz0cAqzorVFUdpqpqtXwDDfDxJDKucEhk1OUkAnw8S6SJik+2mOb42WhG9tN6j+8Z3IUgX68S+xgzqBNhpy6Rk1v+pwk34+flQkzBMDuA2KRM/Dxrm6fxrE1sUtE0Gfh5aR0CdT2ciU/RbiTiU7LwLnIT06mZD5sX3sV3LwyhRWCJvqNKit+VmMTCp0axien4e7mapfG3kMavWBpLGvi4s/mtcax++W66tfSvxJhdzONJysDPq1ide9UmNqlozKXUubtW5ycuJjKsoBMiuGk9guq64u9Vm38ik+neyg9P11o4OdoxILgBAd7m+6vJ8QO8/FAPFvywD0Ml9Fz7eboQc4P2XLSMJdq8Z0H87s7EpxbEn5qFt7vTTfep1+nYuGAUYR+PJ/TvGMLOJtSImMuS76jujfl1z3nT348MbsmWI5Gm/Gpi/DodvHR/FxasOGAxnncn9WbjglE8M7pd+eP2LBn39XNovsHI1cwcPF1radsWPbcma9uWlufN6jbQuzb167my63hcqXGXlS0+CxWOrwrrv6GPGyO7N2bdyyP4dsYgGvkWfvkI6dSAbW/ezTfPDWLGF7tqRFlKM7hDfeKSMzl5KbnUdFbFXYWf3cMRV9hzMo6DH47j0Ifj2H4s2jRq4fl7O/D5huNkFXScVqgcyRn4ejpbSJMJFNR/Vi6errXw9XQutm2mqXzz7+/MwpWHMRTrEXpk0G1sORJVrvPkv5lfHWfzNlKkDoumuV7PRevfz9OF2ILjAhCXnIlfHWdOR6fStYUPdWo74uRoR/+2AQQUtM3Gvu50be7DmrlDWDlzIO0alby3rgj/uu5Exxd2AMVcSSOgrvlIkYC67sRcMU/jXyTNpLt6sOvzp/no+THUcS08dzb08yR0yVTWvTeJHm0bVWrc4t9H1qyoYgWjKGYARuAocBZIBy4AnYHvFUXJAuYAj6uqenfBdoOBJ1VVHXODfC8AnVVVTVAUZQ7wEBAJXAEOVWYZiowENCn+1MVCEq4/6pg8/ysWvXA/cyaN4vftYSU6JFo3CeC1aWMZPuXdSorYnM5CdCXit1jG0vM9diGRbs+sJPNaHgPaB/Hl9EH0eW5VRUK1yGJsxZ9al+EYFRefnEHnJ78hOT2bdk3q8dXzw+g3/QfSs3IrEG1BOBaCLh6O5eNSer4frQ3jlYd6svn1MfwTmczfFxLIzzcQEZPCx2vDWTF7OBnZuZy4lEh+BZ54Vnf8gzo0ICEti2PnE0zz9iuiLO3Z0me2It0kBqORkLlrcXdx5PNn+nNbUB1ORZW9P7WqYr5Zvj4ezrQM8jRNAfGt48zwro1QFm68Sc7l2w9UbvwPDWzJ1vAosxvc66Z9uoO45ExqO9mzdFp/7unVlJ93nbU6bkuMpWyrt/AYxGgsW92O6t6Y9fsvlvhiZC1bfBbKozrrH8DRwY5rufkMn/c7IZ0b8O6k3tyzYAMAGw9dYuOhS3S7zZcZ93Tg/jc3l70gpcRzM6WV5UacHO14enQ7HihnjJZU92e3kY8bzQI86PqMCsAPM4fQ7bYYrmbl0tDXnZe/P0BQ3Zs/bCjT/soUk9HyNQ8Y2D6QhLRsjl1MontLX9N7vnWcGd6lIcobFa//f42y3CvfsP4tvA5ExKbx2YYTfD9jABnZeZyITCav4IGGvV6HR21H7lqwmfaNvfnkyd70nrm2EgpSeqw3TVPQ6r5cu4+3vtuK0QhzJw5iwZPDmPr2auKSrtLmvjdJTssiuHkA37/6IN0ffZ+rmZU7MuRWVBkPq/6NpLOiCimK0gatE6JXQaeCFzANQFXVVYqiTAVmqKp6UFEUHfCuoij1VFW9AkwElpVhH52A8UAHtON5mBt0ViiKMhmYrP1V+oXw/5QBPDamLwAHj5+nvl9hj22Qr5dp+sZ10fHJBBUZbRHk60VMQZpTF+IYPmURAM0b+HJnn8InfYE+nvy0aCqPvvQF56JKLhpprYcHt+L+/rcBEH4uwewpu7+XC5dTzG/wY5MyTE+4tTS1uZyspUlIzcKnjvak3KeOM4kFTxGKfqnfGh7Fa3Z6PF1rWb3AV1GPDG3LA4O0oXThEfEEeBceL39vV+KK9N6DNpKieJrLyeZpisvJM5CTrg0BPnruChcvp9HU39O0AGd5PTy4NQ8MaAlA2LkrBfFoc+m1+iwWc5L5CBF/71LqPK2wzqcv2W7aZu8H93GpYIHTH/86xY9/aQtPvTiui9kTjpoe/6ieTRnSsSEDghtQy8EON2dHPniqP9M+Nl/IrNT4B7Xkvn7aXNHwcwkE3KA9F8afeeM2n5aFj4f2tNDHw7nUNQ+KS8vMYc8/cfRrF3jTzorqiDk2KbPUfEd0a8TGQxfJK+jcatPQm0a+7oS+cw8Azo72hL4zhj4zVteo+Ds1r0fXFr48NLAltZ3scbDXk5GdxxvqIeIK8szIzmPNnvMEN617w84Ki/kXOz/GJWUS4F2buORM7PQ63FwcSUm/pm1b9NzqWbitpTzLUrejujdmbsHixtaqKZ+FsqjO+r++v/UHtPVANh68xLuTepeIad+pyzT0dSv39ayqymJJIx836tdzZdNrowv25cKGV0cycv46rpThSb8tP7t392rCkYgrpqk3245G06FZPTKyc2nXyJvdi+7F3k6Ht7sT6uyQMnecltifZ23ik7MspHEprH9nB1IycrTjYratC5eTMxncoT6DOwTRv32gdm1ycmDx5F6s3XeBhr5u7HjrLkD7LO94czR9Z/7vrj8Ql5xl3kY8XbicUqz+k7MI8KpNXHKWWf1r7atwFIZfkW1Xhp5jZag2Le75Me1N5/fY5Ew2HtKmX4SfT8RgNOLlVoukCkwHeXx0dx4e3hmAI6eiCfQpnPIdUM+d2MSrZumjr6QRUM88TVyCluZKcuHI02/WHWDlQm1NkZzcfHJytbKFnYnhfEwSzYLqcuR0NEJYItNAqtYAYJWqqgkAqqqWXF66gKqqRuA74MGCtSh6ABvKsI8+wC+qqmaqqpoG3LBbVVXVpaqqdlZVtfPNMv1M3UqX8fPpMn4+a7cd4YER2kKAXds2ITU9k7gE87mBcQmpXM3MpmtbbZ2EB0b05Lft2ly3ep7aMFOdTsesSSNZuuovADxcnfn1w2eZ++HP7Ak3nwtZUd9sOWla+HLjwYvc26cZAB2b1eNqVq5piP518SlZpGfl0rGZtijgvX2asfmQdkO35fAlxvZpDsDYPs3ZfFj7tYB6RaaDBDepi16nq5SOCoCvNx0zLXy54cA5xt6hfYnu2NyXq5k5xBe7iYtPySQ9K4eOzbUnH2PvaMnGA+dL5FuUt7sTer3WLd7Ax53G/h5cjLd+zuc3W04wZNZqhsxazaaDF7i3oM46NvMhLTPHcp1n59CxmQ8A9/ZpzqZDFwDYfOgiY/tqN5Jj+7ZgU8GxcHdxxMFOO23dP6Al+07GmjqNrg+9DfCuzZ1dGrNmd/nalC3jf+PHA3Se+gPdp61gygd/sut4dLk6KgC++eMf0wKFmw5d4p7eTQHo0LSe1maK3cDHp2aRkZ1rWgjznt5NTW17y+FI02fm3j7NTK/fiJdbLdOCiU4OdvRpE2BxMTZbxLzlcGSp+Y7u0cRsCsjW8Cg6Pb2SntNX0XP6KrJy8ix2VNg6/mmfhtL9P1qMC1Yc5OedZ3lDPYSdXoenay0A7O10DAwOKrXTKPxcAo383KlfzxUHOz2jujdmy+FIszRbjkRyb28ttuFdG7HrRKwptlHdG+Nor6d+PVca+bkTdjbhhnnerG6b+LnjUbsWh85UrOPalp+F8qrO+gfYdOiSaZ2C7i39OB+XBmBatA/g9oZeONrpy309q4qy3Mg/USl0eKqwLcUmZXLnS7+VqaMCbPvZjUnMoFtLP+z0OuztdHRv6UtETArf/XmKztNUek5fxZhXN3A+Lq1cI7zCzyfS2NeN+nW1+h/ZrSFbjhSr/7BI7i2IaViXhuw+qU232nIkkpHdGmr1X9eVxr5uhJ1L5M1VR+g2fTW9ZvzC1E9D2X0yjmeX7mJreDSdn1lFrxm/0GvGL2Tl5P1Pd1RA0fqvXVj/YeZfwP8Ii+KentpU0GGdG7C7YHHkLWHRReq/tqn+AbzdtPN5gJcLIZ2C+HXfBQA2H4miZ8GaF4193XCw11eoowLgi1/3mha+/H3nCe4brK0917lVfdIysrmcZN5ZcTnpKumZ1+jcSlsb5b7BHVi3W/sFlKLrW4zo04aT57WyenvUNt17NvL3pGmQNxdib/j1SAgZWVHFdJRvNOky4DcgG/hJVdWyLuBQpeOGNuw8Skjvdpxc+wZZ2Tk8Pv8r03sHftQ6NACmLvyOL19+FKdajmzadYyNO7WfLBsX0o0nxw0AYM3Ww3zz604ApowfSNP6PsyeNJLZk0YCMOzJd7mSbH4yrKitYZEMCA5i56KxZOfkMX1JqOm9TQvvYujsNQDMXrabRU/0xcnRjr/Co9gaHgXAR78d5bOnBzC+XwuiEzL4vw/+BLQbrQmDWpGfbyA7N58pH5Xvy2VZ/Xn4IgM7NGTPhxO0n9H8+E/Te1veHsfg51cC8OLn21n81ECcHO3ZGnaRrUe0L8h3dm3Cgkf74u3uzHezRnD8QgL3vbaW7q0CeX5cV/LyjRgMBmYu/YuUSups+fNIJAOCG7Br8XjtJ9uW/GV6b/PrYxgyS/uCMuurnQU//WnPtrBItoZpN1Yfrw3js2cGcV+/lkQnpvPE4j8AaB5Yh/ef7E++wcjp6GRmLC0cpfD5fwbj6epEXr6BOct2knqDBdlqavyVaWt4FAOCA9n5zhiycvJ57vOdpvc2LhhFyFytT3P213u0n+JzsGPb0Wi2hWs3Vh//foxPp97B+DuaE52YzpMfauWv5+HMuldG4OrsgMEAjw1tzYCZa/Cp48J7k3tjp9eh1+v4bd8F/gyLqhExl5ZvUF1XArxc2PtPxddHsEX8ljg62LH8hcE42OnR63XsPB7LD9tO3zB9vsHIS9/uZfnzg7HT61i5I4LT0Sk8NyaYo+cT2XIkkh+3n2Hx//Uh9J0xpKRf46mPtXZ7OjqF3/ddYOsbd5FnMDL3m73a9A0jFvO8mdE9mph+naKyVPdnIT27fNPoqrv+P/n9GB882YfHQ9qQkZ3L819qa1Pc2aUh9/RuSl6+keycPKZ8XP5zU5WUBfhoSl+6t/LDy9WJ/e+P5d3VYazcfqbc8d1IdX921+2/SM/W/mxZOBojsP1oNH8cKd/50pJ8g5GXlu/nuxkDtfoPjeB0TCrT727PsfOJbAmLYuWOCBZP7s2ON0eTkpHD1E+1+6HTMan8fuAify4cRV6+gbnf7a+0qVjV4bEfPqBFv+641vXk9cg9/DbvPXZ/pVZrDPkGI/9dfpBvp/fHTq9D3XmOMzGpTL+rLUcvJPFHWDQrd5zlvUk92f76SK3+l2ht4kxMKusOXOKPBcPJMxh5afkBU/1/9lQfPF1rkZtv4L/LD5KWqZ1j1NBzvP1oNza/MozcfAPPfVGxEWnFbd53iiHdbiNs+XNkZufy1Fs/m94LXTqVPpM/AmD64l8LfrrUni37T5t+9eOVJ0Jo29Qfo9HIpcspPLtIu9fu1a4RsycOIi/fgMFg4D/v/UryVVn3BG4+fft/lU4qpuoUTAP5BeihqmpikWkg6aqqvqMoym/AIlVVtxXZ5jegIzBYVdUTFjOmcM0KoAHwNdCNwmkgS1RVfae02Bw7PHrLHvjcsGUE3v+FrcOwWvQPj+N374e2DsNqcaueJmD8EluHYbWYH5+45eMPevCmM8RqrKjlEyV+G5L4bUvit61bOf6o5RMBqP/wtzdJWTNFfqP97P0TNLRxJNZZgvYAqMHE720ciXUuLXsAAPf+s2wciXXStr2O0Wi0uETev0Xw7PU1/rtZ2MJh1X4MZBpIFVJV9TjwGrBdUZRwYFGxJF8DnymKEqYoyvU5Bd8DkaV1VBTbx2FgJRAG/AyElr6FEEIIIYQQQghRs8k0kCqmquo3wDc3eO9ntA6GonoDn5ch30ZF/v8aWqeIEEIIIYQQQohbiNFg6whqJumsqEEURTkEZADP2ToWIYQQQgghhBDCVqSzogZRVbVT8dcURdkH1Cr28gRVVY9VT1RCCCGEEEIIIUT1ks6KGk5V1W62jkEIIYQQQgghRNUwGGr8+po2IQtsCiGEEEIIIYQQokaRzgohhBBCCCGEEELUKNJZIYQQQgghhBBCiBpF1qwQQgghhBBCCCFsxChrVlgkIyuEEEIIIYQQQghRo0hnhRBCCCGEEEIIIWoUmQYihBBCCCGEEELYiEwDsUxGVgghhBBCCCGEEKJGkc4KIYQQQgghhBBC1CgyDUQIIYQQQgghhLARg1GmgVgiIyuEEEIIIYQQQghRo0hnhRBCCCGEEEIIIWoUmQYierCiUgAAIABJREFUhBBCCCGEEELYiPwaiGUyskIIIYQQQgghhBA1is4oi3n8T9LpdHLghRBCCCGEEDWe0WjU2TqGqtTymV9r/Hezf94fXe3HQKaB/I/yHvG6rUOwWuLvs2gw8Xtbh2G1S8seoNGkn2wdhtUufD6WoAeX2ToMq0Utnyjx29C/If76D39r6zCsFvnNQ7d8/d/q8d/q169bvf5v1fijlk8EuGXbz6VlDwC3fvxP0NDGkVhnCRcBaDdznY0jsc7RN4fbOoQqJ9NALJNpIEIIIYQQQgghhKhRpLNCCCGEEEIIIYQQNYp0VgghhBBCCCGEEKJGkTUrhBBCCCGEEEIIGzHImhUWycgKIYQQQgghhBBC1CjSWSGEEEIIIYQQQogaRaaBCCGEEEIIIYQQNmI0yjQQS2RkhRBCCCGEEEIIIWoU6awQQgghhBBCCCFEjSLTQIQQQgghhBBCCBsxyq+BWCQjK4QQQgghhBBCCFGjSGeFEEIIIYQQQgghahSZBiKEEEIIIYQQQtiIQaaBWCQjK4QQQgghhBBCCFGjSGeFEEIIIYQQQgghahSZBiKEEEIIIYQQQtiI0ZBv6xBqJBlZIYQQQgghhBBCiBpFOiuEEEIIIYQQQghRo8g0EFEmCycPYlCnpmRdy+Xp99dx9OzlEmnaN/Xlw2eH4+TowB+HzjJ76R8AvPhAH+7s1hyD0UhCaiZPL15HXFI6d3ZrzosP9MFgNJKfb2DOF3+y70RUpcR7x+3+zLu/E3Y6HT+GnuXT9SfM3ne017Po8R60behFcsY1pn66i6jEDACmDGvNuD5NyTcamf/9IXYcjwVg4qDbuK9vU3Q6WLHjLF9tOWWW5+ShLZkzriPB034mOf1apZQDoG8bX+aNC0av17Fy53k+22i+X0d7Pe9O7MLtDT1Jychh6tK9RCdmUqe2I5/8X3faNfTi5z0XmLcizLTNiufuwMfDiexcbcjZQ4tDSbxa8ZhfntCVAe2DyLqWx/SlO/n7YlKJNG0bebNocm+cHO3YGh7FvO/2A1CntiMfT+1H/bquRCakM+XDv0jNzCk139njOzGgfRB6nY7Q4zGmvEZ3b8zUUe0wGo1cTsli2qc7yn1MqqIsTf09eHdSL25v5M3bqw6zZP1xU17vPN6LgR2CSEzLZtCsX8sVa1XGXFq+3z0/mA5N63Hg9GUmLvqzxL5emdANpW8zWk763qryVGW5SjsWFXVH2wDm398ZO72OH3dE8Mk687wd7fW8N6kXbRt5kZyew1Of7iAqQTv/PDX8dsb1bUq+wci87w+w4+9Y03Z6nY7f5w/jcnImExdvA+D9J3rTrpEXeflGws4lMOubveTlW7eieHW3HwBXJwe2vXkXGw9d4qVv9+HkaMdnT/ejoY87+QYDfxyJ4g31UI0oy43ajL+XC4uf6EM9D2cMRiM/bDvNV5tPljtmqPxrVxM/Nz76v96m7RvUc2XRmqN8teUUwzrX5z+j29LM34NRCzZx7ELJOiqr6m47F755iH8iUwCISUzn0fe2ArBocm+6tfTlamYuANOX7uTEpfKVqzrbTi0HO1bNCcHRwQ47vY71By6yaHVYif2V1a3afqoqfij93u2RgS14aGAL8vMNbD0aw+s/WV/3FTHhy7doO2IAV+MTebXtUJvEUFzPFnWZObI1ep2OXw5E8tX2c2bvO9jpeU1pR6tAD1Izc3lhxRFikrMI8HTml+l9uXBFOy7HLqWwYM3fuDjasez/epi29/VwYt2RaN7+3bpz5b+RTAOxTEZWiJsa1KkJTQI86frEEqZ/vJG3n7R8In17ylCmf7SRrk8soUmAJwM7NQHgo9X7uGPaV/R/ZhmbD0QwY3wvAHaEXzC9Pu2D9Sx++s5KiVev0/Hqg515+L1tDJq7jlHdGtI8wN0szbg+TUnNyOGOWb/x5eZTvDg2GIDmAe6M7NaQwS+t4+FF21gwoTN6nY4WgR7c17cpoxZsImTeBga2D6SRj5spP39PF3q38Td94agseh28cn8HHvlgJ0PmbWJUl/o083czS6P0akRqZg79527kyz9O8+KYtgBcy81n0a/HWbjqqMW8n/1yP8Nf/YPhr/5RKR0V/dsH0tjXnT4zVjPzqz0snNjDYrqFj3Rn5le76TNjNY193enXLhCAKSPbsut4LH2fX82u47FMGdm21Hw7Na9H5+Y+DJm9lkGzfqV947p0b+mHnV7H/AldURZuZMictZyMTOKRwa1qRFlSMq4x77t9LF3/d4m8fgqNYMJbW8oVZ3XEXFq+n637m2eX7LC4n3aNvXF3cbS6PFVdrtKORUXodToWTOjKw4u2MnD2b4zq1ojmAR5macb1bUZqZg59Z/7KF5tPMmtsRwCaB3gwsltDBs35jYfe3cprD3VDr9OZtnt0SEsiYlLN8lqz5xz9Z61l8NzfcHK0Y3zf5lbFbYv2AzDj3g7s/ce883vJ+uP0n/kLd879jS4tfEz7sHVZbtRm8vONvPrDAQa8uIbRL6/j4UEtSxzzsqiKa9e5uKsMm7+BYfM3MOLljWTl5LHpcCQAp6NTeeLjUPadji93rEXZou1k5+QTMnctIXPXmjoqrnttxUHTe+XtqKjutnMtN59xr29i6Bwt3n7tAunQtF65Yr7uVm0/VRl/afduPVr6MLhDECH/Xc/gl9azdKPtvjTv+XoVH4Y8bLP9F6fXwezRbZiy7AB3v7eDkOAAmvi4mqW5u0sQaVl5jHxnO8t3nufZkNtM70UlZjLug52M+2AnC9ZobT4zJ9/02rgPdhKbnMWfx+OqtVzi1iSdFVVAUZRnFUVxqax0N9j2C0VRWlt4/RFFUT6yJs8bubN7c9St2snm0KkYPGrXwteztlkaX8/auLnU4uCpGADUrX8zrLt205yelWNK51LLAaNRe+qXkZ1r8fWKCm7izYX4dCKvZJCbb+C3fRcZHBxklmZwhyB+3n0egPUHL9Grla/2enAQv+27SE6egciEDC7EpxPcxJtm/u4cOZdAdk4++QYj+07FM7RjYZ7/va8jr/90BCOV+xvJ7Rt7cTE+nciEDHLzjfx2IJLB7QPMyxIcwM97LgKw4VA0PVv5AJCVk8/BiESu5VZPT+2Qjg34eedZAI6cvYK7iyM+Hs5maXw8nHF1duRwxBUAft55lqGdGpi2XxUaAcCq0Aiz1y3lazRqT6Uc7fU4OuhxsNOTkJaFTgc6dLjU0gaOuTo5cjkls0aUJTEtm/DzieRaePK979RlUjJySrxu65hLy3fXiVjSs/JKxKLX6ZgzvjMLfzxodXmqulylHYuKCG7izYXLV7l0Jd10/hnSob55mTrUZ1VBmdYfuEiv1n6m1wvPP+lcuHyV4CbeAPh5ujCwfSA/7ogwy2vb0RjT/8POJeLvZdUlxSbtp20jb+p5OLPj78IyZOfks+ekdgObm2/g2IXyl6m620x8apbp6XtGdh4RMan4WXEcquLaVVSv1r5cik8nOlE7H0bEpnEu7mq54yzOFm2nqtjifJN5TTuH2tvpsbfTW30fcau2n6qMv7R7twf7N+eT9cfJyTMAVMpDG2tFhO4nMyn15gmrye316xCZmEl0UhZ5+UY2hsfSr7WvWZr+rX1Ze1gbDb3l7zi6Nqtb5vwbeLvg5erI4fPJlRq3+HeSzoqq8SxQljuVsqYrQVXVx1VVPXHzlBXn7+1GdELhBSkm8Sr+3m4l0sQUTZNgnmb2hL6EfzWFe/u14Y3vQ02vD+vegj2fTmLFvLFMe399pcTrV8eZ2KTCEQ6xyZn4ebqUSBNTkCbfYORqVi6errXw83QhNqnwi21cciZ+dZw5HZ1K1xY+1KntiJOjHf3bBhBQcDM6KDiQuOQsThYMSa1MWlmyCuNJycLP0/zGybdImsKy3PyJ9luPdGbdS4N4enj5Rh3cMFZPF1OdAsQmZZS4YffzcjE/NkkZpmNT192Z+FStHPGpWXi7O5Wa7+GIK+w5GcfBD8dx6MNxbD8WTURMKnn5RmZ/vYctr4/m4IcKLQI9+PGvMzWiLFWpuuu/NI8MbsmWI5Gm/CriVjsWJeJNzsC32GdWS6OdZ4qef3w9nYttW3jumn9/ZxauPIzhBp269nY6xvRszPZjMRbfL3fcVdx+dDp46f4uLFhx4IYxubs4MqhDfXYdj71hmuosS1kE1XWlTUMvjkQklCtmqJprV1GjujZk7b6L5Y7rpnHb4NxTy8GOdS+P4Nd5w00dAte9MLYjm18bxbwHuuBoX77bXFu0Hb1Ox8YFowj7eDyhf8cQdrb8bQdu3fZTlfGXdu/W2Nedrs19WDN3CCtnDqRdI68qK9utxsfdibjUbNPf8alZ+LrXKpkmRUuTbzCSnp1LHRcHAAK9nFk5rRdfTu5Gh0aeJfK/MziATUfLd14X/7tkzYoKUhSlNqACQYAd8BMQAGxTFCVBVdX+iqJ8CnQBnIFVqqrOUxRlmoV0Q4CXgVrAWWCiqqrpN9jvX8AMVVUPKooyEZgFxAKnAYvdw4qiTAYma391LHMZdRZeKz4KQmchUdEkC7/bwcLvdvDMvd15fEQn3vxhJwDr955m/d7T9GhTn1kP9uWel34sc1zlCbhs8Rotv472BOGzDSf4fsYAMrLzOBGZTJ7BiJOjHVNHtGHCu9sqHrcFN6vXsqYp7tkv93E5JZvatez59MkejOnegNV7L1kfaBnjsNiWrMy3kY8bzQI86PqMCsAPM4fQ7bYYDkXEM2Hgbdw59zcuxl/l1Ye6MXVUWz741fJ0mPLs0yyNhe0q9xl9+VR3/d+Ibx1nhndthLJw401yLptb7Vjc6Bxy0zRGIzoLbxiBge0DSUjL5tjFJLq39C25MfDaQ93Yfzqe/VYOya7u9vPQwJZsDY8y+4JRlJ1ex0dT+rJs80kuXbF4GSz3Ps3SWNiuom3GpZY9S6b1Y/73+0kvMnKwzKrg2nWdg52eQcGBvPlzePnjuglbnHu6P/sTl1OyaFDPlR9nhfBPZDIX46/yxspDxKdm4Wiv541He/LkiLa8v6bsZbZF2zEYjYTMXYu7iyOfP9Of24LqcCrKiocft2j7ManGezcAe70Oj9qO3LVgM+0be/PJk73pPXNtJRTk1mf1dQy4knaNoW9sIzUzl1aB7iye0Ikx74WSca1wFObQdv7MUauwLd2i/g1rViiKEgK8j/ad+AtVVd8o9n4t4FugE5AIjFNV9UJpeUpnRcWFADGqqg4HUBTFA5gI9FdV9Xr3+BxVVZMURbED/lQUpZ2qqh8oijL9ejpFUeoCc4FBqqpmKIoyE5gOvFLazhVF8Ufr4OgEpALbgCOW0qqquhRYClB35BulXlsfHdaRCUPbAxB2JpbAuoWjJAK83YhLMr95jEm4SkDRNHXdiEsqOTzw5+0nWDFvrKmz4ro9xyNp5F8HL3dnktIq9jQ2LjkLf6/CaSr+ni5cTjHPMzY5iwCv2sQlZ2Gn1+Hm7EBKRg6xSZlmQ479imy7MvQcK0O1BYaeH9OeuORMGtZzpX5dVza8fKdpX+vmhTD61U1cScumomKTs/D3Kny64VfHuURZ4grSxKWYl6U0lwt6wzOu5fHrvku0b+xlVWfFw4Nacl+/FgCEn0sgoGi9e9XmcrL5FxGtfi2nSUjLwsdDeyrl4+FMYkH9xSZlWsz37l5NOBJxxTSEdtvRaDo0q0d2jvb3xXit/f2+74Jp3rCty1LZbFn/N9KmoTeNfN0JfeceAJwd7Ql9Zwx9ZqyuUeWqKiXqy7M28clZFtK4EJecafaZjSuxrQuXkzMZ3KE+gzsE0b99ILUc7HBzcmDx5F48u3QXAM+OboeXmxMvfv1XuWK1Zfvp1LweXVv48tDAltR2ssfBXk9Gdp5pMc03H+3J+ctpfLmpbAMIbd1m7O10LJ3WnzW7z7HxoHUdv1V17QLo19afvy8mk1BJ7d/W557rZbt0JZ29/8TRpqEXF+OvmkY15OQZUHdE8MSwNjWiLGWRlpnDnn/i6Ncu0KrOilup/VRn/Jbu3bS8Mtl4SFt/I/x8IgajES+3WiTZcDpITXE5NRs/j8JRQT4ezsSnXSuZpo4T8WnZ2Ol1uDo5kFqwsG1qpja15mR0GpFJmTSsW5sT0do0lxb+btjr9ZyMTqum0ojqUvA992NgMBAFHFAUZW2xmQCPAcmqqjZTFGU88CYwrrR8ZRpIxR0DBimK8qaiKH1UVbU06UxRFOUwWidCG6DEWhNA94LXdymKEgY8DDQsw/67AX+pqnpFVdUcYKVVpSjmq/WH6f/MMvo/s4z1e8+gDLgdgE63BZCWeY3LyeYLSV5OziA9K4dOt2nrKSgDbmfDXm3ofRP/wiFgId2acyYqEYDG/nVMr7dr6oujvV2FOypAu+g09nWjft3aONjpGdmtIVvCos3S/BEWxT09GwMwrHMDdhcs8LYlLJqR3RriaK+nft3aNPZ1I+ycFq+3mzYELsDLhZBOQfy67wKnolPp9Oxqer+wlt4vrCU2OZPhL2+slI4KgKMXkmnk40qQtwsOdjpGdqnPH+HmQ+f+CI/lnh5aU7mzUyB7/in9yaqdXmeaJmJvp2NgO39OWXnR+OaPf0wLmW06dIl7ejcFoEPTelzNzCkxDSA+NYuM7FzTAmL39G7K5sPajf2Ww5Hc26cZAPf2aWb2uqV8YxIz6FawoKa9nY7uLX2JiEkhLjmT5oF18Co4Xn1uDyAi+uY3ftVRlspmy/q/ka3hUXR6eiU9p6+i5/RVZOXklaujorrKVVUKzz+uheefI5FmabaERXJvQZmGdWnI7oI1GrYciSxy/nE1nX/eXHWEbtNX02vGL0z9NJTdJ+NMHRXj+zaj7+3+TP009KYjqoqzZfuZ9mko3f+jtZEFKw7y886zpo6K5+/tgJuLA/OX769RZSnN24/34kxMKp9vtH52ZlVduwBGdWvE2v2VN4Tflm3Hw8XRNL3D07UWnZv7cKbgHF90fYmhnRqU6Uu/LduOl1st00LETg529GkTUGIR3bK6ldpPdcZv6d4NYPORKHoWrHnR2NcNB3u9dFQUOB6VSgPv2gR6OmNvpyOkvT/bT5gvhPzXiXhGFaz/Mfh2P/af1erbs7Yj+oJRF4FezjT0rk1UkRF0d7YPYEO4ddMVRY3XFYhQVfVcwXfSH4HRxdKMBr4p+P8qYKCiKJYGrJnIyIoKUlX1tKIonYBhwOuKomwu+r6iKI2BGUAXVVWTFUX5GrA0iVEHbFFV9T4rwqjSEc9bDp5lUOcmHFj6BFnXcs3Wltj2/kT6P7MMgOc/2VTw06X2/HnoHH8c0nqyX3qkH80CvTAYjERdSeO5j7Xh4SN63sa4AbeTm2cgOyePx9+y7ucai8s3GPnv8oN8O70/dnod6s5znIlJZfpdbTl6IYk/wqJZueMs703qyfbXR2o/97lEG+lxJiaVdQcu8ceC4eQZjLy0/IBpjvhnT/XB07UWufkG/rv8IGmZVgzztaIs81aE8e2zfdDrdfy06wJnYtP4z6jWHLuYzB/hsazceZ73HuvKtgUhpGbk8PTn+0zbhy68E1dnBxzs9AwODuChxaFEJ2byzTN9cLDTodfr2HUynh9Dz5USRdlsDY9iQHAgO98ZQ1ZOPs99Xjh6ZuOCUYTM1YZXzv56j/aTbw52bDsazbZw7Wbk49+P8enUOxh/R3OiE9N58sO/Ss133f6L9Gztz5aFozEC249G88cRbbGnxb+Es2rOneTlG4hKzGD6UvORPLYqSz0PZ9a9MgJXZwcMBnhsaGsGzFxDenYuH03pS/dWfni5OrH//bG8uzqMldvLvtZGddc/wM9z76Spvwe1nezZ//5Ynv9il9VrJlR3uUo7FhWRbzDy0vL9fDdjIHZ6HStDIzgdk8r0u9tz7HwiW8KiWLkjgsWTe7PjzdHa+edTbR2f0zGp/H7gIn8uHEVevoG53+2/4RoV1y18uBvRiRmseSlEq5ODl3h/7bFyx22L9mOJn6cL00a350x0ChteHQXA11tO8mMN+CzcqM20auDJvb2bcfJSEhsXaDG/+dMhU35lVVXXLidHO/q08WP2t+adP0M7BvHy/Z3xcqvFsmfu4ERkCg8tKv+UxupuO80CPXhjYk8MRiN6nY6Pfz/GmYIv+B9M6Yu3mxM6HRy/mMSsZXtqRFlu1HZ86rjw3uTe2Om16/Fv+y7wZ5h1P+F+q7afqo7/Rvduaug53n60G5tfGUZuvoHnvthrdewV9dgPH9CiX3dc63ryeuQefpv3Hru/Um0WT77ByOtrj/Ppo13R62HNwSjOxqczZXBzjkelsv1kPL8cjOQ1pT2/zbiDtCztp0sBOjb24qnBzckzGDEYjCxY8zdpWYXX1SFt/Xnq6xuvVfS/zJh/y08DCQSKPp2JQnuobjGNqqp5iqKkAt7ADRfr0VXWLzD8r1IUJQBIUlU1W1GUu4BHgKbAKFVVzyuK0h5tbk4HoB5wFJipqurXiqIcK5KuHnAIGKCqakTBr4QEqap6+gb7/QutEyQa2Iu2CEUasBUIV1V1amlx32waSE2W+PssGkz83tZhWO3SsgdoNOknW4dhtQufjyXowWW2DsNqUcsnSvw29G+Iv/7D39o6DKtFfvPQLV//t3r8t/r161av/1s1/qjlEwFu2fZzadkDwK0f/xNlGvRc8yxBGxnTbuY6G0dinaNvDsdoNJb6BP5WV3/C1zX+u1mPa+ufwLT+IQBLC5YZQFGUscBQVVUfL/h7AtBVVdWnrydWFOV4QZqogr/PFqRJ5AZkZEXFtQXeVhTFAOQCTwI9gA2KosQWLJx5BDgOnAN2Fdl2abF0jwArChYfAW0NC4udFdepqhqrKMp8YA/aApuH0RY1EUIIIYQQQgghKqzo+ocWRAFFf6s9CCg+3PZ6mihFUewBDyCptH1KZ0UFqaq6CdhU7OWDwIdF0jxyg20/LJZuK9qvhpRlv/2K/H8ZcGs+KhBCCCGEEEKI/2H/gl8DOQA0L1gCIRoYD9xfLM1atHUZ9wD3AltVVS11RIkssCmEEEIIIYQQQgirqKqaB0xFe4h/UntJPa4oyiuKoowqSPYl4K0oSgTar16+eLN8ZWRFDacoyi9A42IvzywY0SGEEEIIIYQQQtiUqqrrgfXFXvtvkf9nA2PLk6d0VtRwqqrebesYhBBCCCGEEEJUjX/BNJAqIdNAhBBCCCGEEEIIUaNIZ4UQQgghhBBCCCFqFJkGIoQQQgghhBBC2IhMA7FMRlYIIYQQQgghhBCiRpHOCiGEEEIIIYQQQtQo0lkhhBBCCCGEEEKIGkXWrBBCCCGEEEIIIWxE1qywTEZWCCGEEEIIIYQQokaRzgohhBBCCCGEEELUKDINRAghhBBCCCGEsBGZBmKZjKwQQgghhBBCCCFEjSKdFUIIIYQQQgghhKhRZBqIEEIIIYQQQghhIwaZBmKRjKwQQgghhBBCCCFEjaIzGo22jkHYgE6nkwMvhBBCCCGEqPGMRqPO1jFUJZ+7F9X472bxv0yv9mMg00D+RwU9uMzWIVgtavlEmjyxytZhWO3cknvxu/dDW4dhtbhVTxN4/xe2DsNq0T88fsvHf6t/fiV+24laPlHavw1J+7GtW7n9RC2fCNy692/X43fvP8vGkVgnbdvrALSbuc7GkVjn6JvDAXiChjaOxDpLuGjrEKqc/BqIZTINRAghhBBCCCGEEDWKdFYIIYQQQgghhBCiRpFpIEIIIYQQQgghhI3INBDLZGSFEEIIIYQQQgghahTprBBCCCGEEEIIIUSNIp0VQgghhBBCCCGEqFFkzQohhBBCCCGEEMJGjPmyZoUlMrJCCCGEEEIIIYQQNYp0VgghhBBCCCGEEKJGkWkgQgghhBBCCCGEjchPl1omIyuEEEIIIYQQQghRo0hnhRBCCCGEEEIIIWoUmQYihBBCCCGEEELYiEwDsUxGVgghhBBCCCGEEKJGkc4KIYQQQgghhBBC1CgyDUQIIYQQQgghhLARmQZimYysEEIIIYQQQgghRI0inRVCCCGEEEIIIYSoUWQaiDDz8oSuDGgfRNa1PKYv3cnfF5NKpGnbyJtFk3vj5GjH1vAo5n23H4A6tR35eGo/6td1JTIhnSkf/kVqZk6p+X73/GA6NK3HgdOXmbjoT9M+Fk3uTbeWvlzNzAVg+tKdnLhUMpay6Nval5eU9tjpdazcdZ4lm06bve9or+edRzpzewNPkjNymPbFPqITM+nVyocX7rodB3s9uXkG3lh9jD2nrgDw3Og23N2tAe4ujrR79ler4iqPVyf2YWDHhmRdy+PZj//k2PkrJdK0a1KPxU8NwsnRjj8PX+SlZaEAjOjelBlKV5oHejFs1k+En4sHwMFez1uT+9O+qQ8Gg5GXloWy50R0pcX8ykPdGdC+Plk5efxnyQ7+vpBYIk3bRt689399cXKwZ2t4JP/9di+gtaVPnh5A/XquRF5J58kPtpKamUOPVn58OX0wkVeuArDhwAUW/xJmyk+v07F+wWjikjN45J0tt1T87i6OvD2pN7cFeWI0wnNLQzkcEW91/FXxWb6rZxOmDL8dgIxrecz+eg8nLyVTy8GOVXNCcHSww06vY/2BiyxaHVZif7aOv6m/B+9O6sXtjbx5e9Vhlqw/bspr96J7ycjOJd9gJD/fwPB5v98y8ft7ubD4iT7U83DGYDTyw7bTfLX5ZIXir4r2f3fPpkwZ2Q6AjOxcZi3bzclLSTTx9+DTp/ub8m3g48Y7qw7z5cbjJfZZVtXdfkA7/6x7ZQRxyZlm17Ob6dc2kPkTumKn17HirzN88vsxs/cd7fUsfqIPbRt7k5x+jSkfbScqIR2Ap0a2Zfwdzck3GJn33T62H4spNc9erf2Zc19n9DodGdm5PLd0JxfirzIppDXj+7UgP99A4tVsZny+i+jEjLJXeBHV2XYA9ixWTJ/dvHwDw19aa1Xc11V323F3ceStx3oWnPuNzPjBNtuVAAAgAElEQVRiF4cjSl7ja2r8j4e0ZvwdzQH4JzKZ5z7fxbXcyhnO/ubUEQzpdhuZ2TlMeetnws/ElEgT3DyAT2bei3MtBzbvO8XMj7Rz94sPD+Th4Z1JSNHa8StfbmbLvtM08K3D/q//w5lIrY4PnojkP4sr/z6uZ4u6zBzZGr1Oxy8HIvlq+zmz9x3s9LymtKNVoAepmbm8sOIIMclZBHg688v0vly4osV97FIKC9b8jYujHcv+r4dpe18PJ9Ydiebt3yt2rq8ME758i7YjBnA1PpFX2w61dTi3LKPBYOsQaiQZWSFM+rcPpLGvO31mrGbmV3tYOLGHxXQLH+nOzK9202fGahr7utOvXSAAU0a2ZdfxWPo+v5pdx2OZMrLtTfP9bN3fPLtkh8X9vLbiICFz1xIyd63VHRV6Hcy/L5hHP9rF0Jc3M7JLfZr5u5mlGdurEamZuQz47yaW/XmGmXdrX8aS068x6ZPdDHv1D57/5iDvTOxi2ubPo7Hc/cY2q2IqrwEdGtLEvw49n17O80u28cakOyyme2NSP55fso2eTy+niX8dBgQ3AOBUZBKPvbOBvSfNL/IPDGyj5f/cCsa9+ivzH+6FTldJMbcPorGfO72f+4mZX+7k9Yk9LaZ7/dFevPDFLno/9xON/dzp3z4IgKdGtWfX8Rj6PLeKXcdjeGpUe9M2+0/FMXT2GobOXmPWUQHwWEgbImJSbsn4X57Qnb/Co+j3/M8MmfVLhcpRVZ/lyCtXGfvaRobMWcv7a8J581GtXq7l5jPu9U0MnaN9Xvu1C6RD03o1Lv6UjGvM+24fS9f/bTE/ZeFGQuaurXBHRXXHn59v5NUfDjDgxTWMfnkdDw9qSfMAD6vjr6r2f+nKVe59dR2DZ/3C+2vCeOuxXgCci001fSbunPMrWdfy2HjwotXx26r9PDa0FRExqeWKVa/TseDhbjz09hYGzFzD6B6NSxy78Xc0JyUjhz4zVvPFxhPMHtcJgOYBHozq3piBL65hwttbeO3h7uh1ulLzXPhId6Z9uoOQuWv5dc85pt2lHZu/LyYx/L+/MWTOWtYfuMic8Z3LVY7rqrvtXDd2wXqGzl5T4Y4KW7Sd+Q925a+j0fSf+QtD56wtdxuyZfx+ni5MHNKKEf/9nUGzfkWv1zGqe2Or4y9qcLcWNA30psOEd3lm0RoWPTvaYrpF/xnNM4t+ocOEd2ka6M2gri1M732yahd9Jn9En8kfsWVf4YOq8zFJpteroqNCr4PZo9swZdkB7n5vByHBATTxcTVLc3eXINKy8hj5znaW7zzPsyG3md6LSsxk3Ac7GffBThas0eo8Myff9Nq4D3YSm5zFn8fjKj12a+z5ehUfhjxs6zDEv5R0VpSDoij9FEWxfOW1EUVR6iuKsk1RlJOKohxXFOUZa/Ma0rEBP+88C8CRs1dwd3HEx8PZLI2PhzOuzo6mXv+fd55laKcGpu1XhUYAsCo0wuz1G+W760Qs6Vl51oZ8U+0beXExPoPIhAxy8438fiCKQe0CzNIMahfA6j3ajfGGw9H0aOkDwInIVOJTswE4HZNGLXs9jvbaRybsfBJX0rKrLO6iQro05qft/wBw+Mxl3GvXwqeOi1kanzouuDk7cui0duH6afs/hHRtAsCZ6GTOWvji2yLIk53HIgFITMsiNeMa7Zv6VErMQzo1NLWFwxEFx7xOsbZUxxlXZwfT6AGtzTTUtu/YgJ9Cz2hlCT1jakul8fdyYWBwfX7YduqWi9/V2YFuLf1Y8Zd2M5WbbyCtYFSSVfFX0Wf50JkrptFSRyKu4O9Z2A4zr2mfY3s7PfZ2eowYa1z8iWnZhJ9PJDff+thqYvzxqVmmp6cZ2XlExKTi52V+jihX/FXU/g+diTe1n8Nn4vH3ql1i371vD+Bi/FWiC0YOWBW/DdqPn6cLA4KDWLH9dIn3ShPctC4XLl/l0pV0cvMNrN17niHFzhdDOjZg1U4tnnX7L9Crjb/2eqcGrN17npw8A5FX0rlw+SrBTeuWmqcR7XwD4ObiyOXkTAD2nIwjO0d7Gn444orV7ceWbacyVHfbcXVyoFtLX37crpW5pp77S2v79no9To7aqDpnR3tTm6qo4T1bs2LLEQAOnozEw9UJXy/zh02+Xm64uThx4IR2L7NiyxFG9GpdKfuviNvr1yEyMZPopCzy8o1sDI+lX2tfszT9W/uy9nAUAFv+jqNrs7plzr+Btwtero4cPp9cqXFbKyJ0P5lJ1neyCVEa6awon35AlXZWKIqiUxSlPMclD3hOVdVWQHfgKUVRrDpT+3m6EJNUOOwzNimjxA2Ln5cLscXTFHxhqevuTHxqFqDdPHu7O5U5X0teGNuRza+NYt4DXUydBOXl6+lMbJELZ1xKFr6e5hduvzpOxCZrcecbjFzNysWztqNZmpCOgZyITCUnr/qHaPl5uRKTWHjjHpuYjr+XeQ+9v4U0fsXSFHfiYiJDuzTBTq+jvo8b7Zr4EOjtVuo2ZY/ZhZjEosc8Ez9P85tLP8/aJdtSQbuo6+FMfEpBW0rJwrvIzVanZj5sXngX370whBaBdUyvz5/QnddW7MdorPgX0eqOv4GPG0lXs1n0RB82vnYXbz/eG+da1s/Sq6rPclHj+zVn29HCaUN6nY6NC0YR9vF4Qv+OIexsQo2OvzgjRr6fOYR1r4zg/v4tbpq+psV/XVBdV9o09OJIRAXqvwrb/3Xj+7VgW3hUiddHdW/Cr7vPWh27Flv11//8B7uy8MdDlHcUr8VYPUvGev145BuMXM3MwdO1lrZt0eOUrG1bWp4vfLGLb58bxP73xzKmV1M+/s18ygloIzn+OmrdlEBbtB2jEX54MYT1C0bzQP/bSqQvV/zV3HYa+LiRlJbNosm92fDqSN56rGeNP/cXFZecyZL1f7N38VgOfTiOq1k57Pi75FQNa/jXdSc6vvALcMyVNALqupulCajrTswV8zT+RdJMuqsHuz5/mo+eH0Md18KyNPTzJHTJVNa9N4kebRtVSrxF+bg7EZda+EArPjULX/daJdOkaGnyDUbSs3Op46J1JAZ6ObNyWi++nNyNDo08S+R/Z3AAm47GVnrcwraMhvwa/88WZM0KQFGUh4AZaA8djgIqMBdwBBKBBwBn4P+AfEVRHgSeBv4BPgOuPwZ5VlXVXYqi1AN+ALyBA0AI0ElV1QRFUaYDjxak/0JV1cWKojQCNgDbgB7AGkVR6qiq+p+C+CYBrVRVnV48dlVVY4HYgv9fVRTlJBAInLBQzsnAZABqDStRD5amABT/3mdplsDNvhqWJd/i3lh5iPjULBzt9bzxaE+eHNGW99eE32RPFvZt6cUShSqZqmiK5v5uvHD37Tzy/s5y778yWKy/4rVusY5Lr+QVW0/QPNCTjW8qRF25ysFTseTlV05njM5CQMXjsaZdHLuQSLdnVpJ5LY8B7YP4cvog+jy3ioEd6pOQms2xC4n0aOVXkdC12Ko5fnu9ntsbefPSN3s4cvYKL0/ozlMj2/HOqsPWxV9Fn+XrerTyY1zf5oxZsMH0msFoJGTuWtxdHPn8mf7cFlSHU1HWTWWp6vgtGfPKei6naDfnP8wcwtmYVPadumxVXraIH8Cllj1LpvVj/vf7Sc/OtTqfqmr/1/Vs7c/4frdx9yvm020c7PQM6dSAN1YeKHOsllR3/Q8MDiIxTTv/dG9ZvvOPtfVoLGVbvYW+/et5Ph7Shofe/YOwswk8MawN/32gCy98uduU7u6eTWjXuC5jX9tQMpMysEXbufvl37mckom3uxMrXgwhIjaVff9YNzy+utuOvZ1OO/d/t4+wswnMf7ArT41oyzs/H7Eqv+qO38PFkSGdGtBz+irSMnP47On+3N2zCb/sPnfzjW/CclnK0JYKSvPl2n289d1WjEaYO3EQC54cxtS3VxOXdJU2971JcloWwc0D+P7VB+n+6PtczbxW4ZhLj6tsaa6kXWPoG9tIzcylVaA7iyd0Ysx7oWRcKxyFPLSdP3PU8t8TC3Er+p/vrFAUpQ0wB+hV0JnghXa+6K6qqlFRlMeBF1RVfU5RlM+AdFVV3ynY9gfgPVVVdyqK0gDYBLQC5gFbVVV9XVGUEAo6CBRF6QRMBLqhXS/2KYqyHUgGbgMmqqo6RVGU2sBRRVFeUFU1t2CbJ8pQlkZAB2CfpfdVVV0KLAWoP+FrI8DDg1pyXz/tKWL4uQQCigyt9PeqXWI4X2xSptnwy6JpEtKy8PHQeuV9PJxJLJgmEZuUedN8i7ves5+TZ0DdEcETw9rcrPgWxSVnmQ1V96vjzOWUbAtpnIlLycJOr8PN2YGUjBxT+k//rwfPf32QSwnWLTZmjUeGtuWBQdoAmfCIeAK8C0dJ+Hu7EpdkHktsYnqJNJeTS48332Bk3jeFHTBrF9zD+Tjr10l4eHAr7i94qhV+LoEA76LH3IXLKcXbUsaN21JqFj51tCdsPnWcSSxoD+lZhV/AtoZH8ZqdHk/XWnRp4cuQTg0YEBxELQc73Jwd+eDJO5j26fZbIv7YpAxikzI4clYblrtu/3meGtme8qiOzzJAy/qevP1YTya88wcp6SVv7tIyc9jzTxz92gWWq7OiuuK/kcsFT3MT07LZePASwU3rlquzwtbx29vpWDqtP2t2n2PjwUtljtsUfzW0f4BW9T156/HeTHhrU4n20z84iGMXEkmwYoqdLeu/cwsfBnesT//2188/Dv/f3n2Hy1WV7R//JiGQ0KvSO0iRKigooLQXAcUC3NhQKQqv0gT5+ar4EkBRiiAGXxTR0ES9QXoJINKLQiBUBRSIVOkhlBBIzu+PtSeZJCfJzMnkrL0mz+e65uLMnnPCnZN15uy99lrPwyn7b8nBv7x5lrl7/f04zff6uZffZNklFuC5V95Mv6Pmn5dXX387fW3zv9NiU762tz9z8YXmY50VF5u86umyvz7BOYdvP/nztlh3GQ7cZX12P3ZkW6sIc4+dxp+ffnbHsOGqS7Y1WZFz7Dz78ps8+/Kbk/9NrvzbE5PrRJSQf4v3L8OTL4zj5XHp3+OqO8ewyRrv6fNkxb6f2oyv7Jzqpdzz8NMs954p9VuWXWphnn1p3FSf//QLr7HsUlN/znMvps954ZUpq03PuuJO/nhsqqkw4Z2JTHgnjavRjz7D48+8zOrLL8k9j3SuwPh/xo5n6UWmrOR4zyJDef61t6f/nEWH8Pxr4xk0cAALDhnM2Kqo/Ng308/f359+jSdffpOVllyAh55OK0jWXGYh5hk4kL8//VrH8oZQZ7ENBLYBLrD9IoDtl4Hlgasl3Q8cDszoSnk74FRJo4FLgYUlLQRsAfyh+vNGkiYjqI5fZPsN268DFwJbVq+NsX1H9TVvAH8BPiFpLWCw7enXajaRtCDwJ9Lqjpbfwc768z8mF7G8etS/2XWL1QDYaLWlGPfmhMmTBg3Pj32LN8a/M7l43q5brMY1d6cT42vvfpLdtlwdgN22XH2q47P6c6fVvMdyhw+s2Oc7tPeNeYWV37Mgyy8xP4MHDeATmy7PdfdNvUTxuvue4bObp/2yO2683OSOHwsNHcwZB3yYEy5+gFH/mr6a+Zx05tX3s/3hf2T7w//IVXc+xu4fXQuAjdd4b/r+TXPy9/yrb/L6WxPYeI20J3L3j67FyDsfn+n/Y+i880xebrrV+iswceIkHnmq7/sfz7r275OL5I28a8zksbDx6ksx7q13Ji/tnZL5LV5/6x02Xj2Npd22XJ1rRqXaIdfe/W923zJVF999yzUmj6WlmsbFhqsuycABA3jl9bf5yR/vYtMD/8Dmh5hvnno9tz70TFsTFbnzvzD2LZ556Q1WXSaddG2x7rI8+nR7/xb98bO87BIL8OuDt+bgX93M489NeZtZfKH5WHj+tHVqyOBBbLnusm0XieuP/DMydL55WGDIPJM/3mq9ZXn4yfbec3LmBzhh34/w6DNj+fXI6RbVtZa/H8b/sksswK8P2Y6DT7txqvHT8KnNV+vzFpCc3//jfDcfPPh8PnzoBXzzFzdy60PPtjRRAenicuWlF2aFpRZk8KCB7LLZKlx795NTfc619zzJblukPDt/cGVufejZyTl32WwV5p1nICsstSArL70wo//14gz/zLFvTGCh+edllaXTMvkt37/s5EK+6660OD/Za3P2Pvm6libHmuUcO+lnd/Dkj7dabzkebvP3WM6x88LYt3j25TdYtfo3+ci6y/Lo0+W8dz790htstNpSDJl3UJV/GR6djeLQZ1xyx+TCl5ff8hCf334jADZZewVee2M8/3l56smK/7w8jtfffJtN1l4BgM9vvxFX3JbeA5vrW3xiy3X5++Np8nmJRRZg4MC0rGHlZRZjteWX4Iln+1bEfUYefGosKy6xAMstNpR5Bg3g4xssw40PTT35fcNDz7PLxqmw7PbvX5q/VeeZiy0wL1U8llt8KCstsQBPvTzlnG/HDZblqns7s9UmhBLM9SsrSCscpl2dNRw4yfalkj4GDJvB1w4ENrc91W8CSTPqqTCzXgvT3gY/A/geaavJiJl8HZIGkyYqfmf7wpl97sz85d6n2GbD5bjlxM/y1oSJHPbrKXfdR/5wFz5+RKqy/b0zb08trwYP4vr7nub6e9Ns9C8uv5/TDvgon/voGjz90uv89/AbZvnn/umIHVltmUVYYMg8/O2U3Tn8jFu58f5n+Pk3tmKJhYYwYAA8OOZlvjvi9j79nSZO6uGoP47mzIO2YODAAVxw2xM8+uw4DvnkOtw/5hWuu+9ZfOsT/HSvTfnL0Tvw6psTOPiM1MLryx9bjZWWWpADdlqbA3ZaG4Cv/vwWXhr3Nt/57Pv55KYrMHTeQdzy4x3xrU/w8znUPuq6u8ew7UYrcfvwPVMruF9MaYl37Ql7sP3hfwTgf359Iz/75rYMmXce/jJ6DH+5J5387fjBVfnh3luxxMJDOee7n+DBJ17k8z+6lCUWGcrvj9iFnkk9PPvyGxw4/M8dy/yX0U+yzYbLc8tJuzN+wrsc+qspJ+5XH/tpdvjexQB8b8RtnLTfVgyZdxA33PsUf6n2IZ962X388sBt+NzH1uTpF99g/5+nv/POH1yZPbdbm4kTJzH+nYl849Q505ElR/4fnH07w7/xUeadZxBjnh/HYTPoktNS/jn0s3zIpzdg0QXn40dfSRXmGy0+37Po/Jz89S0YNHAAAwcO4LK/PsF1o6evR5A7/1KLDOWKoz/BgkMHM2kS7LPDOmzznYtZfKH5+PUh2wAwaOAALrn9cW64v+932fo7/9orLsZuW6zO3//9MiN/uAsAx50/avKf13b+OTT+v/WZjVh0ofk4tuoQ0dxmcsi8g9jq/cvyP7+Z/e12/f39n50tNxMn9fCDs+/g3MO3T+21b/onjzz9Kod9dkPue/wlrr3nSf5w46P8bP8tufnEz/Lq62/zzV+kidhHnn6Vy//6BH/5yad5d1IPR5x1B5N6eqCHXv9MgO/85jZOP2hrJvX0MPaNCXy7+t58/3ObMP+QwfyyaiH7zEuvs/fJf2n779PfY2ephYdyxre2BWDQoIFcfNu/+lxvA/KMnR+c/VeG//dWDJ5nIP9+4XUOO73vPwP9nX/0v17kyjvHcNUxuzBx0iQeeOJlzru+vSKzM3LNXx/mvz70Pkafexhvjn+Hbx7/p8mv3Xz6AWz59VMBOPRnl1StS+fh2r89Mrnrx9H7fZz1VluGnp4e/v2fVznkpDT2PrL+ynxvr+14d+IkJk2axLdOvoRXxs38Blq7Jk7q4ceXPshpe3+QgQPh4rue4l/Pv843tl+DB58ay41/f56L7nqSH2kDLvv2R3ntrdS6FGDjVRbnm9uvwbuTepg0qYcfXvwArzWtyvyv9Zbhm2fO3la5TtvnvJ+z5sc2Y8ElF+PHT97OZUeezG2/de5YxclVE6LuBnSiGF3Jqm0gF5EmHV6qtoFcB+xre5SkEcAqtj8m6TBgYdtHVl97HnCP7ROq5xvaHi3pF8C/bR8n6b9I20OWItW2OJNUCHMAabvGnqSVF5fbfv802e6uvm59273eKqgmRs4CXrZ9SKt/78Y2kBI9de5erLrfBblj9Nljv9qNpXcbnjtGnz13wYEs94Uzcsfos6fP27f4/Mt/aabzl7X21Ll7Rf6Mnjp3rxj/GcX4yavk8fPUuXsBFJ9/4a2/mzlJ37x2/Y8BWP87V2RO0jf3HbczAPuxUuYkffMrxtDT0zOzm77FW2irb9f+2mzcTSf2+7/BXL8NxPaDwI+AGyXdC5xEWklxvqSbgeaS6pcBn5E0WtKWwEHAJpLuk/QQqQAnwFHAf1WTDTuSCmCOs303abLib6SJijNsz6yKkoFbZzRRUfkIacJjmyrXaEnTV88MIYQQQgghhBAKEdtAANtnkVYnNLukl897BFh/msN79PJHjgV2sP2upM2BrW2/Xf0ZJ5EmRJr/3CeA90/3p6QaFyfPIvstzHx7SQghhBBCCCGEmpoU20B6FZMVc8aKgCUNBCYAX2vniyUtSlp9ca/t62b1+SGEEEIIIYQQQjeJyYo5wPajpBaiff36V4E1m49JWoJUS2Na29ru31YVIYQQQgghhBDCHBSTFYWoJiQ2zJ0jhBBCCCGEEELn9EyMbSC9mesLbIYQQgghhBBCCKFeYrIihBBCCCGEEEIItRLbQEIIIYQQQgghhEx6ohtIr2JlRQghhBBCCCGEEGolJitCCCGEEEIIIYRQK7ENJIQQQgghhBBCyCS2gfQuVlaEEEIIIYQQQgihVmKyIoQQQgghhBBCCLUSkxUhhBBCCCGEEEKolahZEUIIIYQQQgghZBI1K3oXKytCCCGEEEIIIYRQKzFZEUIIIYQQQgghhFqJbSAhhBBCCCGEEEImsQ2kd7GyIoQQQgghhBBCCPXS09MTj3h0/LH77rt/PXeGuTV/ydkjf/5H5I/8kT9/jshf5iPyR/7Inz9HPLrrESsrwpzy9dwBZlPJ+UvODpE/t8ifV+TPK/LnFfnzivx5Rf4QphGTFSGEEEIIIYQQQqiVmKwIIYQQQgghhBBCrcRkRZhTTs8dYDaVnL/k7BD5c4v8eUX+vCJ/XpE/r8ifV+QPYRoDenp6cmcIIYQQQgghhBBCmCxWVoQQQgghhBBCCKFWYrIihBBCCCGEEEIItRKTFSGEEEIIIYQQQqiVmKwIIYQQQkdIWiJ3hhBCCCF0hyiwGWabpOHADAeS7YP6MU7bJB06s9dtn9RfWfpC0uIze932y/2VpdMk7WV7RO4csyJpLWA54K+2X286/nHbI/MlmzlJSwNHApOA/wUOBHYF/g4cbPvZjPFmSdIAYHfS+88FwDbAp4B/AL+0PSljvFmSND9wACn/cOBzwGdJ+Y9uHkt1JOknwIm2X5S0CWDSWBoMfNn2jVkDzoKkzwA32n5Z0lLAT4GNgIeAw2w/lTXgLEg6APhD9f1fHfgtsD7wMLCv7fuzBmyRpMG235nm2JK2X8yVqRWSVgBOIL33XwWc0Ph7SLrY9qdz5ut2XXDuVvS5M5R77hPKEisrQifcBYwChgAbA49Wjw2BiRlztWqh6rEJ8N+kN97lgP2BdTLmatUopvwbvAA8Qvr+v1AdK9lRuQPMiqSDgEtIF/oPSPpU08vH5knVsjNJF2ZPAtcDbwE7AzcDv8wXq2W/AATsCZxD+pm9C9gKODljrladCbwXWAW4gvQedCIwADgtX6yW7dx0QXkCsIft1YHtSRf+dfejpsncU4F7gB1JF561nyQF/rvp+38KcLLtRYHvUMDPr6StJT0FPCPpGkkrN718TaZY7fgtcAPpvX8Z4MamlUUr5QrVKknrSbpD0pOSTpe0WNNrf8uZrUWln7sVfe5c+LlPKMg8uQOE8tk+C0DSV4Gtm+4s/JICTjhsHwUg6RpgY9vjqufDgPMzRmuJ7VVg8vf7UttXVs93BLbLma0Vku6bwUsDSBdydfc14AO2X69Oti+QtLLtU0h/hzp7r+3hAJK+Yfu46vhwSftkzNWqLW2vJ2kw8BywjO0Jks4jXXjW3Zq2Va0QeRbYznaPpJuBezNna8VgSfPYfhcYavtOANuPSJovc7ZWDGr6eHXbe1QfnynpkByB2tR8Dvce2xcB2L5B0kKZMrXjeGAH2w9K2g24VtKetu+g/u+dAEvZbkwKHSjpS8BNknZhJnfMa+Q0YBhwB7AvcIukXWz/i7Q6qta64Nyt6HNnyj73CQWJlRWhk5YlzXI3LFgdK8WKwISm5xOAlfNE6ZNNGxMVALavAj6aMU+r3gt8GfhkL4+XMuZq1aDG8kfbTwAfA3aUdBL1/4Xd/Dvg7Jm8VlfvAlQneXfanlA9f5cC7kw12O4Brqz+23hewsXOL4ArJW0DjJT0M0lbSToKGJ05WytukHS0pKHVx5+GdMcfGJs3WksukHSmpFWBiyQdImlFSXsB/84drgXz2n4QwPYFwKeBs6rtOSWM/8GShjSe2D4XOBi4mrTSou4WtD3S9qu2TyRtSRspaTPK+P43lH7uVuq5c8nnPqEgJZyMhnL8BLinOnk6E7ibspaCnQP8TdIwSUcCf2X6C7g6e1HSEZJWlrSSpO9TxsX+5aSTpjHTPJ4gLbGtu+ckbdh4Uv3y/gSwJLBetlStuUTSggC2j2gcrPa/P5ItVeuea8r/8cbBqhbHhBl+VX3c1ZR/78ZBSasB47KlalG1KudYYD9SrZBtge8CzwB7z+RL6+IAUo2Nh0m1Ty6UNI50x3DPnMFaYfv7pPfI3wOHAscAI4E1gC/mS9ayd6qfVQCqiYttSXV01siWqnVnAB9qPmD7z6Sx9ECWRO0ZIGmRxhPb15NqFp1DAdtYmpR+7lbquXPJ5z6hIFFgM3RUdeLR+OX9V9vP5czTLkkbA1tWT2+yXcJScmByoc0jSfv1AW4Cjiq5wGYzSYvZfiV3jmlJWh54t7exLukjtsR4FbwAACAASURBVG+tPq5l/m4kaQFgAdvP587SV5IGNFZahDmvumibx3YJE7xdQdJ2wAu2753m+CLAAbZ/lCfZ3EHSF4DHqm03zcdXBH5g+2t5krWv5HM3KPPcOc59Qn+JyYow2yStZfsf1S+L6di+u78ztUPSwrZf0wy6anTLxX7pJN1tu9cxVoI6559BVfWxwCjbtV/OP4P3nrHAmGpLSK1J+mwvh8cC95cw4RLjJ6/Sx083kvS/to/OnaOblX7uVvq5c6vqfO4TyhAFNkMnHAp8nd6rv/eQ2gnW2XmkpWujmHqf5oDq+ao5QrVK0s9sHyLpMnrZZ2p7lwyx5oTS90DWOf8m1eOy6vnOwJ3A/pLOt318tmSt+T9SNfX7SN/n91cfLyFpf9t1L1a2D7A5qSMLpL2/dwBrSjra9jm5grUoxk9epY+f6Ui6yvaOuXPMhn2BYicrJJ1u++u5c8xC0edulH/u3Ko6n/uEAsRkRZhtjV9otree2edJ2t72tf2TqnW2P1H9d5WZfZ6kdRvFwGqmcSJ6YtYUc17py8DqnH8JUjX11wGqfb8XkLYUjSJV7a+zJ4B9Gj+fktYBDift4b+Q+ldWnwSsbfs/AJLeS6rU/yHSdq66X2zG+MmryPEzozvKpIubDWfwWm1Iem0GLw0AhvZnlr6Y0YoEUv6d+jNLX5R+7lb6uXMb6nzuEwoQkxWhPx0HlPyGew7p7lut2B5V/ffGmX2epD/Z3rV/UoXCTFtN/R1gJdtvSXo7U6Z2rNV8Mmr7IUkb2X5MUs5crVq5caFZeZ7U1vRlSe/kCtWGGD95lTp+7gRupPc7r4v2c5a+eJXUhes/074g6ckMedr1AjCGqb//PdXz92RJNGfU8tytDaWfO4cwW2KyIvSn0peClZ6/7ksiZ6X073+d858H3CHpkur5J4HfV4UqH8oXq2UPSzoN+EP1fA/gEUnzkS6c6+5mSZcD51fPdwVuqr7/r+aL1bIYP3mVOn7+Duxn+9FpXyjkYv9sUteM6SYrSD8TdfcYsK3t6drcFvL9b1Wdf/e2IvKHuVpMVoT+VPpSsMg/B8xkKSowVZGsbfshTttKzw9g+xhJVwEfIZ1Y7G/7rurlElogfhX4BnAIKf8twLdJF5ozXWJbE98kXWA2vv9nA3+quoHUPn+Mn+xKHT/DgIEzeO3AfszRJ83tnnt57Tv9maWPfgYsBkw3WUH9t261o5bnPm2odX5JJwIjZrLVprbnPqEM0Q0k9JvSKwJH/jlD0uNMWXo6rR7btV4RUnr+ZpLeAwxpPO/tjlsIMxLjJ8yNSu8m0+3qeu7Tqrrnl7QvsBfpBvgI4Pe2x+ZNFbpJrKwI/emJ3AFm04RZf0qt1XIp3qyKY9Vd6fkBJO1Cqki+LGm/+4rAP4B1c+ZqlaQ1gB8D6zD1xXIRE0WSNgOGA2sD8wKDgDdsL5w1WIti/OTVBeOn6Na3FN5NZi5ofVv6udsTuQPMjO0zgDMkvY80aXGfpFuBX9u+fuZfHcKsxWRF6BhJQ0hLabcg3Wm+BTjN9ngA2739QqwNSX8CfgtcZXvStK/b3qz/U7VG0iDgLNtfmsmn1X5ZqqTFgDWY+oLhpnyJ2lNw/mOAzYA/295I0tbA5zNnascI4EjgZNKy972o6eTcDJwKfI5Uc2AT4MvA6lkTtSfGT16lj5/SW98+QdndZIpufVvyuRuApPmBw4AVbX+tmjx9n+3Lof7nzjD5HHSt6vEicC9wqKT9bH8ua7hQvBntFQyhL84m3UkbTjp5WpuatkybgdOALwCPSvqJpLVyB2qV7YnAUpLmncnn1PqEqVpKeBNwNXBU9d9hOTO1o/D879h+CRgoaWB1N6T2rQObDLV9HTDA9hjbwyisR73tfwKDbE+0PYJ61xqYVoyfzAofP43Wt4fZPow0cbEUqfXtV3MGa9F03WSAjWw/ljFTOxqtb3etOoatA7xNan1b+5scFHzuVhlB+n5vXj1/CvhhvjjtkXQSaSXdTsCxtj9g+zjbnwQ2ypsudINYWRE66X22N2h6fr2ke7OlaZPtPwN/lrQI6a7gtVVF7F8D59que1X4J4BbJV0KvNE4aPukbInaczCwKXCH7a2rE46jMmdqR8n5X5W0IGmy5XeSngdK2ms9XtJA0snqAcDTlNV6781qonG0pOOBZ4EFMmdqR4yfvEofP6W3vi29m0yprW+Brjh3W832HpI+D1CN+yJWdlU5XwE2sP1mL5/ywX6OFLpQrKwInXRPtXcWAEkfAm7NmKdtkpYg3cnZF7gHOIW0F7WEHtfPAJeTfq4XanqUYnxjy5Ck+Wz/A3hf5kztKDn/p4C3gG8BI4F/kdpPluIQYH7gIOADwJ7AV7Imas+epDoDB5AmGlcgdXcoRYyfvEofP43Wt0dKOpJ03lBS69uvAv8kjaNvkVqCfpVyusncLOlySV+R9BXgEspofTtZ4eduEyQNper6IWk10kqL2qs6Dn16BhMVRKHN0AnRDSR0jKS/ky7OGhXgVyT1UZ9E6oqwfq5srZB0IWm/3TnAmbafbXrtLtubZAvXBkkLkb7fr+fO0g5JF5H2ih9CWoL9CjDY9k5Zg7Wo9PwhhJCLpE2Y0nr1lqbWt2EOq+6ON7e+vYUprW9rr/RzN0n/BXyftP3mGtK/w16lFKeU9AvS9/3O3FlCd4rJitAxklaa2eu2x/RXlnZVS4CPsH107ix9Jen9pF/Wi1eHXgS+PJPe17Ul6aPAIsBI28VV8i4lv6Rx9N7DfQBpwqvW3QQkXcZMetDb3qUf47RN0v3MPH/dJ3hj/GRU+viZVqmtb0vvJlM6STvZvnKaY/PZLmJ1AkxeGbIZ6b3zDtsvZo7UMkkPAWsCY0gruxrv/0W9/4T6ipoVoZN6PWkq4YTD9iRJOwLFTlYApwOHNmbjJX2MtGfzwzlDtaraQvSg7XG2b6xWiGwE/DVztJaUmN92S9uEJC1m+5U5nacPTswdYDZ9IneA2RHjJ7uix09D6a1vKbybTOmtb0nFKK+c5tjtpG0gtSfpOtvbAlf0cqwEO+YOELpbTFaETrqCNGExgHR3YRXgYco54bhG0q7AhaUsf5zGAs3LBm3fUO05LcVpTH1y8UYvx+qs9Pwzcx01/HvYvrGVz5P0p6rKfa20utpM0u22N5/1Z9ZWjJ85oIvGT+mtb4favk7SgOrfZJikm0kTGCUosvWtpKWB5YChkjZiygTRwqQaNLUmaQgp55JV2/Pm/MtmC9Ym22MkbQBsWR262XYxxfVD/cVkRegY2+s1P5e0MbBfpjh9cSipgvpESW9RyFLmJo9J+gFT2sV+CXg8Y552DWieJKpWu5T0HlV6/pkp5i7hDJS+HHvIrD+l1mL85FX38fOO7ZckTW59K+m43KHaUHo3GWz/U9Kgqg36CEm35c7Ugh1IRTWXB5q7no0DvpcjUJv2I9W4WhYYxZT3ydeAX+QK1S5JBwNfAy6sDp0r6XTbwzPGCl2kW06kQw3ZvlvSprlztKrVJc01tjepVWbjF8ZNlNGjvuExSQeRViMAfINUVb0UpeefmRJXGjWL/HlF/rzqnr/01rfN3WSOIRVYLqmbTJGtb22fBZwlaVfbf8qdp122TwFOkXRg4Rf2+wAfsv0GQDXReDtpa1EIsy0mK0LHSDq06elA0rLfFzLF6ZNq7+xW1dMbbF+eM0+btrN9UPMBSbuTlnaWYH/g58ARpJPr64CvZ03UntLzhxBCDp8CxpPafn6RVJy4mPpRTV0QXifVqyhNc+vbb1FI61tJX7J9LrDyNOefANg+qZcvqx3bw6sC6dMWaD07X6q2DAAmNj2fSPmr6UKNxGRF6KTmlQnvkmpYFDPbLeknwKbA76pDB0vawvb/ZIzVju8y/cREb8dqyfbzpH2zRSo9/yyUfuIR+fOK/HnVOn/jjmzlrGxB2lR6N5mGptonb5FWZ5aisfpjwV5eq/tqoskkHQl8jDRZcSWpYOUtQCmTFSOAv1bt2wE+DfwmY57QZWKyInSM7aMAqi4IPbZfzxypXTsBG9qeBCDpLOAeoNaTFVUXk52A5ST9vOmlhSlgKa2k/2f7eEnD6eUEY9rVInVTen4ASasBT9l+u+oisz5wtu1Xq08ppSo5VaGyFWzf13T4O7nytKIqhPtWVedkTWAt4Crb71Sfsme+dLMW4yevUsdP6a1vKbybTOmtb23/qvpwVeDgxvtN9TP802zB2rcbsAFwj+29JL0XOCNzppbZPknSDcAWpJ/dvWzfkzdV6CYxWRE6plrGdg6wePX8ReArth/IGqw9iwIvVx8vkjNIG54B7gJ2IRVpahhHWtJZd3+v/ntX1hR9V3p+SCugNpG0OumOyKXAeaRJMGy/PJOvza46UdqF9DttNPCCpBttHwpg+5qM8VpxE7BldZJ9HWks7UFaEk8B76ExfvIqcvyU3vq29G4ydEnrW2D9polRbL9SdQcpRWOi8V1JC5Pa9xZT1FfS4sAT1aNxbHDTZGkIsyUmK0InnQ4c2mifWd1hOx34cM5QbfgxcI+k60mzw1uRtlHUWtUi6t5qCd4bVTVvJA0C5ssargW2L6uyvt/24bnztKv0/JVJtt+V9BngZ9Ue2pLujCxi+zVJ+wIjbB8p6b5ZflV9DLD9pqR9gOHVSp2Svv8xfvIqffzMSi1b37ahlheeXdT6dmDzhFZ18VzS9c1dkhYFfk264fQ68Le8kdpyN6nOySukc+dFgWerQrlfsz1qZl8cwqwMzB0gdJUFGhMVALZvoICK0g22f0/q9X5h9djc9h/ypmrLNcDQpudDgT9nytKWaoLlA7lz9FXp+YF3JH2eVMG+UVR2cMY87ZpH0jKAmJK/JAMkbU66E35Fdaykk+0YP3mVPn5mpdY1N1pQTP2EGah769ufArdJOkbS0cBtwPGZM7XM9jdsv2r7l8D2pBXJJRVqHQnsZHtJ20uQam6Y1BHt/7ImC12hm36Zhfwek/QD0lYQgC8Bj2fM0xZJjTs3T1X/XbbaCzzGdu1rPwBDmuuE2H5d0vw5A7XpHkmXkgqCTi64ZvvCGX9JrZScfy9SN5Mf2X5c0irAuZkzteNo4GrgVtt3SloVeDRzpnYcTFrFdZHtB6v818/ia+okxk9epY+fWSn9Yr90tf7+2z5b0l2klrEDgM/afihzrJZJus72tgC2n5j2WAE2sb1/44ntayQda/tQSbVf3Rvqb0BPT63fg0JBqv2yR5GK7EDaR3tUHfea9kbSHaSlpveRfuG9v/p4CWD/uu9blnQrcKDtu6vnHwBOrfnyzckkjejlcI/tvfs9TB90Qf6hwIq2H86dJZQnxk+YUyTdbbvYbSCS7rFdUg2FqZT+/a8rSUOA+UkTix9jygqihUkFctfOFK0tkq4hbdVqrETeg7RC5OPAnTF2wuyKlRWhI6o9+98rofPBTDwB7GP7QQBJ6wCHA8eQtoXUerICOAQ4X9Iz1fNlSL80ilDYssfplJxf0idJle3nBVaRtCFwdCmt96oOCKcB77X9fknrA7vY/mHmaC2p8n8bWJmm38u2t8mVqR0xfvIqffy0oJhtICV2k2lBMd//wuxHOm9bllSrYgBpFcs44NSMudr1BeBI4OLq+S3VsUGkrXUhzJaoWRE6ogv27AOs1ZioAKiWEW5k+7GMmVpm+05Sy7r/Ju0VXLukwkaS1pR0naQHqufrSzoid65WFZ5/GPBB4FUA26OBVXIGatOvScvg3wGoLhQ+lzVRe84ntUk+gjRB2niUYhgxfnIqevxIWq2xXFzSxyQdVBUcbKj1cnhJN0hauCrseC8wQtJJjdcLWJW5gKSB1cdrStpFUnPNmVq2vi2d7VNsrwL8CNiw+ngE8Bhwe9ZwbbD9ou0DgS1tb2T7QNsv2J5g+5+584XyxcqK0Ekl79kHeFjSaUy9lO2R6iSq9i2YqvoUhwIr2f6apDUkvc92KQXjfk06wf4VpAsGSecBRdzdpOz879oeK011E6SkPYLz2/7bNPlLqDPT8K7t03KHmA0xfvIqffwU3fqW8rvJFNn6tovsZvtoSVuQtk/8lLTS60N5Y7VG0oeBM4AFgRUlbQDsZ/sbeZOFbhGTFaGTFgdeIhU5aughbaEowVdJKxIOIS3Hu4W0tPYdYOt8sVo2grSUsFGj4inSxFEpkxWlXzCUnP8BSV8ABklaAziIVFG9FC9KWo3qAlnSbsCzeSPNWnUnFuAySd8ALgLebrxewEVaQ4yfDLpo/JTe+ra5m8z3c4fpg25vfVt3E6v/7gz80vYlkoZlzNOuk4EdSJOM2L5X0lZ5I4VuEpMVoWNK3rMPYPstSf8HXN5LkbjXe/uamlnN9h5VC8HG36ekvaZFXjA0KTn/gaST7LeB35M6IxyTNVF7vgmcDqwl6WlSF6Iv5Y3UklGk8dL4OW1eut8DrNrvifomxk8e3TJ+mlvffrI6VlLr29K7yTS3vt2nOhbXB/3naUm/ArYDjqtW8xa1Td/2k9PcqJk4o88NoV3xZhQ6RtLPezk8FrjL9iX9naddknYBTqDQInHAhKoif+NieTWa7rIVoNQLhoZi89t+k3SxWeJdQaq6MtsptRoeaHtc7kytqPYoI2mI7fHNr1WV4osQ4yePbhk/FN761vb5pFWMjeePAbvmS9S2bm99W3cidc440far1SqdYmrOAE9WW0F6JM1LWln398yZQheJyYrQSUNIBR4bv7R3BR4E9pG0te1DsiVrzZGkInE3QCoSJ2nlnIHadCQwElhB0u+Aj5C2thSh1AuGhhLzS7qMmdQWKGWiTtLBpG1Q44BfS9oY+J+6F7ZrchupbfKsjtVKjJ/aKHL8NNh+SNJ3gBWr548DP8mbqnWld5OxfROpbkXj+WOkC87QD6rJ3gubnj9LOasyIU00ngIsR9p+fA1pS3UIHRGTFaGTVge2sf0uQFWs8hpSwaD7cwZrUW9F4oph+1pJdwObkZYFH2z7xcyxWlZVf/8yVfu9xr9DKe1wC81/Yu4AHbK37VMk7QC8h3SndgQ1bzcsaWnSCd5QSRsxZTn/wsD82YK1LsZPRl0wfoDyW99SdnHluaH1bZiz3mf7i80HJH0EuDVTntBlYrIidNJywAKkrR9UHy9re6KkErYjFF0krvrlMNr2FZK+BHxP0im2x+TO1qIrgTtIE1uTMmfpi+Ly274xd4YOaVyk7USqxn9vIfVadiCtfloeOKnp+DjgezkCtSPGT3ZFj58mw5h+VWNJrW9LLq4MaTXsL0kdHaLWQGjXcKZfxdXbsRD6JCYrQicdD4yWdAPp5G8r4NhqWfyfcwZrUXORuPMor0jcacAGVduow4HfAmcDH82aqnVDbB+aO8RsKDZ/NTn3Y2Ad0nYuAGyXUqBvlKRrgFWA70paiAImjGyfBZwlaVfbf8qdp69i/OTRLeOH8lvfllxcGcpvfRsyqIqyfhhYSlLzuc/CwKA8qUI3ismK0DG2fyPpStIdkgHA92w/U718uKR1bT+YL+Es7Wx7qiJxknanqXBWzb1ru0fSp4CfV/8eX8kdqg3nSPoaqdVqie33Ss4/glTz5GRSm969mHK3uQT7ABsCj1Ut+JYg/R1KcXm1qmtlpl6GfXS2RO2J8ZNX6eOn6FWNFFpcuYta34Y85gUWJL3nLNR0/DVgtyyJQleKyYrQUVVhoBl1/jiHei8L+y7TT0z0dqyuxkn6LrAnsKWkQZTV/m0CqRvL95lyV62k9nsl5x9q+zpJA6ptQ8Mk3Uy6AK0925MkPQ6sWVgXhIZLSNvnRlFWB5+GGD95lT5+im59W2Jx5Uq3tL4NGVTbAG+UdGZB241DgWKyIvSnWt5pk7Qjaa/yctO0X12Ysvad7gF8gVQs7jlJK5IunktxKLB6SUVBp1Fy/vGSBgKPSjoAeJpUaLAIkvYltd9bHhhNKjJ7O1BKgbjlbX88d4jZEOMnr6LHT+mtb0vtJtNFrW9DXm9KOgFYl6m3AZby/hlqbmDuAGGuUtc9qM8AdwHjSXcaGo9LSQXMimD7OVKtjcWq6uoTbJ+dOVY7HgTezB1iNpSc/xBS94CDgA+QVueUtIXoYGBTYIztrYGNgBfyRmrLbZLWyx1iNsT4yavI8SPpMkmXzuiRO18b9rb9GvBfTOkmU0zrVXrfclPSNpyQ1++Af5Bq/hwFPAHcmTNQ6C6xsiLM9WzfC9wr6Tzb7+TO01fV3cH/Bf5CWsUyXNLRtn+bN1nLJpIKtF7P1Ptm69z6s1mx+W03Tixel7QPsGB18l2K8bbHS0LSfLb/Iel9uUO1YQvgq9VWhLdJP789ttfPG6s1MX6yK3X8dEvr2yK7yXRL69uQ3RJVjbSDm7aGdEunqFADMVkR+tOE3AFmYWVJJVe0PxzYyPZLAFWRuNtIXUFKcHH1KFWx+SWdB+xPmnAZBSwi6STbpWwjekrSoqTv/7WSXiGtmCrFjrkDzI4YP9kVOX66qPVtkd1k6J7WtyGvxk2+ZyXtTHrvXD5jntBlYrIidIyk62xvO6NjtjfLk6xlpVe0f4p0ktEwDngyU5a2VW34ilV4/nVsvybpi8CVwHdIF51FXGza/kz14bBqZcsiwMiMkdpie0zVcnjL6tDN1YqvUsT4yaj08dMFrW+L7CbTRa1vQ14/lLQIcBgwnLQy55C8kUI3icmKMNuqQkzzA0tKWoyplxIumy1Y+4qsaN/U3/pp4K+SLiHVB/kU8LdswdpULWGerq5JKSeshecfLGkw8GngVNvvSKprjZleVd1v3ktqGwiwNPDvfIlaVxXo+xpwYXXoXEmn2x6eMVY7Yvxk1AXjp+gbBV3QTab01rchr92BW2w/AGxdtcQ9Ebgsb6zQLWKyInTCfqRZ1GVJd9MaJxmvAb/IFaoPSq1o3+hv/a/q0TCjFrJ1tUnTx0NIvwAXn8Hn1lHJ+X9FKop1L3CTpJVIP79FkHQg6WLnP0xZft0D1H3PfsM+wIdsvwEg6ThSN4pSLjZj/ORV+vgp8kZBQxd0kym99W3Ia33brzae2H65qoESQkfEZEWYbbZPAU6RdGBBd3J601zR/hjSHZ7aV7S3fVTuDJ3QqLXR5GeSbiEVDa29kvPb/jkwuW2vpH+Txn/j+Vdqvs3lYOB9vfwblGIAqd5Dw0TKurMc4yevoscP5d4oaGh0k7nD9taS1iJ1RShF0a1vQ3YDJS1m+xWAamVFXF+GjonBFDrG9nBJH2b6pYRFtM9srmhPAftNp1Xtte5tG0IRd3eq3vQNA0krFRaawafXTun5m9nuAd5tOnQwUOeLzSdJdwZLNYK0heui6vmngd9kzDNbYvz0u9LHz7Q3CrahgBsFTUrvJnObpPVs3587SCjST0lj6ALSOaiAH+WNFLpJTFaEjpF0DrAaaRlk4y5PD1DEZIWka4HdG8vZqvobf7C9Q95kLft208dDgF2Z+oKh7n7KlMmWd0nLynfPlqZ9peefmVrepW2q1/IYcIOkK5i6bexJvX5hzdg+SdINpBaUA4C9bN+TN1VHxfiZg0ofP13Q+rb0bjKltr4NNWD7bEl3kSYZBwCftf1Q5lihi8RkReikTUhV4YsqrNZkyWn23b0iqZilqLZHTXPo1sJ6Xe9ImmBZmSnvTZ8DSinyVXr+manrz3Rj5cq/q8e81aNEj5MmueYBBkja2PbdmTN1SoyfOa/Y8VN669vSu8lQaOvbUB/V5ERMUIQ5IiYrQic9QKqg/mzuIH00SdKKtv8NUBWJq+tJ9nSqfYINjW0IS2eK0xcXA68CdwPjM2fpi9Lzz0wt74x3S70WSccAXyUVyG285/RQToG+WYnxMwd1wfgpuvUtlN1NpvTWtyGE7haTFaGTlgQekvQ3pl5Ku0u+SG35PnBL02qErYCvZ8zTrlGkE9QBwDukbQj75AzUptKLfJWef2ZuzR1gZrpgC5eA1WxPyB1kDonxM2eVPn6Kbn1bejeZLmh9G0LoYjFZETppWO4As8P2yKpI4makC/5v2X6x8bqkdW0/mC3grH0HGFndofoBsDHwZuZM7Si9yFex+Zv27jcbC4yyPdr2Af2dqU1LlbyFi7QqbVHg+dxB+iLGT3ZFjx8Kb31L+d1kSm99G0LoYjFZETrGdkn1EXpVTU5cPoOXzyFNANTVEbYtaQtge1LBx9OAD+WN1bLSi3yVnH+T6nFZ9Xxn4E5gf0nn2z4+W7LWTCx5CxfwY+AeSQ9Q5qq0GD95FT1+uqD1bendZEpvfRtC6GIxWRE6RtJmpJn4tUlFygYBb9heOGuwzqn7L+/GycbOwC9tXyJpWMY87Sq9yFfJ+ZcANrb9OoCkI4ELSFuhRgF1v9gsfQvXWcBxwP1MWUZekhg/eZU+fqZSSuvbbukmQ/mtb0MIXSwmK0InnUrqfnA+6S7bl4E1sibqrLrfaXta0q+A7YDjJM1HKrRZBNtjcmeYHYXnXxFo3u/+DrCS7bckvT2Dr6kFSQOAB0mrnnrdwlWAF6u7y6WK8ZNX6eNnVup6o6ArusmU3vo2hNDdYrIidJTtf0oaZHsiMELSbbkzzUUEfBw40farkpYBDs+cKZThPOAOSZdUzz8J/F7SAtS8HZntHkkX2/4AM97CVXejJP0YuJSp78wW0XqSGD+5lT5+ZqWWNwq6pZtMpdjWtyGE7haTFaGT3pQ0LzBa0vGkFqYLZM7USbWutG77TaZU88b2s5TbRjb0I9vHSLqSKXfW9rd9V/XyF/Mla9kdkja1fWfuIH20UfXfzZqOFdN6MsZPdkWPnxbUdWUFUH43mS5ofRtC6GIxWRE6aU/StoMDgG8BKwC7Zk3UBknX2d52Rsdsb9b7V4ZQNkmnAH+0fUruLH20NbCfpDHAG5RV3BTbW8/s9boXGIzxk1fp46cFtW59S/ndZEpvfRtC6GIxWRE6pmnP/nigmOWRkoYA8wNLVndEGndxFgaWzRYshP5zN3CEpDWBi0gXnnfN4mvqpOTiuEeJbQAADM5JREFUpq2oZYHBJjF+6q3W46cLWt+W3k2m9Na3IYQuFpMVoWMkfQQYBqxE09iyvWquTC3aDziENDExiimTFa8Bv8gVKoT+Ut11PUvS4qTVUMdVJ9+lFMgt6cKgL2q9DD7GT+3VevxQfuvb0rvJFN36NoTQ3WKyInTSb0jbP0Yxdc/uWquWLp8i6UDbw3PnCSGj1YG1gJWpeWHEaVxBuuAcAAwBVgEeBtbNGaqDSrmYjvFTT3UfP8W2vu2SbjJd1fo2hNBdYrIidNJY21flDtFXtodL+jDpRLt5ZcjZ2UKF0A8kHQd8llRg7Y/AMc17sOvO9nrNzyVtTFox1S1qfWc8xk/t1Xr8UHDr2y7pJtPtrW9DCAWLyYow26oTO4DrJZ1A6khRXPs0SecAqwGjmbIypAeIyYrQ7R4HPgysCswHrC8J2zfljdU3tu+WtGnuHB1U9wKDMX7qre7jp9jWt5XSu8l0e+vbEELBYrIidMJPp3m+SdPHJbW/2gRYx3bdl8yG0GkTgb8Ay5Mm6zYDbqeQn91pCvQNJC3JfiFTnLZJei9wLLCs7R0lrQNsbvs3ACUUGCTGTzalj58uaH1bdDcZur/1bQihYDFZEWbbrNqmFeQBYGng2dxBQuhnBwGbAnfY3lrSWhTU0QdYqOnjd0k1CP6UKUtfnAmMIBXqA3iEtJ3iN7kCtSnGT15nUvD46YLWt0V3k5kLWt+GEAo2MHeA0D0kHStp0abni0n6Yc5MbVoSeEjS1ZIubTxyhwqhH4y3PR5A0ny2/wG8L3Omltk+yvZRwMnAz23/rvH3KcSStk1V3M72uxRUpJgYP7mVPn4arW//KekESZvM8ivqpWcGj25xcO4AIYS5V6ysCJ20o+3vNZ7YfkXSTsARGTO1Y1juACFk8lQ10XgxcK2kV4BnMmdqWXVxM4LqDrmkscDetkdlDda6NyQtQXWBI2kzYGzeSG2J8ZNX0eOnC1rfdns3mboXaA0hdLGYrAidNKi6q/Y2gKShpGJrRbB946w/K4TuY/sz1YfDJF0PLAKMzBipXb8FvmH7ZgBJW5AuPkvZM34YqbjdapJuBZYCdssbqXUxfrIrevw0KbL17VzQTaabVomEEAoTkxWhk84FrpM0gvTLbW9S/+4iVHejhgNrA/MCg4A3bC+cNVgI/ajQSbtxjQtNANu3SBqXM1A7bI+S9FHS1okBwMO238kcq09i/PS/0sdP6a1vp9WF3WRiZUUIIZuYrAgdY/t4SfcB25F+uR1j++rMsdpxKvA54HxSZ5AvA6UsQw1hbvY3Sb8Cfk+aKN0DuKHRVrnuLfgk3Uu6SPuj7X/lzjMXivGTV9Gtb0vvJtOCure+DSF0sZisCB0haRBwte3tKGv571Rs/1PSINsTgRGSbsudKYQwSxtW/z1ymuMfpowWfLuQLpAtaRLpwtO2/5031lwjxk9eRbe+pfBuMqW3vg0hdLcBPT2xFS10RtU5Y0/bxRT2aibpJtKqkDOA50gtTL9qe4OswUIIs6Wk1nuS1gB+AHzR9qDceUKMnzlN0v1MaX27YaP1re09Mkdri6SFgR7bxWwhApB0FVXrW9sbSJoHuGfaWhwhhJBDrKwInTQeuF/StcAbjYO2D8oXqS17kpZwHgB8C1iBVJk8hFC2g6l5/RxJKwMi3SGfCPy/rIFCsxg/c9Z42+MlTW59K6mY1rdd0E1mSduW9F1IrW8lldT6NoTQxWKyInTSFdWjSLbHVB+OB47KmSWE0FG1LhAn6a/AYFK9nN1tP5Y5UphajJ85q+jWt5TfTabo1rchhO4WkxWhY2yfVbUrXdH2w7nztEvSR4BhwEo0/WzYXjVXphBCR9R9v+NXbP8jd4gwQzF+5qAuaH1bdDcZuqf1bQihC8VkRegYSZ8ETiS1/VxF0obA0bZ3yZusZb8hbf8YRVpGG0LoDrW8My7pS7bPBXaStNO0r9s+KUOsML0YP/2k0Na3RXeTKb31bQihu8VkReikYcAHgRsAbI+WtErOQG0aa/uq3CFCCB1X19Z7C1T/XaiX1+p+N39uEuMnzEzR3WS6oPVtCKGLxWRF6KR3bY+V1Hys9idMjbsfwPWSTgAuBN5uvF73uyIhzO0kHdrL4bHAKNuj69p6z/avqg//bHuqC+JqW1roBzF+wuywvfXMXi+gm0zprW9DCF0sJitCJz0g6QvAoKp92kHAbZkzteKn0zzfpOnj2t8VCSGwSfW4rHq+M3AnsL+k820fny1Za4YDG7dwLMwZMX7CnFTrbjJVcfHjgeObWt8eBxTR+jaE0N1isiJ00oHA90mrEs4DrgaOyZqoBbO6KxJCqL0lgI1tvw4g6UjgAmArUg2aWl5sStqctFR8qWnu7i9MXCj0pxg/YU6qZc2TZoW3vg0hdLGBuQOErrJO9ZgHGAJ8inR3qgiSjq3apzWeLybphzkzhRBasiIwoen5O8BKtt+iaUtXDc0LLEh6z1yo6fEaUY2/P8X4CXNSrbfDVq1vLyRNcO1u+4O2p11xGkIIWcTKitBJvwO+DTwATMqcpS92tP29xhPbr1QV1o/ImCmEMGvnAXdIuqR6/kng95IWAB7KF2vmqs4HN0o6s1qKHfKI8RPmpLqvrCi69W0IobvFZEXopBdsXzbrT6utQZLms/02gKShwHyZM4UQZsH2MZKuBLYgXRjsb/uu6uUv5kvWsjMk7W77VUiruoA/2N4hc665QoyfMIfVsptMN7a+DSF0n5isCJ10pKQzgOuYupvGhfkiteVc4DpJI0jLNvemxkWxQgiJpFNIbfdOyZ2lj5ZsXGjC5FVd78kZaG4S4yfMjlK7yRCtb0MIBYjJitBJewFrAYOZsg2kh7QXsvZsHy/pPmA70t21Y2xfnTlWCGHW7gaOkLQmcBHpwvOuWXxNnUyStGKjVWBV7C4uFvpPjJ8wO4rsJhOtb0MIJYjJitBJG9heL3eIvpA0CLja9nbAyNx5Qgits30WcJakxYFdgeOqi7c1Mkdr1feBWyTdWD3fCvh6xjxzlRg/YTYV2U2mSbS+DSHUVnQDCZ10h6R1cofoC9sTgTclLZI7Swihz1Ynre5aGSimYJztkaQ7sw8DfwQOA97KGmruFOMn9EWR3WQkbS7pMKrWt02PYUTr2xBCTcTKitBJWwBfkfQ46Rf0AKDH9vp5Y7VsPHC/pGuBNxoHbR+UL1IIYVYkHQd8FvgX6WLtmOY9/HUnaV/gYGB5YDSwGXA7sE3OXHOLGD9hNhXZTYbpW982ROvbEEJtxGRF6KSP5w4wm66oHiGEsjwOfBhYldTBZ31J2L4pb6yWHQxsCtxhe2tJawFHZc40N4nxE/qs1G4y0fo2hFCCmKwIHVP6LzvbZ1XtSle0/XDuPCGElk0E/kK5d5bH2x4viap98j8kvS93qLlIjJ/QZ13QTSZa34YQaitqVoRQkfRJ0onqyOr5hpIuzZsqhNCCg0h3lsfY3hrYCHghb6S2PCVpUeBi4NpqOfkzmTPNTWL8hNnR6CbzT0knSNokd6A2Tdf6FojWtyGEWojJihCmGAZ8EHgVwPZoYJWcgUIILRlvezww+c4yUMydZdufsf2q7WHAD4DfAJ/Om2quEuMn9Jnts2zvRDp/eITUTebRzLHaMUnSio0n0fo2hFAnsQ0khCnetT1WUvOx+IUdQv1Ne2f5FQq9s1ztIw/9K8ZP6ITmbjJ1Lqw5rWh9G0KorQE9PXEtFgKApN8A1wH/A+xKWho82Pb+WYOFEFom6aPAIsBI2xNm9fkhNIvxE9rVSzeZi0rqJgMg6T2kCYrRwBDg+YIKzIYQulisrAhhigNJdxjeJrUiuxo4JmuiEEJb4s5ymB0xfkIfFN1NJlrfhhDqLGpWhDDFOtVjHtKdhU8Bd2ZNFEIIIYQ6a3STGUlqGXs1qQZWKRqtb0stMBtC6GIxWRHCFL8DfktazvmJ6vHJrIlCCCGEUGeld5MpusBsCKG7xTaQEKZ4wfZluUOEEEIIoRjjbY+XNPliX1JJF/tdU2A2hNB9osBmCBVJ2wKfJxXZfLtx3PaF2UKFEEIIobYkXQTsBRxCqvPwCqk4905Zg/VBFJgNIdRNrKwIYYq9SG3HBgOTqmM9QExWhBBCCGE6tj9TfThM0vVUF/sZI/VZFJgNIdRNrKwIoSLpftvr5c4RQgghhBBCCHO7KLAZwhR3SFond4gQQgghhBBCmNvFyooQKpL+DqxG6pn+NjAA6LG9ftZgIYQQQgghhDCXiZoVIUzx8dwBQgghhBBCCCHEyooQQgghhBBCCCHUTNSsCCGEEEIIIYQQQq3EZEUIIYQQQgghhBBqJSYrQgghhBBCCCGEUCsxWRFCCCGEEEIIIYRaicmKEEIIIYQQQggh1Mr/BxXNoF+k0jv4AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1440x1080 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train= pd.read_csv(\"train.csv\")## merchants's data set\n",
    "\n",
    "\n",
    "values = { 'avg_sales_lag3': merchants[\"avg_sales_lag3\"].mean(), 'avg_purchases_lag3': merchants[\"avg_purchases_lag3\"].mean(),'avg_sales_lag6': merchants[\"avg_sales_lag6\"].mean(),'avg_purchases_lag6': merchants[\"avg_purchases_lag6\"].mean(),'avg_sales_lag12': merchants[\"avg_sales_lag12\"].mean(),'category_2': merchants[\"category_2\"].mean(),'avg_purchases_lag12': merchants[\"avg_purchases_lag12\"].mean()}\n",
    "merchants.fillna(value=values, inplace=True)\n",
    "f, ax = plt.subplots(figsize=(20, 15))#Plots correlation matrix\n",
    "plt.title('Correlation Matrix',fontsize=25)\n",
    "sns.heatmap(merchants[list(merchants)].corr(), linewidths=0.25, vmax=1.0, square=True, cmap=\"RdBu_r\", linecolor='k', annot=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ther is colinearity between many predictors like active_months_lag12 and active_months_lag6 etc. those with significance covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "h2o.init(strict_version_check=False) # start h2o\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume the following are passed by the user from the web interface\n",
    "\n",
    "'''\n",
    "Need a user id and project id?\n",
    "\n",
    "'''\n",
    "target='category_4' #For Classification and Logistic Regression\n",
    "output='avg_purchases_lag6' #For Linear Regression \n",
    "\n",
    "data_file='merchants.csv'#Dataset\n",
    "run_time=500\n",
    "run_id='SOME_ID_20180617_221529' # Just some arbitrary ID\n",
    "server_path='/Users/Suprita Ganesh/Desktop/ML3'\n",
    "classification=True\n",
    "scale=False\n",
    "max_models=None\n",
    "balance_y=False # balance_classes=balance_y\n",
    "balance_threshold=0.2\n",
    "project =\"automl_test\"  # project_name = project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/Suprita Ganesh/Desktop/ML3\\\\merchants.csv'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "data_path=os.path.join(server_path,data_file)\n",
    "data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load data into H2O\n",
    "df = h2o.import_file(data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows:334696\n",
      "Cols:22\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>       </th><th>merchant_id    </th><th>merchant_group_id  </th><th>merchant_category_id  </th><th>subsector_id     </th><th>numerical_1         </th><th>numerical_2         </th><th>category_1  </th><th>most_recent_sales_range  </th><th>most_recent_purchases_range  </th><th>avg_sales_lag3    </th><th>avg_purchases_lag3  </th><th>active_months_lag3  </th><th>avg_sales_lag6    </th><th>avg_purchases_lag6  </th><th>active_months_lag6  </th><th>avg_sales_lag12   </th><th>avg_purchases_lag12  </th><th>active_months_lag12  </th><th>category_4  </th><th>city_id           </th><th>state_id         </th><th>category_2        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>type   </td><td>string         </td><td>int                </td><td>int                   </td><td>int              </td><td>real                </td><td>real                </td><td>enum        </td><td>enum                     </td><td>enum                         </td><td>real              </td><td>real                </td><td>int                 </td><td>real              </td><td>real                </td><td>int                 </td><td>real              </td><td>real                 </td><td>int                  </td><td>enum        </td><td>int               </td><td>int              </td><td>int               </td></tr>\n",
       "<tr><td>mins   </td><td>NaN            </td><td>1.0                </td><td>-1.0                  </td><td>-1.0             </td><td>-0.05747065         </td><td>-0.05747065         </td><td>            </td><td>                         </td><td>                             </td><td>-82.13            </td><td>0.33349533          </td><td>1.0                 </td><td>-82.13            </td><td>0.16704466          </td><td>1.0                 </td><td>-82.13            </td><td>0.09832954           </td><td>1.0                  </td><td>            </td><td>-1.0              </td><td>-1.0             </td><td>1.0               </td></tr>\n",
       "<tr><td>mean   </td><td>NaN            </td><td>31028.736142648864 </td><td>423.1316627626265     </td><td>25.11640413987618</td><td>0.011476379786761658</td><td>0.008103109673703913</td><td>            </td><td>                         </td><td>                             </td><td>13.832992503353953</td><td>1.5907620965243703  </td><td>2.9941080861438434  </td><td>21.65078713289889 </td><td>1.8875678157761608  </td><td>5.947397040896815   </td><td>25.227708876757905</td><td>2.0791954108497923   </td><td>11.599334918851728   </td><td>            </td><td>102.91792552047231</td><td>11.86094246719412</td><td>2.3800017967280946</td></tr>\n",
       "<tr><td>maxs   </td><td>NaN            </td><td>112586.0           </td><td>891.0                 </td><td>41.0             </td><td>183.73511137        </td><td>182.07932234        </td><td>            </td><td>                         </td><td>                             </td><td>851844.64         </td><td>61851.33333333      </td><td>3.0                 </td><td>1513959.0         </td><td>56077.5             </td><td>6.0                 </td><td>2567408.0         </td><td>50215.55555556       </td><td>12.0                 </td><td>            </td><td>347.0             </td><td>24.0             </td><td>5.0               </td></tr>\n",
       "<tr><td>sigma  </td><td>NaN            </td><td>31623.04342585761  </td><td>252.89804640741087    </td><td>9.807371150499078</td><td>1.0981535340747228  </td><td>1.070497129139856   </td><td>            </td><td>                         </td><td>                             </td><td>2395.4899987266786</td><td>107.18705938009496  </td><td>0.0952474880224711  </td><td>3947.1080986745974</td><td>97.86279027368853   </td><td>0.3949360216945969  </td><td>5251.842164947328 </td><td>88.44238392934712    </td><td>1.5201376720923252   </td><td>            </td><td>107.0906729099498 </td><td>6.176888783729171</td><td>1.562661049268994 </td></tr>\n",
       "<tr><td>zeros  </td><td>0              </td><td>0                  </td><td>0                     </td><td>0                </td><td>0                   </td><td>0                   </td><td>            </td><td>                         </td><td>                             </td><td>0                 </td><td>0                   </td><td>0                   </td><td>0                 </td><td>0                   </td><td>0                   </td><td>0                 </td><td>0                    </td><td>0                    </td><td>            </td><td>0                 </td><td>0                </td><td>0                 </td></tr>\n",
       "<tr><td>missing</td><td>0              </td><td>0                  </td><td>0                     </td><td>0                </td><td>0                   </td><td>0                   </td><td>0           </td><td>0                        </td><td>0                            </td><td>13                </td><td>3                   </td><td>0                   </td><td>13                </td><td>3                   </td><td>0                   </td><td>13                </td><td>3                    </td><td>0                    </td><td>0           </td><td>0                 </td><td>0                </td><td>11887             </td></tr>\n",
       "<tr><td>0      </td><td>M_ID_838061e48c</td><td>8353.0             </td><td>792.0                 </td><td>9.0              </td><td>-0.05747065         </td><td>-0.05747065         </td><td>N           </td><td>E                        </td><td>E                            </td><td>-0.4              </td><td>9.66666667          </td><td>3.0                 </td><td>-2.25             </td><td>18.66666667         </td><td>6.0                 </td><td>-2.32             </td><td>13.91666667          </td><td>12.0                 </td><td>N           </td><td>242.0             </td><td>9.0              </td><td>1.0               </td></tr>\n",
       "<tr><td>1      </td><td>M_ID_9339d880ad</td><td>3184.0             </td><td>840.0                 </td><td>20.0             </td><td>-0.05747065         </td><td>-0.05747065         </td><td>N           </td><td>E                        </td><td>E                            </td><td>-0.72             </td><td>1.75                </td><td>3.0                 </td><td>-0.74             </td><td>1.29166667          </td><td>6.0                 </td><td>-0.57             </td><td>1.6875               </td><td>12.0                 </td><td>N           </td><td>22.0              </td><td>16.0             </td><td>1.0               </td></tr>\n",
       "<tr><td>2      </td><td>M_ID_e726bbae1e</td><td>447.0              </td><td>690.0                 </td><td>1.0              </td><td>-0.05747065         </td><td>-0.05747065         </td><td>N           </td><td>E                        </td><td>E                            </td><td>-82.13            </td><td>260.0               </td><td>2.0                 </td><td>-82.13            </td><td>260.0               </td><td>2.0                 </td><td>-82.13            </td><td>260.0                </td><td>2.0                  </td><td>N           </td><td>-1.0              </td><td>5.0              </td><td>5.0               </td></tr>\n",
       "<tr><td>3      </td><td>M_ID_a70e9c5f81</td><td>5026.0             </td><td>792.0                 </td><td>9.0              </td><td>-0.05747065         </td><td>-0.05747065         </td><td>Y           </td><td>E                        </td><td>E                            </td><td>nan               </td><td>1.66666667          </td><td>3.0                 </td><td>nan               </td><td>4.66666667          </td><td>6.0                 </td><td>nan               </td><td>3.83333333           </td><td>12.0                 </td><td>Y           </td><td>-1.0              </td><td>-1.0             </td><td>nan               </td></tr>\n",
       "<tr><td>4      </td><td>M_ID_64456c37ce</td><td>2228.0             </td><td>222.0                 </td><td>21.0             </td><td>-0.05747065         </td><td>-0.05747065         </td><td>Y           </td><td>E                        </td><td>E                            </td><td>nan               </td><td>0.5                 </td><td>3.0                 </td><td>nan               </td><td>0.36111111          </td><td>6.0                 </td><td>nan               </td><td>0.34722222           </td><td>12.0                 </td><td>Y           </td><td>-1.0              </td><td>-1.0             </td><td>nan               </td></tr>\n",
       "<tr><td>5      </td><td>M_ID_a0915f62b5</td><td>20201.0            </td><td>87.0                  </td><td>27.0             </td><td>-0.05747065         </td><td>-0.05747065         </td><td>N           </td><td>E                        </td><td>E                            </td><td>nan               </td><td>1.0                 </td><td>3.0                 </td><td>nan               </td><td>3.66666667          </td><td>6.0                 </td><td>nan               </td><td>3.83333333           </td><td>12.0                 </td><td>Y           </td><td>160.0             </td><td>21.0             </td><td>5.0               </td></tr>\n",
       "<tr><td>6      </td><td>M_ID_bfd41933db</td><td>33861.0            </td><td>792.0                 </td><td>9.0              </td><td>-0.05747065         </td><td>-0.05747065         </td><td>N           </td><td>E                        </td><td>E                            </td><td>nan               </td><td>2.83333333          </td><td>3.0                 </td><td>nan               </td><td>4.83333333          </td><td>6.0                 </td><td>nan               </td><td>6.33333333           </td><td>12.0                 </td><td>N           </td><td>60.0              </td><td>16.0             </td><td>1.0               </td></tr>\n",
       "<tr><td>7      </td><td>M_ID_d8ff08219e</td><td>16430.0            </td><td>529.0                 </td><td>20.0             </td><td>-0.05747065         </td><td>-0.05747065         </td><td>Y           </td><td>E                        </td><td>E                            </td><td>nan               </td><td>1.0                 </td><td>3.0                 </td><td>nan               </td><td>1.66666667          </td><td>6.0                 </td><td>nan               </td><td>1.5                  </td><td>11.0                 </td><td>Y           </td><td>-1.0              </td><td>-1.0             </td><td>nan               </td></tr>\n",
       "<tr><td>8      </td><td>M_ID_c5b389236d</td><td>37179.0            </td><td>813.0                 </td><td>29.0             </td><td>-0.05747065         </td><td>-0.05747065         </td><td>N           </td><td>E                        </td><td>E                            </td><td>nan               </td><td>115.0               </td><td>3.0                 </td><td>nan               </td><td>189.91666667        </td><td>6.0                 </td><td>nan               </td><td>197.0                </td><td>7.0                  </td><td>N           </td><td>248.0             </td><td>15.0             </td><td>1.0               </td></tr>\n",
       "<tr><td>9      </td><td>M_ID_d2162ed113</td><td>112122.0           </td><td>81.0                  </td><td>29.0             </td><td>-0.05747065         </td><td>-0.05747065         </td><td>Y           </td><td>E                        </td><td>E                            </td><td>nan               </td><td>1.0                 </td><td>2.0                 </td><td>nan               </td><td>1.0                 </td><td>2.0                 </td><td>nan               </td><td>1.0                  </td><td>2.0                  </td><td>Y           </td><td>-1.0              </td><td>-1.0             </td><td>nan               </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification algorithms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category_4\n",
      "['merchant_id', 'merchant_group_id', 'merchant_category_id', 'subsector_id', 'numerical_1', 'numerical_2', 'category_1', 'most_recent_sales_range', 'most_recent_purchases_range', 'avg_sales_lag3', 'avg_purchases_lag3', 'active_months_lag3', 'avg_sales_lag6', 'avg_purchases_lag6', 'active_months_lag6', 'avg_sales_lag12', 'avg_purchases_lag12', 'active_months_lag12', 'city_id', 'state_id', 'category_2']\n"
     ]
    }
   ],
   "source": [
    "# assign target and inputs\n",
    "y = target\n",
    "X = [name for name in df.columns if name != y]\n",
    "print(y)\n",
    "print(X)\n",
    "# Get Column values of dataset for training X: Predictors , y: response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['merchant_group_id', 'merchant_category_id', 'subsector_id', 'active_months_lag3', 'active_months_lag6', 'active_months_lag12', 'city_id', 'state_id', 'category_2']\n",
      "['category_1', 'most_recent_sales_range', 'most_recent_purchases_range']\n",
      "['merchant_id', 'numerical_1', 'numerical_2', 'avg_sales_lag3', 'avg_purchases_lag3', 'avg_sales_lag6', 'avg_purchases_lag6', 'avg_sales_lag12', 'avg_purchases_lag12']\n"
     ]
    }
   ],
   "source": [
    "# determine column types\n",
    "ints, reals, enums = [], [], []\n",
    "for key, val in df.types.items():\n",
    "    if key in X:\n",
    "        if val == 'enum':\n",
    "            enums.append(key)\n",
    "        elif val == 'int':\n",
    "            ints.append(key)            \n",
    "        else: \n",
    "            reals.append(key)\n",
    "\n",
    "print(ints)\n",
    "print(enums)\n",
    "print(reals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute missing values\n",
    "_=df[reals].impute(method='mean')\n",
    "_=df[ints].impute(method='median')\n",
    "\n",
    "if scale:\n",
    "    df[reals] = df[reals].scale()\n",
    "    df[ints] = df[ints].scale()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows:334696\n",
      "Cols:22\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>       </th><th>merchant_id    </th><th>merchant_group_id  </th><th>merchant_category_id  </th><th>subsector_id     </th><th>numerical_1         </th><th>numerical_2         </th><th>category_1  </th><th>most_recent_sales_range  </th><th>most_recent_purchases_range  </th><th>avg_sales_lag3    </th><th>avg_purchases_lag3  </th><th>active_months_lag3  </th><th>avg_sales_lag6    </th><th>avg_purchases_lag6  </th><th>active_months_lag6  </th><th>avg_sales_lag12   </th><th>avg_purchases_lag12  </th><th>active_months_lag12  </th><th>category_4  </th><th>city_id           </th><th>state_id         </th><th>category_2        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>type   </td><td>string         </td><td>int                </td><td>int                   </td><td>int              </td><td>real                </td><td>real                </td><td>enum        </td><td>enum                     </td><td>enum                         </td><td>real              </td><td>real                </td><td>int                 </td><td>real              </td><td>real                </td><td>int                 </td><td>real              </td><td>real                 </td><td>int                  </td><td>enum        </td><td>int               </td><td>int              </td><td>real              </td></tr>\n",
       "<tr><td>mins   </td><td>NaN            </td><td>1.0                </td><td>-1.0                  </td><td>-1.0             </td><td>-0.05747065         </td><td>-0.05747065         </td><td>            </td><td>                         </td><td>                             </td><td>-82.13            </td><td>0.33349533          </td><td>1.0                 </td><td>-82.13            </td><td>0.16704466          </td><td>1.0                 </td><td>-82.13            </td><td>0.09832954           </td><td>1.0                  </td><td>            </td><td>-1.0              </td><td>-1.0             </td><td>1.0               </td></tr>\n",
       "<tr><td>mean   </td><td>NaN            </td><td>31028.736142648864 </td><td>423.1316627626265     </td><td>25.11640413987618</td><td>0.011476379786761658</td><td>0.008103109673703913</td><td>            </td><td>                         </td><td>                             </td><td>13.832992503353958</td><td>1.5907620965243676  </td><td>2.9941080861438434  </td><td>21.650787132898987</td><td>1.8875678157761566  </td><td>5.947397040896815   </td><td>25.227708876757813</td><td>2.079195410849794    </td><td>11.599334918851728   </td><td>            </td><td>102.91792552047231</td><td>11.86094246719412</td><td>2.380001796728098 </td></tr>\n",
       "<tr><td>maxs   </td><td>NaN            </td><td>112586.0           </td><td>891.0                 </td><td>41.0             </td><td>183.73511137        </td><td>182.07932234        </td><td>            </td><td>                         </td><td>                             </td><td>851844.64         </td><td>61851.33333333      </td><td>3.0                 </td><td>1513959.0         </td><td>56077.5             </td><td>6.0                 </td><td>2567408.0         </td><td>50215.55555556       </td><td>12.0                 </td><td>            </td><td>347.0             </td><td>24.0             </td><td>5.0               </td></tr>\n",
       "<tr><td>sigma  </td><td>NaN            </td><td>31623.04342585761  </td><td>252.89804640741087    </td><td>9.807371150499078</td><td>1.0981535340747228  </td><td>1.070497129139856   </td><td>            </td><td>                         </td><td>                             </td><td>2395.4434762623737</td><td>107.18657899960115  </td><td>0.0952474880224711  </td><td>3947.031442459927 </td><td>97.86235168179363   </td><td>0.3949360216945969  </td><td>5251.74016968131  </td><td>88.44198755690937    </td><td>1.5201376720923252   </td><td>            </td><td>107.0906729099498 </td><td>6.176888783729171</td><td>1.5346605151185726</td></tr>\n",
       "<tr><td>zeros  </td><td>0              </td><td>0                  </td><td>0                     </td><td>0                </td><td>0                   </td><td>0                   </td><td>            </td><td>                         </td><td>                             </td><td>0                 </td><td>0                   </td><td>0                   </td><td>0                 </td><td>0                   </td><td>0                   </td><td>0                 </td><td>0                    </td><td>0                    </td><td>            </td><td>0                 </td><td>0                </td><td>0                 </td></tr>\n",
       "<tr><td>missing</td><td>0              </td><td>0                  </td><td>0                     </td><td>0                </td><td>0                   </td><td>0                   </td><td>0           </td><td>0                        </td><td>0                            </td><td>0                 </td><td>0                   </td><td>0                   </td><td>0                 </td><td>0                   </td><td>0                   </td><td>0                 </td><td>0                    </td><td>0                    </td><td>0           </td><td>0                 </td><td>0                </td><td>0                 </td></tr>\n",
       "<tr><td>0      </td><td>M_ID_838061e48c</td><td>8353.0             </td><td>792.0                 </td><td>9.0              </td><td>-0.05747065         </td><td>-0.05747065         </td><td>N           </td><td>E                        </td><td>E                            </td><td>-0.4              </td><td>9.66666667          </td><td>3.0                 </td><td>-2.25             </td><td>18.66666667         </td><td>6.0                 </td><td>-2.32             </td><td>13.91666667          </td><td>12.0                 </td><td>N           </td><td>242.0             </td><td>9.0              </td><td>1.0               </td></tr>\n",
       "<tr><td>1      </td><td>M_ID_9339d880ad</td><td>3184.0             </td><td>840.0                 </td><td>20.0             </td><td>-0.05747065         </td><td>-0.05747065         </td><td>N           </td><td>E                        </td><td>E                            </td><td>-0.72             </td><td>1.75                </td><td>3.0                 </td><td>-0.74             </td><td>1.29166667          </td><td>6.0                 </td><td>-0.57             </td><td>1.6875               </td><td>12.0                 </td><td>N           </td><td>22.0              </td><td>16.0             </td><td>1.0               </td></tr>\n",
       "<tr><td>2      </td><td>M_ID_e726bbae1e</td><td>447.0              </td><td>690.0                 </td><td>1.0              </td><td>-0.05747065         </td><td>-0.05747065         </td><td>N           </td><td>E                        </td><td>E                            </td><td>-82.13            </td><td>260.0               </td><td>2.0                 </td><td>-82.13            </td><td>260.0               </td><td>2.0                 </td><td>-82.13            </td><td>260.0                </td><td>2.0                  </td><td>N           </td><td>-1.0              </td><td>5.0              </td><td>5.0               </td></tr>\n",
       "<tr><td>3      </td><td>M_ID_a70e9c5f81</td><td>5026.0             </td><td>792.0                 </td><td>9.0              </td><td>-0.05747065         </td><td>-0.05747065         </td><td>Y           </td><td>E                        </td><td>E                            </td><td>13.832992503353953</td><td>1.66666667          </td><td>3.0                 </td><td>21.65078713289889 </td><td>4.66666667          </td><td>6.0                 </td><td>25.227708876757905</td><td>3.83333333           </td><td>12.0                 </td><td>Y           </td><td>-1.0              </td><td>-1.0             </td><td>2.3800017967280946</td></tr>\n",
       "<tr><td>4      </td><td>M_ID_64456c37ce</td><td>2228.0             </td><td>222.0                 </td><td>21.0             </td><td>-0.05747065         </td><td>-0.05747065         </td><td>Y           </td><td>E                        </td><td>E                            </td><td>13.832992503353953</td><td>0.5                 </td><td>3.0                 </td><td>21.65078713289889 </td><td>0.36111111          </td><td>6.0                 </td><td>25.227708876757905</td><td>0.34722222           </td><td>12.0                 </td><td>Y           </td><td>-1.0              </td><td>-1.0             </td><td>2.3800017967280946</td></tr>\n",
       "<tr><td>5      </td><td>M_ID_a0915f62b5</td><td>20201.0            </td><td>87.0                  </td><td>27.0             </td><td>-0.05747065         </td><td>-0.05747065         </td><td>N           </td><td>E                        </td><td>E                            </td><td>13.832992503353953</td><td>1.0                 </td><td>3.0                 </td><td>21.65078713289889 </td><td>3.66666667          </td><td>6.0                 </td><td>25.227708876757905</td><td>3.83333333           </td><td>12.0                 </td><td>Y           </td><td>160.0             </td><td>21.0             </td><td>5.0               </td></tr>\n",
       "<tr><td>6      </td><td>M_ID_bfd41933db</td><td>33861.0            </td><td>792.0                 </td><td>9.0              </td><td>-0.05747065         </td><td>-0.05747065         </td><td>N           </td><td>E                        </td><td>E                            </td><td>13.832992503353953</td><td>2.83333333          </td><td>3.0                 </td><td>21.65078713289889 </td><td>4.83333333          </td><td>6.0                 </td><td>25.227708876757905</td><td>6.33333333           </td><td>12.0                 </td><td>N           </td><td>60.0              </td><td>16.0             </td><td>1.0               </td></tr>\n",
       "<tr><td>7      </td><td>M_ID_d8ff08219e</td><td>16430.0            </td><td>529.0                 </td><td>20.0             </td><td>-0.05747065         </td><td>-0.05747065         </td><td>Y           </td><td>E                        </td><td>E                            </td><td>13.832992503353953</td><td>1.0                 </td><td>3.0                 </td><td>21.65078713289889 </td><td>1.66666667          </td><td>6.0                 </td><td>25.227708876757905</td><td>1.5                  </td><td>11.0                 </td><td>Y           </td><td>-1.0              </td><td>-1.0             </td><td>2.3800017967280946</td></tr>\n",
       "<tr><td>8      </td><td>M_ID_c5b389236d</td><td>37179.0            </td><td>813.0                 </td><td>29.0             </td><td>-0.05747065         </td><td>-0.05747065         </td><td>N           </td><td>E                        </td><td>E                            </td><td>13.832992503353953</td><td>115.0               </td><td>3.0                 </td><td>21.65078713289889 </td><td>189.91666667        </td><td>6.0                 </td><td>25.227708876757905</td><td>197.0                </td><td>7.0                  </td><td>N           </td><td>248.0             </td><td>15.0             </td><td>1.0               </td></tr>\n",
       "<tr><td>9      </td><td>M_ID_d2162ed113</td><td>112122.0           </td><td>81.0                  </td><td>29.0             </td><td>-0.05747065         </td><td>-0.05747065         </td><td>Y           </td><td>E                        </td><td>E                            </td><td>13.832992503353953</td><td>1.0                 </td><td>2.0                 </td><td>21.65078713289889 </td><td>1.0                 </td><td>2.0                 </td><td>25.227708876757905</td><td>1.0                  </td><td>2.0                  </td><td>Y           </td><td>-1.0              </td><td>-1.0             </td><td>2.3800017967280946</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if scale:\n",
    "    df[reals] = df[reals].scale()\n",
    "    df[ints] = df[ints].scale()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set target to factor for classification by default or if user specifies classification\n",
    "if classification:\n",
    "    df[y] = df[y].asfactor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['N', 'Y']]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[y].levels()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if classification:\n",
    "    class_percentage = y_balance=df[y].mean()[0]/(df[y].max()-df[y].min())\n",
    "    if class_percentage < balance_threshold:\n",
    "        balance_y=True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(run_time)\n",
    "type(run_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML progress: |████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "# automl\n",
    "# runs for run_time seconds then builds a stacked ensemble\n",
    "aml = H2OAutoML(max_runtime_secs=run_time,project_name = project,balance_classes=balance_y) # init automl, run for 300 seconds\n",
    "aml.train(x=X,  \n",
    "           y=y,\n",
    "           training_frame=df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>model_id                                           </th><th style=\"text-align: right;\">     auc</th><th style=\"text-align: right;\">  logloss</th><th style=\"text-align: right;\">  mean_per_class_error</th><th style=\"text-align: right;\">    rmse</th><th style=\"text-align: right;\">      mse</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DRF_1_AutoML_20181211_205354                       </td><td style=\"text-align: right;\">0.998415</td><td style=\"text-align: right;\">0.0984845</td><td style=\"text-align: right;\">             0.018678 </td><td style=\"text-align: right;\">0.14085 </td><td style=\"text-align: right;\">0.0198387</td></tr>\n",
       "<tr><td>DRF_1_AutoML_20181211_204538                       </td><td style=\"text-align: right;\">0.998365</td><td style=\"text-align: right;\">0.103154 </td><td style=\"text-align: right;\">             0.0207174</td><td style=\"text-align: right;\">0.144604</td><td style=\"text-align: right;\">0.0209104</td></tr>\n",
       "<tr><td>StackedEnsemble_AllModels_AutoML_20181211_204538   </td><td style=\"text-align: right;\">0.998342</td><td style=\"text-align: right;\">0.038458 </td><td style=\"text-align: right;\">             0.0208069</td><td style=\"text-align: right;\">0.103479</td><td style=\"text-align: right;\">0.0107079</td></tr>\n",
       "<tr><td>StackedEnsemble_BestOfFamily_AutoML_20181211_204538</td><td style=\"text-align: right;\">0.998342</td><td style=\"text-align: right;\">0.038458 </td><td style=\"text-align: right;\">             0.0208069</td><td style=\"text-align: right;\">0.103479</td><td style=\"text-align: right;\">0.0107079</td></tr>\n",
       "<tr><td>XRT_1_AutoML_20181211_204538                       </td><td style=\"text-align: right;\">0.998057</td><td style=\"text-align: right;\">0.116858 </td><td style=\"text-align: right;\">             0.0237241</td><td style=\"text-align: right;\">0.15579 </td><td style=\"text-align: right;\">0.0242706</td></tr>\n",
       "<tr><td>XRT_1_AutoML_20181211_205354                       </td><td style=\"text-align: right;\">0.997643</td><td style=\"text-align: right;\">0.125676 </td><td style=\"text-align: right;\">             0.0259222</td><td style=\"text-align: right;\">0.164174</td><td style=\"text-align: right;\">0.0269531</td></tr>\n",
       "<tr><td>GLM_grid_1_AutoML_20181211_204538_model_1          </td><td style=\"text-align: right;\">0.636805</td><td style=\"text-align: right;\">0.558565 </td><td style=\"text-align: right;\">             0.423959 </td><td style=\"text-align: right;\">0.433881</td><td style=\"text-align: right;\">0.188253 </td></tr>\n",
       "<tr><td>GLM_grid_1_AutoML_20181211_205354_model_1          </td><td style=\"text-align: right;\">0.636805</td><td style=\"text-align: right;\">0.558565 </td><td style=\"text-align: right;\">             0.423959 </td><td style=\"text-align: right;\">0.433881</td><td style=\"text-align: right;\">0.188253 </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view leaderboard\n",
    "lb = aml.leaderboard\n",
    "lb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Which hyper-parameters are important?   \n",
    "For DRF :\n",
    "mtries\n",
    "categorical_encoding\n",
    "weight_column\n",
    "stopping_rounds\n",
    "offset_column\n",
    "fold_column \n",
    "max_runtime_secs\n",
    "\n",
    "For GBM:\n",
    "weight_column\n",
    "stopping_rounds\n",
    "offset_column\n",
    "fold_column \n",
    "max_runtime_secs\n",
    "learn_rate\n",
    "learn_rate_annealing\n",
    "\n",
    "\n",
    "Which algorithm works best?\n",
    "Distributed Random Forest because its rmse is 0.14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2ORandomForestEstimator :  Distributed Random Forest\n",
      "Model Key:  DRF_1_AutoML_20181211_205354\n",
      "\n",
      "\n",
      "ModelMetricsBinomial: drf\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.020242828646662245\n",
      "RMSE: 0.14227729490913948\n",
      "LogLoss: 0.09673799546133012\n",
      "Mean Per-Class Error: 0.01872350523172872\n",
      "AUC: 0.9982640258173935\n",
      "pr_auc: 0.9089612037582203\n",
      "Gini: 0.996528051634787\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.49174027253987507: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>N</b></td>\n",
       "<td><b>Y</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>N</td>\n",
       "<td>213435.0</td>\n",
       "<td>1453.0</td>\n",
       "<td>0.0068</td>\n",
       "<td> (1453.0/214888.0)</td></tr>\n",
       "<tr><td>Y</td>\n",
       "<td>3098.0</td>\n",
       "<td>83246.0</td>\n",
       "<td>0.0359</td>\n",
       "<td> (3098.0/86344.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>216533.0</td>\n",
       "<td>84699.0</td>\n",
       "<td>0.0151</td>\n",
       "<td> (4551.0/301232.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       N       Y      Error    Rate\n",
       "-----  ------  -----  -------  -----------------\n",
       "N      213435  1453   0.0068   (1453.0/214888.0)\n",
       "Y      3098    83246  0.0359   (3098.0/86344.0)\n",
       "Total  216533  84699  0.0151   (4551.0/301232.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.4917403</td>\n",
       "<td>0.9733927</td>\n",
       "<td>188.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.3549770</td>\n",
       "<td>0.9761585</td>\n",
       "<td>222.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.5960178</td>\n",
       "<td>0.9839807</td>\n",
       "<td>165.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.4917403</td>\n",
       "<td>0.9848920</td>\n",
       "<td>188.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9999810</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0000123</td>\n",
       "<td>1.0</td>\n",
       "<td>399.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9999810</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.4917403</td>\n",
       "<td>0.9629320</td>\n",
       "<td>188.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.3912923</td>\n",
       "<td>0.9810294</td>\n",
       "<td>212.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.4162169</td>\n",
       "<td>0.9812765</td>\n",
       "<td>206.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.49174      0.973393  188\n",
       "max f2                       0.354977     0.976159  222\n",
       "max f0point5                 0.596018     0.983981  165\n",
       "max accuracy                 0.49174      0.984892  188\n",
       "max precision                0.999981     1         0\n",
       "max recall                   1.23132e-05  1         399\n",
       "max specificity              0.999981     1         0\n",
       "max absolute_mcc             0.49174      0.962932  188\n",
       "max min_per_class_accuracy   0.391292     0.981029  212\n",
       "max mean_per_class_accuracy  0.416217     0.981276  206"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 28.66 %, avg score: 28.74 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>score</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>cumulative_score</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0245724</td>\n",
       "<td>1.0</td>\n",
       "<td>3.4887427</td>\n",
       "<td>3.4887427</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0857269</td>\n",
       "<td>0.0857269</td>\n",
       "<td>248.8742704</td>\n",
       "<td>248.8742704</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0300001</td>\n",
       "<td>0.9923801</td>\n",
       "<td>3.4887427</td>\n",
       "<td>3.4887427</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9960116</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9992784</td>\n",
       "<td>0.0189359</td>\n",
       "<td>0.1046627</td>\n",
       "<td>248.8742704</td>\n",
       "<td>248.8742704</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0400024</td>\n",
       "<td>0.9817353</td>\n",
       "<td>3.4887427</td>\n",
       "<td>3.4887427</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9873043</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9962844</td>\n",
       "<td>0.0348953</td>\n",
       "<td>0.1395580</td>\n",
       "<td>248.8742704</td>\n",
       "<td>248.8742704</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0500013</td>\n",
       "<td>0.9724944</td>\n",
       "<td>3.4887427</td>\n",
       "<td>3.4887427</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9772090</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9924698</td>\n",
       "<td>0.0348837</td>\n",
       "<td>0.1744418</td>\n",
       "<td>248.8742704</td>\n",
       "<td>248.8742704</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.1000060</td>\n",
       "<td>0.9298701</td>\n",
       "<td>3.4880479</td>\n",
       "<td>3.4883953</td>\n",
       "<td>0.9998008</td>\n",
       "<td>0.9503510</td>\n",
       "<td>0.9999004</td>\n",
       "<td>0.9714097</td>\n",
       "<td>0.1744186</td>\n",
       "<td>0.3488604</td>\n",
       "<td>248.8047873</td>\n",
       "<td>248.8395277</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1500007</td>\n",
       "<td>0.8884800</td>\n",
       "<td>3.4885110</td>\n",
       "<td>3.4884339</td>\n",
       "<td>0.9999336</td>\n",
       "<td>0.9095350</td>\n",
       "<td>0.9999115</td>\n",
       "<td>0.9507871</td>\n",
       "<td>0.1744070</td>\n",
       "<td>0.5232674</td>\n",
       "<td>248.8511047</td>\n",
       "<td>248.8433863</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.2000020</td>\n",
       "<td>0.8358737</td>\n",
       "<td>3.4873530</td>\n",
       "<td>3.4881636</td>\n",
       "<td>0.9996016</td>\n",
       "<td>0.8638037</td>\n",
       "<td>0.9998340</td>\n",
       "<td>0.9290409</td>\n",
       "<td>0.1743723</td>\n",
       "<td>0.6976397</td>\n",
       "<td>248.7352951</td>\n",
       "<td>248.8163630</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.3000013</td>\n",
       "<td>0.3581678</td>\n",
       "<td>2.8753781</td>\n",
       "<td>3.2839041</td>\n",
       "<td>0.8241875</td>\n",
       "<td>0.6756746</td>\n",
       "<td>0.9412858</td>\n",
       "<td>0.8445864</td>\n",
       "<td>0.2875359</td>\n",
       "<td>0.9851756</td>\n",
       "<td>187.5378120</td>\n",
       "<td>228.3904054</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.4000007</td>\n",
       "<td>0.1144822</td>\n",
       "<td>0.1351579</td>\n",
       "<td>2.4967241</td>\n",
       "<td>0.0387412</td>\n",
       "<td>0.2041120</td>\n",
       "<td>0.7156515</td>\n",
       "<td>0.6844691</td>\n",
       "<td>0.0135157</td>\n",
       "<td>0.9986913</td>\n",
       "<td>-86.4842056</td>\n",
       "<td>149.6724059</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0506433</td>\n",
       "<td>0.0044010</td>\n",
       "<td>1.9982628</td>\n",
       "<td>0.0012615</td>\n",
       "<td>0.0768782</td>\n",
       "<td>0.5727745</td>\n",
       "<td>0.5629517</td>\n",
       "<td>0.0004401</td>\n",
       "<td>0.9991314</td>\n",
       "<td>-99.5598970</td>\n",
       "<td>99.8262763</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.6000027</td>\n",
       "<td>0.0228758</td>\n",
       "<td>0.0026637</td>\n",
       "<td>1.6656556</td>\n",
       "<td>0.0007635</td>\n",
       "<td>0.0346323</td>\n",
       "<td>0.4774372</td>\n",
       "<td>0.4748965</td>\n",
       "<td>0.0002664</td>\n",
       "<td>0.9993978</td>\n",
       "<td>-99.7336307</td>\n",
       "<td>66.5655557</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.7000186</td>\n",
       "<td>0.0115814</td>\n",
       "<td>0.0020844</td>\n",
       "<td>1.4279710</td>\n",
       "<td>0.0005975</td>\n",
       "<td>0.0165641</td>\n",
       "<td>0.4093082</td>\n",
       "<td>0.4094118</td>\n",
       "<td>0.0002085</td>\n",
       "<td>0.9996062</td>\n",
       "<td>-99.7915648</td>\n",
       "<td>42.7970971</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.7999980</td>\n",
       "<td>0.0032095</td>\n",
       "<td>0.0028960</td>\n",
       "<td>1.2498728</td>\n",
       "<td>0.0008301</td>\n",
       "<td>0.0069621</td>\n",
       "<td>0.3582588</td>\n",
       "<td>0.3591158</td>\n",
       "<td>0.0002895</td>\n",
       "<td>0.9998958</td>\n",
       "<td>-99.7104009</td>\n",
       "<td>24.9872819</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0005212</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0001494</td>\n",
       "<td>0.0006021</td>\n",
       "<td>0.2866362</td>\n",
       "<td>0.2874123</td>\n",
       "<td>0.0001042</td>\n",
       "<td>1.0</td>\n",
       "<td>-99.9478834</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift         cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  -----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.0245724                   1                  3.48874      3.48874            1                1            1                           1                   0.0857269       0.0857269                  248.874   248.874\n",
       "    2        0.0300001                   0.99238            3.48874      3.48874            1                0.996012     1                           0.999278            0.0189359       0.104663                   248.874   248.874\n",
       "    3        0.0400024                   0.981735           3.48874      3.48874            1                0.987304     1                           0.996284            0.0348953       0.139558                   248.874   248.874\n",
       "    4        0.0500013                   0.972494           3.48874      3.48874            1                0.977209     1                           0.99247             0.0348837       0.174442                   248.874   248.874\n",
       "    5        0.100006                    0.92987            3.48805      3.4884             0.999801         0.950351     0.9999                      0.97141             0.174419        0.34886                    248.805   248.84\n",
       "    6        0.150001                    0.88848            3.48851      3.48843            0.999934         0.909535     0.999911                    0.950787            0.174407        0.523267                   248.851   248.843\n",
       "    7        0.200002                    0.835874           3.48735      3.48816            0.999602         0.863804     0.999834                    0.929041            0.174372        0.69764                    248.735   248.816\n",
       "    8        0.300001                    0.358168           2.87538      3.2839             0.824187         0.675675     0.941286                    0.844586            0.287536        0.985176                   187.538   228.39\n",
       "    9        0.400001                    0.114482           0.135158     2.49672            0.0387412        0.204112     0.715652                    0.684469            0.0135157       0.998691                   -86.4842  149.672\n",
       "    10       0.5                         0.0506433          0.00440103   1.99826            0.00126149       0.0768782    0.572774                    0.562952            0.0004401       0.999131                   -99.5599  99.8263\n",
       "    11       0.600003                    0.0228758          0.00266369   1.66566            0.000763511      0.0346323    0.477437                    0.474897            0.000266376     0.999398                   -99.7336  66.5656\n",
       "    12       0.700019                    0.0115814          0.00208435   1.42797            0.000597451      0.0165641    0.409308                    0.409412            0.000208468     0.999606                   -99.7916  42.7971\n",
       "    13       0.799998                    0.00320951         0.00289599   1.24987            0.000830096      0.00696211   0.358259                    0.359116            0.00028954      0.999896                   -99.7104  24.9873\n",
       "    14       1                           0                  0.000521166  1                  0.000149385      0.000602119  0.286636                    0.287412            0.000104234     1                          -99.9479  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: drf\n",
      "** Reported on validation data. **\n",
      "\n",
      "MSE: 0.018881497714415916\n",
      "RMSE: 0.1374099622094989\n",
      "LogLoss: 0.0955319096107168\n",
      "Mean Per-Class Error: 0.015262034263669788\n",
      "AUC: 0.9984440687687627\n",
      "pr_auc: 0.9622318205609467\n",
      "Gini: 0.9968881375375254\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4416887505133839: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>N</b></td>\n",
       "<td><b>Y</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>N</td>\n",
       "<td>23520.0</td>\n",
       "<td>188.0</td>\n",
       "<td>0.0079</td>\n",
       "<td> (188.0/23708.0)</td></tr>\n",
       "<tr><td>Y</td>\n",
       "<td>239.0</td>\n",
       "<td>9517.0</td>\n",
       "<td>0.0245</td>\n",
       "<td> (239.0/9756.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>23759.0</td>\n",
       "<td>9705.0</td>\n",
       "<td>0.0128</td>\n",
       "<td> (427.0/33464.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       N      Y     Error    Rate\n",
       "-----  -----  ----  -------  ---------------\n",
       "N      23520  188   0.0079   (188.0/23708.0)\n",
       "Y      239    9517  0.0245   (239.0/9756.0)\n",
       "Total  23759  9705  0.0128   (427.0/33464.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.4416888</td>\n",
       "<td>0.9780587</td>\n",
       "<td>195.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.3852141</td>\n",
       "<td>0.9802661</td>\n",
       "<td>210.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.6038533</td>\n",
       "<td>0.9869264</td>\n",
       "<td>161.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.4482769</td>\n",
       "<td>0.9872400</td>\n",
       "<td>193.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9999085</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0044250</td>\n",
       "<td>1.0</td>\n",
       "<td>394.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9999085</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.4416888</td>\n",
       "<td>0.9690697</td>\n",
       "<td>195.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.3852141</td>\n",
       "<td>0.9843513</td>\n",
       "<td>210.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.3914551</td>\n",
       "<td>0.9847380</td>\n",
       "<td>208.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.441689     0.978059  195\n",
       "max f2                       0.385214     0.980266  210\n",
       "max f0point5                 0.603853     0.986926  161\n",
       "max accuracy                 0.448277     0.98724   193\n",
       "max precision                0.999909     1         0\n",
       "max recall                   0.004425     1         394\n",
       "max specificity              0.999909     1         0\n",
       "max absolute_mcc             0.441689     0.96907   195\n",
       "max min_per_class_accuracy   0.385214     0.984351  210\n",
       "max mean_per_class_accuracy  0.391455     0.984738  208"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 29.15 %, avg score: 29.08 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>score</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>cumulative_score</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0100108</td>\n",
       "<td>0.9984228</td>\n",
       "<td>3.4300943</td>\n",
       "<td>3.4300943</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999521</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999521</td>\n",
       "<td>0.0343378</td>\n",
       "<td>0.0343378</td>\n",
       "<td>243.0094301</td>\n",
       "<td>243.0094301</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0200514</td>\n",
       "<td>0.9915056</td>\n",
       "<td>3.4300943</td>\n",
       "<td>3.4300943</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9932968</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9966195</td>\n",
       "<td>0.0344403</td>\n",
       "<td>0.0687782</td>\n",
       "<td>243.0094301</td>\n",
       "<td>243.0094301</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0307495</td>\n",
       "<td>0.9817939</td>\n",
       "<td>3.4300943</td>\n",
       "<td>3.4300943</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9859367</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9929028</td>\n",
       "<td>0.0366954</td>\n",
       "<td>0.1054736</td>\n",
       "<td>243.0094301</td>\n",
       "<td>243.0094301</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0400131</td>\n",
       "<td>0.9722330</td>\n",
       "<td>3.4300943</td>\n",
       "<td>3.4300943</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9778358</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9894146</td>\n",
       "<td>0.0317753</td>\n",
       "<td>0.1372489</td>\n",
       "<td>243.0094301</td>\n",
       "<td>243.0094301</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0500239</td>\n",
       "<td>0.9638823</td>\n",
       "<td>3.4300943</td>\n",
       "<td>3.4300943</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9674898</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9850270</td>\n",
       "<td>0.0343378</td>\n",
       "<td>0.1715867</td>\n",
       "<td>243.0094301</td>\n",
       "<td>243.0094301</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1000179</td>\n",
       "<td>0.9218599</td>\n",
       "<td>3.4300943</td>\n",
       "<td>3.4300943</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9416622</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9633511</td>\n",
       "<td>0.1714842</td>\n",
       "<td>0.3430709</td>\n",
       "<td>243.0094301</td>\n",
       "<td>243.0094301</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1500120</td>\n",
       "<td>0.8882195</td>\n",
       "<td>3.4300943</td>\n",
       "<td>3.4300943</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9053718</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9440285</td>\n",
       "<td>0.1714842</td>\n",
       "<td>0.5145551</td>\n",
       "<td>243.0094301</td>\n",
       "<td>243.0094301</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2000060</td>\n",
       "<td>0.8421777</td>\n",
       "<td>3.4280440</td>\n",
       "<td>3.4295818</td>\n",
       "<td>0.9994023</td>\n",
       "<td>0.8670677</td>\n",
       "<td>0.9998506</td>\n",
       "<td>0.9247912</td>\n",
       "<td>0.1713817</td>\n",
       "<td>0.6859369</td>\n",
       "<td>242.8044035</td>\n",
       "<td>242.9581811</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.2999940</td>\n",
       "<td>0.3708652</td>\n",
       "<td>2.9964631</td>\n",
       "<td>3.2852233</td>\n",
       "<td>0.8735804</td>\n",
       "<td>0.7020466</td>\n",
       "<td>0.9577647</td>\n",
       "<td>0.8505504</td>\n",
       "<td>0.2996105</td>\n",
       "<td>0.9855474</td>\n",
       "<td>199.6463133</td>\n",
       "<td>228.5223299</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4000120</td>\n",
       "<td>0.1124730</td>\n",
       "<td>0.1311778</td>\n",
       "<td>2.4965941</td>\n",
       "<td>0.0382432</td>\n",
       "<td>0.2071155</td>\n",
       "<td>0.7278500</td>\n",
       "<td>0.6896676</td>\n",
       "<td>0.0131201</td>\n",
       "<td>0.9986675</td>\n",
       "<td>-86.8822208</td>\n",
       "<td>149.6594111</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0486775</td>\n",
       "<td>0.0020503</td>\n",
       "<td>1.9977450</td>\n",
       "<td>0.0005977</td>\n",
       "<td>0.0752963</td>\n",
       "<td>0.5824169</td>\n",
       "<td>0.5668081</td>\n",
       "<td>0.0002050</td>\n",
       "<td>0.9988725</td>\n",
       "<td>-99.7949734</td>\n",
       "<td>99.7744977</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.6000179</td>\n",
       "<td>0.0250341</td>\n",
       "<td>0.0030745</td>\n",
       "<td>1.6652502</td>\n",
       "<td>0.0008963</td>\n",
       "<td>0.0353917</td>\n",
       "<td>0.4854823</td>\n",
       "<td>0.4782254</td>\n",
       "<td>0.0003075</td>\n",
       "<td>0.9991800</td>\n",
       "<td>-99.6925520</td>\n",
       "<td>66.5250224</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.7000060</td>\n",
       "<td>0.0144942</td>\n",
       "<td>0.0020503</td>\n",
       "<td>1.4276807</td>\n",
       "<td>0.0005977</td>\n",
       "<td>0.0190908</td>\n",
       "<td>0.4162220</td>\n",
       "<td>0.4126432</td>\n",
       "<td>0.0002050</td>\n",
       "<td>0.9993850</td>\n",
       "<td>-99.7949734</td>\n",
       "<td>42.7680659</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.8000239</td>\n",
       "<td>0.0087596</td>\n",
       "<td>0.0030745</td>\n",
       "<td>1.2495783</td>\n",
       "<td>0.0008963</td>\n",
       "<td>0.0113545</td>\n",
       "<td>0.3642985</td>\n",
       "<td>0.3624746</td>\n",
       "<td>0.0003075</td>\n",
       "<td>0.9996925</td>\n",
       "<td>-99.6925520</td>\n",
       "<td>24.9578280</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.8999821</td>\n",
       "<td>0.0040031</td>\n",
       "<td>0.0020509</td>\n",
       "<td>1.1110194</td>\n",
       "<td>0.0005979</td>\n",
       "<td>0.0063164</td>\n",
       "<td>0.3239034</td>\n",
       "<td>0.3229172</td>\n",
       "<td>0.0002050</td>\n",
       "<td>0.9998975</td>\n",
       "<td>-99.7949121</td>\n",
       "<td>11.1019355</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0010248</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0002988</td>\n",
       "<td>0.0016149</td>\n",
       "<td>0.2915372</td>\n",
       "<td>0.2907812</td>\n",
       "<td>0.0001025</td>\n",
       "<td>1.0</td>\n",
       "<td>-99.8975173</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.0100108                   0.998423           3.43009     3.43009            1                0.999952    1                           0.999952            0.0343378       0.0343378                  243.009   243.009\n",
       "    2        0.0200514                   0.991506           3.43009     3.43009            1                0.993297    1                           0.99662             0.0344403       0.0687782                  243.009   243.009\n",
       "    3        0.0307495                   0.981794           3.43009     3.43009            1                0.985937    1                           0.992903            0.0366954       0.105474                   243.009   243.009\n",
       "    4        0.0400131                   0.972233           3.43009     3.43009            1                0.977836    1                           0.989415            0.0317753       0.137249                   243.009   243.009\n",
       "    5        0.0500239                   0.963882           3.43009     3.43009            1                0.96749     1                           0.985027            0.0343378       0.171587                   243.009   243.009\n",
       "    6        0.100018                    0.92186            3.43009     3.43009            1                0.941662    1                           0.963351            0.171484        0.343071                   243.009   243.009\n",
       "    7        0.150012                    0.88822            3.43009     3.43009            1                0.905372    1                           0.944028            0.171484        0.514555                   243.009   243.009\n",
       "    8        0.200006                    0.842178           3.42804     3.42958            0.999402         0.867068    0.999851                    0.924791            0.171382        0.685937                   242.804   242.958\n",
       "    9        0.299994                    0.370865           2.99646     3.28522            0.87358          0.702047    0.957765                    0.85055             0.29961         0.985547                   199.646   228.522\n",
       "    10       0.400012                    0.112473           0.131178    2.49659            0.0382432        0.207116    0.72785                     0.689668            0.0131201       0.998667                   -86.8822  149.659\n",
       "    11       0.5                         0.0486775          0.00205027  1.99774            0.000597729      0.0752963   0.582417                    0.566808            0.000205002     0.998872                   -99.795   99.7745\n",
       "    12       0.600018                    0.0250341          0.00307448  1.66525            0.000896325      0.0353917   0.485482                    0.478225            0.000307503     0.99918                    -99.6926  66.525\n",
       "    13       0.700006                    0.0144942          0.00205027  1.42768            0.000597729      0.0190908   0.416222                    0.412643            0.000205002     0.999385                   -99.795   42.7681\n",
       "    14       0.800024                    0.00875963         0.00307448  1.24958            0.000896325      0.0113545   0.364299                    0.362475            0.000307503     0.999692                   -99.6926  24.9578\n",
       "    15       0.899982                    0.00400315         0.00205088  1.11102            0.000597907      0.0063164   0.323903                    0.322917            0.000205002     0.999897                   -99.7949  11.1019\n",
       "    16       1                           0                  0.00102483  1                  0.000298775      0.00161486  0.291537                    0.290781            0.000102501     1                          -99.8975  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: drf\n",
      "** Reported on cross-validation data. **\n",
      "\n",
      "MSE: 0.019838655136353946\n",
      "RMSE: 0.14084976086722314\n",
      "LogLoss: 0.09848448113892687\n",
      "Mean Per-Class Error: 0.01697642178512626\n",
      "AUC: 0.9984149199275788\n",
      "pr_auc: 0.9438620129204796\n",
      "Gini: 0.9968298398551576\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4721316665854305: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>N</b></td>\n",
       "<td><b>Y</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>N</td>\n",
       "<td>213304.0</td>\n",
       "<td>1584.0</td>\n",
       "<td>0.0074</td>\n",
       "<td> (1584.0/214888.0)</td></tr>\n",
       "<tr><td>Y</td>\n",
       "<td>2589.0</td>\n",
       "<td>83755.0</td>\n",
       "<td>0.03</td>\n",
       "<td> (2589.0/86344.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>215893.0</td>\n",
       "<td>85339.0</td>\n",
       "<td>0.0139</td>\n",
       "<td> (4173.0/301232.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       N       Y      Error    Rate\n",
       "-----  ------  -----  -------  -----------------\n",
       "N      213304  1584   0.0074   (1584.0/214888.0)\n",
       "Y      2589    83755  0.03     (2589.0/86344.0)\n",
       "Total  215893  85339  0.0139   (4173.0/301232.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.4721317</td>\n",
       "<td>0.9756936</td>\n",
       "<td>186.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.3610743</td>\n",
       "<td>0.9781708</td>\n",
       "<td>216.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.5859488</td>\n",
       "<td>0.9856473</td>\n",
       "<td>162.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.4721317</td>\n",
       "<td>0.9861469</td>\n",
       "<td>186.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9999495</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0013795</td>\n",
       "<td>1.0</td>\n",
       "<td>397.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9999495</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.4721317</td>\n",
       "<td>0.9660394</td>\n",
       "<td>186.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.3911902</td>\n",
       "<td>0.9824606</td>\n",
       "<td>207.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.4120424</td>\n",
       "<td>0.9830236</td>\n",
       "<td>201.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.472132     0.975694  186\n",
       "max f2                       0.361074     0.978171  216\n",
       "max f0point5                 0.585949     0.985647  162\n",
       "max accuracy                 0.472132     0.986147  186\n",
       "max precision                0.999949     1         0\n",
       "max recall                   0.00137952   1         397\n",
       "max specificity              0.999949     1         0\n",
       "max absolute_mcc             0.472132     0.966039  186\n",
       "max min_per_class_accuracy   0.39119      0.982461  207\n",
       "max mean_per_class_accuracy  0.412042     0.983024  201"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 28.66 %, avg score: 28.75 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>score</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>cumulative_score</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0140490</td>\n",
       "<td>1.0</td>\n",
       "<td>3.4887427</td>\n",
       "<td>3.4887427</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0490132</td>\n",
       "<td>0.0490132</td>\n",
       "<td>248.8742704</td>\n",
       "<td>248.8742704</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0200311</td>\n",
       "<td>0.9953594</td>\n",
       "<td>3.4887427</td>\n",
       "<td>3.4887427</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9974951</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9992519</td>\n",
       "<td>0.0208700</td>\n",
       "<td>0.0698833</td>\n",
       "<td>248.8742704</td>\n",
       "<td>248.8742704</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0301263</td>\n",
       "<td>0.9863092</td>\n",
       "<td>3.4887427</td>\n",
       "<td>3.4887427</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9906092</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9963558</td>\n",
       "<td>0.0352196</td>\n",
       "<td>0.1051028</td>\n",
       "<td>248.8742704</td>\n",
       "<td>248.8742704</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0400024</td>\n",
       "<td>0.9741634</td>\n",
       "<td>3.4887427</td>\n",
       "<td>3.4887427</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9807678</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9925073</td>\n",
       "<td>0.0344552</td>\n",
       "<td>0.1395580</td>\n",
       "<td>248.8742704</td>\n",
       "<td>248.8742704</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0500013</td>\n",
       "<td>0.9587926</td>\n",
       "<td>3.4887427</td>\n",
       "<td>3.4887427</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9660452</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9872156</td>\n",
       "<td>0.0348837</td>\n",
       "<td>0.1744418</td>\n",
       "<td>248.8742704</td>\n",
       "<td>248.8742704</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1000027</td>\n",
       "<td>0.9146654</td>\n",
       "<td>3.4887427</td>\n",
       "<td>3.4887427</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9343891</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9608024</td>\n",
       "<td>0.1744418</td>\n",
       "<td>0.3488835</td>\n",
       "<td>248.8742704</td>\n",
       "<td>248.8742704</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1500007</td>\n",
       "<td>0.8794678</td>\n",
       "<td>3.4885111</td>\n",
       "<td>3.4886655</td>\n",
       "<td>0.9999336</td>\n",
       "<td>0.8973287</td>\n",
       "<td>0.9999779</td>\n",
       "<td>0.9396454</td>\n",
       "<td>0.1744186</td>\n",
       "<td>0.5233021</td>\n",
       "<td>248.8511063</td>\n",
       "<td>248.8665493</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2000020</td>\n",
       "<td>0.8359674</td>\n",
       "<td>3.4882795</td>\n",
       "<td>3.4885690</td>\n",
       "<td>0.9998672</td>\n",
       "<td>0.8590832</td>\n",
       "<td>0.9999502</td>\n",
       "<td>0.9195045</td>\n",
       "<td>0.1744186</td>\n",
       "<td>0.6977207</td>\n",
       "<td>248.8279453</td>\n",
       "<td>248.8568982</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3000013</td>\n",
       "<td>0.3577441</td>\n",
       "<td>2.8957618</td>\n",
       "<td>3.2909688</td>\n",
       "<td>0.8300302</td>\n",
       "<td>0.6803003</td>\n",
       "<td>0.9433108</td>\n",
       "<td>0.8397707</td>\n",
       "<td>0.2895743</td>\n",
       "<td>0.9872950</td>\n",
       "<td>189.5761837</td>\n",
       "<td>229.0968787</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4000007</td>\n",
       "<td>0.1138118</td>\n",
       "<td>0.1148900</td>\n",
       "<td>2.4969557</td>\n",
       "<td>0.0329316</td>\n",
       "<td>0.2046500</td>\n",
       "<td>0.7157179</td>\n",
       "<td>0.6809918</td>\n",
       "<td>0.0114889</td>\n",
       "<td>0.9987839</td>\n",
       "<td>-88.5109957</td>\n",
       "<td>149.6955691</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0508306</td>\n",
       "<td>0.0033587</td>\n",
       "<td>1.9982396</td>\n",
       "<td>0.0009627</td>\n",
       "<td>0.0769064</td>\n",
       "<td>0.5727678</td>\n",
       "<td>0.5601755</td>\n",
       "<td>0.0003359</td>\n",
       "<td>0.9991198</td>\n",
       "<td>-99.6641319</td>\n",
       "<td>99.8239600</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.5999993</td>\n",
       "<td>0.0265169</td>\n",
       "<td>0.0013898</td>\n",
       "<td>1.6654331</td>\n",
       "<td>0.0003984</td>\n",
       "<td>0.0369419</td>\n",
       "<td>0.4773735</td>\n",
       "<td>0.4729704</td>\n",
       "<td>0.0001390</td>\n",
       "<td>0.9992588</td>\n",
       "<td>-99.8610201</td>\n",
       "<td>66.5433141</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.6999987</td>\n",
       "<td>0.0145751</td>\n",
       "<td>0.0019689</td>\n",
       "<td>1.4277965</td>\n",
       "<td>0.0005644</td>\n",
       "<td>0.0201392</td>\n",
       "<td>0.4092582</td>\n",
       "<td>0.4082805</td>\n",
       "<td>0.0001969</td>\n",
       "<td>0.9994557</td>\n",
       "<td>-99.8031118</td>\n",
       "<td>42.7796517</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.8001441</td>\n",
       "<td>0.0076869</td>\n",
       "<td>0.0028912</td>\n",
       "<td>1.2494565</td>\n",
       "<td>0.0008287</td>\n",
       "<td>0.0107899</td>\n",
       "<td>0.3581395</td>\n",
       "<td>0.3585309</td>\n",
       "<td>0.0002895</td>\n",
       "<td>0.9997452</td>\n",
       "<td>-99.7108809</td>\n",
       "<td>24.9456487</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.8999973</td>\n",
       "<td>0.0025570</td>\n",
       "<td>0.0020877</td>\n",
       "<td>1.1110629</td>\n",
       "<td>0.0005984</td>\n",
       "<td>0.0051052</td>\n",
       "<td>0.3184709</td>\n",
       "<td>0.3193189</td>\n",
       "<td>0.0002085</td>\n",
       "<td>0.9999537</td>\n",
       "<td>-99.7912252</td>\n",
       "<td>11.1062916</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0004633</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0001328</td>\n",
       "<td>0.0008872</td>\n",
       "<td>0.2866362</td>\n",
       "<td>0.2874749</td>\n",
       "<td>0.0000463</td>\n",
       "<td>1.0</td>\n",
       "<td>-99.9536749</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift         cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  -----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.014049                    1                  3.48874      3.48874            1                1            1                           1                   0.0490132       0.0490132                  248.874   248.874\n",
       "    2        0.0200311                   0.995359           3.48874      3.48874            1                0.997495     1                           0.999252            0.02087         0.0698833                  248.874   248.874\n",
       "    3        0.0301263                   0.986309           3.48874      3.48874            1                0.990609     1                           0.996356            0.0352196       0.105103                   248.874   248.874\n",
       "    4        0.0400024                   0.974163           3.48874      3.48874            1                0.980768     1                           0.992507            0.0344552       0.139558                   248.874   248.874\n",
       "    5        0.0500013                   0.958793           3.48874      3.48874            1                0.966045     1                           0.987216            0.0348837       0.174442                   248.874   248.874\n",
       "    6        0.100003                    0.914665           3.48874      3.48874            1                0.934389     1                           0.960802            0.174442        0.348884                   248.874   248.874\n",
       "    7        0.150001                    0.879468           3.48851      3.48867            0.999934         0.897329     0.999978                    0.939645            0.174419        0.523302                   248.851   248.867\n",
       "    8        0.200002                    0.835967           3.48828      3.48857            0.999867         0.859083     0.99995                     0.919505            0.174419        0.697721                   248.828   248.857\n",
       "    9        0.300001                    0.357744           2.89576      3.29097            0.83003          0.6803       0.943311                    0.839771            0.289574        0.987295                   189.576   229.097\n",
       "    10       0.400001                    0.113812           0.11489      2.49696            0.0329316        0.20465      0.715718                    0.680992            0.0114889       0.998784                   -88.511   149.696\n",
       "    11       0.5                         0.0508306          0.00335868   1.99824            0.00096272       0.0769064    0.572768                    0.560176            0.000335866     0.99912                    -99.6641  99.824\n",
       "    12       0.599999                    0.0265169          0.0013898    1.66543            0.000398367      0.0369419    0.477373                    0.47297             0.000138979     0.999259                   -99.861   66.5433\n",
       "    13       0.699999                    0.0145751          0.00196888   1.4278             0.000564353      0.0201392    0.409258                    0.408281            0.000196887     0.999456                   -99.8031  42.7797\n",
       "    14       0.800144                    0.00768693         0.00289119   1.24946            0.00082872       0.0107899    0.358139                    0.358531            0.00028954      0.999745                   -99.7109  24.9456\n",
       "    15       0.899997                    0.002557           0.00208775   1.11106            0.000598424      0.00510517   0.318471                    0.319319            0.000208468     0.999954                   -99.7912  11.1063\n",
       "    16       1                           0                  0.000463251  1                  0.000132784      0.000887211  0.286636                    0.287475            4.63263e-05     1                          -99.9537  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-Validation Metrics Summary: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>mean</b></td>\n",
       "<td><b>sd</b></td>\n",
       "<td><b>cv_1_valid</b></td>\n",
       "<td><b>cv_2_valid</b></td>\n",
       "<td><b>cv_3_valid</b></td>\n",
       "<td><b>cv_4_valid</b></td>\n",
       "<td><b>cv_5_valid</b></td></tr>\n",
       "<tr><td>accuracy</td>\n",
       "<td>0.9862399</td>\n",
       "<td>0.0003246</td>\n",
       "<td>0.9861902</td>\n",
       "<td>0.9866052</td>\n",
       "<td>0.9858912</td>\n",
       "<td>0.9868871</td>\n",
       "<td>0.9856256</td></tr>\n",
       "<tr><td>auc</td>\n",
       "<td>0.9984168</td>\n",
       "<td>0.0000323</td>\n",
       "<td>0.9984430</td>\n",
       "<td>0.9983832</td>\n",
       "<td>0.9983691</td>\n",
       "<td>0.9984936</td>\n",
       "<td>0.9983954</td></tr>\n",
       "<tr><td>err</td>\n",
       "<td>0.0137602</td>\n",
       "<td>0.0003246</td>\n",
       "<td>0.0138098</td>\n",
       "<td>0.0133949</td>\n",
       "<td>0.0141088</td>\n",
       "<td>0.0131129</td>\n",
       "<td>0.0143744</td></tr>\n",
       "<tr><td>err_count</td>\n",
       "<td>829.0</td>\n",
       "<td>19.55505</td>\n",
       "<td>832.0</td>\n",
       "<td>807.0</td>\n",
       "<td>850.0</td>\n",
       "<td>790.0</td>\n",
       "<td>866.0</td></tr>\n",
       "<tr><td>f0point5</td>\n",
       "<td>0.9792042</td>\n",
       "<td>0.0005735</td>\n",
       "<td>0.9803233</td>\n",
       "<td>0.9791669</td>\n",
       "<td>0.9783503</td>\n",
       "<td>0.9798901</td>\n",
       "<td>0.9782903</td></tr>\n",
       "<tr><td>f1</td>\n",
       "<td>0.9758602</td>\n",
       "<td>0.0005739</td>\n",
       "<td>0.9757661</td>\n",
       "<td>0.9764785</td>\n",
       "<td>0.9754321</td>\n",
       "<td>0.9769773</td>\n",
       "<td>0.9746472</td></tr>\n",
       "<tr><td>f2</td>\n",
       "<td>0.97254</td>\n",
       "<td>0.0008897</td>\n",
       "<td>0.9712509</td>\n",
       "<td>0.9738048</td>\n",
       "<td>0.9725312</td>\n",
       "<td>0.9740818</td>\n",
       "<td>0.9710313</td></tr>\n",
       "<tr><td>lift_top_group</td>\n",
       "<td>3.4887974</td>\n",
       "<td>0.0097586</td>\n",
       "<td>3.4826868</td>\n",
       "<td>3.496025</td>\n",
       "<td>3.4654012</td>\n",
       "<td>3.4941423</td>\n",
       "<td>3.5057318</td></tr>\n",
       "<tr><td>logloss</td>\n",
       "<td>0.0984845</td>\n",
       "<td>0.0005711</td>\n",
       "<td>0.0989524</td>\n",
       "<td>0.0975894</td>\n",
       "<td>0.0976437</td>\n",
       "<td>0.0985139</td>\n",
       "<td>0.0997231</td></tr>\n",
       "<tr><td>max_per_class_error</td>\n",
       "<td>0.0296604</td>\n",
       "<td>0.0011602</td>\n",
       "<td>0.0317359</td>\n",
       "<td>0.0279696</td>\n",
       "<td>0.0293932</td>\n",
       "<td>0.0278390</td>\n",
       "<td>0.0313646</td></tr>\n",
       "<tr><td>mcc</td>\n",
       "<td>0.9662698</td>\n",
       "<td>0.0007951</td>\n",
       "<td>0.9661673</td>\n",
       "<td>0.9671350</td>\n",
       "<td>0.96556</td>\n",
       "<td>0.9678338</td>\n",
       "<td>0.9646531</td></tr>\n",
       "<tr><td>mean_per_class_accuracy</td>\n",
       "<td>0.9814841</td>\n",
       "<td>0.0005400</td>\n",
       "<td>0.9808374</td>\n",
       "<td>0.9822373</td>\n",
       "<td>0.9813487</td>\n",
       "<td>0.9824762</td>\n",
       "<td>0.9805208</td></tr>\n",
       "<tr><td>mean_per_class_error</td>\n",
       "<td>0.0185159</td>\n",
       "<td>0.0005400</td>\n",
       "<td>0.0191627</td>\n",
       "<td>0.0177626</td>\n",
       "<td>0.0186512</td>\n",
       "<td>0.0175238</td>\n",
       "<td>0.0194792</td></tr>\n",
       "<tr><td>mse</td>\n",
       "<td>0.0198387</td>\n",
       "<td>0.0001794</td>\n",
       "<td>0.0200267</td>\n",
       "<td>0.0195677</td>\n",
       "<td>0.0197068</td>\n",
       "<td>0.0196522</td>\n",
       "<td>0.0202399</td></tr>\n",
       "<tr><td>precision</td>\n",
       "<td>0.9814468</td>\n",
       "<td>0.0007716</td>\n",
       "<td>0.9833852</td>\n",
       "<td>0.9809675</td>\n",
       "<td>0.9803056</td>\n",
       "<td>0.9818416</td>\n",
       "<td>0.9807341</td></tr>\n",
       "<tr><td>r2</td>\n",
       "<td>0.9029759</td>\n",
       "<td>0.0009448</td>\n",
       "<td>0.9021599</td>\n",
       "<td>0.9041837</td>\n",
       "<td>0.9040078</td>\n",
       "<td>0.9038008</td>\n",
       "<td>0.9007272</td></tr>\n",
       "<tr><td>recall</td>\n",
       "<td>0.9703395</td>\n",
       "<td>0.0011602</td>\n",
       "<td>0.9682640</td>\n",
       "<td>0.9720304</td>\n",
       "<td>0.9706069</td>\n",
       "<td>0.972161</td>\n",
       "<td>0.9686354</td></tr>\n",
       "<tr><td>rmse</td>\n",
       "<td>0.1408469</td>\n",
       "<td>0.0006359</td>\n",
       "<td>0.1415158</td>\n",
       "<td>0.1398845</td>\n",
       "<td>0.1403809</td>\n",
       "<td>0.1401864</td>\n",
       "<td>0.1422668</td></tr>\n",
       "<tr><td>specificity</td>\n",
       "<td>0.9926286</td>\n",
       "<td>0.0003179</td>\n",
       "<td>0.9934106</td>\n",
       "<td>0.9924443</td>\n",
       "<td>0.9920907</td>\n",
       "<td>0.9927913</td>\n",
       "<td>0.9924061</td></tr></table></div>"
      ],
      "text/plain": [
       "                         mean       sd           cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid\n",
       "-----------------------  ---------  -----------  ------------  ------------  ------------  ------------  ------------\n",
       "accuracy                 0.98624    0.000324608  0.98619       0.986605      0.985891      0.986887      0.985626\n",
       "auc                      0.998417   3.23065e-05  0.998443      0.998383      0.998369      0.998494      0.998395\n",
       "err                      0.0137602  0.000324608  0.0138098     0.0133949     0.0141088     0.0131129     0.0143744\n",
       "err_count                829        19.5551      832           807           850           790           866\n",
       "f0point5                 0.979204   0.000573461  0.980323      0.979167      0.97835       0.97989       0.97829\n",
       "f1                       0.97586    0.000573905  0.975766      0.976478      0.975432      0.976977      0.974647\n",
       "f2                       0.97254    0.000889657  0.971251      0.973805      0.972531      0.974082      0.971031\n",
       "lift_top_group           3.4888     0.00975858   3.48269       3.49602       3.4654        3.49414       3.50573\n",
       "logloss                  0.0984845  0.000571146  0.0989524     0.0975894     0.0976437     0.0985139     0.0997231\n",
       "max_per_class_error      0.0296604  0.00116016   0.0317359     0.0279696     0.0293932     0.027839      0.0313646\n",
       "mcc                      0.96627    0.000795138  0.966167      0.967135      0.96556       0.967834      0.964653\n",
       "mean_per_class_accuracy  0.981484   0.000540021  0.980837      0.982237      0.981349      0.982476      0.980521\n",
       "mean_per_class_error     0.0185159  0.000540021  0.0191627     0.0177626     0.0186512     0.0175238     0.0194792\n",
       "mse                      0.0198387  0.000179418  0.0200267     0.0195677     0.0197068     0.0196522     0.0202399\n",
       "precision                0.981447   0.000771579  0.983385      0.980967      0.980306      0.981842      0.980734\n",
       "r2                       0.902976   0.000944809  0.90216       0.904184      0.904008      0.903801      0.900727\n",
       "recall                   0.97034    0.00116016   0.968264      0.97203       0.970607      0.972161      0.968635\n",
       "rmse                     0.140847   0.000635873  0.141516      0.139884      0.140381      0.140186      0.142267\n",
       "specificity              0.992629   0.000317939  0.993411      0.992444      0.992091      0.992791      0.992406"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>timestamp</b></td>\n",
       "<td><b>duration</b></td>\n",
       "<td><b>number_of_trees</b></td>\n",
       "<td><b>training_rmse</b></td>\n",
       "<td><b>training_logloss</b></td>\n",
       "<td><b>training_auc</b></td>\n",
       "<td><b>training_pr_auc</b></td>\n",
       "<td><b>training_lift</b></td>\n",
       "<td><b>training_classification_error</b></td>\n",
       "<td><b>validation_rmse</b></td>\n",
       "<td><b>validation_logloss</b></td>\n",
       "<td><b>validation_auc</b></td>\n",
       "<td><b>validation_pr_auc</b></td>\n",
       "<td><b>validation_lift</b></td>\n",
       "<td><b>validation_classification_error</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-12-11 20:57:15</td>\n",
       "<td> 3 min 19.834 sec</td>\n",
       "<td>0.0</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-12-11 20:57:16</td>\n",
       "<td> 3 min 20.186 sec</td>\n",
       "<td>1.0</td>\n",
       "<td>0.2275729</td>\n",
       "<td>0.8023489</td>\n",
       "<td>0.9643373</td>\n",
       "<td>0.2973424</td>\n",
       "<td>3.2871077</td>\n",
       "<td>0.0678526</td>\n",
       "<td>0.2279121</td>\n",
       "<td>0.7845200</td>\n",
       "<td>0.9645842</td>\n",
       "<td>0.3021248</td>\n",
       "<td>3.2463666</td>\n",
       "<td>0.0692386</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-12-11 20:57:16</td>\n",
       "<td> 3 min 20.516 sec</td>\n",
       "<td>2.0</td>\n",
       "<td>0.1947116</td>\n",
       "<td>0.5755505</td>\n",
       "<td>0.9754294</td>\n",
       "<td>0.2674530</td>\n",
       "<td>3.3580941</td>\n",
       "<td>0.0477174</td>\n",
       "<td>0.1637330</td>\n",
       "<td>0.1682876</td>\n",
       "<td>0.9918950</td>\n",
       "<td>0.4090383</td>\n",
       "<td>3.4077110</td>\n",
       "<td>0.0301219</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-12-11 20:57:16</td>\n",
       "<td> 3 min 20.899 sec</td>\n",
       "<td>3.0</td>\n",
       "<td>0.2134816</td>\n",
       "<td>0.4830622</td>\n",
       "<td>0.9741121</td>\n",
       "<td>0.3753213</td>\n",
       "<td>3.3749162</td>\n",
       "<td>0.0549736</td>\n",
       "<td>0.1680320</td>\n",
       "<td>0.1352552</td>\n",
       "<td>0.9942703</td>\n",
       "<td>0.6381483</td>\n",
       "<td>3.4221034</td>\n",
       "<td>0.0240856</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-12-11 20:57:17</td>\n",
       "<td> 3 min 21.359 sec</td>\n",
       "<td>4.0</td>\n",
       "<td>0.2066882</td>\n",
       "<td>0.4262715</td>\n",
       "<td>0.9769762</td>\n",
       "<td>0.4401881</td>\n",
       "<td>3.3820812</td>\n",
       "<td>0.0500909</td>\n",
       "<td>0.1618993</td>\n",
       "<td>0.1214420</td>\n",
       "<td>0.9954384</td>\n",
       "<td>0.7329649</td>\n",
       "<td>3.4246605</td>\n",
       "<td>0.0223524</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-12-11 20:57:17</td>\n",
       "<td> 3 min 21.859 sec</td>\n",
       "<td>5.0</td>\n",
       "<td>0.1937728</td>\n",
       "<td>0.3528538</td>\n",
       "<td>0.9816797</td>\n",
       "<td>0.4619649</td>\n",
       "<td>3.4018667</td>\n",
       "<td>0.0430413</td>\n",
       "<td>0.1506791</td>\n",
       "<td>0.1056986</td>\n",
       "<td>0.9970041</td>\n",
       "<td>0.7713415</td>\n",
       "<td>3.4253653</td>\n",
       "<td>0.0180194</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-12-11 20:57:18</td>\n",
       "<td> 3 min 22.433 sec</td>\n",
       "<td>6.0</td>\n",
       "<td>0.1869723</td>\n",
       "<td>0.3042406</td>\n",
       "<td>0.9844282</td>\n",
       "<td>0.4974868</td>\n",
       "<td>3.4114792</td>\n",
       "<td>0.0393220</td>\n",
       "<td>0.1467868</td>\n",
       "<td>0.0978622</td>\n",
       "<td>0.9974764</td>\n",
       "<td>0.7976991</td>\n",
       "<td>3.4300943</td>\n",
       "<td>0.0173918</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-12-11 20:57:18</td>\n",
       "<td> 3 min 23.078 sec</td>\n",
       "<td>7.0</td>\n",
       "<td>0.1854219</td>\n",
       "<td>0.2674861</td>\n",
       "<td>0.9861019</td>\n",
       "<td>0.5391322</td>\n",
       "<td>3.4207316</td>\n",
       "<td>0.0376572</td>\n",
       "<td>0.1490559</td>\n",
       "<td>0.1007377</td>\n",
       "<td>0.9975420</td>\n",
       "<td>0.8216224</td>\n",
       "<td>3.4300943</td>\n",
       "<td>0.0170033</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-12-11 20:57:19</td>\n",
       "<td> 3 min 23.758 sec</td>\n",
       "<td>8.0</td>\n",
       "<td>0.1872386</td>\n",
       "<td>0.2432327</td>\n",
       "<td>0.9869286</td>\n",
       "<td>0.5870945</td>\n",
       "<td>3.4287745</td>\n",
       "<td>0.0383898</td>\n",
       "<td>0.1540573</td>\n",
       "<td>0.1084683</td>\n",
       "<td>0.9974627</td>\n",
       "<td>0.8487917</td>\n",
       "<td>3.4300943</td>\n",
       "<td>0.0169137</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-12-11 20:57:23</td>\n",
       "<td> 3 min 27.842 sec</td>\n",
       "<td>20.0</td>\n",
       "<td>0.1502654</td>\n",
       "<td>0.1015057</td>\n",
       "<td>0.9972609</td>\n",
       "<td>0.8269213</td>\n",
       "<td>3.4858202</td>\n",
       "<td>0.0187077</td>\n",
       "<td>0.1376642</td>\n",
       "<td>0.0955218</td>\n",
       "<td>0.9983738</td>\n",
       "<td>0.9522312</td>\n",
       "<td>3.4300943</td>\n",
       "<td>0.0132680</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-12-11 20:57:27</td>\n",
       "<td> 3 min 31.979 sec</td>\n",
       "<td>31.0</td>\n",
       "<td>0.1450408</td>\n",
       "<td>0.0973989</td>\n",
       "<td>0.9980205</td>\n",
       "<td>0.8773195</td>\n",
       "<td>3.4887427</td>\n",
       "<td>0.0163495</td>\n",
       "<td>0.1371480</td>\n",
       "<td>0.0951007</td>\n",
       "<td>0.9984275</td>\n",
       "<td>0.9580318</td>\n",
       "<td>3.4300943</td>\n",
       "<td>0.0130887</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-12-11 20:57:32</td>\n",
       "<td> 3 min 37.002 sec</td>\n",
       "<td>44.0</td>\n",
       "<td>0.1427767</td>\n",
       "<td>0.0966466</td>\n",
       "<td>0.9982077</td>\n",
       "<td>0.9023397</td>\n",
       "<td>3.4887427</td>\n",
       "<td>0.0154665</td>\n",
       "<td>0.1372723</td>\n",
       "<td>0.0951708</td>\n",
       "<td>0.9984373</td>\n",
       "<td>0.9617304</td>\n",
       "<td>3.4300943</td>\n",
       "<td>0.0128795</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-12-11 20:57:35</td>\n",
       "<td> 3 min 39.588 sec</td>\n",
       "<td>50.0</td>\n",
       "<td>0.1422773</td>\n",
       "<td>0.0967380</td>\n",
       "<td>0.9982640</td>\n",
       "<td>0.9089612</td>\n",
       "<td>3.4887427</td>\n",
       "<td>0.0151080</td>\n",
       "<td>0.1374100</td>\n",
       "<td>0.0955319</td>\n",
       "<td>0.9984441</td>\n",
       "<td>0.9622318</td>\n",
       "<td>3.4300943</td>\n",
       "<td>0.0127600</td></tr></table></div>"
      ],
      "text/plain": [
       "    timestamp            duration          number_of_trees    training_rmse    training_logloss    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_auc    validation_pr_auc    validation_lift    validation_classification_error\n",
       "--  -------------------  ----------------  -----------------  ---------------  ------------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ----------------  -------------------  -----------------  ---------------------------------\n",
       "    2018-12-11 20:57:15  3 min 19.834 sec  0                  nan              nan                 nan             nan                nan              nan                              nan                nan                   nan               nan                  nan                nan\n",
       "    2018-12-11 20:57:16  3 min 20.186 sec  1                  0.227573         0.802349            0.964337        0.297342           3.28711          0.0678526                        0.227912           0.78452               0.964584          0.302125             3.24637            0.0692386\n",
       "    2018-12-11 20:57:16  3 min 20.516 sec  2                  0.194712         0.57555             0.975429        0.267453           3.35809          0.0477174                        0.163733           0.168288              0.991895          0.409038             3.40771            0.0301219\n",
       "    2018-12-11 20:57:16  3 min 20.899 sec  3                  0.213482         0.483062            0.974112        0.375321           3.37492          0.0549736                        0.168032           0.135255              0.99427           0.638148             3.4221             0.0240856\n",
       "    2018-12-11 20:57:17  3 min 21.359 sec  4                  0.206688         0.426271            0.976976        0.440188           3.38208          0.0500909                        0.161899           0.121442              0.995438          0.732965             3.42466            0.0223524\n",
       "    2018-12-11 20:57:17  3 min 21.859 sec  5                  0.193773         0.352854            0.98168         0.461965           3.40187          0.0430413                        0.150679           0.105699              0.997004          0.771341             3.42537            0.0180194\n",
       "    2018-12-11 20:57:18  3 min 22.433 sec  6                  0.186972         0.304241            0.984428        0.497487           3.41148          0.039322                         0.146787           0.0978622             0.997476          0.797699             3.43009            0.0173918\n",
       "    2018-12-11 20:57:18  3 min 23.078 sec  7                  0.185422         0.267486            0.986102        0.539132           3.42073          0.0376572                        0.149056           0.100738              0.997542          0.821622             3.43009            0.0170033\n",
       "    2018-12-11 20:57:19  3 min 23.758 sec  8                  0.187239         0.243233            0.986929        0.587094           3.42877          0.0383898                        0.154057           0.108468              0.997463          0.848792             3.43009            0.0169137\n",
       "    2018-12-11 20:57:23  3 min 27.842 sec  20                 0.150265         0.101506            0.997261        0.826921           3.48582          0.0187077                        0.137664           0.0955218             0.998374          0.952231             3.43009            0.013268\n",
       "    2018-12-11 20:57:27  3 min 31.979 sec  31                 0.145041         0.0973989           0.99802         0.87732            3.48874          0.0163495                        0.137148           0.0951007             0.998428          0.958032             3.43009            0.0130887\n",
       "    2018-12-11 20:57:32  3 min 37.002 sec  44                 0.142777         0.0966466           0.998208        0.90234            3.48874          0.0154665                        0.137272           0.0951708             0.998437          0.96173              3.43009            0.0128795\n",
       "    2018-12-11 20:57:35  3 min 39.588 sec  50                 0.142277         0.096738            0.998264        0.908961           3.48874          0.015108                         0.13741            0.0955319             0.998444          0.962232             3.43009            0.01276"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable Importances: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>variable</b></td>\n",
       "<td><b>relative_importance</b></td>\n",
       "<td><b>scaled_importance</b></td>\n",
       "<td><b>percentage</b></td></tr>\n",
       "<tr><td>city_id</td>\n",
       "<td>955775.3125000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.5581109</td></tr>\n",
       "<tr><td>state_id</td>\n",
       "<td>257751.2343750</td>\n",
       "<td>0.2696776</td>\n",
       "<td>0.1505100</td></tr>\n",
       "<tr><td>category_2</td>\n",
       "<td>160059.9062500</td>\n",
       "<td>0.1674660</td>\n",
       "<td>0.0934646</td></tr>\n",
       "<tr><td>category_1</td>\n",
       "<td>115193.4609375</td>\n",
       "<td>0.1205236</td>\n",
       "<td>0.0672655</td></tr>\n",
       "<tr><td>merchant_group_id</td>\n",
       "<td>70843.8906250</td>\n",
       "<td>0.0741219</td>\n",
       "<td>0.0413682</td></tr>\n",
       "<tr><td>subsector_id</td>\n",
       "<td>31761.3027344</td>\n",
       "<td>0.0332309</td>\n",
       "<td>0.0185465</td></tr>\n",
       "<tr><td>merchant_category_id</td>\n",
       "<td>19091.6308594</td>\n",
       "<td>0.0199750</td>\n",
       "<td>0.0111483</td></tr>\n",
       "<tr><td>most_recent_sales_range</td>\n",
       "<td>14489.4287109</td>\n",
       "<td>0.0151599</td>\n",
       "<td>0.0084609</td></tr>\n",
       "<tr><td>numerical_1</td>\n",
       "<td>11903.5019531</td>\n",
       "<td>0.0124543</td>\n",
       "<td>0.0069509</td></tr>\n",
       "<tr><td>most_recent_purchases_range</td>\n",
       "<td>10130.6972656</td>\n",
       "<td>0.0105995</td>\n",
       "<td>0.0059157</td></tr>\n",
       "<tr><td>numerical_2</td>\n",
       "<td>9703.4843750</td>\n",
       "<td>0.0101525</td>\n",
       "<td>0.0056662</td></tr>\n",
       "<tr><td>avg_purchases_lag3</td>\n",
       "<td>8831.2177734</td>\n",
       "<td>0.0092398</td>\n",
       "<td>0.0051569</td></tr>\n",
       "<tr><td>avg_purchases_lag6</td>\n",
       "<td>8387.1093750</td>\n",
       "<td>0.0087752</td>\n",
       "<td>0.0048975</td></tr>\n",
       "<tr><td>avg_purchases_lag12</td>\n",
       "<td>8357.7822266</td>\n",
       "<td>0.0087445</td>\n",
       "<td>0.0048804</td></tr>\n",
       "<tr><td>avg_sales_lag3</td>\n",
       "<td>8332.0605469</td>\n",
       "<td>0.0087176</td>\n",
       "<td>0.0048654</td></tr>\n",
       "<tr><td>avg_sales_lag12</td>\n",
       "<td>7839.9199219</td>\n",
       "<td>0.0082027</td>\n",
       "<td>0.0045780</td></tr>\n",
       "<tr><td>avg_sales_lag6</td>\n",
       "<td>7648.2841797</td>\n",
       "<td>0.0080022</td>\n",
       "<td>0.0044661</td></tr>\n",
       "<tr><td>active_months_lag12</td>\n",
       "<td>4748.7172852</td>\n",
       "<td>0.0049684</td>\n",
       "<td>0.0027729</td></tr>\n",
       "<tr><td>active_months_lag6</td>\n",
       "<td>1353.7655029</td>\n",
       "<td>0.0014164</td>\n",
       "<td>0.0007905</td></tr>\n",
       "<tr><td>active_months_lag3</td>\n",
       "<td>315.8672791</td>\n",
       "<td>0.0003305</td>\n",
       "<td>0.0001844</td></tr></table></div>"
      ],
      "text/plain": [
       "variable                     relative_importance    scaled_importance    percentage\n",
       "---------------------------  ---------------------  -------------------  ------------\n",
       "city_id                      955775                 1                    0.558111\n",
       "state_id                     257751                 0.269678             0.15051\n",
       "category_2                   160060                 0.167466             0.0934646\n",
       "category_1                   115193                 0.120524             0.0672655\n",
       "merchant_group_id            70843.9                0.0741219            0.0413682\n",
       "subsector_id                 31761.3                0.0332309            0.0185465\n",
       "merchant_category_id         19091.6                0.019975             0.0111483\n",
       "most_recent_sales_range      14489.4                0.0151599            0.00846089\n",
       "numerical_1                  11903.5                0.0124543            0.00695087\n",
       "most_recent_purchases_range  10130.7                0.0105995            0.00591567\n",
       "numerical_2                  9703.48                0.0101525            0.00566621\n",
       "avg_purchases_lag3           8831.22                0.00923985           0.00515686\n",
       "avg_purchases_lag6           8387.11                0.00877519           0.00489753\n",
       "avg_purchases_lag12          8357.78                0.00874451           0.0048804\n",
       "avg_sales_lag3               8332.06                0.00871759           0.00486538\n",
       "avg_sales_lag12              7839.92                0.00820268           0.00457801\n",
       "avg_sales_lag6               7648.28                0.00800218           0.0044661\n",
       "active_months_lag12          4748.72                0.00496845           0.00277294\n",
       "active_months_lag6           1353.77                0.00141641           0.000790511\n",
       "active_months_lag3           315.867                0.000330483          0.000184446"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aml.leader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'drf'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aml.leader.algo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['F0point5',\n",
       " 'F1',\n",
       " 'F2',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_bc',\n",
       " '_bcin',\n",
       " '_check_and_save_parm',\n",
       " '_check_targets',\n",
       " '_compute_algo',\n",
       " '_estimator_type',\n",
       " '_future',\n",
       " '_get_metrics',\n",
       " '_have_mojo',\n",
       " '_have_pojo',\n",
       " '_id',\n",
       " '_is_xvalidated',\n",
       " '_job',\n",
       " '_keyify_if_h2oframe',\n",
       " '_metrics_class',\n",
       " '_model_json',\n",
       " '_parms',\n",
       " '_plot',\n",
       " '_requires_training_frame',\n",
       " '_resolve_model',\n",
       " '_verify_training_frame_params',\n",
       " '_xval_keys',\n",
       " 'accuracy',\n",
       " 'actual_params',\n",
       " 'aic',\n",
       " 'algo',\n",
       " 'auc',\n",
       " 'balance_classes',\n",
       " 'biases',\n",
       " 'binomial_double_trees',\n",
       " 'build_tree_one_node',\n",
       " 'calibrate_model',\n",
       " 'calibration_frame',\n",
       " 'categorical_encoding',\n",
       " 'catoffsets',\n",
       " 'checkpoint',\n",
       " 'class_sampling_factors',\n",
       " 'coef',\n",
       " 'coef_norm',\n",
       " 'col_sample_rate_change_per_level',\n",
       " 'col_sample_rate_per_tree',\n",
       " 'confusion_matrix',\n",
       " 'convert_H2OXGBoostParams_2_XGBoostParams',\n",
       " 'cross_validation_fold_assignment',\n",
       " 'cross_validation_holdout_predictions',\n",
       " 'cross_validation_metrics_summary',\n",
       " 'cross_validation_models',\n",
       " 'cross_validation_predictions',\n",
       " 'custom_metric_func',\n",
       " 'deepfeatures',\n",
       " 'default_params',\n",
       " 'distribution',\n",
       " 'download_mojo',\n",
       " 'download_pojo',\n",
       " 'error',\n",
       " 'fallout',\n",
       " 'find_idx_by_threshold',\n",
       " 'find_threshold_by_max_metric',\n",
       " 'fit',\n",
       " 'fnr',\n",
       " 'fold_assignment',\n",
       " 'fold_column',\n",
       " 'fpr',\n",
       " 'full_parameters',\n",
       " 'gains_lift',\n",
       " 'get_params',\n",
       " 'get_xval_models',\n",
       " 'gini',\n",
       " 'have_mojo',\n",
       " 'have_pojo',\n",
       " 'histogram_type',\n",
       " 'ignore_const_cols',\n",
       " 'ignored_columns',\n",
       " 'is_cross_validated',\n",
       " 'join',\n",
       " 'keep_cross_validation_fold_assignment',\n",
       " 'keep_cross_validation_models',\n",
       " 'keep_cross_validation_predictions',\n",
       " 'logloss',\n",
       " 'mae',\n",
       " 'max_after_balance_size',\n",
       " 'max_confusion_matrix_size',\n",
       " 'max_depth',\n",
       " 'max_hit_ratio_k',\n",
       " 'max_per_class_error',\n",
       " 'max_runtime_secs',\n",
       " 'mcc',\n",
       " 'mean_per_class_error',\n",
       " 'mean_residual_deviance',\n",
       " 'metric',\n",
       " 'min_rows',\n",
       " 'min_split_improvement',\n",
       " 'missrate',\n",
       " 'mixin',\n",
       " 'model_id',\n",
       " 'model_performance',\n",
       " 'mse',\n",
       " 'mtries',\n",
       " 'nbins',\n",
       " 'nbins_cats',\n",
       " 'nbins_top_level',\n",
       " 'nfolds',\n",
       " 'normmul',\n",
       " 'normsub',\n",
       " 'ntrees',\n",
       " 'null_degrees_of_freedom',\n",
       " 'null_deviance',\n",
       " 'offset_column',\n",
       " 'params',\n",
       " 'parms',\n",
       " 'partial_plot',\n",
       " 'plot',\n",
       " 'pprint_coef',\n",
       " 'precision',\n",
       " 'predict',\n",
       " 'predict_leaf_node_assignment',\n",
       " 'r2',\n",
       " 'r2_stopping',\n",
       " 'recall',\n",
       " 'residual_degrees_of_freedom',\n",
       " 'residual_deviance',\n",
       " 'respmul',\n",
       " 'response_column',\n",
       " 'respsub',\n",
       " 'rmse',\n",
       " 'rmsle',\n",
       " 'roc',\n",
       " 'rotation',\n",
       " 'sample_rate',\n",
       " 'sample_rate_per_class',\n",
       " 'save_model_details',\n",
       " 'save_mojo',\n",
       " 'score_each_iteration',\n",
       " 'score_history',\n",
       " 'score_tree_interval',\n",
       " 'scoring_history',\n",
       " 'seed',\n",
       " 'sensitivity',\n",
       " 'set_params',\n",
       " 'show',\n",
       " 'specificity',\n",
       " 'staged_predict_proba',\n",
       " 'start',\n",
       " 'std_coef_plot',\n",
       " 'stopping_metric',\n",
       " 'stopping_rounds',\n",
       " 'stopping_tolerance',\n",
       " 'summary',\n",
       " 'tnr',\n",
       " 'tpr',\n",
       " 'train',\n",
       " 'training_frame',\n",
       " 'type',\n",
       " 'validation_frame',\n",
       " 'varimp',\n",
       " 'varimp_plot',\n",
       " 'weights',\n",
       " 'weights_column',\n",
       " 'xval_keys',\n",
       " 'xvals']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(aml.leader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_id</th>\n",
       "      <th>auc</th>\n",
       "      <th>logloss</th>\n",
       "      <th>mean_per_class_error</th>\n",
       "      <th>rmse</th>\n",
       "      <th>mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DRF_1_AutoML_20181211_205354</td>\n",
       "      <td>0.998415</td>\n",
       "      <td>0.098484</td>\n",
       "      <td>0.018678</td>\n",
       "      <td>0.140850</td>\n",
       "      <td>0.019839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DRF_1_AutoML_20181211_204538</td>\n",
       "      <td>0.998365</td>\n",
       "      <td>0.103154</td>\n",
       "      <td>0.020717</td>\n",
       "      <td>0.144604</td>\n",
       "      <td>0.020910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>StackedEnsemble_AllModels_AutoML_20181211_204538</td>\n",
       "      <td>0.998342</td>\n",
       "      <td>0.038458</td>\n",
       "      <td>0.020807</td>\n",
       "      <td>0.103479</td>\n",
       "      <td>0.010708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>StackedEnsemble_BestOfFamily_AutoML_20181211_2...</td>\n",
       "      <td>0.998342</td>\n",
       "      <td>0.038458</td>\n",
       "      <td>0.020807</td>\n",
       "      <td>0.103479</td>\n",
       "      <td>0.010708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XRT_1_AutoML_20181211_204538</td>\n",
       "      <td>0.998057</td>\n",
       "      <td>0.116858</td>\n",
       "      <td>0.023724</td>\n",
       "      <td>0.155790</td>\n",
       "      <td>0.024271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XRT_1_AutoML_20181211_205354</td>\n",
       "      <td>0.997643</td>\n",
       "      <td>0.125676</td>\n",
       "      <td>0.025922</td>\n",
       "      <td>0.164174</td>\n",
       "      <td>0.026953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GLM_grid_1_AutoML_20181211_204538_model_1</td>\n",
       "      <td>0.636805</td>\n",
       "      <td>0.558565</td>\n",
       "      <td>0.423959</td>\n",
       "      <td>0.433881</td>\n",
       "      <td>0.188253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GLM_grid_1_AutoML_20181211_205354_model_1</td>\n",
       "      <td>0.636805</td>\n",
       "      <td>0.558565</td>\n",
       "      <td>0.423959</td>\n",
       "      <td>0.433881</td>\n",
       "      <td>0.188253</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            model_id       auc   logloss  \\\n",
       "0                       DRF_1_AutoML_20181211_205354  0.998415  0.098484   \n",
       "1                       DRF_1_AutoML_20181211_204538  0.998365  0.103154   \n",
       "2   StackedEnsemble_AllModels_AutoML_20181211_204538  0.998342  0.038458   \n",
       "3  StackedEnsemble_BestOfFamily_AutoML_20181211_2...  0.998342  0.038458   \n",
       "4                       XRT_1_AutoML_20181211_204538  0.998057  0.116858   \n",
       "5                       XRT_1_AutoML_20181211_205354  0.997643  0.125676   \n",
       "6          GLM_grid_1_AutoML_20181211_204538_model_1  0.636805  0.558565   \n",
       "7          GLM_grid_1_AutoML_20181211_205354_model_1  0.636805  0.558565   \n",
       "\n",
       "   mean_per_class_error      rmse       mse  \n",
       "0              0.018678  0.140850  0.019839  \n",
       "1              0.020717  0.144604  0.020910  \n",
       "2              0.020807  0.103479  0.010708  \n",
       "3              0.020807  0.103479  0.010708  \n",
       "4              0.023724  0.155790  0.024271  \n",
       "5              0.025922  0.164174  0.026953  \n",
       "6              0.423959  0.433881  0.188253  \n",
       "7              0.423959  0.433881  0.188253  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aml_leaderboard_df=aml.leaderboard.as_data_frame()\n",
    "aml_leaderboard_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model ids for all models in the AutoML Leaderboard\n",
    "model_ids = list(aml.leaderboard['model_id'].as_data_frame().iloc[:,0])\n",
    "# Get the \"All Models\" Stacked Ensemble model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "se = h2o.get_model([mid for mid in model_ids if \"StackedEnsemble_AllModels\" in mid][0])\n",
    "# Get the Stacked Ensemble metalearner model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2ORandomForestEstimator :  Distributed Random Forest\n",
      "Model Key:  DRF_1_AutoML_20181211_205354\n",
      "\n",
      "\n",
      "ModelMetricsBinomial: drf\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.020242828646662245\n",
      "RMSE: 0.14227729490913948\n",
      "LogLoss: 0.09673799546133012\n",
      "Mean Per-Class Error: 0.01872350523172872\n",
      "AUC: 0.9982640258173935\n",
      "pr_auc: 0.9089612037582203\n",
      "Gini: 0.996528051634787\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.49174027253987507: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>N</b></td>\n",
       "<td><b>Y</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>N</td>\n",
       "<td>213435.0</td>\n",
       "<td>1453.0</td>\n",
       "<td>0.0068</td>\n",
       "<td> (1453.0/214888.0)</td></tr>\n",
       "<tr><td>Y</td>\n",
       "<td>3098.0</td>\n",
       "<td>83246.0</td>\n",
       "<td>0.0359</td>\n",
       "<td> (3098.0/86344.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>216533.0</td>\n",
       "<td>84699.0</td>\n",
       "<td>0.0151</td>\n",
       "<td> (4551.0/301232.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       N       Y      Error    Rate\n",
       "-----  ------  -----  -------  -----------------\n",
       "N      213435  1453   0.0068   (1453.0/214888.0)\n",
       "Y      3098    83246  0.0359   (3098.0/86344.0)\n",
       "Total  216533  84699  0.0151   (4551.0/301232.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.4917403</td>\n",
       "<td>0.9733927</td>\n",
       "<td>188.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.3549770</td>\n",
       "<td>0.9761585</td>\n",
       "<td>222.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.5960178</td>\n",
       "<td>0.9839807</td>\n",
       "<td>165.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.4917403</td>\n",
       "<td>0.9848920</td>\n",
       "<td>188.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9999810</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0000123</td>\n",
       "<td>1.0</td>\n",
       "<td>399.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9999810</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.4917403</td>\n",
       "<td>0.9629320</td>\n",
       "<td>188.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.3912923</td>\n",
       "<td>0.9810294</td>\n",
       "<td>212.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.4162169</td>\n",
       "<td>0.9812765</td>\n",
       "<td>206.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.49174      0.973393  188\n",
       "max f2                       0.354977     0.976159  222\n",
       "max f0point5                 0.596018     0.983981  165\n",
       "max accuracy                 0.49174      0.984892  188\n",
       "max precision                0.999981     1         0\n",
       "max recall                   1.23132e-05  1         399\n",
       "max specificity              0.999981     1         0\n",
       "max absolute_mcc             0.49174      0.962932  188\n",
       "max min_per_class_accuracy   0.391292     0.981029  212\n",
       "max mean_per_class_accuracy  0.416217     0.981276  206"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 28.66 %, avg score: 28.74 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>score</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>cumulative_score</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0245724</td>\n",
       "<td>1.0</td>\n",
       "<td>3.4887427</td>\n",
       "<td>3.4887427</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0857269</td>\n",
       "<td>0.0857269</td>\n",
       "<td>248.8742704</td>\n",
       "<td>248.8742704</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0300001</td>\n",
       "<td>0.9923801</td>\n",
       "<td>3.4887427</td>\n",
       "<td>3.4887427</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9960116</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9992784</td>\n",
       "<td>0.0189359</td>\n",
       "<td>0.1046627</td>\n",
       "<td>248.8742704</td>\n",
       "<td>248.8742704</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0400024</td>\n",
       "<td>0.9817353</td>\n",
       "<td>3.4887427</td>\n",
       "<td>3.4887427</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9873043</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9962844</td>\n",
       "<td>0.0348953</td>\n",
       "<td>0.1395580</td>\n",
       "<td>248.8742704</td>\n",
       "<td>248.8742704</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0500013</td>\n",
       "<td>0.9724944</td>\n",
       "<td>3.4887427</td>\n",
       "<td>3.4887427</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9772090</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9924698</td>\n",
       "<td>0.0348837</td>\n",
       "<td>0.1744418</td>\n",
       "<td>248.8742704</td>\n",
       "<td>248.8742704</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.1000060</td>\n",
       "<td>0.9298701</td>\n",
       "<td>3.4880479</td>\n",
       "<td>3.4883953</td>\n",
       "<td>0.9998008</td>\n",
       "<td>0.9503510</td>\n",
       "<td>0.9999004</td>\n",
       "<td>0.9714097</td>\n",
       "<td>0.1744186</td>\n",
       "<td>0.3488604</td>\n",
       "<td>248.8047873</td>\n",
       "<td>248.8395277</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1500007</td>\n",
       "<td>0.8884800</td>\n",
       "<td>3.4885110</td>\n",
       "<td>3.4884339</td>\n",
       "<td>0.9999336</td>\n",
       "<td>0.9095350</td>\n",
       "<td>0.9999115</td>\n",
       "<td>0.9507871</td>\n",
       "<td>0.1744070</td>\n",
       "<td>0.5232674</td>\n",
       "<td>248.8511047</td>\n",
       "<td>248.8433863</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.2000020</td>\n",
       "<td>0.8358737</td>\n",
       "<td>3.4873530</td>\n",
       "<td>3.4881636</td>\n",
       "<td>0.9996016</td>\n",
       "<td>0.8638037</td>\n",
       "<td>0.9998340</td>\n",
       "<td>0.9290409</td>\n",
       "<td>0.1743723</td>\n",
       "<td>0.6976397</td>\n",
       "<td>248.7352951</td>\n",
       "<td>248.8163630</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.3000013</td>\n",
       "<td>0.3581678</td>\n",
       "<td>2.8753781</td>\n",
       "<td>3.2839041</td>\n",
       "<td>0.8241875</td>\n",
       "<td>0.6756746</td>\n",
       "<td>0.9412858</td>\n",
       "<td>0.8445864</td>\n",
       "<td>0.2875359</td>\n",
       "<td>0.9851756</td>\n",
       "<td>187.5378120</td>\n",
       "<td>228.3904054</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.4000007</td>\n",
       "<td>0.1144822</td>\n",
       "<td>0.1351579</td>\n",
       "<td>2.4967241</td>\n",
       "<td>0.0387412</td>\n",
       "<td>0.2041120</td>\n",
       "<td>0.7156515</td>\n",
       "<td>0.6844691</td>\n",
       "<td>0.0135157</td>\n",
       "<td>0.9986913</td>\n",
       "<td>-86.4842056</td>\n",
       "<td>149.6724059</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0506433</td>\n",
       "<td>0.0044010</td>\n",
       "<td>1.9982628</td>\n",
       "<td>0.0012615</td>\n",
       "<td>0.0768782</td>\n",
       "<td>0.5727745</td>\n",
       "<td>0.5629517</td>\n",
       "<td>0.0004401</td>\n",
       "<td>0.9991314</td>\n",
       "<td>-99.5598970</td>\n",
       "<td>99.8262763</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.6000027</td>\n",
       "<td>0.0228758</td>\n",
       "<td>0.0026637</td>\n",
       "<td>1.6656556</td>\n",
       "<td>0.0007635</td>\n",
       "<td>0.0346323</td>\n",
       "<td>0.4774372</td>\n",
       "<td>0.4748965</td>\n",
       "<td>0.0002664</td>\n",
       "<td>0.9993978</td>\n",
       "<td>-99.7336307</td>\n",
       "<td>66.5655557</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.7000186</td>\n",
       "<td>0.0115814</td>\n",
       "<td>0.0020844</td>\n",
       "<td>1.4279710</td>\n",
       "<td>0.0005975</td>\n",
       "<td>0.0165641</td>\n",
       "<td>0.4093082</td>\n",
       "<td>0.4094118</td>\n",
       "<td>0.0002085</td>\n",
       "<td>0.9996062</td>\n",
       "<td>-99.7915648</td>\n",
       "<td>42.7970971</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.7999980</td>\n",
       "<td>0.0032095</td>\n",
       "<td>0.0028960</td>\n",
       "<td>1.2498728</td>\n",
       "<td>0.0008301</td>\n",
       "<td>0.0069621</td>\n",
       "<td>0.3582588</td>\n",
       "<td>0.3591158</td>\n",
       "<td>0.0002895</td>\n",
       "<td>0.9998958</td>\n",
       "<td>-99.7104009</td>\n",
       "<td>24.9872819</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0005212</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0001494</td>\n",
       "<td>0.0006021</td>\n",
       "<td>0.2866362</td>\n",
       "<td>0.2874123</td>\n",
       "<td>0.0001042</td>\n",
       "<td>1.0</td>\n",
       "<td>-99.9478834</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift         cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  -----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.0245724                   1                  3.48874      3.48874            1                1            1                           1                   0.0857269       0.0857269                  248.874   248.874\n",
       "    2        0.0300001                   0.99238            3.48874      3.48874            1                0.996012     1                           0.999278            0.0189359       0.104663                   248.874   248.874\n",
       "    3        0.0400024                   0.981735           3.48874      3.48874            1                0.987304     1                           0.996284            0.0348953       0.139558                   248.874   248.874\n",
       "    4        0.0500013                   0.972494           3.48874      3.48874            1                0.977209     1                           0.99247             0.0348837       0.174442                   248.874   248.874\n",
       "    5        0.100006                    0.92987            3.48805      3.4884             0.999801         0.950351     0.9999                      0.97141             0.174419        0.34886                    248.805   248.84\n",
       "    6        0.150001                    0.88848            3.48851      3.48843            0.999934         0.909535     0.999911                    0.950787            0.174407        0.523267                   248.851   248.843\n",
       "    7        0.200002                    0.835874           3.48735      3.48816            0.999602         0.863804     0.999834                    0.929041            0.174372        0.69764                    248.735   248.816\n",
       "    8        0.300001                    0.358168           2.87538      3.2839             0.824187         0.675675     0.941286                    0.844586            0.287536        0.985176                   187.538   228.39\n",
       "    9        0.400001                    0.114482           0.135158     2.49672            0.0387412        0.204112     0.715652                    0.684469            0.0135157       0.998691                   -86.4842  149.672\n",
       "    10       0.5                         0.0506433          0.00440103   1.99826            0.00126149       0.0768782    0.572774                    0.562952            0.0004401       0.999131                   -99.5599  99.8263\n",
       "    11       0.600003                    0.0228758          0.00266369   1.66566            0.000763511      0.0346323    0.477437                    0.474897            0.000266376     0.999398                   -99.7336  66.5656\n",
       "    12       0.700019                    0.0115814          0.00208435   1.42797            0.000597451      0.0165641    0.409308                    0.409412            0.000208468     0.999606                   -99.7916  42.7971\n",
       "    13       0.799998                    0.00320951         0.00289599   1.24987            0.000830096      0.00696211   0.358259                    0.359116            0.00028954      0.999896                   -99.7104  24.9873\n",
       "    14       1                           0                  0.000521166  1                  0.000149385      0.000602119  0.286636                    0.287412            0.000104234     1                          -99.9479  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: drf\n",
      "** Reported on validation data. **\n",
      "\n",
      "MSE: 0.018881497714415916\n",
      "RMSE: 0.1374099622094989\n",
      "LogLoss: 0.0955319096107168\n",
      "Mean Per-Class Error: 0.015262034263669788\n",
      "AUC: 0.9984440687687627\n",
      "pr_auc: 0.9622318205609467\n",
      "Gini: 0.9968881375375254\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4416887505133839: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>N</b></td>\n",
       "<td><b>Y</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>N</td>\n",
       "<td>23520.0</td>\n",
       "<td>188.0</td>\n",
       "<td>0.0079</td>\n",
       "<td> (188.0/23708.0)</td></tr>\n",
       "<tr><td>Y</td>\n",
       "<td>239.0</td>\n",
       "<td>9517.0</td>\n",
       "<td>0.0245</td>\n",
       "<td> (239.0/9756.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>23759.0</td>\n",
       "<td>9705.0</td>\n",
       "<td>0.0128</td>\n",
       "<td> (427.0/33464.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       N      Y     Error    Rate\n",
       "-----  -----  ----  -------  ---------------\n",
       "N      23520  188   0.0079   (188.0/23708.0)\n",
       "Y      239    9517  0.0245   (239.0/9756.0)\n",
       "Total  23759  9705  0.0128   (427.0/33464.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.4416888</td>\n",
       "<td>0.9780587</td>\n",
       "<td>195.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.3852141</td>\n",
       "<td>0.9802661</td>\n",
       "<td>210.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.6038533</td>\n",
       "<td>0.9869264</td>\n",
       "<td>161.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.4482769</td>\n",
       "<td>0.9872400</td>\n",
       "<td>193.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9999085</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0044250</td>\n",
       "<td>1.0</td>\n",
       "<td>394.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9999085</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.4416888</td>\n",
       "<td>0.9690697</td>\n",
       "<td>195.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.3852141</td>\n",
       "<td>0.9843513</td>\n",
       "<td>210.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.3914551</td>\n",
       "<td>0.9847380</td>\n",
       "<td>208.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.441689     0.978059  195\n",
       "max f2                       0.385214     0.980266  210\n",
       "max f0point5                 0.603853     0.986926  161\n",
       "max accuracy                 0.448277     0.98724   193\n",
       "max precision                0.999909     1         0\n",
       "max recall                   0.004425     1         394\n",
       "max specificity              0.999909     1         0\n",
       "max absolute_mcc             0.441689     0.96907   195\n",
       "max min_per_class_accuracy   0.385214     0.984351  210\n",
       "max mean_per_class_accuracy  0.391455     0.984738  208"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 29.15 %, avg score: 29.08 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>score</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>cumulative_score</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0100108</td>\n",
       "<td>0.9984228</td>\n",
       "<td>3.4300943</td>\n",
       "<td>3.4300943</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999521</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999521</td>\n",
       "<td>0.0343378</td>\n",
       "<td>0.0343378</td>\n",
       "<td>243.0094301</td>\n",
       "<td>243.0094301</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0200514</td>\n",
       "<td>0.9915056</td>\n",
       "<td>3.4300943</td>\n",
       "<td>3.4300943</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9932968</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9966195</td>\n",
       "<td>0.0344403</td>\n",
       "<td>0.0687782</td>\n",
       "<td>243.0094301</td>\n",
       "<td>243.0094301</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0307495</td>\n",
       "<td>0.9817939</td>\n",
       "<td>3.4300943</td>\n",
       "<td>3.4300943</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9859367</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9929028</td>\n",
       "<td>0.0366954</td>\n",
       "<td>0.1054736</td>\n",
       "<td>243.0094301</td>\n",
       "<td>243.0094301</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0400131</td>\n",
       "<td>0.9722330</td>\n",
       "<td>3.4300943</td>\n",
       "<td>3.4300943</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9778358</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9894146</td>\n",
       "<td>0.0317753</td>\n",
       "<td>0.1372489</td>\n",
       "<td>243.0094301</td>\n",
       "<td>243.0094301</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0500239</td>\n",
       "<td>0.9638823</td>\n",
       "<td>3.4300943</td>\n",
       "<td>3.4300943</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9674898</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9850270</td>\n",
       "<td>0.0343378</td>\n",
       "<td>0.1715867</td>\n",
       "<td>243.0094301</td>\n",
       "<td>243.0094301</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1000179</td>\n",
       "<td>0.9218599</td>\n",
       "<td>3.4300943</td>\n",
       "<td>3.4300943</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9416622</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9633511</td>\n",
       "<td>0.1714842</td>\n",
       "<td>0.3430709</td>\n",
       "<td>243.0094301</td>\n",
       "<td>243.0094301</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1500120</td>\n",
       "<td>0.8882195</td>\n",
       "<td>3.4300943</td>\n",
       "<td>3.4300943</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9053718</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9440285</td>\n",
       "<td>0.1714842</td>\n",
       "<td>0.5145551</td>\n",
       "<td>243.0094301</td>\n",
       "<td>243.0094301</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2000060</td>\n",
       "<td>0.8421777</td>\n",
       "<td>3.4280440</td>\n",
       "<td>3.4295818</td>\n",
       "<td>0.9994023</td>\n",
       "<td>0.8670677</td>\n",
       "<td>0.9998506</td>\n",
       "<td>0.9247912</td>\n",
       "<td>0.1713817</td>\n",
       "<td>0.6859369</td>\n",
       "<td>242.8044035</td>\n",
       "<td>242.9581811</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.2999940</td>\n",
       "<td>0.3708652</td>\n",
       "<td>2.9964631</td>\n",
       "<td>3.2852233</td>\n",
       "<td>0.8735804</td>\n",
       "<td>0.7020466</td>\n",
       "<td>0.9577647</td>\n",
       "<td>0.8505504</td>\n",
       "<td>0.2996105</td>\n",
       "<td>0.9855474</td>\n",
       "<td>199.6463133</td>\n",
       "<td>228.5223299</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4000120</td>\n",
       "<td>0.1124730</td>\n",
       "<td>0.1311778</td>\n",
       "<td>2.4965941</td>\n",
       "<td>0.0382432</td>\n",
       "<td>0.2071155</td>\n",
       "<td>0.7278500</td>\n",
       "<td>0.6896676</td>\n",
       "<td>0.0131201</td>\n",
       "<td>0.9986675</td>\n",
       "<td>-86.8822208</td>\n",
       "<td>149.6594111</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0486775</td>\n",
       "<td>0.0020503</td>\n",
       "<td>1.9977450</td>\n",
       "<td>0.0005977</td>\n",
       "<td>0.0752963</td>\n",
       "<td>0.5824169</td>\n",
       "<td>0.5668081</td>\n",
       "<td>0.0002050</td>\n",
       "<td>0.9988725</td>\n",
       "<td>-99.7949734</td>\n",
       "<td>99.7744977</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.6000179</td>\n",
       "<td>0.0250341</td>\n",
       "<td>0.0030745</td>\n",
       "<td>1.6652502</td>\n",
       "<td>0.0008963</td>\n",
       "<td>0.0353917</td>\n",
       "<td>0.4854823</td>\n",
       "<td>0.4782254</td>\n",
       "<td>0.0003075</td>\n",
       "<td>0.9991800</td>\n",
       "<td>-99.6925520</td>\n",
       "<td>66.5250224</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.7000060</td>\n",
       "<td>0.0144942</td>\n",
       "<td>0.0020503</td>\n",
       "<td>1.4276807</td>\n",
       "<td>0.0005977</td>\n",
       "<td>0.0190908</td>\n",
       "<td>0.4162220</td>\n",
       "<td>0.4126432</td>\n",
       "<td>0.0002050</td>\n",
       "<td>0.9993850</td>\n",
       "<td>-99.7949734</td>\n",
       "<td>42.7680659</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.8000239</td>\n",
       "<td>0.0087596</td>\n",
       "<td>0.0030745</td>\n",
       "<td>1.2495783</td>\n",
       "<td>0.0008963</td>\n",
       "<td>0.0113545</td>\n",
       "<td>0.3642985</td>\n",
       "<td>0.3624746</td>\n",
       "<td>0.0003075</td>\n",
       "<td>0.9996925</td>\n",
       "<td>-99.6925520</td>\n",
       "<td>24.9578280</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.8999821</td>\n",
       "<td>0.0040031</td>\n",
       "<td>0.0020509</td>\n",
       "<td>1.1110194</td>\n",
       "<td>0.0005979</td>\n",
       "<td>0.0063164</td>\n",
       "<td>0.3239034</td>\n",
       "<td>0.3229172</td>\n",
       "<td>0.0002050</td>\n",
       "<td>0.9998975</td>\n",
       "<td>-99.7949121</td>\n",
       "<td>11.1019355</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0010248</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0002988</td>\n",
       "<td>0.0016149</td>\n",
       "<td>0.2915372</td>\n",
       "<td>0.2907812</td>\n",
       "<td>0.0001025</td>\n",
       "<td>1.0</td>\n",
       "<td>-99.8975173</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.0100108                   0.998423           3.43009     3.43009            1                0.999952    1                           0.999952            0.0343378       0.0343378                  243.009   243.009\n",
       "    2        0.0200514                   0.991506           3.43009     3.43009            1                0.993297    1                           0.99662             0.0344403       0.0687782                  243.009   243.009\n",
       "    3        0.0307495                   0.981794           3.43009     3.43009            1                0.985937    1                           0.992903            0.0366954       0.105474                   243.009   243.009\n",
       "    4        0.0400131                   0.972233           3.43009     3.43009            1                0.977836    1                           0.989415            0.0317753       0.137249                   243.009   243.009\n",
       "    5        0.0500239                   0.963882           3.43009     3.43009            1                0.96749     1                           0.985027            0.0343378       0.171587                   243.009   243.009\n",
       "    6        0.100018                    0.92186            3.43009     3.43009            1                0.941662    1                           0.963351            0.171484        0.343071                   243.009   243.009\n",
       "    7        0.150012                    0.88822            3.43009     3.43009            1                0.905372    1                           0.944028            0.171484        0.514555                   243.009   243.009\n",
       "    8        0.200006                    0.842178           3.42804     3.42958            0.999402         0.867068    0.999851                    0.924791            0.171382        0.685937                   242.804   242.958\n",
       "    9        0.299994                    0.370865           2.99646     3.28522            0.87358          0.702047    0.957765                    0.85055             0.29961         0.985547                   199.646   228.522\n",
       "    10       0.400012                    0.112473           0.131178    2.49659            0.0382432        0.207116    0.72785                     0.689668            0.0131201       0.998667                   -86.8822  149.659\n",
       "    11       0.5                         0.0486775          0.00205027  1.99774            0.000597729      0.0752963   0.582417                    0.566808            0.000205002     0.998872                   -99.795   99.7745\n",
       "    12       0.600018                    0.0250341          0.00307448  1.66525            0.000896325      0.0353917   0.485482                    0.478225            0.000307503     0.99918                    -99.6926  66.525\n",
       "    13       0.700006                    0.0144942          0.00205027  1.42768            0.000597729      0.0190908   0.416222                    0.412643            0.000205002     0.999385                   -99.795   42.7681\n",
       "    14       0.800024                    0.00875963         0.00307448  1.24958            0.000896325      0.0113545   0.364299                    0.362475            0.000307503     0.999692                   -99.6926  24.9578\n",
       "    15       0.899982                    0.00400315         0.00205088  1.11102            0.000597907      0.0063164   0.323903                    0.322917            0.000205002     0.999897                   -99.7949  11.1019\n",
       "    16       1                           0                  0.00102483  1                  0.000298775      0.00161486  0.291537                    0.290781            0.000102501     1                          -99.8975  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: drf\n",
      "** Reported on cross-validation data. **\n",
      "\n",
      "MSE: 0.019838655136353946\n",
      "RMSE: 0.14084976086722314\n",
      "LogLoss: 0.09848448113892687\n",
      "Mean Per-Class Error: 0.01697642178512626\n",
      "AUC: 0.9984149199275788\n",
      "pr_auc: 0.9438620129204796\n",
      "Gini: 0.9968298398551576\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4721316665854305: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>N</b></td>\n",
       "<td><b>Y</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>N</td>\n",
       "<td>213304.0</td>\n",
       "<td>1584.0</td>\n",
       "<td>0.0074</td>\n",
       "<td> (1584.0/214888.0)</td></tr>\n",
       "<tr><td>Y</td>\n",
       "<td>2589.0</td>\n",
       "<td>83755.0</td>\n",
       "<td>0.03</td>\n",
       "<td> (2589.0/86344.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>215893.0</td>\n",
       "<td>85339.0</td>\n",
       "<td>0.0139</td>\n",
       "<td> (4173.0/301232.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       N       Y      Error    Rate\n",
       "-----  ------  -----  -------  -----------------\n",
       "N      213304  1584   0.0074   (1584.0/214888.0)\n",
       "Y      2589    83755  0.03     (2589.0/86344.0)\n",
       "Total  215893  85339  0.0139   (4173.0/301232.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.4721317</td>\n",
       "<td>0.9756936</td>\n",
       "<td>186.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.3610743</td>\n",
       "<td>0.9781708</td>\n",
       "<td>216.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.5859488</td>\n",
       "<td>0.9856473</td>\n",
       "<td>162.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.4721317</td>\n",
       "<td>0.9861469</td>\n",
       "<td>186.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9999495</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0013795</td>\n",
       "<td>1.0</td>\n",
       "<td>397.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9999495</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.4721317</td>\n",
       "<td>0.9660394</td>\n",
       "<td>186.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.3911902</td>\n",
       "<td>0.9824606</td>\n",
       "<td>207.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.4120424</td>\n",
       "<td>0.9830236</td>\n",
       "<td>201.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.472132     0.975694  186\n",
       "max f2                       0.361074     0.978171  216\n",
       "max f0point5                 0.585949     0.985647  162\n",
       "max accuracy                 0.472132     0.986147  186\n",
       "max precision                0.999949     1         0\n",
       "max recall                   0.00137952   1         397\n",
       "max specificity              0.999949     1         0\n",
       "max absolute_mcc             0.472132     0.966039  186\n",
       "max min_per_class_accuracy   0.39119      0.982461  207\n",
       "max mean_per_class_accuracy  0.412042     0.983024  201"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 28.66 %, avg score: 28.75 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>score</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>cumulative_score</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0140490</td>\n",
       "<td>1.0</td>\n",
       "<td>3.4887427</td>\n",
       "<td>3.4887427</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0490132</td>\n",
       "<td>0.0490132</td>\n",
       "<td>248.8742704</td>\n",
       "<td>248.8742704</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0200311</td>\n",
       "<td>0.9953594</td>\n",
       "<td>3.4887427</td>\n",
       "<td>3.4887427</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9974951</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9992519</td>\n",
       "<td>0.0208700</td>\n",
       "<td>0.0698833</td>\n",
       "<td>248.8742704</td>\n",
       "<td>248.8742704</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0301263</td>\n",
       "<td>0.9863092</td>\n",
       "<td>3.4887427</td>\n",
       "<td>3.4887427</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9906092</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9963558</td>\n",
       "<td>0.0352196</td>\n",
       "<td>0.1051028</td>\n",
       "<td>248.8742704</td>\n",
       "<td>248.8742704</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0400024</td>\n",
       "<td>0.9741634</td>\n",
       "<td>3.4887427</td>\n",
       "<td>3.4887427</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9807678</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9925073</td>\n",
       "<td>0.0344552</td>\n",
       "<td>0.1395580</td>\n",
       "<td>248.8742704</td>\n",
       "<td>248.8742704</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0500013</td>\n",
       "<td>0.9587926</td>\n",
       "<td>3.4887427</td>\n",
       "<td>3.4887427</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9660452</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9872156</td>\n",
       "<td>0.0348837</td>\n",
       "<td>0.1744418</td>\n",
       "<td>248.8742704</td>\n",
       "<td>248.8742704</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1000027</td>\n",
       "<td>0.9146654</td>\n",
       "<td>3.4887427</td>\n",
       "<td>3.4887427</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9343891</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9608024</td>\n",
       "<td>0.1744418</td>\n",
       "<td>0.3488835</td>\n",
       "<td>248.8742704</td>\n",
       "<td>248.8742704</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1500007</td>\n",
       "<td>0.8794678</td>\n",
       "<td>3.4885111</td>\n",
       "<td>3.4886655</td>\n",
       "<td>0.9999336</td>\n",
       "<td>0.8973287</td>\n",
       "<td>0.9999779</td>\n",
       "<td>0.9396454</td>\n",
       "<td>0.1744186</td>\n",
       "<td>0.5233021</td>\n",
       "<td>248.8511063</td>\n",
       "<td>248.8665493</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2000020</td>\n",
       "<td>0.8359674</td>\n",
       "<td>3.4882795</td>\n",
       "<td>3.4885690</td>\n",
       "<td>0.9998672</td>\n",
       "<td>0.8590832</td>\n",
       "<td>0.9999502</td>\n",
       "<td>0.9195045</td>\n",
       "<td>0.1744186</td>\n",
       "<td>0.6977207</td>\n",
       "<td>248.8279453</td>\n",
       "<td>248.8568982</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3000013</td>\n",
       "<td>0.3577441</td>\n",
       "<td>2.8957618</td>\n",
       "<td>3.2909688</td>\n",
       "<td>0.8300302</td>\n",
       "<td>0.6803003</td>\n",
       "<td>0.9433108</td>\n",
       "<td>0.8397707</td>\n",
       "<td>0.2895743</td>\n",
       "<td>0.9872950</td>\n",
       "<td>189.5761837</td>\n",
       "<td>229.0968787</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4000007</td>\n",
       "<td>0.1138118</td>\n",
       "<td>0.1148900</td>\n",
       "<td>2.4969557</td>\n",
       "<td>0.0329316</td>\n",
       "<td>0.2046500</td>\n",
       "<td>0.7157179</td>\n",
       "<td>0.6809918</td>\n",
       "<td>0.0114889</td>\n",
       "<td>0.9987839</td>\n",
       "<td>-88.5109957</td>\n",
       "<td>149.6955691</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0508306</td>\n",
       "<td>0.0033587</td>\n",
       "<td>1.9982396</td>\n",
       "<td>0.0009627</td>\n",
       "<td>0.0769064</td>\n",
       "<td>0.5727678</td>\n",
       "<td>0.5601755</td>\n",
       "<td>0.0003359</td>\n",
       "<td>0.9991198</td>\n",
       "<td>-99.6641319</td>\n",
       "<td>99.8239600</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.5999993</td>\n",
       "<td>0.0265169</td>\n",
       "<td>0.0013898</td>\n",
       "<td>1.6654331</td>\n",
       "<td>0.0003984</td>\n",
       "<td>0.0369419</td>\n",
       "<td>0.4773735</td>\n",
       "<td>0.4729704</td>\n",
       "<td>0.0001390</td>\n",
       "<td>0.9992588</td>\n",
       "<td>-99.8610201</td>\n",
       "<td>66.5433141</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.6999987</td>\n",
       "<td>0.0145751</td>\n",
       "<td>0.0019689</td>\n",
       "<td>1.4277965</td>\n",
       "<td>0.0005644</td>\n",
       "<td>0.0201392</td>\n",
       "<td>0.4092582</td>\n",
       "<td>0.4082805</td>\n",
       "<td>0.0001969</td>\n",
       "<td>0.9994557</td>\n",
       "<td>-99.8031118</td>\n",
       "<td>42.7796517</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.8001441</td>\n",
       "<td>0.0076869</td>\n",
       "<td>0.0028912</td>\n",
       "<td>1.2494565</td>\n",
       "<td>0.0008287</td>\n",
       "<td>0.0107899</td>\n",
       "<td>0.3581395</td>\n",
       "<td>0.3585309</td>\n",
       "<td>0.0002895</td>\n",
       "<td>0.9997452</td>\n",
       "<td>-99.7108809</td>\n",
       "<td>24.9456487</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.8999973</td>\n",
       "<td>0.0025570</td>\n",
       "<td>0.0020877</td>\n",
       "<td>1.1110629</td>\n",
       "<td>0.0005984</td>\n",
       "<td>0.0051052</td>\n",
       "<td>0.3184709</td>\n",
       "<td>0.3193189</td>\n",
       "<td>0.0002085</td>\n",
       "<td>0.9999537</td>\n",
       "<td>-99.7912252</td>\n",
       "<td>11.1062916</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0004633</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0001328</td>\n",
       "<td>0.0008872</td>\n",
       "<td>0.2866362</td>\n",
       "<td>0.2874749</td>\n",
       "<td>0.0000463</td>\n",
       "<td>1.0</td>\n",
       "<td>-99.9536749</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift         cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  -----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.014049                    1                  3.48874      3.48874            1                1            1                           1                   0.0490132       0.0490132                  248.874   248.874\n",
       "    2        0.0200311                   0.995359           3.48874      3.48874            1                0.997495     1                           0.999252            0.02087         0.0698833                  248.874   248.874\n",
       "    3        0.0301263                   0.986309           3.48874      3.48874            1                0.990609     1                           0.996356            0.0352196       0.105103                   248.874   248.874\n",
       "    4        0.0400024                   0.974163           3.48874      3.48874            1                0.980768     1                           0.992507            0.0344552       0.139558                   248.874   248.874\n",
       "    5        0.0500013                   0.958793           3.48874      3.48874            1                0.966045     1                           0.987216            0.0348837       0.174442                   248.874   248.874\n",
       "    6        0.100003                    0.914665           3.48874      3.48874            1                0.934389     1                           0.960802            0.174442        0.348884                   248.874   248.874\n",
       "    7        0.150001                    0.879468           3.48851      3.48867            0.999934         0.897329     0.999978                    0.939645            0.174419        0.523302                   248.851   248.867\n",
       "    8        0.200002                    0.835967           3.48828      3.48857            0.999867         0.859083     0.99995                     0.919505            0.174419        0.697721                   248.828   248.857\n",
       "    9        0.300001                    0.357744           2.89576      3.29097            0.83003          0.6803       0.943311                    0.839771            0.289574        0.987295                   189.576   229.097\n",
       "    10       0.400001                    0.113812           0.11489      2.49696            0.0329316        0.20465      0.715718                    0.680992            0.0114889       0.998784                   -88.511   149.696\n",
       "    11       0.5                         0.0508306          0.00335868   1.99824            0.00096272       0.0769064    0.572768                    0.560176            0.000335866     0.99912                    -99.6641  99.824\n",
       "    12       0.599999                    0.0265169          0.0013898    1.66543            0.000398367      0.0369419    0.477373                    0.47297             0.000138979     0.999259                   -99.861   66.5433\n",
       "    13       0.699999                    0.0145751          0.00196888   1.4278             0.000564353      0.0201392    0.409258                    0.408281            0.000196887     0.999456                   -99.8031  42.7797\n",
       "    14       0.800144                    0.00768693         0.00289119   1.24946            0.00082872       0.0107899    0.358139                    0.358531            0.00028954      0.999745                   -99.7109  24.9456\n",
       "    15       0.899997                    0.002557           0.00208775   1.11106            0.000598424      0.00510517   0.318471                    0.319319            0.000208468     0.999954                   -99.7912  11.1063\n",
       "    16       1                           0                  0.000463251  1                  0.000132784      0.000887211  0.286636                    0.287475            4.63263e-05     1                          -99.9537  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-Validation Metrics Summary: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>mean</b></td>\n",
       "<td><b>sd</b></td>\n",
       "<td><b>cv_1_valid</b></td>\n",
       "<td><b>cv_2_valid</b></td>\n",
       "<td><b>cv_3_valid</b></td>\n",
       "<td><b>cv_4_valid</b></td>\n",
       "<td><b>cv_5_valid</b></td></tr>\n",
       "<tr><td>accuracy</td>\n",
       "<td>0.9862399</td>\n",
       "<td>0.0003246</td>\n",
       "<td>0.9861902</td>\n",
       "<td>0.9866052</td>\n",
       "<td>0.9858912</td>\n",
       "<td>0.9868871</td>\n",
       "<td>0.9856256</td></tr>\n",
       "<tr><td>auc</td>\n",
       "<td>0.9984168</td>\n",
       "<td>0.0000323</td>\n",
       "<td>0.9984430</td>\n",
       "<td>0.9983832</td>\n",
       "<td>0.9983691</td>\n",
       "<td>0.9984936</td>\n",
       "<td>0.9983954</td></tr>\n",
       "<tr><td>err</td>\n",
       "<td>0.0137602</td>\n",
       "<td>0.0003246</td>\n",
       "<td>0.0138098</td>\n",
       "<td>0.0133949</td>\n",
       "<td>0.0141088</td>\n",
       "<td>0.0131129</td>\n",
       "<td>0.0143744</td></tr>\n",
       "<tr><td>err_count</td>\n",
       "<td>829.0</td>\n",
       "<td>19.55505</td>\n",
       "<td>832.0</td>\n",
       "<td>807.0</td>\n",
       "<td>850.0</td>\n",
       "<td>790.0</td>\n",
       "<td>866.0</td></tr>\n",
       "<tr><td>f0point5</td>\n",
       "<td>0.9792042</td>\n",
       "<td>0.0005735</td>\n",
       "<td>0.9803233</td>\n",
       "<td>0.9791669</td>\n",
       "<td>0.9783503</td>\n",
       "<td>0.9798901</td>\n",
       "<td>0.9782903</td></tr>\n",
       "<tr><td>f1</td>\n",
       "<td>0.9758602</td>\n",
       "<td>0.0005739</td>\n",
       "<td>0.9757661</td>\n",
       "<td>0.9764785</td>\n",
       "<td>0.9754321</td>\n",
       "<td>0.9769773</td>\n",
       "<td>0.9746472</td></tr>\n",
       "<tr><td>f2</td>\n",
       "<td>0.97254</td>\n",
       "<td>0.0008897</td>\n",
       "<td>0.9712509</td>\n",
       "<td>0.9738048</td>\n",
       "<td>0.9725312</td>\n",
       "<td>0.9740818</td>\n",
       "<td>0.9710313</td></tr>\n",
       "<tr><td>lift_top_group</td>\n",
       "<td>3.4887974</td>\n",
       "<td>0.0097586</td>\n",
       "<td>3.4826868</td>\n",
       "<td>3.496025</td>\n",
       "<td>3.4654012</td>\n",
       "<td>3.4941423</td>\n",
       "<td>3.5057318</td></tr>\n",
       "<tr><td>logloss</td>\n",
       "<td>0.0984845</td>\n",
       "<td>0.0005711</td>\n",
       "<td>0.0989524</td>\n",
       "<td>0.0975894</td>\n",
       "<td>0.0976437</td>\n",
       "<td>0.0985139</td>\n",
       "<td>0.0997231</td></tr>\n",
       "<tr><td>max_per_class_error</td>\n",
       "<td>0.0296604</td>\n",
       "<td>0.0011602</td>\n",
       "<td>0.0317359</td>\n",
       "<td>0.0279696</td>\n",
       "<td>0.0293932</td>\n",
       "<td>0.0278390</td>\n",
       "<td>0.0313646</td></tr>\n",
       "<tr><td>mcc</td>\n",
       "<td>0.9662698</td>\n",
       "<td>0.0007951</td>\n",
       "<td>0.9661673</td>\n",
       "<td>0.9671350</td>\n",
       "<td>0.96556</td>\n",
       "<td>0.9678338</td>\n",
       "<td>0.9646531</td></tr>\n",
       "<tr><td>mean_per_class_accuracy</td>\n",
       "<td>0.9814841</td>\n",
       "<td>0.0005400</td>\n",
       "<td>0.9808374</td>\n",
       "<td>0.9822373</td>\n",
       "<td>0.9813487</td>\n",
       "<td>0.9824762</td>\n",
       "<td>0.9805208</td></tr>\n",
       "<tr><td>mean_per_class_error</td>\n",
       "<td>0.0185159</td>\n",
       "<td>0.0005400</td>\n",
       "<td>0.0191627</td>\n",
       "<td>0.0177626</td>\n",
       "<td>0.0186512</td>\n",
       "<td>0.0175238</td>\n",
       "<td>0.0194792</td></tr>\n",
       "<tr><td>mse</td>\n",
       "<td>0.0198387</td>\n",
       "<td>0.0001794</td>\n",
       "<td>0.0200267</td>\n",
       "<td>0.0195677</td>\n",
       "<td>0.0197068</td>\n",
       "<td>0.0196522</td>\n",
       "<td>0.0202399</td></tr>\n",
       "<tr><td>precision</td>\n",
       "<td>0.9814468</td>\n",
       "<td>0.0007716</td>\n",
       "<td>0.9833852</td>\n",
       "<td>0.9809675</td>\n",
       "<td>0.9803056</td>\n",
       "<td>0.9818416</td>\n",
       "<td>0.9807341</td></tr>\n",
       "<tr><td>r2</td>\n",
       "<td>0.9029759</td>\n",
       "<td>0.0009448</td>\n",
       "<td>0.9021599</td>\n",
       "<td>0.9041837</td>\n",
       "<td>0.9040078</td>\n",
       "<td>0.9038008</td>\n",
       "<td>0.9007272</td></tr>\n",
       "<tr><td>recall</td>\n",
       "<td>0.9703395</td>\n",
       "<td>0.0011602</td>\n",
       "<td>0.9682640</td>\n",
       "<td>0.9720304</td>\n",
       "<td>0.9706069</td>\n",
       "<td>0.972161</td>\n",
       "<td>0.9686354</td></tr>\n",
       "<tr><td>rmse</td>\n",
       "<td>0.1408469</td>\n",
       "<td>0.0006359</td>\n",
       "<td>0.1415158</td>\n",
       "<td>0.1398845</td>\n",
       "<td>0.1403809</td>\n",
       "<td>0.1401864</td>\n",
       "<td>0.1422668</td></tr>\n",
       "<tr><td>specificity</td>\n",
       "<td>0.9926286</td>\n",
       "<td>0.0003179</td>\n",
       "<td>0.9934106</td>\n",
       "<td>0.9924443</td>\n",
       "<td>0.9920907</td>\n",
       "<td>0.9927913</td>\n",
       "<td>0.9924061</td></tr></table></div>"
      ],
      "text/plain": [
       "                         mean       sd           cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid\n",
       "-----------------------  ---------  -----------  ------------  ------------  ------------  ------------  ------------\n",
       "accuracy                 0.98624    0.000324608  0.98619       0.986605      0.985891      0.986887      0.985626\n",
       "auc                      0.998417   3.23065e-05  0.998443      0.998383      0.998369      0.998494      0.998395\n",
       "err                      0.0137602  0.000324608  0.0138098     0.0133949     0.0141088     0.0131129     0.0143744\n",
       "err_count                829        19.5551      832           807           850           790           866\n",
       "f0point5                 0.979204   0.000573461  0.980323      0.979167      0.97835       0.97989       0.97829\n",
       "f1                       0.97586    0.000573905  0.975766      0.976478      0.975432      0.976977      0.974647\n",
       "f2                       0.97254    0.000889657  0.971251      0.973805      0.972531      0.974082      0.971031\n",
       "lift_top_group           3.4888     0.00975858   3.48269       3.49602       3.4654        3.49414       3.50573\n",
       "logloss                  0.0984845  0.000571146  0.0989524     0.0975894     0.0976437     0.0985139     0.0997231\n",
       "max_per_class_error      0.0296604  0.00116016   0.0317359     0.0279696     0.0293932     0.027839      0.0313646\n",
       "mcc                      0.96627    0.000795138  0.966167      0.967135      0.96556       0.967834      0.964653\n",
       "mean_per_class_accuracy  0.981484   0.000540021  0.980837      0.982237      0.981349      0.982476      0.980521\n",
       "mean_per_class_error     0.0185159  0.000540021  0.0191627     0.0177626     0.0186512     0.0175238     0.0194792\n",
       "mse                      0.0198387  0.000179418  0.0200267     0.0195677     0.0197068     0.0196522     0.0202399\n",
       "precision                0.981447   0.000771579  0.983385      0.980967      0.980306      0.981842      0.980734\n",
       "r2                       0.902976   0.000944809  0.90216       0.904184      0.904008      0.903801      0.900727\n",
       "recall                   0.97034    0.00116016   0.968264      0.97203       0.970607      0.972161      0.968635\n",
       "rmse                     0.140847   0.000635873  0.141516      0.139884      0.140381      0.140186      0.142267\n",
       "specificity              0.992629   0.000317939  0.993411      0.992444      0.992091      0.992791      0.992406"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>timestamp</b></td>\n",
       "<td><b>duration</b></td>\n",
       "<td><b>number_of_trees</b></td>\n",
       "<td><b>training_rmse</b></td>\n",
       "<td><b>training_logloss</b></td>\n",
       "<td><b>training_auc</b></td>\n",
       "<td><b>training_pr_auc</b></td>\n",
       "<td><b>training_lift</b></td>\n",
       "<td><b>training_classification_error</b></td>\n",
       "<td><b>validation_rmse</b></td>\n",
       "<td><b>validation_logloss</b></td>\n",
       "<td><b>validation_auc</b></td>\n",
       "<td><b>validation_pr_auc</b></td>\n",
       "<td><b>validation_lift</b></td>\n",
       "<td><b>validation_classification_error</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-12-11 20:57:15</td>\n",
       "<td> 3 min 19.834 sec</td>\n",
       "<td>0.0</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-12-11 20:57:16</td>\n",
       "<td> 3 min 20.186 sec</td>\n",
       "<td>1.0</td>\n",
       "<td>0.2275729</td>\n",
       "<td>0.8023489</td>\n",
       "<td>0.9643373</td>\n",
       "<td>0.2973424</td>\n",
       "<td>3.2871077</td>\n",
       "<td>0.0678526</td>\n",
       "<td>0.2279121</td>\n",
       "<td>0.7845200</td>\n",
       "<td>0.9645842</td>\n",
       "<td>0.3021248</td>\n",
       "<td>3.2463666</td>\n",
       "<td>0.0692386</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-12-11 20:57:16</td>\n",
       "<td> 3 min 20.516 sec</td>\n",
       "<td>2.0</td>\n",
       "<td>0.1947116</td>\n",
       "<td>0.5755505</td>\n",
       "<td>0.9754294</td>\n",
       "<td>0.2674530</td>\n",
       "<td>3.3580941</td>\n",
       "<td>0.0477174</td>\n",
       "<td>0.1637330</td>\n",
       "<td>0.1682876</td>\n",
       "<td>0.9918950</td>\n",
       "<td>0.4090383</td>\n",
       "<td>3.4077110</td>\n",
       "<td>0.0301219</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-12-11 20:57:16</td>\n",
       "<td> 3 min 20.899 sec</td>\n",
       "<td>3.0</td>\n",
       "<td>0.2134816</td>\n",
       "<td>0.4830622</td>\n",
       "<td>0.9741121</td>\n",
       "<td>0.3753213</td>\n",
       "<td>3.3749162</td>\n",
       "<td>0.0549736</td>\n",
       "<td>0.1680320</td>\n",
       "<td>0.1352552</td>\n",
       "<td>0.9942703</td>\n",
       "<td>0.6381483</td>\n",
       "<td>3.4221034</td>\n",
       "<td>0.0240856</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-12-11 20:57:17</td>\n",
       "<td> 3 min 21.359 sec</td>\n",
       "<td>4.0</td>\n",
       "<td>0.2066882</td>\n",
       "<td>0.4262715</td>\n",
       "<td>0.9769762</td>\n",
       "<td>0.4401881</td>\n",
       "<td>3.3820812</td>\n",
       "<td>0.0500909</td>\n",
       "<td>0.1618993</td>\n",
       "<td>0.1214420</td>\n",
       "<td>0.9954384</td>\n",
       "<td>0.7329649</td>\n",
       "<td>3.4246605</td>\n",
       "<td>0.0223524</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-12-11 20:57:17</td>\n",
       "<td> 3 min 21.859 sec</td>\n",
       "<td>5.0</td>\n",
       "<td>0.1937728</td>\n",
       "<td>0.3528538</td>\n",
       "<td>0.9816797</td>\n",
       "<td>0.4619649</td>\n",
       "<td>3.4018667</td>\n",
       "<td>0.0430413</td>\n",
       "<td>0.1506791</td>\n",
       "<td>0.1056986</td>\n",
       "<td>0.9970041</td>\n",
       "<td>0.7713415</td>\n",
       "<td>3.4253653</td>\n",
       "<td>0.0180194</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-12-11 20:57:18</td>\n",
       "<td> 3 min 22.433 sec</td>\n",
       "<td>6.0</td>\n",
       "<td>0.1869723</td>\n",
       "<td>0.3042406</td>\n",
       "<td>0.9844282</td>\n",
       "<td>0.4974868</td>\n",
       "<td>3.4114792</td>\n",
       "<td>0.0393220</td>\n",
       "<td>0.1467868</td>\n",
       "<td>0.0978622</td>\n",
       "<td>0.9974764</td>\n",
       "<td>0.7976991</td>\n",
       "<td>3.4300943</td>\n",
       "<td>0.0173918</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-12-11 20:57:18</td>\n",
       "<td> 3 min 23.078 sec</td>\n",
       "<td>7.0</td>\n",
       "<td>0.1854219</td>\n",
       "<td>0.2674861</td>\n",
       "<td>0.9861019</td>\n",
       "<td>0.5391322</td>\n",
       "<td>3.4207316</td>\n",
       "<td>0.0376572</td>\n",
       "<td>0.1490559</td>\n",
       "<td>0.1007377</td>\n",
       "<td>0.9975420</td>\n",
       "<td>0.8216224</td>\n",
       "<td>3.4300943</td>\n",
       "<td>0.0170033</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-12-11 20:57:19</td>\n",
       "<td> 3 min 23.758 sec</td>\n",
       "<td>8.0</td>\n",
       "<td>0.1872386</td>\n",
       "<td>0.2432327</td>\n",
       "<td>0.9869286</td>\n",
       "<td>0.5870945</td>\n",
       "<td>3.4287745</td>\n",
       "<td>0.0383898</td>\n",
       "<td>0.1540573</td>\n",
       "<td>0.1084683</td>\n",
       "<td>0.9974627</td>\n",
       "<td>0.8487917</td>\n",
       "<td>3.4300943</td>\n",
       "<td>0.0169137</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-12-11 20:57:23</td>\n",
       "<td> 3 min 27.842 sec</td>\n",
       "<td>20.0</td>\n",
       "<td>0.1502654</td>\n",
       "<td>0.1015057</td>\n",
       "<td>0.9972609</td>\n",
       "<td>0.8269213</td>\n",
       "<td>3.4858202</td>\n",
       "<td>0.0187077</td>\n",
       "<td>0.1376642</td>\n",
       "<td>0.0955218</td>\n",
       "<td>0.9983738</td>\n",
       "<td>0.9522312</td>\n",
       "<td>3.4300943</td>\n",
       "<td>0.0132680</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-12-11 20:57:27</td>\n",
       "<td> 3 min 31.979 sec</td>\n",
       "<td>31.0</td>\n",
       "<td>0.1450408</td>\n",
       "<td>0.0973989</td>\n",
       "<td>0.9980205</td>\n",
       "<td>0.8773195</td>\n",
       "<td>3.4887427</td>\n",
       "<td>0.0163495</td>\n",
       "<td>0.1371480</td>\n",
       "<td>0.0951007</td>\n",
       "<td>0.9984275</td>\n",
       "<td>0.9580318</td>\n",
       "<td>3.4300943</td>\n",
       "<td>0.0130887</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-12-11 20:57:32</td>\n",
       "<td> 3 min 37.002 sec</td>\n",
       "<td>44.0</td>\n",
       "<td>0.1427767</td>\n",
       "<td>0.0966466</td>\n",
       "<td>0.9982077</td>\n",
       "<td>0.9023397</td>\n",
       "<td>3.4887427</td>\n",
       "<td>0.0154665</td>\n",
       "<td>0.1372723</td>\n",
       "<td>0.0951708</td>\n",
       "<td>0.9984373</td>\n",
       "<td>0.9617304</td>\n",
       "<td>3.4300943</td>\n",
       "<td>0.0128795</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-12-11 20:57:35</td>\n",
       "<td> 3 min 39.588 sec</td>\n",
       "<td>50.0</td>\n",
       "<td>0.1422773</td>\n",
       "<td>0.0967380</td>\n",
       "<td>0.9982640</td>\n",
       "<td>0.9089612</td>\n",
       "<td>3.4887427</td>\n",
       "<td>0.0151080</td>\n",
       "<td>0.1374100</td>\n",
       "<td>0.0955319</td>\n",
       "<td>0.9984441</td>\n",
       "<td>0.9622318</td>\n",
       "<td>3.4300943</td>\n",
       "<td>0.0127600</td></tr></table></div>"
      ],
      "text/plain": [
       "    timestamp            duration          number_of_trees    training_rmse    training_logloss    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_auc    validation_pr_auc    validation_lift    validation_classification_error\n",
       "--  -------------------  ----------------  -----------------  ---------------  ------------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ----------------  -------------------  -----------------  ---------------------------------\n",
       "    2018-12-11 20:57:15  3 min 19.834 sec  0                  nan              nan                 nan             nan                nan              nan                              nan                nan                   nan               nan                  nan                nan\n",
       "    2018-12-11 20:57:16  3 min 20.186 sec  1                  0.227573         0.802349            0.964337        0.297342           3.28711          0.0678526                        0.227912           0.78452               0.964584          0.302125             3.24637            0.0692386\n",
       "    2018-12-11 20:57:16  3 min 20.516 sec  2                  0.194712         0.57555             0.975429        0.267453           3.35809          0.0477174                        0.163733           0.168288              0.991895          0.409038             3.40771            0.0301219\n",
       "    2018-12-11 20:57:16  3 min 20.899 sec  3                  0.213482         0.483062            0.974112        0.375321           3.37492          0.0549736                        0.168032           0.135255              0.99427           0.638148             3.4221             0.0240856\n",
       "    2018-12-11 20:57:17  3 min 21.359 sec  4                  0.206688         0.426271            0.976976        0.440188           3.38208          0.0500909                        0.161899           0.121442              0.995438          0.732965             3.42466            0.0223524\n",
       "    2018-12-11 20:57:17  3 min 21.859 sec  5                  0.193773         0.352854            0.98168         0.461965           3.40187          0.0430413                        0.150679           0.105699              0.997004          0.771341             3.42537            0.0180194\n",
       "    2018-12-11 20:57:18  3 min 22.433 sec  6                  0.186972         0.304241            0.984428        0.497487           3.41148          0.039322                         0.146787           0.0978622             0.997476          0.797699             3.43009            0.0173918\n",
       "    2018-12-11 20:57:18  3 min 23.078 sec  7                  0.185422         0.267486            0.986102        0.539132           3.42073          0.0376572                        0.149056           0.100738              0.997542          0.821622             3.43009            0.0170033\n",
       "    2018-12-11 20:57:19  3 min 23.758 sec  8                  0.187239         0.243233            0.986929        0.587094           3.42877          0.0383898                        0.154057           0.108468              0.997463          0.848792             3.43009            0.0169137\n",
       "    2018-12-11 20:57:23  3 min 27.842 sec  20                 0.150265         0.101506            0.997261        0.826921           3.48582          0.0187077                        0.137664           0.0955218             0.998374          0.952231             3.43009            0.013268\n",
       "    2018-12-11 20:57:27  3 min 31.979 sec  31                 0.145041         0.0973989           0.99802         0.87732            3.48874          0.0163495                        0.137148           0.0951007             0.998428          0.958032             3.43009            0.0130887\n",
       "    2018-12-11 20:57:32  3 min 37.002 sec  44                 0.142777         0.0966466           0.998208        0.90234            3.48874          0.0154665                        0.137272           0.0951708             0.998437          0.96173              3.43009            0.0128795\n",
       "    2018-12-11 20:57:35  3 min 39.588 sec  50                 0.142277         0.096738            0.998264        0.908961           3.48874          0.015108                         0.13741            0.0955319             0.998444          0.962232             3.43009            0.01276"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable Importances: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>variable</b></td>\n",
       "<td><b>relative_importance</b></td>\n",
       "<td><b>scaled_importance</b></td>\n",
       "<td><b>percentage</b></td></tr>\n",
       "<tr><td>city_id</td>\n",
       "<td>955775.3125000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.5581109</td></tr>\n",
       "<tr><td>state_id</td>\n",
       "<td>257751.2343750</td>\n",
       "<td>0.2696776</td>\n",
       "<td>0.1505100</td></tr>\n",
       "<tr><td>category_2</td>\n",
       "<td>160059.9062500</td>\n",
       "<td>0.1674660</td>\n",
       "<td>0.0934646</td></tr>\n",
       "<tr><td>category_1</td>\n",
       "<td>115193.4609375</td>\n",
       "<td>0.1205236</td>\n",
       "<td>0.0672655</td></tr>\n",
       "<tr><td>merchant_group_id</td>\n",
       "<td>70843.8906250</td>\n",
       "<td>0.0741219</td>\n",
       "<td>0.0413682</td></tr>\n",
       "<tr><td>subsector_id</td>\n",
       "<td>31761.3027344</td>\n",
       "<td>0.0332309</td>\n",
       "<td>0.0185465</td></tr>\n",
       "<tr><td>merchant_category_id</td>\n",
       "<td>19091.6308594</td>\n",
       "<td>0.0199750</td>\n",
       "<td>0.0111483</td></tr>\n",
       "<tr><td>most_recent_sales_range</td>\n",
       "<td>14489.4287109</td>\n",
       "<td>0.0151599</td>\n",
       "<td>0.0084609</td></tr>\n",
       "<tr><td>numerical_1</td>\n",
       "<td>11903.5019531</td>\n",
       "<td>0.0124543</td>\n",
       "<td>0.0069509</td></tr>\n",
       "<tr><td>most_recent_purchases_range</td>\n",
       "<td>10130.6972656</td>\n",
       "<td>0.0105995</td>\n",
       "<td>0.0059157</td></tr>\n",
       "<tr><td>numerical_2</td>\n",
       "<td>9703.4843750</td>\n",
       "<td>0.0101525</td>\n",
       "<td>0.0056662</td></tr>\n",
       "<tr><td>avg_purchases_lag3</td>\n",
       "<td>8831.2177734</td>\n",
       "<td>0.0092398</td>\n",
       "<td>0.0051569</td></tr>\n",
       "<tr><td>avg_purchases_lag6</td>\n",
       "<td>8387.1093750</td>\n",
       "<td>0.0087752</td>\n",
       "<td>0.0048975</td></tr>\n",
       "<tr><td>avg_purchases_lag12</td>\n",
       "<td>8357.7822266</td>\n",
       "<td>0.0087445</td>\n",
       "<td>0.0048804</td></tr>\n",
       "<tr><td>avg_sales_lag3</td>\n",
       "<td>8332.0605469</td>\n",
       "<td>0.0087176</td>\n",
       "<td>0.0048654</td></tr>\n",
       "<tr><td>avg_sales_lag12</td>\n",
       "<td>7839.9199219</td>\n",
       "<td>0.0082027</td>\n",
       "<td>0.0045780</td></tr>\n",
       "<tr><td>avg_sales_lag6</td>\n",
       "<td>7648.2841797</td>\n",
       "<td>0.0080022</td>\n",
       "<td>0.0044661</td></tr>\n",
       "<tr><td>active_months_lag12</td>\n",
       "<td>4748.7172852</td>\n",
       "<td>0.0049684</td>\n",
       "<td>0.0027729</td></tr>\n",
       "<tr><td>active_months_lag6</td>\n",
       "<td>1353.7655029</td>\n",
       "<td>0.0014164</td>\n",
       "<td>0.0007905</td></tr>\n",
       "<tr><td>active_months_lag3</td>\n",
       "<td>315.8672791</td>\n",
       "<td>0.0003305</td>\n",
       "<td>0.0001844</td></tr></table></div>"
      ],
      "text/plain": [
       "variable                     relative_importance    scaled_importance    percentage\n",
       "---------------------------  ---------------------  -------------------  ------------\n",
       "city_id                      955775                 1                    0.558111\n",
       "state_id                     257751                 0.269678             0.15051\n",
       "category_2                   160060                 0.167466             0.0934646\n",
       "category_1                   115193                 0.120524             0.0672655\n",
       "merchant_group_id            70843.9                0.0741219            0.0413682\n",
       "subsector_id                 31761.3                0.0332309            0.0185465\n",
       "merchant_category_id         19091.6                0.019975             0.0111483\n",
       "most_recent_sales_range      14489.4                0.0151599            0.00846089\n",
       "numerical_1                  11903.5                0.0124543            0.00695087\n",
       "most_recent_purchases_range  10130.7                0.0105995            0.00591567\n",
       "numerical_2                  9703.48                0.0101525            0.00566621\n",
       "avg_purchases_lag3           8831.22                0.00923985           0.00515686\n",
       "avg_purchases_lag6           8387.11                0.00877519           0.00489753\n",
       "avg_purchases_lag12          8357.78                0.00874451           0.0048804\n",
       "avg_sales_lag3               8332.06                0.00871759           0.00486538\n",
       "avg_sales_lag12              7839.92                0.00820268           0.00457801\n",
       "avg_sales_lag6               7648.28                0.00800218           0.0044661\n",
       "active_months_lag12          4748.72                0.00496845           0.00277294\n",
       "active_months_lag6           1353.77                0.00141641           0.000790511\n",
       "active_months_lag3           315.867                0.000330483          0.000184446"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method H2OBinomialModel.sensitivity of >\n"
     ]
    }
   ],
   "source": [
    "print(aml.leader.sensitivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2ORandomForestEstimator :  Distributed Random Forest\n",
      "Model Key:  DRF_1_AutoML_20181211_205354\n",
      "\n",
      "\n",
      "ModelMetricsBinomial: drf\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.020242828646662245\n",
      "RMSE: 0.14227729490913948\n",
      "LogLoss: 0.09673799546133012\n",
      "Mean Per-Class Error: 0.01872350523172872\n",
      "AUC: 0.9982640258173935\n",
      "pr_auc: 0.9089612037582203\n",
      "Gini: 0.996528051634787\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.49174027253987507: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>N</b></td>\n",
       "<td><b>Y</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>N</td>\n",
       "<td>213435.0</td>\n",
       "<td>1453.0</td>\n",
       "<td>0.0068</td>\n",
       "<td> (1453.0/214888.0)</td></tr>\n",
       "<tr><td>Y</td>\n",
       "<td>3098.0</td>\n",
       "<td>83246.0</td>\n",
       "<td>0.0359</td>\n",
       "<td> (3098.0/86344.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>216533.0</td>\n",
       "<td>84699.0</td>\n",
       "<td>0.0151</td>\n",
       "<td> (4551.0/301232.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       N       Y      Error    Rate\n",
       "-----  ------  -----  -------  -----------------\n",
       "N      213435  1453   0.0068   (1453.0/214888.0)\n",
       "Y      3098    83246  0.0359   (3098.0/86344.0)\n",
       "Total  216533  84699  0.0151   (4551.0/301232.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.4917403</td>\n",
       "<td>0.9733927</td>\n",
       "<td>188.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.3549770</td>\n",
       "<td>0.9761585</td>\n",
       "<td>222.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.5960178</td>\n",
       "<td>0.9839807</td>\n",
       "<td>165.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.4917403</td>\n",
       "<td>0.9848920</td>\n",
       "<td>188.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9999810</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0000123</td>\n",
       "<td>1.0</td>\n",
       "<td>399.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9999810</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.4917403</td>\n",
       "<td>0.9629320</td>\n",
       "<td>188.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.3912923</td>\n",
       "<td>0.9810294</td>\n",
       "<td>212.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.4162169</td>\n",
       "<td>0.9812765</td>\n",
       "<td>206.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.49174      0.973393  188\n",
       "max f2                       0.354977     0.976159  222\n",
       "max f0point5                 0.596018     0.983981  165\n",
       "max accuracy                 0.49174      0.984892  188\n",
       "max precision                0.999981     1         0\n",
       "max recall                   1.23132e-05  1         399\n",
       "max specificity              0.999981     1         0\n",
       "max absolute_mcc             0.49174      0.962932  188\n",
       "max min_per_class_accuracy   0.391292     0.981029  212\n",
       "max mean_per_class_accuracy  0.416217     0.981276  206"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 28.66 %, avg score: 28.74 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>score</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>cumulative_score</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0245724</td>\n",
       "<td>1.0</td>\n",
       "<td>3.4887427</td>\n",
       "<td>3.4887427</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0857269</td>\n",
       "<td>0.0857269</td>\n",
       "<td>248.8742704</td>\n",
       "<td>248.8742704</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0300001</td>\n",
       "<td>0.9923801</td>\n",
       "<td>3.4887427</td>\n",
       "<td>3.4887427</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9960116</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9992784</td>\n",
       "<td>0.0189359</td>\n",
       "<td>0.1046627</td>\n",
       "<td>248.8742704</td>\n",
       "<td>248.8742704</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0400024</td>\n",
       "<td>0.9817353</td>\n",
       "<td>3.4887427</td>\n",
       "<td>3.4887427</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9873043</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9962844</td>\n",
       "<td>0.0348953</td>\n",
       "<td>0.1395580</td>\n",
       "<td>248.8742704</td>\n",
       "<td>248.8742704</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0500013</td>\n",
       "<td>0.9724944</td>\n",
       "<td>3.4887427</td>\n",
       "<td>3.4887427</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9772090</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9924698</td>\n",
       "<td>0.0348837</td>\n",
       "<td>0.1744418</td>\n",
       "<td>248.8742704</td>\n",
       "<td>248.8742704</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.1000060</td>\n",
       "<td>0.9298701</td>\n",
       "<td>3.4880479</td>\n",
       "<td>3.4883953</td>\n",
       "<td>0.9998008</td>\n",
       "<td>0.9503510</td>\n",
       "<td>0.9999004</td>\n",
       "<td>0.9714097</td>\n",
       "<td>0.1744186</td>\n",
       "<td>0.3488604</td>\n",
       "<td>248.8047873</td>\n",
       "<td>248.8395277</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1500007</td>\n",
       "<td>0.8884800</td>\n",
       "<td>3.4885110</td>\n",
       "<td>3.4884339</td>\n",
       "<td>0.9999336</td>\n",
       "<td>0.9095350</td>\n",
       "<td>0.9999115</td>\n",
       "<td>0.9507871</td>\n",
       "<td>0.1744070</td>\n",
       "<td>0.5232674</td>\n",
       "<td>248.8511047</td>\n",
       "<td>248.8433863</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.2000020</td>\n",
       "<td>0.8358737</td>\n",
       "<td>3.4873530</td>\n",
       "<td>3.4881636</td>\n",
       "<td>0.9996016</td>\n",
       "<td>0.8638037</td>\n",
       "<td>0.9998340</td>\n",
       "<td>0.9290409</td>\n",
       "<td>0.1743723</td>\n",
       "<td>0.6976397</td>\n",
       "<td>248.7352951</td>\n",
       "<td>248.8163630</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.3000013</td>\n",
       "<td>0.3581678</td>\n",
       "<td>2.8753781</td>\n",
       "<td>3.2839041</td>\n",
       "<td>0.8241875</td>\n",
       "<td>0.6756746</td>\n",
       "<td>0.9412858</td>\n",
       "<td>0.8445864</td>\n",
       "<td>0.2875359</td>\n",
       "<td>0.9851756</td>\n",
       "<td>187.5378120</td>\n",
       "<td>228.3904054</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.4000007</td>\n",
       "<td>0.1144822</td>\n",
       "<td>0.1351579</td>\n",
       "<td>2.4967241</td>\n",
       "<td>0.0387412</td>\n",
       "<td>0.2041120</td>\n",
       "<td>0.7156515</td>\n",
       "<td>0.6844691</td>\n",
       "<td>0.0135157</td>\n",
       "<td>0.9986913</td>\n",
       "<td>-86.4842056</td>\n",
       "<td>149.6724059</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0506433</td>\n",
       "<td>0.0044010</td>\n",
       "<td>1.9982628</td>\n",
       "<td>0.0012615</td>\n",
       "<td>0.0768782</td>\n",
       "<td>0.5727745</td>\n",
       "<td>0.5629517</td>\n",
       "<td>0.0004401</td>\n",
       "<td>0.9991314</td>\n",
       "<td>-99.5598970</td>\n",
       "<td>99.8262763</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.6000027</td>\n",
       "<td>0.0228758</td>\n",
       "<td>0.0026637</td>\n",
       "<td>1.6656556</td>\n",
       "<td>0.0007635</td>\n",
       "<td>0.0346323</td>\n",
       "<td>0.4774372</td>\n",
       "<td>0.4748965</td>\n",
       "<td>0.0002664</td>\n",
       "<td>0.9993978</td>\n",
       "<td>-99.7336307</td>\n",
       "<td>66.5655557</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.7000186</td>\n",
       "<td>0.0115814</td>\n",
       "<td>0.0020844</td>\n",
       "<td>1.4279710</td>\n",
       "<td>0.0005975</td>\n",
       "<td>0.0165641</td>\n",
       "<td>0.4093082</td>\n",
       "<td>0.4094118</td>\n",
       "<td>0.0002085</td>\n",
       "<td>0.9996062</td>\n",
       "<td>-99.7915648</td>\n",
       "<td>42.7970971</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.7999980</td>\n",
       "<td>0.0032095</td>\n",
       "<td>0.0028960</td>\n",
       "<td>1.2498728</td>\n",
       "<td>0.0008301</td>\n",
       "<td>0.0069621</td>\n",
       "<td>0.3582588</td>\n",
       "<td>0.3591158</td>\n",
       "<td>0.0002895</td>\n",
       "<td>0.9998958</td>\n",
       "<td>-99.7104009</td>\n",
       "<td>24.9872819</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0005212</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0001494</td>\n",
       "<td>0.0006021</td>\n",
       "<td>0.2866362</td>\n",
       "<td>0.2874123</td>\n",
       "<td>0.0001042</td>\n",
       "<td>1.0</td>\n",
       "<td>-99.9478834</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift         cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  -----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.0245724                   1                  3.48874      3.48874            1                1            1                           1                   0.0857269       0.0857269                  248.874   248.874\n",
       "    2        0.0300001                   0.99238            3.48874      3.48874            1                0.996012     1                           0.999278            0.0189359       0.104663                   248.874   248.874\n",
       "    3        0.0400024                   0.981735           3.48874      3.48874            1                0.987304     1                           0.996284            0.0348953       0.139558                   248.874   248.874\n",
       "    4        0.0500013                   0.972494           3.48874      3.48874            1                0.977209     1                           0.99247             0.0348837       0.174442                   248.874   248.874\n",
       "    5        0.100006                    0.92987            3.48805      3.4884             0.999801         0.950351     0.9999                      0.97141             0.174419        0.34886                    248.805   248.84\n",
       "    6        0.150001                    0.88848            3.48851      3.48843            0.999934         0.909535     0.999911                    0.950787            0.174407        0.523267                   248.851   248.843\n",
       "    7        0.200002                    0.835874           3.48735      3.48816            0.999602         0.863804     0.999834                    0.929041            0.174372        0.69764                    248.735   248.816\n",
       "    8        0.300001                    0.358168           2.87538      3.2839             0.824187         0.675675     0.941286                    0.844586            0.287536        0.985176                   187.538   228.39\n",
       "    9        0.400001                    0.114482           0.135158     2.49672            0.0387412        0.204112     0.715652                    0.684469            0.0135157       0.998691                   -86.4842  149.672\n",
       "    10       0.5                         0.0506433          0.00440103   1.99826            0.00126149       0.0768782    0.572774                    0.562952            0.0004401       0.999131                   -99.5599  99.8263\n",
       "    11       0.600003                    0.0228758          0.00266369   1.66566            0.000763511      0.0346323    0.477437                    0.474897            0.000266376     0.999398                   -99.7336  66.5656\n",
       "    12       0.700019                    0.0115814          0.00208435   1.42797            0.000597451      0.0165641    0.409308                    0.409412            0.000208468     0.999606                   -99.7916  42.7971\n",
       "    13       0.799998                    0.00320951         0.00289599   1.24987            0.000830096      0.00696211   0.358259                    0.359116            0.00028954      0.999896                   -99.7104  24.9873\n",
       "    14       1                           0                  0.000521166  1                  0.000149385      0.000602119  0.286636                    0.287412            0.000104234     1                          -99.9479  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: drf\n",
      "** Reported on validation data. **\n",
      "\n",
      "MSE: 0.018881497714415916\n",
      "RMSE: 0.1374099622094989\n",
      "LogLoss: 0.0955319096107168\n",
      "Mean Per-Class Error: 0.015262034263669788\n",
      "AUC: 0.9984440687687627\n",
      "pr_auc: 0.9622318205609467\n",
      "Gini: 0.9968881375375254\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4416887505133839: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>N</b></td>\n",
       "<td><b>Y</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>N</td>\n",
       "<td>23520.0</td>\n",
       "<td>188.0</td>\n",
       "<td>0.0079</td>\n",
       "<td> (188.0/23708.0)</td></tr>\n",
       "<tr><td>Y</td>\n",
       "<td>239.0</td>\n",
       "<td>9517.0</td>\n",
       "<td>0.0245</td>\n",
       "<td> (239.0/9756.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>23759.0</td>\n",
       "<td>9705.0</td>\n",
       "<td>0.0128</td>\n",
       "<td> (427.0/33464.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       N      Y     Error    Rate\n",
       "-----  -----  ----  -------  ---------------\n",
       "N      23520  188   0.0079   (188.0/23708.0)\n",
       "Y      239    9517  0.0245   (239.0/9756.0)\n",
       "Total  23759  9705  0.0128   (427.0/33464.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.4416888</td>\n",
       "<td>0.9780587</td>\n",
       "<td>195.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.3852141</td>\n",
       "<td>0.9802661</td>\n",
       "<td>210.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.6038533</td>\n",
       "<td>0.9869264</td>\n",
       "<td>161.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.4482769</td>\n",
       "<td>0.9872400</td>\n",
       "<td>193.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9999085</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0044250</td>\n",
       "<td>1.0</td>\n",
       "<td>394.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9999085</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.4416888</td>\n",
       "<td>0.9690697</td>\n",
       "<td>195.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.3852141</td>\n",
       "<td>0.9843513</td>\n",
       "<td>210.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.3914551</td>\n",
       "<td>0.9847380</td>\n",
       "<td>208.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.441689     0.978059  195\n",
       "max f2                       0.385214     0.980266  210\n",
       "max f0point5                 0.603853     0.986926  161\n",
       "max accuracy                 0.448277     0.98724   193\n",
       "max precision                0.999909     1         0\n",
       "max recall                   0.004425     1         394\n",
       "max specificity              0.999909     1         0\n",
       "max absolute_mcc             0.441689     0.96907   195\n",
       "max min_per_class_accuracy   0.385214     0.984351  210\n",
       "max mean_per_class_accuracy  0.391455     0.984738  208"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 29.15 %, avg score: 29.08 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>score</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>cumulative_score</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0100108</td>\n",
       "<td>0.9984228</td>\n",
       "<td>3.4300943</td>\n",
       "<td>3.4300943</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999521</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999521</td>\n",
       "<td>0.0343378</td>\n",
       "<td>0.0343378</td>\n",
       "<td>243.0094301</td>\n",
       "<td>243.0094301</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0200514</td>\n",
       "<td>0.9915056</td>\n",
       "<td>3.4300943</td>\n",
       "<td>3.4300943</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9932968</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9966195</td>\n",
       "<td>0.0344403</td>\n",
       "<td>0.0687782</td>\n",
       "<td>243.0094301</td>\n",
       "<td>243.0094301</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0307495</td>\n",
       "<td>0.9817939</td>\n",
       "<td>3.4300943</td>\n",
       "<td>3.4300943</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9859367</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9929028</td>\n",
       "<td>0.0366954</td>\n",
       "<td>0.1054736</td>\n",
       "<td>243.0094301</td>\n",
       "<td>243.0094301</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0400131</td>\n",
       "<td>0.9722330</td>\n",
       "<td>3.4300943</td>\n",
       "<td>3.4300943</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9778358</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9894146</td>\n",
       "<td>0.0317753</td>\n",
       "<td>0.1372489</td>\n",
       "<td>243.0094301</td>\n",
       "<td>243.0094301</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0500239</td>\n",
       "<td>0.9638823</td>\n",
       "<td>3.4300943</td>\n",
       "<td>3.4300943</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9674898</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9850270</td>\n",
       "<td>0.0343378</td>\n",
       "<td>0.1715867</td>\n",
       "<td>243.0094301</td>\n",
       "<td>243.0094301</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1000179</td>\n",
       "<td>0.9218599</td>\n",
       "<td>3.4300943</td>\n",
       "<td>3.4300943</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9416622</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9633511</td>\n",
       "<td>0.1714842</td>\n",
       "<td>0.3430709</td>\n",
       "<td>243.0094301</td>\n",
       "<td>243.0094301</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1500120</td>\n",
       "<td>0.8882195</td>\n",
       "<td>3.4300943</td>\n",
       "<td>3.4300943</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9053718</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9440285</td>\n",
       "<td>0.1714842</td>\n",
       "<td>0.5145551</td>\n",
       "<td>243.0094301</td>\n",
       "<td>243.0094301</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2000060</td>\n",
       "<td>0.8421777</td>\n",
       "<td>3.4280440</td>\n",
       "<td>3.4295818</td>\n",
       "<td>0.9994023</td>\n",
       "<td>0.8670677</td>\n",
       "<td>0.9998506</td>\n",
       "<td>0.9247912</td>\n",
       "<td>0.1713817</td>\n",
       "<td>0.6859369</td>\n",
       "<td>242.8044035</td>\n",
       "<td>242.9581811</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.2999940</td>\n",
       "<td>0.3708652</td>\n",
       "<td>2.9964631</td>\n",
       "<td>3.2852233</td>\n",
       "<td>0.8735804</td>\n",
       "<td>0.7020466</td>\n",
       "<td>0.9577647</td>\n",
       "<td>0.8505504</td>\n",
       "<td>0.2996105</td>\n",
       "<td>0.9855474</td>\n",
       "<td>199.6463133</td>\n",
       "<td>228.5223299</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4000120</td>\n",
       "<td>0.1124730</td>\n",
       "<td>0.1311778</td>\n",
       "<td>2.4965941</td>\n",
       "<td>0.0382432</td>\n",
       "<td>0.2071155</td>\n",
       "<td>0.7278500</td>\n",
       "<td>0.6896676</td>\n",
       "<td>0.0131201</td>\n",
       "<td>0.9986675</td>\n",
       "<td>-86.8822208</td>\n",
       "<td>149.6594111</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0486775</td>\n",
       "<td>0.0020503</td>\n",
       "<td>1.9977450</td>\n",
       "<td>0.0005977</td>\n",
       "<td>0.0752963</td>\n",
       "<td>0.5824169</td>\n",
       "<td>0.5668081</td>\n",
       "<td>0.0002050</td>\n",
       "<td>0.9988725</td>\n",
       "<td>-99.7949734</td>\n",
       "<td>99.7744977</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.6000179</td>\n",
       "<td>0.0250341</td>\n",
       "<td>0.0030745</td>\n",
       "<td>1.6652502</td>\n",
       "<td>0.0008963</td>\n",
       "<td>0.0353917</td>\n",
       "<td>0.4854823</td>\n",
       "<td>0.4782254</td>\n",
       "<td>0.0003075</td>\n",
       "<td>0.9991800</td>\n",
       "<td>-99.6925520</td>\n",
       "<td>66.5250224</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.7000060</td>\n",
       "<td>0.0144942</td>\n",
       "<td>0.0020503</td>\n",
       "<td>1.4276807</td>\n",
       "<td>0.0005977</td>\n",
       "<td>0.0190908</td>\n",
       "<td>0.4162220</td>\n",
       "<td>0.4126432</td>\n",
       "<td>0.0002050</td>\n",
       "<td>0.9993850</td>\n",
       "<td>-99.7949734</td>\n",
       "<td>42.7680659</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.8000239</td>\n",
       "<td>0.0087596</td>\n",
       "<td>0.0030745</td>\n",
       "<td>1.2495783</td>\n",
       "<td>0.0008963</td>\n",
       "<td>0.0113545</td>\n",
       "<td>0.3642985</td>\n",
       "<td>0.3624746</td>\n",
       "<td>0.0003075</td>\n",
       "<td>0.9996925</td>\n",
       "<td>-99.6925520</td>\n",
       "<td>24.9578280</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.8999821</td>\n",
       "<td>0.0040031</td>\n",
       "<td>0.0020509</td>\n",
       "<td>1.1110194</td>\n",
       "<td>0.0005979</td>\n",
       "<td>0.0063164</td>\n",
       "<td>0.3239034</td>\n",
       "<td>0.3229172</td>\n",
       "<td>0.0002050</td>\n",
       "<td>0.9998975</td>\n",
       "<td>-99.7949121</td>\n",
       "<td>11.1019355</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0010248</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0002988</td>\n",
       "<td>0.0016149</td>\n",
       "<td>0.2915372</td>\n",
       "<td>0.2907812</td>\n",
       "<td>0.0001025</td>\n",
       "<td>1.0</td>\n",
       "<td>-99.8975173</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.0100108                   0.998423           3.43009     3.43009            1                0.999952    1                           0.999952            0.0343378       0.0343378                  243.009   243.009\n",
       "    2        0.0200514                   0.991506           3.43009     3.43009            1                0.993297    1                           0.99662             0.0344403       0.0687782                  243.009   243.009\n",
       "    3        0.0307495                   0.981794           3.43009     3.43009            1                0.985937    1                           0.992903            0.0366954       0.105474                   243.009   243.009\n",
       "    4        0.0400131                   0.972233           3.43009     3.43009            1                0.977836    1                           0.989415            0.0317753       0.137249                   243.009   243.009\n",
       "    5        0.0500239                   0.963882           3.43009     3.43009            1                0.96749     1                           0.985027            0.0343378       0.171587                   243.009   243.009\n",
       "    6        0.100018                    0.92186            3.43009     3.43009            1                0.941662    1                           0.963351            0.171484        0.343071                   243.009   243.009\n",
       "    7        0.150012                    0.88822            3.43009     3.43009            1                0.905372    1                           0.944028            0.171484        0.514555                   243.009   243.009\n",
       "    8        0.200006                    0.842178           3.42804     3.42958            0.999402         0.867068    0.999851                    0.924791            0.171382        0.685937                   242.804   242.958\n",
       "    9        0.299994                    0.370865           2.99646     3.28522            0.87358          0.702047    0.957765                    0.85055             0.29961         0.985547                   199.646   228.522\n",
       "    10       0.400012                    0.112473           0.131178    2.49659            0.0382432        0.207116    0.72785                     0.689668            0.0131201       0.998667                   -86.8822  149.659\n",
       "    11       0.5                         0.0486775          0.00205027  1.99774            0.000597729      0.0752963   0.582417                    0.566808            0.000205002     0.998872                   -99.795   99.7745\n",
       "    12       0.600018                    0.0250341          0.00307448  1.66525            0.000896325      0.0353917   0.485482                    0.478225            0.000307503     0.99918                    -99.6926  66.525\n",
       "    13       0.700006                    0.0144942          0.00205027  1.42768            0.000597729      0.0190908   0.416222                    0.412643            0.000205002     0.999385                   -99.795   42.7681\n",
       "    14       0.800024                    0.00875963         0.00307448  1.24958            0.000896325      0.0113545   0.364299                    0.362475            0.000307503     0.999692                   -99.6926  24.9578\n",
       "    15       0.899982                    0.00400315         0.00205088  1.11102            0.000597907      0.0063164   0.323903                    0.322917            0.000205002     0.999897                   -99.7949  11.1019\n",
       "    16       1                           0                  0.00102483  1                  0.000298775      0.00161486  0.291537                    0.290781            0.000102501     1                          -99.8975  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: drf\n",
      "** Reported on cross-validation data. **\n",
      "\n",
      "MSE: 0.019838655136353946\n",
      "RMSE: 0.14084976086722314\n",
      "LogLoss: 0.09848448113892687\n",
      "Mean Per-Class Error: 0.01697642178512626\n",
      "AUC: 0.9984149199275788\n",
      "pr_auc: 0.9438620129204796\n",
      "Gini: 0.9968298398551576\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4721316665854305: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>N</b></td>\n",
       "<td><b>Y</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>N</td>\n",
       "<td>213304.0</td>\n",
       "<td>1584.0</td>\n",
       "<td>0.0074</td>\n",
       "<td> (1584.0/214888.0)</td></tr>\n",
       "<tr><td>Y</td>\n",
       "<td>2589.0</td>\n",
       "<td>83755.0</td>\n",
       "<td>0.03</td>\n",
       "<td> (2589.0/86344.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>215893.0</td>\n",
       "<td>85339.0</td>\n",
       "<td>0.0139</td>\n",
       "<td> (4173.0/301232.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       N       Y      Error    Rate\n",
       "-----  ------  -----  -------  -----------------\n",
       "N      213304  1584   0.0074   (1584.0/214888.0)\n",
       "Y      2589    83755  0.03     (2589.0/86344.0)\n",
       "Total  215893  85339  0.0139   (4173.0/301232.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.4721317</td>\n",
       "<td>0.9756936</td>\n",
       "<td>186.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.3610743</td>\n",
       "<td>0.9781708</td>\n",
       "<td>216.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.5859488</td>\n",
       "<td>0.9856473</td>\n",
       "<td>162.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.4721317</td>\n",
       "<td>0.9861469</td>\n",
       "<td>186.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9999495</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0013795</td>\n",
       "<td>1.0</td>\n",
       "<td>397.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9999495</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.4721317</td>\n",
       "<td>0.9660394</td>\n",
       "<td>186.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.3911902</td>\n",
       "<td>0.9824606</td>\n",
       "<td>207.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.4120424</td>\n",
       "<td>0.9830236</td>\n",
       "<td>201.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.472132     0.975694  186\n",
       "max f2                       0.361074     0.978171  216\n",
       "max f0point5                 0.585949     0.985647  162\n",
       "max accuracy                 0.472132     0.986147  186\n",
       "max precision                0.999949     1         0\n",
       "max recall                   0.00137952   1         397\n",
       "max specificity              0.999949     1         0\n",
       "max absolute_mcc             0.472132     0.966039  186\n",
       "max min_per_class_accuracy   0.39119      0.982461  207\n",
       "max mean_per_class_accuracy  0.412042     0.983024  201"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 28.66 %, avg score: 28.75 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>score</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>cumulative_score</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0140490</td>\n",
       "<td>1.0</td>\n",
       "<td>3.4887427</td>\n",
       "<td>3.4887427</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0490132</td>\n",
       "<td>0.0490132</td>\n",
       "<td>248.8742704</td>\n",
       "<td>248.8742704</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0200311</td>\n",
       "<td>0.9953594</td>\n",
       "<td>3.4887427</td>\n",
       "<td>3.4887427</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9974951</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9992519</td>\n",
       "<td>0.0208700</td>\n",
       "<td>0.0698833</td>\n",
       "<td>248.8742704</td>\n",
       "<td>248.8742704</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0301263</td>\n",
       "<td>0.9863092</td>\n",
       "<td>3.4887427</td>\n",
       "<td>3.4887427</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9906092</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9963558</td>\n",
       "<td>0.0352196</td>\n",
       "<td>0.1051028</td>\n",
       "<td>248.8742704</td>\n",
       "<td>248.8742704</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0400024</td>\n",
       "<td>0.9741634</td>\n",
       "<td>3.4887427</td>\n",
       "<td>3.4887427</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9807678</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9925073</td>\n",
       "<td>0.0344552</td>\n",
       "<td>0.1395580</td>\n",
       "<td>248.8742704</td>\n",
       "<td>248.8742704</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0500013</td>\n",
       "<td>0.9587926</td>\n",
       "<td>3.4887427</td>\n",
       "<td>3.4887427</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9660452</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9872156</td>\n",
       "<td>0.0348837</td>\n",
       "<td>0.1744418</td>\n",
       "<td>248.8742704</td>\n",
       "<td>248.8742704</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1000027</td>\n",
       "<td>0.9146654</td>\n",
       "<td>3.4887427</td>\n",
       "<td>3.4887427</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9343891</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9608024</td>\n",
       "<td>0.1744418</td>\n",
       "<td>0.3488835</td>\n",
       "<td>248.8742704</td>\n",
       "<td>248.8742704</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1500007</td>\n",
       "<td>0.8794678</td>\n",
       "<td>3.4885111</td>\n",
       "<td>3.4886655</td>\n",
       "<td>0.9999336</td>\n",
       "<td>0.8973287</td>\n",
       "<td>0.9999779</td>\n",
       "<td>0.9396454</td>\n",
       "<td>0.1744186</td>\n",
       "<td>0.5233021</td>\n",
       "<td>248.8511063</td>\n",
       "<td>248.8665493</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2000020</td>\n",
       "<td>0.8359674</td>\n",
       "<td>3.4882795</td>\n",
       "<td>3.4885690</td>\n",
       "<td>0.9998672</td>\n",
       "<td>0.8590832</td>\n",
       "<td>0.9999502</td>\n",
       "<td>0.9195045</td>\n",
       "<td>0.1744186</td>\n",
       "<td>0.6977207</td>\n",
       "<td>248.8279453</td>\n",
       "<td>248.8568982</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3000013</td>\n",
       "<td>0.3577441</td>\n",
       "<td>2.8957618</td>\n",
       "<td>3.2909688</td>\n",
       "<td>0.8300302</td>\n",
       "<td>0.6803003</td>\n",
       "<td>0.9433108</td>\n",
       "<td>0.8397707</td>\n",
       "<td>0.2895743</td>\n",
       "<td>0.9872950</td>\n",
       "<td>189.5761837</td>\n",
       "<td>229.0968787</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4000007</td>\n",
       "<td>0.1138118</td>\n",
       "<td>0.1148900</td>\n",
       "<td>2.4969557</td>\n",
       "<td>0.0329316</td>\n",
       "<td>0.2046500</td>\n",
       "<td>0.7157179</td>\n",
       "<td>0.6809918</td>\n",
       "<td>0.0114889</td>\n",
       "<td>0.9987839</td>\n",
       "<td>-88.5109957</td>\n",
       "<td>149.6955691</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0508306</td>\n",
       "<td>0.0033587</td>\n",
       "<td>1.9982396</td>\n",
       "<td>0.0009627</td>\n",
       "<td>0.0769064</td>\n",
       "<td>0.5727678</td>\n",
       "<td>0.5601755</td>\n",
       "<td>0.0003359</td>\n",
       "<td>0.9991198</td>\n",
       "<td>-99.6641319</td>\n",
       "<td>99.8239600</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.5999993</td>\n",
       "<td>0.0265169</td>\n",
       "<td>0.0013898</td>\n",
       "<td>1.6654331</td>\n",
       "<td>0.0003984</td>\n",
       "<td>0.0369419</td>\n",
       "<td>0.4773735</td>\n",
       "<td>0.4729704</td>\n",
       "<td>0.0001390</td>\n",
       "<td>0.9992588</td>\n",
       "<td>-99.8610201</td>\n",
       "<td>66.5433141</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.6999987</td>\n",
       "<td>0.0145751</td>\n",
       "<td>0.0019689</td>\n",
       "<td>1.4277965</td>\n",
       "<td>0.0005644</td>\n",
       "<td>0.0201392</td>\n",
       "<td>0.4092582</td>\n",
       "<td>0.4082805</td>\n",
       "<td>0.0001969</td>\n",
       "<td>0.9994557</td>\n",
       "<td>-99.8031118</td>\n",
       "<td>42.7796517</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.8001441</td>\n",
       "<td>0.0076869</td>\n",
       "<td>0.0028912</td>\n",
       "<td>1.2494565</td>\n",
       "<td>0.0008287</td>\n",
       "<td>0.0107899</td>\n",
       "<td>0.3581395</td>\n",
       "<td>0.3585309</td>\n",
       "<td>0.0002895</td>\n",
       "<td>0.9997452</td>\n",
       "<td>-99.7108809</td>\n",
       "<td>24.9456487</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.8999973</td>\n",
       "<td>0.0025570</td>\n",
       "<td>0.0020877</td>\n",
       "<td>1.1110629</td>\n",
       "<td>0.0005984</td>\n",
       "<td>0.0051052</td>\n",
       "<td>0.3184709</td>\n",
       "<td>0.3193189</td>\n",
       "<td>0.0002085</td>\n",
       "<td>0.9999537</td>\n",
       "<td>-99.7912252</td>\n",
       "<td>11.1062916</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0004633</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0001328</td>\n",
       "<td>0.0008872</td>\n",
       "<td>0.2866362</td>\n",
       "<td>0.2874749</td>\n",
       "<td>0.0000463</td>\n",
       "<td>1.0</td>\n",
       "<td>-99.9536749</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift         cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  -----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.014049                    1                  3.48874      3.48874            1                1            1                           1                   0.0490132       0.0490132                  248.874   248.874\n",
       "    2        0.0200311                   0.995359           3.48874      3.48874            1                0.997495     1                           0.999252            0.02087         0.0698833                  248.874   248.874\n",
       "    3        0.0301263                   0.986309           3.48874      3.48874            1                0.990609     1                           0.996356            0.0352196       0.105103                   248.874   248.874\n",
       "    4        0.0400024                   0.974163           3.48874      3.48874            1                0.980768     1                           0.992507            0.0344552       0.139558                   248.874   248.874\n",
       "    5        0.0500013                   0.958793           3.48874      3.48874            1                0.966045     1                           0.987216            0.0348837       0.174442                   248.874   248.874\n",
       "    6        0.100003                    0.914665           3.48874      3.48874            1                0.934389     1                           0.960802            0.174442        0.348884                   248.874   248.874\n",
       "    7        0.150001                    0.879468           3.48851      3.48867            0.999934         0.897329     0.999978                    0.939645            0.174419        0.523302                   248.851   248.867\n",
       "    8        0.200002                    0.835967           3.48828      3.48857            0.999867         0.859083     0.99995                     0.919505            0.174419        0.697721                   248.828   248.857\n",
       "    9        0.300001                    0.357744           2.89576      3.29097            0.83003          0.6803       0.943311                    0.839771            0.289574        0.987295                   189.576   229.097\n",
       "    10       0.400001                    0.113812           0.11489      2.49696            0.0329316        0.20465      0.715718                    0.680992            0.0114889       0.998784                   -88.511   149.696\n",
       "    11       0.5                         0.0508306          0.00335868   1.99824            0.00096272       0.0769064    0.572768                    0.560176            0.000335866     0.99912                    -99.6641  99.824\n",
       "    12       0.599999                    0.0265169          0.0013898    1.66543            0.000398367      0.0369419    0.477373                    0.47297             0.000138979     0.999259                   -99.861   66.5433\n",
       "    13       0.699999                    0.0145751          0.00196888   1.4278             0.000564353      0.0201392    0.409258                    0.408281            0.000196887     0.999456                   -99.8031  42.7797\n",
       "    14       0.800144                    0.00768693         0.00289119   1.24946            0.00082872       0.0107899    0.358139                    0.358531            0.00028954      0.999745                   -99.7109  24.9456\n",
       "    15       0.899997                    0.002557           0.00208775   1.11106            0.000598424      0.00510517   0.318471                    0.319319            0.000208468     0.999954                   -99.7912  11.1063\n",
       "    16       1                           0                  0.000463251  1                  0.000132784      0.000887211  0.286636                    0.287475            4.63263e-05     1                          -99.9537  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-Validation Metrics Summary: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>mean</b></td>\n",
       "<td><b>sd</b></td>\n",
       "<td><b>cv_1_valid</b></td>\n",
       "<td><b>cv_2_valid</b></td>\n",
       "<td><b>cv_3_valid</b></td>\n",
       "<td><b>cv_4_valid</b></td>\n",
       "<td><b>cv_5_valid</b></td></tr>\n",
       "<tr><td>accuracy</td>\n",
       "<td>0.9862399</td>\n",
       "<td>0.0003246</td>\n",
       "<td>0.9861902</td>\n",
       "<td>0.9866052</td>\n",
       "<td>0.9858912</td>\n",
       "<td>0.9868871</td>\n",
       "<td>0.9856256</td></tr>\n",
       "<tr><td>auc</td>\n",
       "<td>0.9984168</td>\n",
       "<td>0.0000323</td>\n",
       "<td>0.9984430</td>\n",
       "<td>0.9983832</td>\n",
       "<td>0.9983691</td>\n",
       "<td>0.9984936</td>\n",
       "<td>0.9983954</td></tr>\n",
       "<tr><td>err</td>\n",
       "<td>0.0137602</td>\n",
       "<td>0.0003246</td>\n",
       "<td>0.0138098</td>\n",
       "<td>0.0133949</td>\n",
       "<td>0.0141088</td>\n",
       "<td>0.0131129</td>\n",
       "<td>0.0143744</td></tr>\n",
       "<tr><td>err_count</td>\n",
       "<td>829.0</td>\n",
       "<td>19.55505</td>\n",
       "<td>832.0</td>\n",
       "<td>807.0</td>\n",
       "<td>850.0</td>\n",
       "<td>790.0</td>\n",
       "<td>866.0</td></tr>\n",
       "<tr><td>f0point5</td>\n",
       "<td>0.9792042</td>\n",
       "<td>0.0005735</td>\n",
       "<td>0.9803233</td>\n",
       "<td>0.9791669</td>\n",
       "<td>0.9783503</td>\n",
       "<td>0.9798901</td>\n",
       "<td>0.9782903</td></tr>\n",
       "<tr><td>f1</td>\n",
       "<td>0.9758602</td>\n",
       "<td>0.0005739</td>\n",
       "<td>0.9757661</td>\n",
       "<td>0.9764785</td>\n",
       "<td>0.9754321</td>\n",
       "<td>0.9769773</td>\n",
       "<td>0.9746472</td></tr>\n",
       "<tr><td>f2</td>\n",
       "<td>0.97254</td>\n",
       "<td>0.0008897</td>\n",
       "<td>0.9712509</td>\n",
       "<td>0.9738048</td>\n",
       "<td>0.9725312</td>\n",
       "<td>0.9740818</td>\n",
       "<td>0.9710313</td></tr>\n",
       "<tr><td>lift_top_group</td>\n",
       "<td>3.4887974</td>\n",
       "<td>0.0097586</td>\n",
       "<td>3.4826868</td>\n",
       "<td>3.496025</td>\n",
       "<td>3.4654012</td>\n",
       "<td>3.4941423</td>\n",
       "<td>3.5057318</td></tr>\n",
       "<tr><td>logloss</td>\n",
       "<td>0.0984845</td>\n",
       "<td>0.0005711</td>\n",
       "<td>0.0989524</td>\n",
       "<td>0.0975894</td>\n",
       "<td>0.0976437</td>\n",
       "<td>0.0985139</td>\n",
       "<td>0.0997231</td></tr>\n",
       "<tr><td>max_per_class_error</td>\n",
       "<td>0.0296604</td>\n",
       "<td>0.0011602</td>\n",
       "<td>0.0317359</td>\n",
       "<td>0.0279696</td>\n",
       "<td>0.0293932</td>\n",
       "<td>0.0278390</td>\n",
       "<td>0.0313646</td></tr>\n",
       "<tr><td>mcc</td>\n",
       "<td>0.9662698</td>\n",
       "<td>0.0007951</td>\n",
       "<td>0.9661673</td>\n",
       "<td>0.9671350</td>\n",
       "<td>0.96556</td>\n",
       "<td>0.9678338</td>\n",
       "<td>0.9646531</td></tr>\n",
       "<tr><td>mean_per_class_accuracy</td>\n",
       "<td>0.9814841</td>\n",
       "<td>0.0005400</td>\n",
       "<td>0.9808374</td>\n",
       "<td>0.9822373</td>\n",
       "<td>0.9813487</td>\n",
       "<td>0.9824762</td>\n",
       "<td>0.9805208</td></tr>\n",
       "<tr><td>mean_per_class_error</td>\n",
       "<td>0.0185159</td>\n",
       "<td>0.0005400</td>\n",
       "<td>0.0191627</td>\n",
       "<td>0.0177626</td>\n",
       "<td>0.0186512</td>\n",
       "<td>0.0175238</td>\n",
       "<td>0.0194792</td></tr>\n",
       "<tr><td>mse</td>\n",
       "<td>0.0198387</td>\n",
       "<td>0.0001794</td>\n",
       "<td>0.0200267</td>\n",
       "<td>0.0195677</td>\n",
       "<td>0.0197068</td>\n",
       "<td>0.0196522</td>\n",
       "<td>0.0202399</td></tr>\n",
       "<tr><td>precision</td>\n",
       "<td>0.9814468</td>\n",
       "<td>0.0007716</td>\n",
       "<td>0.9833852</td>\n",
       "<td>0.9809675</td>\n",
       "<td>0.9803056</td>\n",
       "<td>0.9818416</td>\n",
       "<td>0.9807341</td></tr>\n",
       "<tr><td>r2</td>\n",
       "<td>0.9029759</td>\n",
       "<td>0.0009448</td>\n",
       "<td>0.9021599</td>\n",
       "<td>0.9041837</td>\n",
       "<td>0.9040078</td>\n",
       "<td>0.9038008</td>\n",
       "<td>0.9007272</td></tr>\n",
       "<tr><td>recall</td>\n",
       "<td>0.9703395</td>\n",
       "<td>0.0011602</td>\n",
       "<td>0.9682640</td>\n",
       "<td>0.9720304</td>\n",
       "<td>0.9706069</td>\n",
       "<td>0.972161</td>\n",
       "<td>0.9686354</td></tr>\n",
       "<tr><td>rmse</td>\n",
       "<td>0.1408469</td>\n",
       "<td>0.0006359</td>\n",
       "<td>0.1415158</td>\n",
       "<td>0.1398845</td>\n",
       "<td>0.1403809</td>\n",
       "<td>0.1401864</td>\n",
       "<td>0.1422668</td></tr>\n",
       "<tr><td>specificity</td>\n",
       "<td>0.9926286</td>\n",
       "<td>0.0003179</td>\n",
       "<td>0.9934106</td>\n",
       "<td>0.9924443</td>\n",
       "<td>0.9920907</td>\n",
       "<td>0.9927913</td>\n",
       "<td>0.9924061</td></tr></table></div>"
      ],
      "text/plain": [
       "                         mean       sd           cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid\n",
       "-----------------------  ---------  -----------  ------------  ------------  ------------  ------------  ------------\n",
       "accuracy                 0.98624    0.000324608  0.98619       0.986605      0.985891      0.986887      0.985626\n",
       "auc                      0.998417   3.23065e-05  0.998443      0.998383      0.998369      0.998494      0.998395\n",
       "err                      0.0137602  0.000324608  0.0138098     0.0133949     0.0141088     0.0131129     0.0143744\n",
       "err_count                829        19.5551      832           807           850           790           866\n",
       "f0point5                 0.979204   0.000573461  0.980323      0.979167      0.97835       0.97989       0.97829\n",
       "f1                       0.97586    0.000573905  0.975766      0.976478      0.975432      0.976977      0.974647\n",
       "f2                       0.97254    0.000889657  0.971251      0.973805      0.972531      0.974082      0.971031\n",
       "lift_top_group           3.4888     0.00975858   3.48269       3.49602       3.4654        3.49414       3.50573\n",
       "logloss                  0.0984845  0.000571146  0.0989524     0.0975894     0.0976437     0.0985139     0.0997231\n",
       "max_per_class_error      0.0296604  0.00116016   0.0317359     0.0279696     0.0293932     0.027839      0.0313646\n",
       "mcc                      0.96627    0.000795138  0.966167      0.967135      0.96556       0.967834      0.964653\n",
       "mean_per_class_accuracy  0.981484   0.000540021  0.980837      0.982237      0.981349      0.982476      0.980521\n",
       "mean_per_class_error     0.0185159  0.000540021  0.0191627     0.0177626     0.0186512     0.0175238     0.0194792\n",
       "mse                      0.0198387  0.000179418  0.0200267     0.0195677     0.0197068     0.0196522     0.0202399\n",
       "precision                0.981447   0.000771579  0.983385      0.980967      0.980306      0.981842      0.980734\n",
       "r2                       0.902976   0.000944809  0.90216       0.904184      0.904008      0.903801      0.900727\n",
       "recall                   0.97034    0.00116016   0.968264      0.97203       0.970607      0.972161      0.968635\n",
       "rmse                     0.140847   0.000635873  0.141516      0.139884      0.140381      0.140186      0.142267\n",
       "specificity              0.992629   0.000317939  0.993411      0.992444      0.992091      0.992791      0.992406"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>timestamp</b></td>\n",
       "<td><b>duration</b></td>\n",
       "<td><b>number_of_trees</b></td>\n",
       "<td><b>training_rmse</b></td>\n",
       "<td><b>training_logloss</b></td>\n",
       "<td><b>training_auc</b></td>\n",
       "<td><b>training_pr_auc</b></td>\n",
       "<td><b>training_lift</b></td>\n",
       "<td><b>training_classification_error</b></td>\n",
       "<td><b>validation_rmse</b></td>\n",
       "<td><b>validation_logloss</b></td>\n",
       "<td><b>validation_auc</b></td>\n",
       "<td><b>validation_pr_auc</b></td>\n",
       "<td><b>validation_lift</b></td>\n",
       "<td><b>validation_classification_error</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-12-11 20:57:15</td>\n",
       "<td> 3 min 19.834 sec</td>\n",
       "<td>0.0</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-12-11 20:57:16</td>\n",
       "<td> 3 min 20.186 sec</td>\n",
       "<td>1.0</td>\n",
       "<td>0.2275729</td>\n",
       "<td>0.8023489</td>\n",
       "<td>0.9643373</td>\n",
       "<td>0.2973424</td>\n",
       "<td>3.2871077</td>\n",
       "<td>0.0678526</td>\n",
       "<td>0.2279121</td>\n",
       "<td>0.7845200</td>\n",
       "<td>0.9645842</td>\n",
       "<td>0.3021248</td>\n",
       "<td>3.2463666</td>\n",
       "<td>0.0692386</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-12-11 20:57:16</td>\n",
       "<td> 3 min 20.516 sec</td>\n",
       "<td>2.0</td>\n",
       "<td>0.1947116</td>\n",
       "<td>0.5755505</td>\n",
       "<td>0.9754294</td>\n",
       "<td>0.2674530</td>\n",
       "<td>3.3580941</td>\n",
       "<td>0.0477174</td>\n",
       "<td>0.1637330</td>\n",
       "<td>0.1682876</td>\n",
       "<td>0.9918950</td>\n",
       "<td>0.4090383</td>\n",
       "<td>3.4077110</td>\n",
       "<td>0.0301219</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-12-11 20:57:16</td>\n",
       "<td> 3 min 20.899 sec</td>\n",
       "<td>3.0</td>\n",
       "<td>0.2134816</td>\n",
       "<td>0.4830622</td>\n",
       "<td>0.9741121</td>\n",
       "<td>0.3753213</td>\n",
       "<td>3.3749162</td>\n",
       "<td>0.0549736</td>\n",
       "<td>0.1680320</td>\n",
       "<td>0.1352552</td>\n",
       "<td>0.9942703</td>\n",
       "<td>0.6381483</td>\n",
       "<td>3.4221034</td>\n",
       "<td>0.0240856</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-12-11 20:57:17</td>\n",
       "<td> 3 min 21.359 sec</td>\n",
       "<td>4.0</td>\n",
       "<td>0.2066882</td>\n",
       "<td>0.4262715</td>\n",
       "<td>0.9769762</td>\n",
       "<td>0.4401881</td>\n",
       "<td>3.3820812</td>\n",
       "<td>0.0500909</td>\n",
       "<td>0.1618993</td>\n",
       "<td>0.1214420</td>\n",
       "<td>0.9954384</td>\n",
       "<td>0.7329649</td>\n",
       "<td>3.4246605</td>\n",
       "<td>0.0223524</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-12-11 20:57:17</td>\n",
       "<td> 3 min 21.859 sec</td>\n",
       "<td>5.0</td>\n",
       "<td>0.1937728</td>\n",
       "<td>0.3528538</td>\n",
       "<td>0.9816797</td>\n",
       "<td>0.4619649</td>\n",
       "<td>3.4018667</td>\n",
       "<td>0.0430413</td>\n",
       "<td>0.1506791</td>\n",
       "<td>0.1056986</td>\n",
       "<td>0.9970041</td>\n",
       "<td>0.7713415</td>\n",
       "<td>3.4253653</td>\n",
       "<td>0.0180194</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-12-11 20:57:18</td>\n",
       "<td> 3 min 22.433 sec</td>\n",
       "<td>6.0</td>\n",
       "<td>0.1869723</td>\n",
       "<td>0.3042406</td>\n",
       "<td>0.9844282</td>\n",
       "<td>0.4974868</td>\n",
       "<td>3.4114792</td>\n",
       "<td>0.0393220</td>\n",
       "<td>0.1467868</td>\n",
       "<td>0.0978622</td>\n",
       "<td>0.9974764</td>\n",
       "<td>0.7976991</td>\n",
       "<td>3.4300943</td>\n",
       "<td>0.0173918</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-12-11 20:57:18</td>\n",
       "<td> 3 min 23.078 sec</td>\n",
       "<td>7.0</td>\n",
       "<td>0.1854219</td>\n",
       "<td>0.2674861</td>\n",
       "<td>0.9861019</td>\n",
       "<td>0.5391322</td>\n",
       "<td>3.4207316</td>\n",
       "<td>0.0376572</td>\n",
       "<td>0.1490559</td>\n",
       "<td>0.1007377</td>\n",
       "<td>0.9975420</td>\n",
       "<td>0.8216224</td>\n",
       "<td>3.4300943</td>\n",
       "<td>0.0170033</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-12-11 20:57:19</td>\n",
       "<td> 3 min 23.758 sec</td>\n",
       "<td>8.0</td>\n",
       "<td>0.1872386</td>\n",
       "<td>0.2432327</td>\n",
       "<td>0.9869286</td>\n",
       "<td>0.5870945</td>\n",
       "<td>3.4287745</td>\n",
       "<td>0.0383898</td>\n",
       "<td>0.1540573</td>\n",
       "<td>0.1084683</td>\n",
       "<td>0.9974627</td>\n",
       "<td>0.8487917</td>\n",
       "<td>3.4300943</td>\n",
       "<td>0.0169137</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-12-11 20:57:23</td>\n",
       "<td> 3 min 27.842 sec</td>\n",
       "<td>20.0</td>\n",
       "<td>0.1502654</td>\n",
       "<td>0.1015057</td>\n",
       "<td>0.9972609</td>\n",
       "<td>0.8269213</td>\n",
       "<td>3.4858202</td>\n",
       "<td>0.0187077</td>\n",
       "<td>0.1376642</td>\n",
       "<td>0.0955218</td>\n",
       "<td>0.9983738</td>\n",
       "<td>0.9522312</td>\n",
       "<td>3.4300943</td>\n",
       "<td>0.0132680</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-12-11 20:57:27</td>\n",
       "<td> 3 min 31.979 sec</td>\n",
       "<td>31.0</td>\n",
       "<td>0.1450408</td>\n",
       "<td>0.0973989</td>\n",
       "<td>0.9980205</td>\n",
       "<td>0.8773195</td>\n",
       "<td>3.4887427</td>\n",
       "<td>0.0163495</td>\n",
       "<td>0.1371480</td>\n",
       "<td>0.0951007</td>\n",
       "<td>0.9984275</td>\n",
       "<td>0.9580318</td>\n",
       "<td>3.4300943</td>\n",
       "<td>0.0130887</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-12-11 20:57:32</td>\n",
       "<td> 3 min 37.002 sec</td>\n",
       "<td>44.0</td>\n",
       "<td>0.1427767</td>\n",
       "<td>0.0966466</td>\n",
       "<td>0.9982077</td>\n",
       "<td>0.9023397</td>\n",
       "<td>3.4887427</td>\n",
       "<td>0.0154665</td>\n",
       "<td>0.1372723</td>\n",
       "<td>0.0951708</td>\n",
       "<td>0.9984373</td>\n",
       "<td>0.9617304</td>\n",
       "<td>3.4300943</td>\n",
       "<td>0.0128795</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-12-11 20:57:35</td>\n",
       "<td> 3 min 39.588 sec</td>\n",
       "<td>50.0</td>\n",
       "<td>0.1422773</td>\n",
       "<td>0.0967380</td>\n",
       "<td>0.9982640</td>\n",
       "<td>0.9089612</td>\n",
       "<td>3.4887427</td>\n",
       "<td>0.0151080</td>\n",
       "<td>0.1374100</td>\n",
       "<td>0.0955319</td>\n",
       "<td>0.9984441</td>\n",
       "<td>0.9622318</td>\n",
       "<td>3.4300943</td>\n",
       "<td>0.0127600</td></tr></table></div>"
      ],
      "text/plain": [
       "    timestamp            duration          number_of_trees    training_rmse    training_logloss    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_auc    validation_pr_auc    validation_lift    validation_classification_error\n",
       "--  -------------------  ----------------  -----------------  ---------------  ------------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ----------------  -------------------  -----------------  ---------------------------------\n",
       "    2018-12-11 20:57:15  3 min 19.834 sec  0                  nan              nan                 nan             nan                nan              nan                              nan                nan                   nan               nan                  nan                nan\n",
       "    2018-12-11 20:57:16  3 min 20.186 sec  1                  0.227573         0.802349            0.964337        0.297342           3.28711          0.0678526                        0.227912           0.78452               0.964584          0.302125             3.24637            0.0692386\n",
       "    2018-12-11 20:57:16  3 min 20.516 sec  2                  0.194712         0.57555             0.975429        0.267453           3.35809          0.0477174                        0.163733           0.168288              0.991895          0.409038             3.40771            0.0301219\n",
       "    2018-12-11 20:57:16  3 min 20.899 sec  3                  0.213482         0.483062            0.974112        0.375321           3.37492          0.0549736                        0.168032           0.135255              0.99427           0.638148             3.4221             0.0240856\n",
       "    2018-12-11 20:57:17  3 min 21.359 sec  4                  0.206688         0.426271            0.976976        0.440188           3.38208          0.0500909                        0.161899           0.121442              0.995438          0.732965             3.42466            0.0223524\n",
       "    2018-12-11 20:57:17  3 min 21.859 sec  5                  0.193773         0.352854            0.98168         0.461965           3.40187          0.0430413                        0.150679           0.105699              0.997004          0.771341             3.42537            0.0180194\n",
       "    2018-12-11 20:57:18  3 min 22.433 sec  6                  0.186972         0.304241            0.984428        0.497487           3.41148          0.039322                         0.146787           0.0978622             0.997476          0.797699             3.43009            0.0173918\n",
       "    2018-12-11 20:57:18  3 min 23.078 sec  7                  0.185422         0.267486            0.986102        0.539132           3.42073          0.0376572                        0.149056           0.100738              0.997542          0.821622             3.43009            0.0170033\n",
       "    2018-12-11 20:57:19  3 min 23.758 sec  8                  0.187239         0.243233            0.986929        0.587094           3.42877          0.0383898                        0.154057           0.108468              0.997463          0.848792             3.43009            0.0169137\n",
       "    2018-12-11 20:57:23  3 min 27.842 sec  20                 0.150265         0.101506            0.997261        0.826921           3.48582          0.0187077                        0.137664           0.0955218             0.998374          0.952231             3.43009            0.013268\n",
       "    2018-12-11 20:57:27  3 min 31.979 sec  31                 0.145041         0.0973989           0.99802         0.87732            3.48874          0.0163495                        0.137148           0.0951007             0.998428          0.958032             3.43009            0.0130887\n",
       "    2018-12-11 20:57:32  3 min 37.002 sec  44                 0.142777         0.0966466           0.998208        0.90234            3.48874          0.0154665                        0.137272           0.0951708             0.998437          0.96173              3.43009            0.0128795\n",
       "    2018-12-11 20:57:35  3 min 39.588 sec  50                 0.142277         0.096738            0.998264        0.908961           3.48874          0.015108                         0.13741            0.0955319             0.998444          0.962232             3.43009            0.01276"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable Importances: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>variable</b></td>\n",
       "<td><b>relative_importance</b></td>\n",
       "<td><b>scaled_importance</b></td>\n",
       "<td><b>percentage</b></td></tr>\n",
       "<tr><td>city_id</td>\n",
       "<td>955775.3125000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.5581109</td></tr>\n",
       "<tr><td>state_id</td>\n",
       "<td>257751.2343750</td>\n",
       "<td>0.2696776</td>\n",
       "<td>0.1505100</td></tr>\n",
       "<tr><td>category_2</td>\n",
       "<td>160059.9062500</td>\n",
       "<td>0.1674660</td>\n",
       "<td>0.0934646</td></tr>\n",
       "<tr><td>category_1</td>\n",
       "<td>115193.4609375</td>\n",
       "<td>0.1205236</td>\n",
       "<td>0.0672655</td></tr>\n",
       "<tr><td>merchant_group_id</td>\n",
       "<td>70843.8906250</td>\n",
       "<td>0.0741219</td>\n",
       "<td>0.0413682</td></tr>\n",
       "<tr><td>subsector_id</td>\n",
       "<td>31761.3027344</td>\n",
       "<td>0.0332309</td>\n",
       "<td>0.0185465</td></tr>\n",
       "<tr><td>merchant_category_id</td>\n",
       "<td>19091.6308594</td>\n",
       "<td>0.0199750</td>\n",
       "<td>0.0111483</td></tr>\n",
       "<tr><td>most_recent_sales_range</td>\n",
       "<td>14489.4287109</td>\n",
       "<td>0.0151599</td>\n",
       "<td>0.0084609</td></tr>\n",
       "<tr><td>numerical_1</td>\n",
       "<td>11903.5019531</td>\n",
       "<td>0.0124543</td>\n",
       "<td>0.0069509</td></tr>\n",
       "<tr><td>most_recent_purchases_range</td>\n",
       "<td>10130.6972656</td>\n",
       "<td>0.0105995</td>\n",
       "<td>0.0059157</td></tr>\n",
       "<tr><td>numerical_2</td>\n",
       "<td>9703.4843750</td>\n",
       "<td>0.0101525</td>\n",
       "<td>0.0056662</td></tr>\n",
       "<tr><td>avg_purchases_lag3</td>\n",
       "<td>8831.2177734</td>\n",
       "<td>0.0092398</td>\n",
       "<td>0.0051569</td></tr>\n",
       "<tr><td>avg_purchases_lag6</td>\n",
       "<td>8387.1093750</td>\n",
       "<td>0.0087752</td>\n",
       "<td>0.0048975</td></tr>\n",
       "<tr><td>avg_purchases_lag12</td>\n",
       "<td>8357.7822266</td>\n",
       "<td>0.0087445</td>\n",
       "<td>0.0048804</td></tr>\n",
       "<tr><td>avg_sales_lag3</td>\n",
       "<td>8332.0605469</td>\n",
       "<td>0.0087176</td>\n",
       "<td>0.0048654</td></tr>\n",
       "<tr><td>avg_sales_lag12</td>\n",
       "<td>7839.9199219</td>\n",
       "<td>0.0082027</td>\n",
       "<td>0.0045780</td></tr>\n",
       "<tr><td>avg_sales_lag6</td>\n",
       "<td>7648.2841797</td>\n",
       "<td>0.0080022</td>\n",
       "<td>0.0044661</td></tr>\n",
       "<tr><td>active_months_lag12</td>\n",
       "<td>4748.7172852</td>\n",
       "<td>0.0049684</td>\n",
       "<td>0.0027729</td></tr>\n",
       "<tr><td>active_months_lag6</td>\n",
       "<td>1353.7655029</td>\n",
       "<td>0.0014164</td>\n",
       "<td>0.0007905</td></tr>\n",
       "<tr><td>active_months_lag3</td>\n",
       "<td>315.8672791</td>\n",
       "<td>0.0003305</td>\n",
       "<td>0.0001844</td></tr></table></div>"
      ],
      "text/plain": [
       "variable                     relative_importance    scaled_importance    percentage\n",
       "---------------------------  ---------------------  -------------------  ------------\n",
       "city_id                      955775                 1                    0.558111\n",
       "state_id                     257751                 0.269678             0.15051\n",
       "category_2                   160060                 0.167466             0.0934646\n",
       "category_1                   115193                 0.120524             0.0672655\n",
       "merchant_group_id            70843.9                0.0741219            0.0413682\n",
       "subsector_id                 31761.3                0.0332309            0.0185465\n",
       "merchant_category_id         19091.6                0.019975             0.0111483\n",
       "most_recent_sales_range      14489.4                0.0151599            0.00846089\n",
       "numerical_1                  11903.5                0.0124543            0.00695087\n",
       "most_recent_purchases_range  10130.7                0.0105995            0.00591567\n",
       "numerical_2                  9703.48                0.0101525            0.00566621\n",
       "avg_purchases_lag3           8831.22                0.00923985           0.00515686\n",
       "avg_purchases_lag6           8387.11                0.00877519           0.00489753\n",
       "avg_purchases_lag12          8357.78                0.00874451           0.0048804\n",
       "avg_sales_lag3               8332.06                0.00871759           0.00486538\n",
       "avg_sales_lag12              7839.92                0.00820268           0.00457801\n",
       "avg_sales_lag6               7648.28                0.00800218           0.0044661\n",
       "active_months_lag12          4748.72                0.00496845           0.00277294\n",
       "active_months_lag6           1353.77                0.00141641           0.000790511\n",
       "active_months_lag3           315.867                0.000330483          0.000184446"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<bound method H2OEstimator.get_params of >"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aml.leader.get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_id</th>\n",
       "      <th>auc</th>\n",
       "      <th>logloss</th>\n",
       "      <th>mean_per_class_error</th>\n",
       "      <th>rmse</th>\n",
       "      <th>mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DRF_1_AutoML_20181211_205354</td>\n",
       "      <td>0.998415</td>\n",
       "      <td>0.098484</td>\n",
       "      <td>0.018678</td>\n",
       "      <td>0.140850</td>\n",
       "      <td>0.019839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DRF_1_AutoML_20181211_204538</td>\n",
       "      <td>0.998365</td>\n",
       "      <td>0.103154</td>\n",
       "      <td>0.020717</td>\n",
       "      <td>0.144604</td>\n",
       "      <td>0.020910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>StackedEnsemble_AllModels_AutoML_20181211_204538</td>\n",
       "      <td>0.998342</td>\n",
       "      <td>0.038458</td>\n",
       "      <td>0.020807</td>\n",
       "      <td>0.103479</td>\n",
       "      <td>0.010708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>StackedEnsemble_BestOfFamily_AutoML_20181211_2...</td>\n",
       "      <td>0.998342</td>\n",
       "      <td>0.038458</td>\n",
       "      <td>0.020807</td>\n",
       "      <td>0.103479</td>\n",
       "      <td>0.010708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XRT_1_AutoML_20181211_204538</td>\n",
       "      <td>0.998057</td>\n",
       "      <td>0.116858</td>\n",
       "      <td>0.023724</td>\n",
       "      <td>0.155790</td>\n",
       "      <td>0.024271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XRT_1_AutoML_20181211_205354</td>\n",
       "      <td>0.997643</td>\n",
       "      <td>0.125676</td>\n",
       "      <td>0.025922</td>\n",
       "      <td>0.164174</td>\n",
       "      <td>0.026953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GLM_grid_1_AutoML_20181211_204538_model_1</td>\n",
       "      <td>0.636805</td>\n",
       "      <td>0.558565</td>\n",
       "      <td>0.423959</td>\n",
       "      <td>0.433881</td>\n",
       "      <td>0.188253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GLM_grid_1_AutoML_20181211_205354_model_1</td>\n",
       "      <td>0.636805</td>\n",
       "      <td>0.558565</td>\n",
       "      <td>0.423959</td>\n",
       "      <td>0.433881</td>\n",
       "      <td>0.188253</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            model_id       auc   logloss  \\\n",
       "0                       DRF_1_AutoML_20181211_205354  0.998415  0.098484   \n",
       "1                       DRF_1_AutoML_20181211_204538  0.998365  0.103154   \n",
       "2   StackedEnsemble_AllModels_AutoML_20181211_204538  0.998342  0.038458   \n",
       "3  StackedEnsemble_BestOfFamily_AutoML_20181211_2...  0.998342  0.038458   \n",
       "4                       XRT_1_AutoML_20181211_204538  0.998057  0.116858   \n",
       "5                       XRT_1_AutoML_20181211_205354  0.997643  0.125676   \n",
       "6          GLM_grid_1_AutoML_20181211_204538_model_1  0.636805  0.558565   \n",
       "7          GLM_grid_1_AutoML_20181211_205354_model_1  0.636805  0.558565   \n",
       "\n",
       "   mean_per_class_error      rmse       mse  \n",
       "0              0.018678  0.140850  0.019839  \n",
       "1              0.020717  0.144604  0.020910  \n",
       "2              0.020807  0.103479  0.010708  \n",
       "3              0.020807  0.103479  0.010708  \n",
       "4              0.023724  0.155790  0.024271  \n",
       "5              0.025922  0.164174  0.026953  \n",
       "6              0.423959  0.433881  0.188253  \n",
       "7              0.423959  0.433881  0.188253  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aml_leaderboard_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DRF_1_AutoML_20181211_205354\n",
      "DRF_1_AutoML_20181211_204538\n",
      "XRT_1_AutoML_20181211_204538\n",
      "XRT_1_AutoML_20181211_205354\n",
      "GLM_grid_1_AutoML_20181211_204538_model_1\n",
      "GLM_grid_1_AutoML_20181211_205354_model_1\n",
      "model_id  DRF_1_AutoML_20181211_205354\n"
     ]
    }
   ],
   "source": [
    "m_id=''\n",
    "for model in aml_leaderboard_df['model_id']:\n",
    "    if 'StackedEnsemble' not in model:\n",
    "      print (model)\n",
    "      if m_id=='':\n",
    "            m_id=model\n",
    "print (\"model_id \", m_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drf\n"
     ]
    }
   ],
   "source": [
    "non_stacked= h2o.get_model(m_id)\n",
    "print (non_stacked.algo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['F0point5',\n",
       " 'F1',\n",
       " 'F2',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_bc',\n",
       " '_bcin',\n",
       " '_check_and_save_parm',\n",
       " '_check_targets',\n",
       " '_compute_algo',\n",
       " '_estimator_type',\n",
       " '_future',\n",
       " '_get_metrics',\n",
       " '_have_mojo',\n",
       " '_have_pojo',\n",
       " '_id',\n",
       " '_is_xvalidated',\n",
       " '_job',\n",
       " '_keyify_if_h2oframe',\n",
       " '_metrics_class',\n",
       " '_model_json',\n",
       " '_parms',\n",
       " '_plot',\n",
       " '_requires_training_frame',\n",
       " '_resolve_model',\n",
       " '_verify_training_frame_params',\n",
       " '_xval_keys',\n",
       " 'accuracy',\n",
       " 'actual_params',\n",
       " 'aic',\n",
       " 'algo',\n",
       " 'auc',\n",
       " 'balance_classes',\n",
       " 'biases',\n",
       " 'binomial_double_trees',\n",
       " 'build_tree_one_node',\n",
       " 'calibrate_model',\n",
       " 'calibration_frame',\n",
       " 'categorical_encoding',\n",
       " 'catoffsets',\n",
       " 'checkpoint',\n",
       " 'class_sampling_factors',\n",
       " 'coef',\n",
       " 'coef_norm',\n",
       " 'col_sample_rate_change_per_level',\n",
       " 'col_sample_rate_per_tree',\n",
       " 'confusion_matrix',\n",
       " 'convert_H2OXGBoostParams_2_XGBoostParams',\n",
       " 'cross_validation_fold_assignment',\n",
       " 'cross_validation_holdout_predictions',\n",
       " 'cross_validation_metrics_summary',\n",
       " 'cross_validation_models',\n",
       " 'cross_validation_predictions',\n",
       " 'custom_metric_func',\n",
       " 'deepfeatures',\n",
       " 'default_params',\n",
       " 'distribution',\n",
       " 'download_mojo',\n",
       " 'download_pojo',\n",
       " 'error',\n",
       " 'fallout',\n",
       " 'find_idx_by_threshold',\n",
       " 'find_threshold_by_max_metric',\n",
       " 'fit',\n",
       " 'fnr',\n",
       " 'fold_assignment',\n",
       " 'fold_column',\n",
       " 'fpr',\n",
       " 'full_parameters',\n",
       " 'gains_lift',\n",
       " 'get_params',\n",
       " 'get_xval_models',\n",
       " 'gini',\n",
       " 'have_mojo',\n",
       " 'have_pojo',\n",
       " 'histogram_type',\n",
       " 'ignore_const_cols',\n",
       " 'ignored_columns',\n",
       " 'is_cross_validated',\n",
       " 'join',\n",
       " 'keep_cross_validation_fold_assignment',\n",
       " 'keep_cross_validation_models',\n",
       " 'keep_cross_validation_predictions',\n",
       " 'logloss',\n",
       " 'mae',\n",
       " 'max_after_balance_size',\n",
       " 'max_confusion_matrix_size',\n",
       " 'max_depth',\n",
       " 'max_hit_ratio_k',\n",
       " 'max_per_class_error',\n",
       " 'max_runtime_secs',\n",
       " 'mcc',\n",
       " 'mean_per_class_error',\n",
       " 'mean_residual_deviance',\n",
       " 'metric',\n",
       " 'min_rows',\n",
       " 'min_split_improvement',\n",
       " 'missrate',\n",
       " 'mixin',\n",
       " 'model_id',\n",
       " 'model_performance',\n",
       " 'mse',\n",
       " 'mtries',\n",
       " 'nbins',\n",
       " 'nbins_cats',\n",
       " 'nbins_top_level',\n",
       " 'nfolds',\n",
       " 'normmul',\n",
       " 'normsub',\n",
       " 'ntrees',\n",
       " 'null_degrees_of_freedom',\n",
       " 'null_deviance',\n",
       " 'offset_column',\n",
       " 'params',\n",
       " 'parms',\n",
       " 'partial_plot',\n",
       " 'plot',\n",
       " 'pprint_coef',\n",
       " 'precision',\n",
       " 'predict',\n",
       " 'predict_leaf_node_assignment',\n",
       " 'r2',\n",
       " 'r2_stopping',\n",
       " 'recall',\n",
       " 'residual_degrees_of_freedom',\n",
       " 'residual_deviance',\n",
       " 'respmul',\n",
       " 'response_column',\n",
       " 'respsub',\n",
       " 'rmse',\n",
       " 'rmsle',\n",
       " 'roc',\n",
       " 'rotation',\n",
       " 'sample_rate',\n",
       " 'sample_rate_per_class',\n",
       " 'save_model_details',\n",
       " 'save_mojo',\n",
       " 'score_each_iteration',\n",
       " 'score_history',\n",
       " 'score_tree_interval',\n",
       " 'scoring_history',\n",
       " 'seed',\n",
       " 'sensitivity',\n",
       " 'set_params',\n",
       " 'show',\n",
       " 'specificity',\n",
       " 'staged_predict_proba',\n",
       " 'start',\n",
       " 'std_coef_plot',\n",
       " 'stopping_metric',\n",
       " 'stopping_rounds',\n",
       " 'stopping_tolerance',\n",
       " 'summary',\n",
       " 'tnr',\n",
       " 'tpr',\n",
       " 'train',\n",
       " 'training_frame',\n",
       " 'type',\n",
       " 'validation_frame',\n",
       " 'varimp',\n",
       " 'varimp_plot',\n",
       " 'weights',\n",
       " 'weights_column',\n",
       " 'xval_keys',\n",
       " 'xvals']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(non_stacked)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Suprita Ganesh\\\\Desktop\\\\ML3\\\\models\\\\DRF_1_AutoML_20181211_205354'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h2o.save_model(aml.leader, path = \"./models\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Suprita Ganesh\\\\Desktop\\\\ML3\\\\models\\\\DRF_1_AutoML_20181211_205354.zip'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aml.leader.download_mojo(path = \"./models\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into training and test for showing how to predict\n",
    "train, test = df.split_frame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drf prediction progress: |████████████████████████████████████████████████| 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>predict  </th><th style=\"text-align: right;\">         N</th><th style=\"text-align: right;\">        Y</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>Y        </td><td style=\"text-align: right;\">0.00849436</td><td style=\"text-align: right;\">0.991506 </td></tr>\n",
       "<tr><td>Y        </td><td style=\"text-align: right;\">0.00849436</td><td style=\"text-align: right;\">0.991506 </td></tr>\n",
       "<tr><td>Y        </td><td style=\"text-align: right;\">0.00849436</td><td style=\"text-align: right;\">0.991506 </td></tr>\n",
       "<tr><td>N        </td><td style=\"text-align: right;\">0.97687   </td><td style=\"text-align: right;\">0.0231296</td></tr>\n",
       "<tr><td>N        </td><td style=\"text-align: right;\">0.98616   </td><td style=\"text-align: right;\">0.0138398</td></tr>\n",
       "<tr><td>N        </td><td style=\"text-align: right;\">0.960908  </td><td style=\"text-align: right;\">0.0390924</td></tr>\n",
       "<tr><td>N        </td><td style=\"text-align: right;\">0.945197  </td><td style=\"text-align: right;\">0.0548034</td></tr>\n",
       "<tr><td>N        </td><td style=\"text-align: right;\">0.95929   </td><td style=\"text-align: right;\">0.0407101</td></tr>\n",
       "<tr><td>Y        </td><td style=\"text-align: right;\">0.121561  </td><td style=\"text-align: right;\">0.878439 </td></tr>\n",
       "<tr><td>N        </td><td style=\"text-align: right;\">0.907685  </td><td style=\"text-align: right;\">0.092315 </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = aml.predict(test)\n",
    "pred.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ModelMetricsBinomial: drf\n",
      "** Reported on test data. **\n",
      "\n",
      "MSE: 0.013160420206305526\n",
      "RMSE: 0.11471887467328785\n",
      "LogLoss: 0.0766522937781008\n",
      "Mean Per-Class Error: 0.006344811648972604\n",
      "AUC: 0.9997667549430631\n",
      "pr_auc: 0.959552665440475\n",
      "Gini: 0.9995335098861262\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4619571400396526: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>N</b></td>\n",
       "<td><b>Y</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>N</td>\n",
       "<td>59697.0</td>\n",
       "<td>83.0</td>\n",
       "<td>0.0014</td>\n",
       "<td> (83.0/59780.0)</td></tr>\n",
       "<tr><td>Y</td>\n",
       "<td>339.0</td>\n",
       "<td>23517.0</td>\n",
       "<td>0.0142</td>\n",
       "<td> (339.0/23856.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>60036.0</td>\n",
       "<td>23600.0</td>\n",
       "<td>0.005</td>\n",
       "<td> (422.0/83636.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       N      Y      Error    Rate\n",
       "-----  -----  -----  -------  ---------------\n",
       "N      59697  83     0.0014   (83.0/59780.0)\n",
       "Y      339    23517  0.0142   (339.0/23856.0)\n",
       "Total  60036  23600  0.005    (422.0/83636.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.4619571</td>\n",
       "<td>0.9911076</td>\n",
       "<td>190.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.3775998</td>\n",
       "<td>0.9916363</td>\n",
       "<td>208.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.5279627</td>\n",
       "<td>0.9949110</td>\n",
       "<td>178.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.4619571</td>\n",
       "<td>0.9949543</td>\n",
       "<td>190.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9999750</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0121433</td>\n",
       "<td>1.0</td>\n",
       "<td>381.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9999750</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.4619571</td>\n",
       "<td>0.9876136</td>\n",
       "<td>190.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.3819419</td>\n",
       "<td>0.9934761</td>\n",
       "<td>207.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.3952244</td>\n",
       "<td>0.9936552</td>\n",
       "<td>204.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.461957     0.991108  190\n",
       "max f2                       0.3776       0.991636  208\n",
       "max f0point5                 0.527963     0.994911  178\n",
       "max accuracy                 0.461957     0.994954  190\n",
       "max precision                0.999975     1         0\n",
       "max recall                   0.0121433    1         381\n",
       "max specificity              0.999975     1         0\n",
       "max absolute_mcc             0.461957     0.987614  190\n",
       "max min_per_class_accuracy   0.381942     0.993476  207\n",
       "max mean_per_class_accuracy  0.395224     0.993655  204"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 28.52 %, avg score: 28.57 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>score</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>cumulative_score</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0110240</td>\n",
       "<td>1.0</td>\n",
       "<td>3.5058685</td>\n",
       "<td>3.5058685</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0386486</td>\n",
       "<td>0.0386486</td>\n",
       "<td>250.5868545</td>\n",
       "<td>250.5868545</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0230164</td>\n",
       "<td>0.9915056</td>\n",
       "<td>3.5058685</td>\n",
       "<td>3.5058685</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9935883</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9966592</td>\n",
       "<td>0.0420439</td>\n",
       "<td>0.0806925</td>\n",
       "<td>250.5868545</td>\n",
       "<td>250.5868545</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0308001</td>\n",
       "<td>0.9856196</td>\n",
       "<td>3.5058685</td>\n",
       "<td>3.5058685</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9882230</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9945273</td>\n",
       "<td>0.0272887</td>\n",
       "<td>0.1079812</td>\n",
       "<td>250.5868545</td>\n",
       "<td>250.5868545</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0400067</td>\n",
       "<td>0.9792541</td>\n",
       "<td>3.5058685</td>\n",
       "<td>3.5058685</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9819725</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9916381</td>\n",
       "<td>0.0322770</td>\n",
       "<td>0.1402582</td>\n",
       "<td>250.5868545</td>\n",
       "<td>250.5868545</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0500024</td>\n",
       "<td>0.9688532</td>\n",
       "<td>3.5058685</td>\n",
       "<td>3.5058685</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9737474</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9880617</td>\n",
       "<td>0.0350436</td>\n",
       "<td>0.1753018</td>\n",
       "<td>250.5868545</td>\n",
       "<td>250.5868545</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1000048</td>\n",
       "<td>0.9325245</td>\n",
       "<td>3.5058685</td>\n",
       "<td>3.5058685</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9502727</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9691672</td>\n",
       "<td>0.1753018</td>\n",
       "<td>0.3506036</td>\n",
       "<td>250.5868545</td>\n",
       "<td>250.5868545</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1500072</td>\n",
       "<td>0.9014737</td>\n",
       "<td>3.5058685</td>\n",
       "<td>3.5058685</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9169112</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9517485</td>\n",
       "<td>0.1753018</td>\n",
       "<td>0.5259054</td>\n",
       "<td>250.5868545</td>\n",
       "<td>250.5868545</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2000096</td>\n",
       "<td>0.8626142</td>\n",
       "<td>3.5058685</td>\n",
       "<td>3.5058685</td>\n",
       "<td>1.0</td>\n",
       "<td>0.8835939</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9347099</td>\n",
       "<td>0.1753018</td>\n",
       "<td>0.7012072</td>\n",
       "<td>250.5868545</td>\n",
       "<td>250.5868545</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3000024</td>\n",
       "<td>0.3037673</td>\n",
       "<td>2.9634084</td>\n",
       "<td>3.3250629</td>\n",
       "<td>0.8452708</td>\n",
       "<td>0.7006114</td>\n",
       "<td>0.9484277</td>\n",
       "<td>0.8566833</td>\n",
       "<td>0.2963196</td>\n",
       "<td>0.9975268</td>\n",
       "<td>196.3408435</td>\n",
       "<td>232.5062921</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4000072</td>\n",
       "<td>0.0895307</td>\n",
       "<td>0.0234731</td>\n",
       "<td>2.4996408</td>\n",
       "<td>0.0066954</td>\n",
       "<td>0.1663412</td>\n",
       "<td>0.7129876</td>\n",
       "<td>0.6840926</td>\n",
       "<td>0.0023474</td>\n",
       "<td>0.9998742</td>\n",
       "<td>-97.6526944</td>\n",
       "<td>149.9640783</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0382832</td>\n",
       "<td>0.0008384</td>\n",
       "<td>1.9999162</td>\n",
       "<td>0.0002391</td>\n",
       "<td>0.0592837</td>\n",
       "<td>0.5704481</td>\n",
       "<td>0.5591398</td>\n",
       "<td>0.0000838</td>\n",
       "<td>0.9999581</td>\n",
       "<td>-99.9161576</td>\n",
       "<td>99.9916164</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.6000048</td>\n",
       "<td>0.0204578</td>\n",
       "<td>0.0</td>\n",
       "<td>1.6665835</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0278722</td>\n",
       "<td>0.4753697</td>\n",
       "<td>0.4705916</td>\n",
       "<td>0.0</td>\n",
       "<td>0.9999581</td>\n",
       "<td>-100.0</td>\n",
       "<td>66.6583519</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.6999976</td>\n",
       "<td>0.0126461</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4285164</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0160211</td>\n",
       "<td>0.4074643</td>\n",
       "<td>0.4056574</td>\n",
       "<td>0.0</td>\n",
       "<td>0.9999581</td>\n",
       "<td>-100.0</td>\n",
       "<td>42.8516426</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.8000383</td>\n",
       "<td>0.0076183</td>\n",
       "<td>0.0004190</td>\n",
       "<td>1.2499402</td>\n",
       "<td>0.0001195</td>\n",
       "<td>0.0100689</td>\n",
       "<td>0.3565280</td>\n",
       "<td>0.3561911</td>\n",
       "<td>0.0000419</td>\n",
       "<td>1.0</td>\n",
       "<td>-99.9580989</td>\n",
       "<td>24.9940220</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.9000430</td>\n",
       "<td>0.0034227</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1110580</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0057087</td>\n",
       "<td>0.3169138</td>\n",
       "<td>0.3172486</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.1057973</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0014302</td>\n",
       "<td>0.2852360</td>\n",
       "<td>0.2856804</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift         cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  -----------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.011024                    1                  3.50587      3.50587            1                1           1                           1                   0.0386486       0.0386486                  250.587   250.587\n",
       "    2        0.0230164                   0.991506           3.50587      3.50587            1                0.993588    1                           0.996659            0.0420439       0.0806925                  250.587   250.587\n",
       "    3        0.0308001                   0.98562            3.50587      3.50587            1                0.988223    1                           0.994527            0.0272887       0.107981                   250.587   250.587\n",
       "    4        0.0400067                   0.979254           3.50587      3.50587            1                0.981973    1                           0.991638            0.032277        0.140258                   250.587   250.587\n",
       "    5        0.0500024                   0.968853           3.50587      3.50587            1                0.973747    1                           0.988062            0.0350436       0.175302                   250.587   250.587\n",
       "    6        0.100005                    0.932525           3.50587      3.50587            1                0.950273    1                           0.969167            0.175302        0.350604                   250.587   250.587\n",
       "    7        0.150007                    0.901474           3.50587      3.50587            1                0.916911    1                           0.951749            0.175302        0.525905                   250.587   250.587\n",
       "    8        0.20001                     0.862614           3.50587      3.50587            1                0.883594    1                           0.93471             0.175302        0.701207                   250.587   250.587\n",
       "    9        0.300002                    0.303767           2.96341      3.32506            0.845271         0.700611    0.948428                    0.856683            0.29632         0.997527                   196.341   232.506\n",
       "    10       0.400007                    0.0895307          0.0234731    2.49964            0.00669536       0.166341    0.712988                    0.684093            0.00234742      0.999874                   -97.6527  149.964\n",
       "    11       0.5                         0.0382832          0.000838424  1.99992            0.000239149      0.0592837   0.570448                    0.55914             8.38364e-05     0.999958                   -99.9162  99.9916\n",
       "    12       0.600005                    0.0204578          0            1.66658            0                0.0278722   0.47537                     0.470592            0               0.999958                   -100      66.6584\n",
       "    13       0.699998                    0.0126461          0            1.42852            0                0.0160211   0.407464                    0.405657            0               0.999958                   -100      42.8516\n",
       "    14       0.800038                    0.00761832         0.000419011  1.24994            0.000119517      0.0100689   0.356528                    0.356191            4.19182e-05     1                          -99.9581  24.994\n",
       "    15       0.900043                    0.00342272         0            1.11106            0                0.00570865  0.316914                    0.317249            0               1                          -100      11.1058\n",
       "    16       1                           0                  0            1                  0                0.00143021  0.285236                    0.28568             0               1                          -100      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf = aml.leader.model_performance(test)\n",
    "perf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['F0point5',\n",
       " 'F1',\n",
       " 'F2',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_algo',\n",
       " '_bc',\n",
       " '_bcin',\n",
       " '_has',\n",
       " '_metric_json',\n",
       " '_on_train',\n",
       " '_on_valid',\n",
       " '_on_xval',\n",
       " 'accuracy',\n",
       " 'aic',\n",
       " 'auc',\n",
       " 'confusion_matrix',\n",
       " 'custom_metric_name',\n",
       " 'custom_metric_value',\n",
       " 'error',\n",
       " 'fallout',\n",
       " 'find_idx_by_threshold',\n",
       " 'find_threshold_by_max_metric',\n",
       " 'fnr',\n",
       " 'fpr',\n",
       " 'fprs',\n",
       " 'gains_lift',\n",
       " 'gini',\n",
       " 'logloss',\n",
       " 'mae',\n",
       " 'make',\n",
       " 'max_per_class_error',\n",
       " 'mcc',\n",
       " 'mean_per_class_error',\n",
       " 'mean_residual_deviance',\n",
       " 'metric',\n",
       " 'missrate',\n",
       " 'mse',\n",
       " 'nobs',\n",
       " 'null_degrees_of_freedom',\n",
       " 'null_deviance',\n",
       " 'plot',\n",
       " 'pr_auc',\n",
       " 'precision',\n",
       " 'r2',\n",
       " 'recall',\n",
       " 'residual_degrees_of_freedom',\n",
       " 'residual_deviance',\n",
       " 'rmse',\n",
       " 'rmsle',\n",
       " 'sensitivity',\n",
       " 'show',\n",
       " 'specificity',\n",
       " 'tnr',\n",
       " 'tpr',\n",
       " 'tprs']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(perf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4619571400396526: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>N</b></td>\n",
       "<td><b>Y</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>N</td>\n",
       "<td>59697.0</td>\n",
       "<td>83.0</td>\n",
       "<td>0.0014</td>\n",
       "<td> (83.0/59780.0)</td></tr>\n",
       "<tr><td>Y</td>\n",
       "<td>339.0</td>\n",
       "<td>23517.0</td>\n",
       "<td>0.0142</td>\n",
       "<td> (339.0/23856.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>60036.0</td>\n",
       "<td>23600.0</td>\n",
       "<td>0.005</td>\n",
       "<td> (422.0/83636.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       N      Y      Error    Rate\n",
       "-----  -----  -----  -------  ---------------\n",
       "N      59697  83     0.0014   (83.0/59780.0)\n",
       "Y      339    23517  0.0142   (339.0/23856.0)\n",
       "Total  60036  23600  0.005    (422.0/83636.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d=perf.confusion_matrix()\n",
    "d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'drf'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aml.leader.algo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9997667549430631"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aml.leader.model_performance(test).auc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ModelMetricsBinomial: drf\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.020242828646662245\n",
      "RMSE: 0.14227729490913948\n",
      "LogLoss: 0.09673799546133012\n",
      "Mean Per-Class Error: 0.01872350523172872\n",
      "AUC: 0.9982640258173935\n",
      "pr_auc: 0.9089612037582203\n",
      "Gini: 0.996528051634787\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.49174027253987507: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>N</b></td>\n",
       "<td><b>Y</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>N</td>\n",
       "<td>213435.0</td>\n",
       "<td>1453.0</td>\n",
       "<td>0.0068</td>\n",
       "<td> (1453.0/214888.0)</td></tr>\n",
       "<tr><td>Y</td>\n",
       "<td>3098.0</td>\n",
       "<td>83246.0</td>\n",
       "<td>0.0359</td>\n",
       "<td> (3098.0/86344.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>216533.0</td>\n",
       "<td>84699.0</td>\n",
       "<td>0.0151</td>\n",
       "<td> (4551.0/301232.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       N       Y      Error    Rate\n",
       "-----  ------  -----  -------  -----------------\n",
       "N      213435  1453   0.0068   (1453.0/214888.0)\n",
       "Y      3098    83246  0.0359   (3098.0/86344.0)\n",
       "Total  216533  84699  0.0151   (4551.0/301232.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.4917403</td>\n",
       "<td>0.9733927</td>\n",
       "<td>188.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.3549770</td>\n",
       "<td>0.9761585</td>\n",
       "<td>222.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.5960178</td>\n",
       "<td>0.9839807</td>\n",
       "<td>165.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.4917403</td>\n",
       "<td>0.9848920</td>\n",
       "<td>188.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9999810</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0000123</td>\n",
       "<td>1.0</td>\n",
       "<td>399.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9999810</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.4917403</td>\n",
       "<td>0.9629320</td>\n",
       "<td>188.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.3912923</td>\n",
       "<td>0.9810294</td>\n",
       "<td>212.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.4162169</td>\n",
       "<td>0.9812765</td>\n",
       "<td>206.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.49174      0.973393  188\n",
       "max f2                       0.354977     0.976159  222\n",
       "max f0point5                 0.596018     0.983981  165\n",
       "max accuracy                 0.49174      0.984892  188\n",
       "max precision                0.999981     1         0\n",
       "max recall                   1.23132e-05  1         399\n",
       "max specificity              0.999981     1         0\n",
       "max absolute_mcc             0.49174      0.962932  188\n",
       "max min_per_class_accuracy   0.391292     0.981029  212\n",
       "max mean_per_class_accuracy  0.416217     0.981276  206"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 28.66 %, avg score: 28.74 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>score</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>cumulative_score</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0245724</td>\n",
       "<td>1.0</td>\n",
       "<td>3.4887427</td>\n",
       "<td>3.4887427</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0857269</td>\n",
       "<td>0.0857269</td>\n",
       "<td>248.8742704</td>\n",
       "<td>248.8742704</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0300001</td>\n",
       "<td>0.9923801</td>\n",
       "<td>3.4887427</td>\n",
       "<td>3.4887427</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9960116</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9992784</td>\n",
       "<td>0.0189359</td>\n",
       "<td>0.1046627</td>\n",
       "<td>248.8742704</td>\n",
       "<td>248.8742704</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0400024</td>\n",
       "<td>0.9817353</td>\n",
       "<td>3.4887427</td>\n",
       "<td>3.4887427</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9873043</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9962844</td>\n",
       "<td>0.0348953</td>\n",
       "<td>0.1395580</td>\n",
       "<td>248.8742704</td>\n",
       "<td>248.8742704</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0500013</td>\n",
       "<td>0.9724944</td>\n",
       "<td>3.4887427</td>\n",
       "<td>3.4887427</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9772090</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9924698</td>\n",
       "<td>0.0348837</td>\n",
       "<td>0.1744418</td>\n",
       "<td>248.8742704</td>\n",
       "<td>248.8742704</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.1000060</td>\n",
       "<td>0.9298701</td>\n",
       "<td>3.4880479</td>\n",
       "<td>3.4883953</td>\n",
       "<td>0.9998008</td>\n",
       "<td>0.9503510</td>\n",
       "<td>0.9999004</td>\n",
       "<td>0.9714097</td>\n",
       "<td>0.1744186</td>\n",
       "<td>0.3488604</td>\n",
       "<td>248.8047873</td>\n",
       "<td>248.8395277</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1500007</td>\n",
       "<td>0.8884800</td>\n",
       "<td>3.4885110</td>\n",
       "<td>3.4884339</td>\n",
       "<td>0.9999336</td>\n",
       "<td>0.9095350</td>\n",
       "<td>0.9999115</td>\n",
       "<td>0.9507871</td>\n",
       "<td>0.1744070</td>\n",
       "<td>0.5232674</td>\n",
       "<td>248.8511047</td>\n",
       "<td>248.8433863</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.2000020</td>\n",
       "<td>0.8358737</td>\n",
       "<td>3.4873530</td>\n",
       "<td>3.4881636</td>\n",
       "<td>0.9996016</td>\n",
       "<td>0.8638037</td>\n",
       "<td>0.9998340</td>\n",
       "<td>0.9290409</td>\n",
       "<td>0.1743723</td>\n",
       "<td>0.6976397</td>\n",
       "<td>248.7352951</td>\n",
       "<td>248.8163630</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.3000013</td>\n",
       "<td>0.3581678</td>\n",
       "<td>2.8753781</td>\n",
       "<td>3.2839041</td>\n",
       "<td>0.8241875</td>\n",
       "<td>0.6756746</td>\n",
       "<td>0.9412858</td>\n",
       "<td>0.8445864</td>\n",
       "<td>0.2875359</td>\n",
       "<td>0.9851756</td>\n",
       "<td>187.5378120</td>\n",
       "<td>228.3904054</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.4000007</td>\n",
       "<td>0.1144822</td>\n",
       "<td>0.1351579</td>\n",
       "<td>2.4967241</td>\n",
       "<td>0.0387412</td>\n",
       "<td>0.2041120</td>\n",
       "<td>0.7156515</td>\n",
       "<td>0.6844691</td>\n",
       "<td>0.0135157</td>\n",
       "<td>0.9986913</td>\n",
       "<td>-86.4842056</td>\n",
       "<td>149.6724059</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0506433</td>\n",
       "<td>0.0044010</td>\n",
       "<td>1.9982628</td>\n",
       "<td>0.0012615</td>\n",
       "<td>0.0768782</td>\n",
       "<td>0.5727745</td>\n",
       "<td>0.5629517</td>\n",
       "<td>0.0004401</td>\n",
       "<td>0.9991314</td>\n",
       "<td>-99.5598970</td>\n",
       "<td>99.8262763</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.6000027</td>\n",
       "<td>0.0228758</td>\n",
       "<td>0.0026637</td>\n",
       "<td>1.6656556</td>\n",
       "<td>0.0007635</td>\n",
       "<td>0.0346323</td>\n",
       "<td>0.4774372</td>\n",
       "<td>0.4748965</td>\n",
       "<td>0.0002664</td>\n",
       "<td>0.9993978</td>\n",
       "<td>-99.7336307</td>\n",
       "<td>66.5655557</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.7000186</td>\n",
       "<td>0.0115814</td>\n",
       "<td>0.0020844</td>\n",
       "<td>1.4279710</td>\n",
       "<td>0.0005975</td>\n",
       "<td>0.0165641</td>\n",
       "<td>0.4093082</td>\n",
       "<td>0.4094118</td>\n",
       "<td>0.0002085</td>\n",
       "<td>0.9996062</td>\n",
       "<td>-99.7915648</td>\n",
       "<td>42.7970971</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.7999980</td>\n",
       "<td>0.0032095</td>\n",
       "<td>0.0028960</td>\n",
       "<td>1.2498728</td>\n",
       "<td>0.0008301</td>\n",
       "<td>0.0069621</td>\n",
       "<td>0.3582588</td>\n",
       "<td>0.3591158</td>\n",
       "<td>0.0002895</td>\n",
       "<td>0.9998958</td>\n",
       "<td>-99.7104009</td>\n",
       "<td>24.9872819</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0005212</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0001494</td>\n",
       "<td>0.0006021</td>\n",
       "<td>0.2866362</td>\n",
       "<td>0.2874123</td>\n",
       "<td>0.0001042</td>\n",
       "<td>1.0</td>\n",
       "<td>-99.9478834</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift         cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  -----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.0245724                   1                  3.48874      3.48874            1                1            1                           1                   0.0857269       0.0857269                  248.874   248.874\n",
       "    2        0.0300001                   0.99238            3.48874      3.48874            1                0.996012     1                           0.999278            0.0189359       0.104663                   248.874   248.874\n",
       "    3        0.0400024                   0.981735           3.48874      3.48874            1                0.987304     1                           0.996284            0.0348953       0.139558                   248.874   248.874\n",
       "    4        0.0500013                   0.972494           3.48874      3.48874            1                0.977209     1                           0.99247             0.0348837       0.174442                   248.874   248.874\n",
       "    5        0.100006                    0.92987            3.48805      3.4884             0.999801         0.950351     0.9999                      0.97141             0.174419        0.34886                    248.805   248.84\n",
       "    6        0.150001                    0.88848            3.48851      3.48843            0.999934         0.909535     0.999911                    0.950787            0.174407        0.523267                   248.851   248.843\n",
       "    7        0.200002                    0.835874           3.48735      3.48816            0.999602         0.863804     0.999834                    0.929041            0.174372        0.69764                    248.735   248.816\n",
       "    8        0.300001                    0.358168           2.87538      3.2839             0.824187         0.675675     0.941286                    0.844586            0.287536        0.985176                   187.538   228.39\n",
       "    9        0.400001                    0.114482           0.135158     2.49672            0.0387412        0.204112     0.715652                    0.684469            0.0135157       0.998691                   -86.4842  149.672\n",
       "    10       0.5                         0.0506433          0.00440103   1.99826            0.00126149       0.0768782    0.572774                    0.562952            0.0004401       0.999131                   -99.5599  99.8263\n",
       "    11       0.600003                    0.0228758          0.00266369   1.66566            0.000763511      0.0346323    0.477437                    0.474897            0.000266376     0.999398                   -99.7336  66.5656\n",
       "    12       0.700019                    0.0115814          0.00208435   1.42797            0.000597451      0.0165641    0.409308                    0.409412            0.000208468     0.999606                   -99.7916  42.7971\n",
       "    13       0.799998                    0.00320951         0.00289599   1.24987            0.000830096      0.00696211   0.358259                    0.359116            0.00028954      0.999896                   -99.7104  24.9873\n",
       "    14       1                           0                  0.000521166  1                  0.000149385      0.000602119  0.286636                    0.287412            0.000104234     1                          -99.9479  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_perf = aml.leader.model_performance()\n",
    "best_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_perf.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2ORandomForestEstimator :  Distributed Random Forest\n",
      "Model Key:  DRF_1_AutoML_20181211_205354\n",
      "\n",
      "\n",
      "ModelMetricsBinomial: drf\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.020242828646662245\n",
      "RMSE: 0.14227729490913948\n",
      "LogLoss: 0.09673799546133012\n",
      "Mean Per-Class Error: 0.01872350523172872\n",
      "AUC: 0.9982640258173935\n",
      "pr_auc: 0.9089612037582203\n",
      "Gini: 0.996528051634787\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.49174027253987507: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>N</b></td>\n",
       "<td><b>Y</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>N</td>\n",
       "<td>213435.0</td>\n",
       "<td>1453.0</td>\n",
       "<td>0.0068</td>\n",
       "<td> (1453.0/214888.0)</td></tr>\n",
       "<tr><td>Y</td>\n",
       "<td>3098.0</td>\n",
       "<td>83246.0</td>\n",
       "<td>0.0359</td>\n",
       "<td> (3098.0/86344.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>216533.0</td>\n",
       "<td>84699.0</td>\n",
       "<td>0.0151</td>\n",
       "<td> (4551.0/301232.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       N       Y      Error    Rate\n",
       "-----  ------  -----  -------  -----------------\n",
       "N      213435  1453   0.0068   (1453.0/214888.0)\n",
       "Y      3098    83246  0.0359   (3098.0/86344.0)\n",
       "Total  216533  84699  0.0151   (4551.0/301232.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.4917403</td>\n",
       "<td>0.9733927</td>\n",
       "<td>188.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.3549770</td>\n",
       "<td>0.9761585</td>\n",
       "<td>222.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.5960178</td>\n",
       "<td>0.9839807</td>\n",
       "<td>165.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.4917403</td>\n",
       "<td>0.9848920</td>\n",
       "<td>188.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9999810</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0000123</td>\n",
       "<td>1.0</td>\n",
       "<td>399.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9999810</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.4917403</td>\n",
       "<td>0.9629320</td>\n",
       "<td>188.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.3912923</td>\n",
       "<td>0.9810294</td>\n",
       "<td>212.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.4162169</td>\n",
       "<td>0.9812765</td>\n",
       "<td>206.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.49174      0.973393  188\n",
       "max f2                       0.354977     0.976159  222\n",
       "max f0point5                 0.596018     0.983981  165\n",
       "max accuracy                 0.49174      0.984892  188\n",
       "max precision                0.999981     1         0\n",
       "max recall                   1.23132e-05  1         399\n",
       "max specificity              0.999981     1         0\n",
       "max absolute_mcc             0.49174      0.962932  188\n",
       "max min_per_class_accuracy   0.391292     0.981029  212\n",
       "max mean_per_class_accuracy  0.416217     0.981276  206"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 28.66 %, avg score: 28.74 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>score</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>cumulative_score</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0245724</td>\n",
       "<td>1.0</td>\n",
       "<td>3.4887427</td>\n",
       "<td>3.4887427</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0857269</td>\n",
       "<td>0.0857269</td>\n",
       "<td>248.8742704</td>\n",
       "<td>248.8742704</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0300001</td>\n",
       "<td>0.9923801</td>\n",
       "<td>3.4887427</td>\n",
       "<td>3.4887427</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9960116</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9992784</td>\n",
       "<td>0.0189359</td>\n",
       "<td>0.1046627</td>\n",
       "<td>248.8742704</td>\n",
       "<td>248.8742704</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0400024</td>\n",
       "<td>0.9817353</td>\n",
       "<td>3.4887427</td>\n",
       "<td>3.4887427</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9873043</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9962844</td>\n",
       "<td>0.0348953</td>\n",
       "<td>0.1395580</td>\n",
       "<td>248.8742704</td>\n",
       "<td>248.8742704</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0500013</td>\n",
       "<td>0.9724944</td>\n",
       "<td>3.4887427</td>\n",
       "<td>3.4887427</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9772090</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9924698</td>\n",
       "<td>0.0348837</td>\n",
       "<td>0.1744418</td>\n",
       "<td>248.8742704</td>\n",
       "<td>248.8742704</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.1000060</td>\n",
       "<td>0.9298701</td>\n",
       "<td>3.4880479</td>\n",
       "<td>3.4883953</td>\n",
       "<td>0.9998008</td>\n",
       "<td>0.9503510</td>\n",
       "<td>0.9999004</td>\n",
       "<td>0.9714097</td>\n",
       "<td>0.1744186</td>\n",
       "<td>0.3488604</td>\n",
       "<td>248.8047873</td>\n",
       "<td>248.8395277</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1500007</td>\n",
       "<td>0.8884800</td>\n",
       "<td>3.4885110</td>\n",
       "<td>3.4884339</td>\n",
       "<td>0.9999336</td>\n",
       "<td>0.9095350</td>\n",
       "<td>0.9999115</td>\n",
       "<td>0.9507871</td>\n",
       "<td>0.1744070</td>\n",
       "<td>0.5232674</td>\n",
       "<td>248.8511047</td>\n",
       "<td>248.8433863</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.2000020</td>\n",
       "<td>0.8358737</td>\n",
       "<td>3.4873530</td>\n",
       "<td>3.4881636</td>\n",
       "<td>0.9996016</td>\n",
       "<td>0.8638037</td>\n",
       "<td>0.9998340</td>\n",
       "<td>0.9290409</td>\n",
       "<td>0.1743723</td>\n",
       "<td>0.6976397</td>\n",
       "<td>248.7352951</td>\n",
       "<td>248.8163630</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.3000013</td>\n",
       "<td>0.3581678</td>\n",
       "<td>2.8753781</td>\n",
       "<td>3.2839041</td>\n",
       "<td>0.8241875</td>\n",
       "<td>0.6756746</td>\n",
       "<td>0.9412858</td>\n",
       "<td>0.8445864</td>\n",
       "<td>0.2875359</td>\n",
       "<td>0.9851756</td>\n",
       "<td>187.5378120</td>\n",
       "<td>228.3904054</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.4000007</td>\n",
       "<td>0.1144822</td>\n",
       "<td>0.1351579</td>\n",
       "<td>2.4967241</td>\n",
       "<td>0.0387412</td>\n",
       "<td>0.2041120</td>\n",
       "<td>0.7156515</td>\n",
       "<td>0.6844691</td>\n",
       "<td>0.0135157</td>\n",
       "<td>0.9986913</td>\n",
       "<td>-86.4842056</td>\n",
       "<td>149.6724059</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0506433</td>\n",
       "<td>0.0044010</td>\n",
       "<td>1.9982628</td>\n",
       "<td>0.0012615</td>\n",
       "<td>0.0768782</td>\n",
       "<td>0.5727745</td>\n",
       "<td>0.5629517</td>\n",
       "<td>0.0004401</td>\n",
       "<td>0.9991314</td>\n",
       "<td>-99.5598970</td>\n",
       "<td>99.8262763</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.6000027</td>\n",
       "<td>0.0228758</td>\n",
       "<td>0.0026637</td>\n",
       "<td>1.6656556</td>\n",
       "<td>0.0007635</td>\n",
       "<td>0.0346323</td>\n",
       "<td>0.4774372</td>\n",
       "<td>0.4748965</td>\n",
       "<td>0.0002664</td>\n",
       "<td>0.9993978</td>\n",
       "<td>-99.7336307</td>\n",
       "<td>66.5655557</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.7000186</td>\n",
       "<td>0.0115814</td>\n",
       "<td>0.0020844</td>\n",
       "<td>1.4279710</td>\n",
       "<td>0.0005975</td>\n",
       "<td>0.0165641</td>\n",
       "<td>0.4093082</td>\n",
       "<td>0.4094118</td>\n",
       "<td>0.0002085</td>\n",
       "<td>0.9996062</td>\n",
       "<td>-99.7915648</td>\n",
       "<td>42.7970971</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.7999980</td>\n",
       "<td>0.0032095</td>\n",
       "<td>0.0028960</td>\n",
       "<td>1.2498728</td>\n",
       "<td>0.0008301</td>\n",
       "<td>0.0069621</td>\n",
       "<td>0.3582588</td>\n",
       "<td>0.3591158</td>\n",
       "<td>0.0002895</td>\n",
       "<td>0.9998958</td>\n",
       "<td>-99.7104009</td>\n",
       "<td>24.9872819</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0005212</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0001494</td>\n",
       "<td>0.0006021</td>\n",
       "<td>0.2866362</td>\n",
       "<td>0.2874123</td>\n",
       "<td>0.0001042</td>\n",
       "<td>1.0</td>\n",
       "<td>-99.9478834</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift         cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  -----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.0245724                   1                  3.48874      3.48874            1                1            1                           1                   0.0857269       0.0857269                  248.874   248.874\n",
       "    2        0.0300001                   0.99238            3.48874      3.48874            1                0.996012     1                           0.999278            0.0189359       0.104663                   248.874   248.874\n",
       "    3        0.0400024                   0.981735           3.48874      3.48874            1                0.987304     1                           0.996284            0.0348953       0.139558                   248.874   248.874\n",
       "    4        0.0500013                   0.972494           3.48874      3.48874            1                0.977209     1                           0.99247             0.0348837       0.174442                   248.874   248.874\n",
       "    5        0.100006                    0.92987            3.48805      3.4884             0.999801         0.950351     0.9999                      0.97141             0.174419        0.34886                    248.805   248.84\n",
       "    6        0.150001                    0.88848            3.48851      3.48843            0.999934         0.909535     0.999911                    0.950787            0.174407        0.523267                   248.851   248.843\n",
       "    7        0.200002                    0.835874           3.48735      3.48816            0.999602         0.863804     0.999834                    0.929041            0.174372        0.69764                    248.735   248.816\n",
       "    8        0.300001                    0.358168           2.87538      3.2839             0.824187         0.675675     0.941286                    0.844586            0.287536        0.985176                   187.538   228.39\n",
       "    9        0.400001                    0.114482           0.135158     2.49672            0.0387412        0.204112     0.715652                    0.684469            0.0135157       0.998691                   -86.4842  149.672\n",
       "    10       0.5                         0.0506433          0.00440103   1.99826            0.00126149       0.0768782    0.572774                    0.562952            0.0004401       0.999131                   -99.5599  99.8263\n",
       "    11       0.600003                    0.0228758          0.00266369   1.66566            0.000763511      0.0346323    0.477437                    0.474897            0.000266376     0.999398                   -99.7336  66.5656\n",
       "    12       0.700019                    0.0115814          0.00208435   1.42797            0.000597451      0.0165641    0.409308                    0.409412            0.000208468     0.999606                   -99.7916  42.7971\n",
       "    13       0.799998                    0.00320951         0.00289599   1.24987            0.000830096      0.00696211   0.358259                    0.359116            0.00028954      0.999896                   -99.7104  24.9873\n",
       "    14       1                           0                  0.000521166  1                  0.000149385      0.000602119  0.286636                    0.287412            0.000104234     1                          -99.9479  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: drf\n",
      "** Reported on validation data. **\n",
      "\n",
      "MSE: 0.018881497714415916\n",
      "RMSE: 0.1374099622094989\n",
      "LogLoss: 0.0955319096107168\n",
      "Mean Per-Class Error: 0.015262034263669788\n",
      "AUC: 0.9984440687687627\n",
      "pr_auc: 0.9622318205609467\n",
      "Gini: 0.9968881375375254\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4416887505133839: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>N</b></td>\n",
       "<td><b>Y</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>N</td>\n",
       "<td>23520.0</td>\n",
       "<td>188.0</td>\n",
       "<td>0.0079</td>\n",
       "<td> (188.0/23708.0)</td></tr>\n",
       "<tr><td>Y</td>\n",
       "<td>239.0</td>\n",
       "<td>9517.0</td>\n",
       "<td>0.0245</td>\n",
       "<td> (239.0/9756.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>23759.0</td>\n",
       "<td>9705.0</td>\n",
       "<td>0.0128</td>\n",
       "<td> (427.0/33464.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       N      Y     Error    Rate\n",
       "-----  -----  ----  -------  ---------------\n",
       "N      23520  188   0.0079   (188.0/23708.0)\n",
       "Y      239    9517  0.0245   (239.0/9756.0)\n",
       "Total  23759  9705  0.0128   (427.0/33464.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.4416888</td>\n",
       "<td>0.9780587</td>\n",
       "<td>195.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.3852141</td>\n",
       "<td>0.9802661</td>\n",
       "<td>210.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.6038533</td>\n",
       "<td>0.9869264</td>\n",
       "<td>161.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.4482769</td>\n",
       "<td>0.9872400</td>\n",
       "<td>193.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9999085</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0044250</td>\n",
       "<td>1.0</td>\n",
       "<td>394.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9999085</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.4416888</td>\n",
       "<td>0.9690697</td>\n",
       "<td>195.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.3852141</td>\n",
       "<td>0.9843513</td>\n",
       "<td>210.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.3914551</td>\n",
       "<td>0.9847380</td>\n",
       "<td>208.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.441689     0.978059  195\n",
       "max f2                       0.385214     0.980266  210\n",
       "max f0point5                 0.603853     0.986926  161\n",
       "max accuracy                 0.448277     0.98724   193\n",
       "max precision                0.999909     1         0\n",
       "max recall                   0.004425     1         394\n",
       "max specificity              0.999909     1         0\n",
       "max absolute_mcc             0.441689     0.96907   195\n",
       "max min_per_class_accuracy   0.385214     0.984351  210\n",
       "max mean_per_class_accuracy  0.391455     0.984738  208"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 29.15 %, avg score: 29.08 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>score</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>cumulative_score</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0100108</td>\n",
       "<td>0.9984228</td>\n",
       "<td>3.4300943</td>\n",
       "<td>3.4300943</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999521</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999521</td>\n",
       "<td>0.0343378</td>\n",
       "<td>0.0343378</td>\n",
       "<td>243.0094301</td>\n",
       "<td>243.0094301</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0200514</td>\n",
       "<td>0.9915056</td>\n",
       "<td>3.4300943</td>\n",
       "<td>3.4300943</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9932968</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9966195</td>\n",
       "<td>0.0344403</td>\n",
       "<td>0.0687782</td>\n",
       "<td>243.0094301</td>\n",
       "<td>243.0094301</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0307495</td>\n",
       "<td>0.9817939</td>\n",
       "<td>3.4300943</td>\n",
       "<td>3.4300943</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9859367</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9929028</td>\n",
       "<td>0.0366954</td>\n",
       "<td>0.1054736</td>\n",
       "<td>243.0094301</td>\n",
       "<td>243.0094301</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0400131</td>\n",
       "<td>0.9722330</td>\n",
       "<td>3.4300943</td>\n",
       "<td>3.4300943</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9778358</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9894146</td>\n",
       "<td>0.0317753</td>\n",
       "<td>0.1372489</td>\n",
       "<td>243.0094301</td>\n",
       "<td>243.0094301</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0500239</td>\n",
       "<td>0.9638823</td>\n",
       "<td>3.4300943</td>\n",
       "<td>3.4300943</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9674898</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9850270</td>\n",
       "<td>0.0343378</td>\n",
       "<td>0.1715867</td>\n",
       "<td>243.0094301</td>\n",
       "<td>243.0094301</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1000179</td>\n",
       "<td>0.9218599</td>\n",
       "<td>3.4300943</td>\n",
       "<td>3.4300943</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9416622</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9633511</td>\n",
       "<td>0.1714842</td>\n",
       "<td>0.3430709</td>\n",
       "<td>243.0094301</td>\n",
       "<td>243.0094301</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1500120</td>\n",
       "<td>0.8882195</td>\n",
       "<td>3.4300943</td>\n",
       "<td>3.4300943</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9053718</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9440285</td>\n",
       "<td>0.1714842</td>\n",
       "<td>0.5145551</td>\n",
       "<td>243.0094301</td>\n",
       "<td>243.0094301</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2000060</td>\n",
       "<td>0.8421777</td>\n",
       "<td>3.4280440</td>\n",
       "<td>3.4295818</td>\n",
       "<td>0.9994023</td>\n",
       "<td>0.8670677</td>\n",
       "<td>0.9998506</td>\n",
       "<td>0.9247912</td>\n",
       "<td>0.1713817</td>\n",
       "<td>0.6859369</td>\n",
       "<td>242.8044035</td>\n",
       "<td>242.9581811</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.2999940</td>\n",
       "<td>0.3708652</td>\n",
       "<td>2.9964631</td>\n",
       "<td>3.2852233</td>\n",
       "<td>0.8735804</td>\n",
       "<td>0.7020466</td>\n",
       "<td>0.9577647</td>\n",
       "<td>0.8505504</td>\n",
       "<td>0.2996105</td>\n",
       "<td>0.9855474</td>\n",
       "<td>199.6463133</td>\n",
       "<td>228.5223299</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4000120</td>\n",
       "<td>0.1124730</td>\n",
       "<td>0.1311778</td>\n",
       "<td>2.4965941</td>\n",
       "<td>0.0382432</td>\n",
       "<td>0.2071155</td>\n",
       "<td>0.7278500</td>\n",
       "<td>0.6896676</td>\n",
       "<td>0.0131201</td>\n",
       "<td>0.9986675</td>\n",
       "<td>-86.8822208</td>\n",
       "<td>149.6594111</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0486775</td>\n",
       "<td>0.0020503</td>\n",
       "<td>1.9977450</td>\n",
       "<td>0.0005977</td>\n",
       "<td>0.0752963</td>\n",
       "<td>0.5824169</td>\n",
       "<td>0.5668081</td>\n",
       "<td>0.0002050</td>\n",
       "<td>0.9988725</td>\n",
       "<td>-99.7949734</td>\n",
       "<td>99.7744977</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.6000179</td>\n",
       "<td>0.0250341</td>\n",
       "<td>0.0030745</td>\n",
       "<td>1.6652502</td>\n",
       "<td>0.0008963</td>\n",
       "<td>0.0353917</td>\n",
       "<td>0.4854823</td>\n",
       "<td>0.4782254</td>\n",
       "<td>0.0003075</td>\n",
       "<td>0.9991800</td>\n",
       "<td>-99.6925520</td>\n",
       "<td>66.5250224</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.7000060</td>\n",
       "<td>0.0144942</td>\n",
       "<td>0.0020503</td>\n",
       "<td>1.4276807</td>\n",
       "<td>0.0005977</td>\n",
       "<td>0.0190908</td>\n",
       "<td>0.4162220</td>\n",
       "<td>0.4126432</td>\n",
       "<td>0.0002050</td>\n",
       "<td>0.9993850</td>\n",
       "<td>-99.7949734</td>\n",
       "<td>42.7680659</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.8000239</td>\n",
       "<td>0.0087596</td>\n",
       "<td>0.0030745</td>\n",
       "<td>1.2495783</td>\n",
       "<td>0.0008963</td>\n",
       "<td>0.0113545</td>\n",
       "<td>0.3642985</td>\n",
       "<td>0.3624746</td>\n",
       "<td>0.0003075</td>\n",
       "<td>0.9996925</td>\n",
       "<td>-99.6925520</td>\n",
       "<td>24.9578280</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.8999821</td>\n",
       "<td>0.0040031</td>\n",
       "<td>0.0020509</td>\n",
       "<td>1.1110194</td>\n",
       "<td>0.0005979</td>\n",
       "<td>0.0063164</td>\n",
       "<td>0.3239034</td>\n",
       "<td>0.3229172</td>\n",
       "<td>0.0002050</td>\n",
       "<td>0.9998975</td>\n",
       "<td>-99.7949121</td>\n",
       "<td>11.1019355</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0010248</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0002988</td>\n",
       "<td>0.0016149</td>\n",
       "<td>0.2915372</td>\n",
       "<td>0.2907812</td>\n",
       "<td>0.0001025</td>\n",
       "<td>1.0</td>\n",
       "<td>-99.8975173</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.0100108                   0.998423           3.43009     3.43009            1                0.999952    1                           0.999952            0.0343378       0.0343378                  243.009   243.009\n",
       "    2        0.0200514                   0.991506           3.43009     3.43009            1                0.993297    1                           0.99662             0.0344403       0.0687782                  243.009   243.009\n",
       "    3        0.0307495                   0.981794           3.43009     3.43009            1                0.985937    1                           0.992903            0.0366954       0.105474                   243.009   243.009\n",
       "    4        0.0400131                   0.972233           3.43009     3.43009            1                0.977836    1                           0.989415            0.0317753       0.137249                   243.009   243.009\n",
       "    5        0.0500239                   0.963882           3.43009     3.43009            1                0.96749     1                           0.985027            0.0343378       0.171587                   243.009   243.009\n",
       "    6        0.100018                    0.92186            3.43009     3.43009            1                0.941662    1                           0.963351            0.171484        0.343071                   243.009   243.009\n",
       "    7        0.150012                    0.88822            3.43009     3.43009            1                0.905372    1                           0.944028            0.171484        0.514555                   243.009   243.009\n",
       "    8        0.200006                    0.842178           3.42804     3.42958            0.999402         0.867068    0.999851                    0.924791            0.171382        0.685937                   242.804   242.958\n",
       "    9        0.299994                    0.370865           2.99646     3.28522            0.87358          0.702047    0.957765                    0.85055             0.29961         0.985547                   199.646   228.522\n",
       "    10       0.400012                    0.112473           0.131178    2.49659            0.0382432        0.207116    0.72785                     0.689668            0.0131201       0.998667                   -86.8822  149.659\n",
       "    11       0.5                         0.0486775          0.00205027  1.99774            0.000597729      0.0752963   0.582417                    0.566808            0.000205002     0.998872                   -99.795   99.7745\n",
       "    12       0.600018                    0.0250341          0.00307448  1.66525            0.000896325      0.0353917   0.485482                    0.478225            0.000307503     0.99918                    -99.6926  66.525\n",
       "    13       0.700006                    0.0144942          0.00205027  1.42768            0.000597729      0.0190908   0.416222                    0.412643            0.000205002     0.999385                   -99.795   42.7681\n",
       "    14       0.800024                    0.00875963         0.00307448  1.24958            0.000896325      0.0113545   0.364299                    0.362475            0.000307503     0.999692                   -99.6926  24.9578\n",
       "    15       0.899982                    0.00400315         0.00205088  1.11102            0.000597907      0.0063164   0.323903                    0.322917            0.000205002     0.999897                   -99.7949  11.1019\n",
       "    16       1                           0                  0.00102483  1                  0.000298775      0.00161486  0.291537                    0.290781            0.000102501     1                          -99.8975  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: drf\n",
      "** Reported on cross-validation data. **\n",
      "\n",
      "MSE: 0.019838655136353946\n",
      "RMSE: 0.14084976086722314\n",
      "LogLoss: 0.09848448113892687\n",
      "Mean Per-Class Error: 0.01697642178512626\n",
      "AUC: 0.9984149199275788\n",
      "pr_auc: 0.9438620129204796\n",
      "Gini: 0.9968298398551576\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4721316665854305: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>N</b></td>\n",
       "<td><b>Y</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>N</td>\n",
       "<td>213304.0</td>\n",
       "<td>1584.0</td>\n",
       "<td>0.0074</td>\n",
       "<td> (1584.0/214888.0)</td></tr>\n",
       "<tr><td>Y</td>\n",
       "<td>2589.0</td>\n",
       "<td>83755.0</td>\n",
       "<td>0.03</td>\n",
       "<td> (2589.0/86344.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>215893.0</td>\n",
       "<td>85339.0</td>\n",
       "<td>0.0139</td>\n",
       "<td> (4173.0/301232.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       N       Y      Error    Rate\n",
       "-----  ------  -----  -------  -----------------\n",
       "N      213304  1584   0.0074   (1584.0/214888.0)\n",
       "Y      2589    83755  0.03     (2589.0/86344.0)\n",
       "Total  215893  85339  0.0139   (4173.0/301232.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.4721317</td>\n",
       "<td>0.9756936</td>\n",
       "<td>186.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.3610743</td>\n",
       "<td>0.9781708</td>\n",
       "<td>216.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.5859488</td>\n",
       "<td>0.9856473</td>\n",
       "<td>162.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.4721317</td>\n",
       "<td>0.9861469</td>\n",
       "<td>186.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9999495</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0013795</td>\n",
       "<td>1.0</td>\n",
       "<td>397.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9999495</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.4721317</td>\n",
       "<td>0.9660394</td>\n",
       "<td>186.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.3911902</td>\n",
       "<td>0.9824606</td>\n",
       "<td>207.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.4120424</td>\n",
       "<td>0.9830236</td>\n",
       "<td>201.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.472132     0.975694  186\n",
       "max f2                       0.361074     0.978171  216\n",
       "max f0point5                 0.585949     0.985647  162\n",
       "max accuracy                 0.472132     0.986147  186\n",
       "max precision                0.999949     1         0\n",
       "max recall                   0.00137952   1         397\n",
       "max specificity              0.999949     1         0\n",
       "max absolute_mcc             0.472132     0.966039  186\n",
       "max min_per_class_accuracy   0.39119      0.982461  207\n",
       "max mean_per_class_accuracy  0.412042     0.983024  201"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 28.66 %, avg score: 28.75 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>score</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>cumulative_score</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0140490</td>\n",
       "<td>1.0</td>\n",
       "<td>3.4887427</td>\n",
       "<td>3.4887427</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0490132</td>\n",
       "<td>0.0490132</td>\n",
       "<td>248.8742704</td>\n",
       "<td>248.8742704</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0200311</td>\n",
       "<td>0.9953594</td>\n",
       "<td>3.4887427</td>\n",
       "<td>3.4887427</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9974951</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9992519</td>\n",
       "<td>0.0208700</td>\n",
       "<td>0.0698833</td>\n",
       "<td>248.8742704</td>\n",
       "<td>248.8742704</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0301263</td>\n",
       "<td>0.9863092</td>\n",
       "<td>3.4887427</td>\n",
       "<td>3.4887427</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9906092</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9963558</td>\n",
       "<td>0.0352196</td>\n",
       "<td>0.1051028</td>\n",
       "<td>248.8742704</td>\n",
       "<td>248.8742704</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0400024</td>\n",
       "<td>0.9741634</td>\n",
       "<td>3.4887427</td>\n",
       "<td>3.4887427</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9807678</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9925073</td>\n",
       "<td>0.0344552</td>\n",
       "<td>0.1395580</td>\n",
       "<td>248.8742704</td>\n",
       "<td>248.8742704</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0500013</td>\n",
       "<td>0.9587926</td>\n",
       "<td>3.4887427</td>\n",
       "<td>3.4887427</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9660452</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9872156</td>\n",
       "<td>0.0348837</td>\n",
       "<td>0.1744418</td>\n",
       "<td>248.8742704</td>\n",
       "<td>248.8742704</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1000027</td>\n",
       "<td>0.9146654</td>\n",
       "<td>3.4887427</td>\n",
       "<td>3.4887427</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9343891</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9608024</td>\n",
       "<td>0.1744418</td>\n",
       "<td>0.3488835</td>\n",
       "<td>248.8742704</td>\n",
       "<td>248.8742704</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1500007</td>\n",
       "<td>0.8794678</td>\n",
       "<td>3.4885111</td>\n",
       "<td>3.4886655</td>\n",
       "<td>0.9999336</td>\n",
       "<td>0.8973287</td>\n",
       "<td>0.9999779</td>\n",
       "<td>0.9396454</td>\n",
       "<td>0.1744186</td>\n",
       "<td>0.5233021</td>\n",
       "<td>248.8511063</td>\n",
       "<td>248.8665493</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2000020</td>\n",
       "<td>0.8359674</td>\n",
       "<td>3.4882795</td>\n",
       "<td>3.4885690</td>\n",
       "<td>0.9998672</td>\n",
       "<td>0.8590832</td>\n",
       "<td>0.9999502</td>\n",
       "<td>0.9195045</td>\n",
       "<td>0.1744186</td>\n",
       "<td>0.6977207</td>\n",
       "<td>248.8279453</td>\n",
       "<td>248.8568982</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3000013</td>\n",
       "<td>0.3577441</td>\n",
       "<td>2.8957618</td>\n",
       "<td>3.2909688</td>\n",
       "<td>0.8300302</td>\n",
       "<td>0.6803003</td>\n",
       "<td>0.9433108</td>\n",
       "<td>0.8397707</td>\n",
       "<td>0.2895743</td>\n",
       "<td>0.9872950</td>\n",
       "<td>189.5761837</td>\n",
       "<td>229.0968787</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4000007</td>\n",
       "<td>0.1138118</td>\n",
       "<td>0.1148900</td>\n",
       "<td>2.4969557</td>\n",
       "<td>0.0329316</td>\n",
       "<td>0.2046500</td>\n",
       "<td>0.7157179</td>\n",
       "<td>0.6809918</td>\n",
       "<td>0.0114889</td>\n",
       "<td>0.9987839</td>\n",
       "<td>-88.5109957</td>\n",
       "<td>149.6955691</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0508306</td>\n",
       "<td>0.0033587</td>\n",
       "<td>1.9982396</td>\n",
       "<td>0.0009627</td>\n",
       "<td>0.0769064</td>\n",
       "<td>0.5727678</td>\n",
       "<td>0.5601755</td>\n",
       "<td>0.0003359</td>\n",
       "<td>0.9991198</td>\n",
       "<td>-99.6641319</td>\n",
       "<td>99.8239600</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.5999993</td>\n",
       "<td>0.0265169</td>\n",
       "<td>0.0013898</td>\n",
       "<td>1.6654331</td>\n",
       "<td>0.0003984</td>\n",
       "<td>0.0369419</td>\n",
       "<td>0.4773735</td>\n",
       "<td>0.4729704</td>\n",
       "<td>0.0001390</td>\n",
       "<td>0.9992588</td>\n",
       "<td>-99.8610201</td>\n",
       "<td>66.5433141</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.6999987</td>\n",
       "<td>0.0145751</td>\n",
       "<td>0.0019689</td>\n",
       "<td>1.4277965</td>\n",
       "<td>0.0005644</td>\n",
       "<td>0.0201392</td>\n",
       "<td>0.4092582</td>\n",
       "<td>0.4082805</td>\n",
       "<td>0.0001969</td>\n",
       "<td>0.9994557</td>\n",
       "<td>-99.8031118</td>\n",
       "<td>42.7796517</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.8001441</td>\n",
       "<td>0.0076869</td>\n",
       "<td>0.0028912</td>\n",
       "<td>1.2494565</td>\n",
       "<td>0.0008287</td>\n",
       "<td>0.0107899</td>\n",
       "<td>0.3581395</td>\n",
       "<td>0.3585309</td>\n",
       "<td>0.0002895</td>\n",
       "<td>0.9997452</td>\n",
       "<td>-99.7108809</td>\n",
       "<td>24.9456487</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.8999973</td>\n",
       "<td>0.0025570</td>\n",
       "<td>0.0020877</td>\n",
       "<td>1.1110629</td>\n",
       "<td>0.0005984</td>\n",
       "<td>0.0051052</td>\n",
       "<td>0.3184709</td>\n",
       "<td>0.3193189</td>\n",
       "<td>0.0002085</td>\n",
       "<td>0.9999537</td>\n",
       "<td>-99.7912252</td>\n",
       "<td>11.1062916</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0004633</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0001328</td>\n",
       "<td>0.0008872</td>\n",
       "<td>0.2866362</td>\n",
       "<td>0.2874749</td>\n",
       "<td>0.0000463</td>\n",
       "<td>1.0</td>\n",
       "<td>-99.9536749</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift         cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  -----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.014049                    1                  3.48874      3.48874            1                1            1                           1                   0.0490132       0.0490132                  248.874   248.874\n",
       "    2        0.0200311                   0.995359           3.48874      3.48874            1                0.997495     1                           0.999252            0.02087         0.0698833                  248.874   248.874\n",
       "    3        0.0301263                   0.986309           3.48874      3.48874            1                0.990609     1                           0.996356            0.0352196       0.105103                   248.874   248.874\n",
       "    4        0.0400024                   0.974163           3.48874      3.48874            1                0.980768     1                           0.992507            0.0344552       0.139558                   248.874   248.874\n",
       "    5        0.0500013                   0.958793           3.48874      3.48874            1                0.966045     1                           0.987216            0.0348837       0.174442                   248.874   248.874\n",
       "    6        0.100003                    0.914665           3.48874      3.48874            1                0.934389     1                           0.960802            0.174442        0.348884                   248.874   248.874\n",
       "    7        0.150001                    0.879468           3.48851      3.48867            0.999934         0.897329     0.999978                    0.939645            0.174419        0.523302                   248.851   248.867\n",
       "    8        0.200002                    0.835967           3.48828      3.48857            0.999867         0.859083     0.99995                     0.919505            0.174419        0.697721                   248.828   248.857\n",
       "    9        0.300001                    0.357744           2.89576      3.29097            0.83003          0.6803       0.943311                    0.839771            0.289574        0.987295                   189.576   229.097\n",
       "    10       0.400001                    0.113812           0.11489      2.49696            0.0329316        0.20465      0.715718                    0.680992            0.0114889       0.998784                   -88.511   149.696\n",
       "    11       0.5                         0.0508306          0.00335868   1.99824            0.00096272       0.0769064    0.572768                    0.560176            0.000335866     0.99912                    -99.6641  99.824\n",
       "    12       0.599999                    0.0265169          0.0013898    1.66543            0.000398367      0.0369419    0.477373                    0.47297             0.000138979     0.999259                   -99.861   66.5433\n",
       "    13       0.699999                    0.0145751          0.00196888   1.4278             0.000564353      0.0201392    0.409258                    0.408281            0.000196887     0.999456                   -99.8031  42.7797\n",
       "    14       0.800144                    0.00768693         0.00289119   1.24946            0.00082872       0.0107899    0.358139                    0.358531            0.00028954      0.999745                   -99.7109  24.9456\n",
       "    15       0.899997                    0.002557           0.00208775   1.11106            0.000598424      0.00510517   0.318471                    0.319319            0.000208468     0.999954                   -99.7912  11.1063\n",
       "    16       1                           0                  0.000463251  1                  0.000132784      0.000887211  0.286636                    0.287475            4.63263e-05     1                          -99.9537  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-Validation Metrics Summary: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>mean</b></td>\n",
       "<td><b>sd</b></td>\n",
       "<td><b>cv_1_valid</b></td>\n",
       "<td><b>cv_2_valid</b></td>\n",
       "<td><b>cv_3_valid</b></td>\n",
       "<td><b>cv_4_valid</b></td>\n",
       "<td><b>cv_5_valid</b></td></tr>\n",
       "<tr><td>accuracy</td>\n",
       "<td>0.9862399</td>\n",
       "<td>0.0003246</td>\n",
       "<td>0.9861902</td>\n",
       "<td>0.9866052</td>\n",
       "<td>0.9858912</td>\n",
       "<td>0.9868871</td>\n",
       "<td>0.9856256</td></tr>\n",
       "<tr><td>auc</td>\n",
       "<td>0.9984168</td>\n",
       "<td>0.0000323</td>\n",
       "<td>0.9984430</td>\n",
       "<td>0.9983832</td>\n",
       "<td>0.9983691</td>\n",
       "<td>0.9984936</td>\n",
       "<td>0.9983954</td></tr>\n",
       "<tr><td>err</td>\n",
       "<td>0.0137602</td>\n",
       "<td>0.0003246</td>\n",
       "<td>0.0138098</td>\n",
       "<td>0.0133949</td>\n",
       "<td>0.0141088</td>\n",
       "<td>0.0131129</td>\n",
       "<td>0.0143744</td></tr>\n",
       "<tr><td>err_count</td>\n",
       "<td>829.0</td>\n",
       "<td>19.55505</td>\n",
       "<td>832.0</td>\n",
       "<td>807.0</td>\n",
       "<td>850.0</td>\n",
       "<td>790.0</td>\n",
       "<td>866.0</td></tr>\n",
       "<tr><td>f0point5</td>\n",
       "<td>0.9792042</td>\n",
       "<td>0.0005735</td>\n",
       "<td>0.9803233</td>\n",
       "<td>0.9791669</td>\n",
       "<td>0.9783503</td>\n",
       "<td>0.9798901</td>\n",
       "<td>0.9782903</td></tr>\n",
       "<tr><td>f1</td>\n",
       "<td>0.9758602</td>\n",
       "<td>0.0005739</td>\n",
       "<td>0.9757661</td>\n",
       "<td>0.9764785</td>\n",
       "<td>0.9754321</td>\n",
       "<td>0.9769773</td>\n",
       "<td>0.9746472</td></tr>\n",
       "<tr><td>f2</td>\n",
       "<td>0.97254</td>\n",
       "<td>0.0008897</td>\n",
       "<td>0.9712509</td>\n",
       "<td>0.9738048</td>\n",
       "<td>0.9725312</td>\n",
       "<td>0.9740818</td>\n",
       "<td>0.9710313</td></tr>\n",
       "<tr><td>lift_top_group</td>\n",
       "<td>3.4887974</td>\n",
       "<td>0.0097586</td>\n",
       "<td>3.4826868</td>\n",
       "<td>3.496025</td>\n",
       "<td>3.4654012</td>\n",
       "<td>3.4941423</td>\n",
       "<td>3.5057318</td></tr>\n",
       "<tr><td>logloss</td>\n",
       "<td>0.0984845</td>\n",
       "<td>0.0005711</td>\n",
       "<td>0.0989524</td>\n",
       "<td>0.0975894</td>\n",
       "<td>0.0976437</td>\n",
       "<td>0.0985139</td>\n",
       "<td>0.0997231</td></tr>\n",
       "<tr><td>max_per_class_error</td>\n",
       "<td>0.0296604</td>\n",
       "<td>0.0011602</td>\n",
       "<td>0.0317359</td>\n",
       "<td>0.0279696</td>\n",
       "<td>0.0293932</td>\n",
       "<td>0.0278390</td>\n",
       "<td>0.0313646</td></tr>\n",
       "<tr><td>mcc</td>\n",
       "<td>0.9662698</td>\n",
       "<td>0.0007951</td>\n",
       "<td>0.9661673</td>\n",
       "<td>0.9671350</td>\n",
       "<td>0.96556</td>\n",
       "<td>0.9678338</td>\n",
       "<td>0.9646531</td></tr>\n",
       "<tr><td>mean_per_class_accuracy</td>\n",
       "<td>0.9814841</td>\n",
       "<td>0.0005400</td>\n",
       "<td>0.9808374</td>\n",
       "<td>0.9822373</td>\n",
       "<td>0.9813487</td>\n",
       "<td>0.9824762</td>\n",
       "<td>0.9805208</td></tr>\n",
       "<tr><td>mean_per_class_error</td>\n",
       "<td>0.0185159</td>\n",
       "<td>0.0005400</td>\n",
       "<td>0.0191627</td>\n",
       "<td>0.0177626</td>\n",
       "<td>0.0186512</td>\n",
       "<td>0.0175238</td>\n",
       "<td>0.0194792</td></tr>\n",
       "<tr><td>mse</td>\n",
       "<td>0.0198387</td>\n",
       "<td>0.0001794</td>\n",
       "<td>0.0200267</td>\n",
       "<td>0.0195677</td>\n",
       "<td>0.0197068</td>\n",
       "<td>0.0196522</td>\n",
       "<td>0.0202399</td></tr>\n",
       "<tr><td>precision</td>\n",
       "<td>0.9814468</td>\n",
       "<td>0.0007716</td>\n",
       "<td>0.9833852</td>\n",
       "<td>0.9809675</td>\n",
       "<td>0.9803056</td>\n",
       "<td>0.9818416</td>\n",
       "<td>0.9807341</td></tr>\n",
       "<tr><td>r2</td>\n",
       "<td>0.9029759</td>\n",
       "<td>0.0009448</td>\n",
       "<td>0.9021599</td>\n",
       "<td>0.9041837</td>\n",
       "<td>0.9040078</td>\n",
       "<td>0.9038008</td>\n",
       "<td>0.9007272</td></tr>\n",
       "<tr><td>recall</td>\n",
       "<td>0.9703395</td>\n",
       "<td>0.0011602</td>\n",
       "<td>0.9682640</td>\n",
       "<td>0.9720304</td>\n",
       "<td>0.9706069</td>\n",
       "<td>0.972161</td>\n",
       "<td>0.9686354</td></tr>\n",
       "<tr><td>rmse</td>\n",
       "<td>0.1408469</td>\n",
       "<td>0.0006359</td>\n",
       "<td>0.1415158</td>\n",
       "<td>0.1398845</td>\n",
       "<td>0.1403809</td>\n",
       "<td>0.1401864</td>\n",
       "<td>0.1422668</td></tr>\n",
       "<tr><td>specificity</td>\n",
       "<td>0.9926286</td>\n",
       "<td>0.0003179</td>\n",
       "<td>0.9934106</td>\n",
       "<td>0.9924443</td>\n",
       "<td>0.9920907</td>\n",
       "<td>0.9927913</td>\n",
       "<td>0.9924061</td></tr></table></div>"
      ],
      "text/plain": [
       "                         mean       sd           cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid\n",
       "-----------------------  ---------  -----------  ------------  ------------  ------------  ------------  ------------\n",
       "accuracy                 0.98624    0.000324608  0.98619       0.986605      0.985891      0.986887      0.985626\n",
       "auc                      0.998417   3.23065e-05  0.998443      0.998383      0.998369      0.998494      0.998395\n",
       "err                      0.0137602  0.000324608  0.0138098     0.0133949     0.0141088     0.0131129     0.0143744\n",
       "err_count                829        19.5551      832           807           850           790           866\n",
       "f0point5                 0.979204   0.000573461  0.980323      0.979167      0.97835       0.97989       0.97829\n",
       "f1                       0.97586    0.000573905  0.975766      0.976478      0.975432      0.976977      0.974647\n",
       "f2                       0.97254    0.000889657  0.971251      0.973805      0.972531      0.974082      0.971031\n",
       "lift_top_group           3.4888     0.00975858   3.48269       3.49602       3.4654        3.49414       3.50573\n",
       "logloss                  0.0984845  0.000571146  0.0989524     0.0975894     0.0976437     0.0985139     0.0997231\n",
       "max_per_class_error      0.0296604  0.00116016   0.0317359     0.0279696     0.0293932     0.027839      0.0313646\n",
       "mcc                      0.96627    0.000795138  0.966167      0.967135      0.96556       0.967834      0.964653\n",
       "mean_per_class_accuracy  0.981484   0.000540021  0.980837      0.982237      0.981349      0.982476      0.980521\n",
       "mean_per_class_error     0.0185159  0.000540021  0.0191627     0.0177626     0.0186512     0.0175238     0.0194792\n",
       "mse                      0.0198387  0.000179418  0.0200267     0.0195677     0.0197068     0.0196522     0.0202399\n",
       "precision                0.981447   0.000771579  0.983385      0.980967      0.980306      0.981842      0.980734\n",
       "r2                       0.902976   0.000944809  0.90216       0.904184      0.904008      0.903801      0.900727\n",
       "recall                   0.97034    0.00116016   0.968264      0.97203       0.970607      0.972161      0.968635\n",
       "rmse                     0.140847   0.000635873  0.141516      0.139884      0.140381      0.140186      0.142267\n",
       "specificity              0.992629   0.000317939  0.993411      0.992444      0.992091      0.992791      0.992406"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>timestamp</b></td>\n",
       "<td><b>duration</b></td>\n",
       "<td><b>number_of_trees</b></td>\n",
       "<td><b>training_rmse</b></td>\n",
       "<td><b>training_logloss</b></td>\n",
       "<td><b>training_auc</b></td>\n",
       "<td><b>training_pr_auc</b></td>\n",
       "<td><b>training_lift</b></td>\n",
       "<td><b>training_classification_error</b></td>\n",
       "<td><b>validation_rmse</b></td>\n",
       "<td><b>validation_logloss</b></td>\n",
       "<td><b>validation_auc</b></td>\n",
       "<td><b>validation_pr_auc</b></td>\n",
       "<td><b>validation_lift</b></td>\n",
       "<td><b>validation_classification_error</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-12-11 20:57:15</td>\n",
       "<td> 3 min 19.834 sec</td>\n",
       "<td>0.0</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-12-11 20:57:16</td>\n",
       "<td> 3 min 20.186 sec</td>\n",
       "<td>1.0</td>\n",
       "<td>0.2275729</td>\n",
       "<td>0.8023489</td>\n",
       "<td>0.9643373</td>\n",
       "<td>0.2973424</td>\n",
       "<td>3.2871077</td>\n",
       "<td>0.0678526</td>\n",
       "<td>0.2279121</td>\n",
       "<td>0.7845200</td>\n",
       "<td>0.9645842</td>\n",
       "<td>0.3021248</td>\n",
       "<td>3.2463666</td>\n",
       "<td>0.0692386</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-12-11 20:57:16</td>\n",
       "<td> 3 min 20.516 sec</td>\n",
       "<td>2.0</td>\n",
       "<td>0.1947116</td>\n",
       "<td>0.5755505</td>\n",
       "<td>0.9754294</td>\n",
       "<td>0.2674530</td>\n",
       "<td>3.3580941</td>\n",
       "<td>0.0477174</td>\n",
       "<td>0.1637330</td>\n",
       "<td>0.1682876</td>\n",
       "<td>0.9918950</td>\n",
       "<td>0.4090383</td>\n",
       "<td>3.4077110</td>\n",
       "<td>0.0301219</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-12-11 20:57:16</td>\n",
       "<td> 3 min 20.899 sec</td>\n",
       "<td>3.0</td>\n",
       "<td>0.2134816</td>\n",
       "<td>0.4830622</td>\n",
       "<td>0.9741121</td>\n",
       "<td>0.3753213</td>\n",
       "<td>3.3749162</td>\n",
       "<td>0.0549736</td>\n",
       "<td>0.1680320</td>\n",
       "<td>0.1352552</td>\n",
       "<td>0.9942703</td>\n",
       "<td>0.6381483</td>\n",
       "<td>3.4221034</td>\n",
       "<td>0.0240856</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-12-11 20:57:17</td>\n",
       "<td> 3 min 21.359 sec</td>\n",
       "<td>4.0</td>\n",
       "<td>0.2066882</td>\n",
       "<td>0.4262715</td>\n",
       "<td>0.9769762</td>\n",
       "<td>0.4401881</td>\n",
       "<td>3.3820812</td>\n",
       "<td>0.0500909</td>\n",
       "<td>0.1618993</td>\n",
       "<td>0.1214420</td>\n",
       "<td>0.9954384</td>\n",
       "<td>0.7329649</td>\n",
       "<td>3.4246605</td>\n",
       "<td>0.0223524</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-12-11 20:57:17</td>\n",
       "<td> 3 min 21.859 sec</td>\n",
       "<td>5.0</td>\n",
       "<td>0.1937728</td>\n",
       "<td>0.3528538</td>\n",
       "<td>0.9816797</td>\n",
       "<td>0.4619649</td>\n",
       "<td>3.4018667</td>\n",
       "<td>0.0430413</td>\n",
       "<td>0.1506791</td>\n",
       "<td>0.1056986</td>\n",
       "<td>0.9970041</td>\n",
       "<td>0.7713415</td>\n",
       "<td>3.4253653</td>\n",
       "<td>0.0180194</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-12-11 20:57:18</td>\n",
       "<td> 3 min 22.433 sec</td>\n",
       "<td>6.0</td>\n",
       "<td>0.1869723</td>\n",
       "<td>0.3042406</td>\n",
       "<td>0.9844282</td>\n",
       "<td>0.4974868</td>\n",
       "<td>3.4114792</td>\n",
       "<td>0.0393220</td>\n",
       "<td>0.1467868</td>\n",
       "<td>0.0978622</td>\n",
       "<td>0.9974764</td>\n",
       "<td>0.7976991</td>\n",
       "<td>3.4300943</td>\n",
       "<td>0.0173918</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-12-11 20:57:18</td>\n",
       "<td> 3 min 23.078 sec</td>\n",
       "<td>7.0</td>\n",
       "<td>0.1854219</td>\n",
       "<td>0.2674861</td>\n",
       "<td>0.9861019</td>\n",
       "<td>0.5391322</td>\n",
       "<td>3.4207316</td>\n",
       "<td>0.0376572</td>\n",
       "<td>0.1490559</td>\n",
       "<td>0.1007377</td>\n",
       "<td>0.9975420</td>\n",
       "<td>0.8216224</td>\n",
       "<td>3.4300943</td>\n",
       "<td>0.0170033</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-12-11 20:57:19</td>\n",
       "<td> 3 min 23.758 sec</td>\n",
       "<td>8.0</td>\n",
       "<td>0.1872386</td>\n",
       "<td>0.2432327</td>\n",
       "<td>0.9869286</td>\n",
       "<td>0.5870945</td>\n",
       "<td>3.4287745</td>\n",
       "<td>0.0383898</td>\n",
       "<td>0.1540573</td>\n",
       "<td>0.1084683</td>\n",
       "<td>0.9974627</td>\n",
       "<td>0.8487917</td>\n",
       "<td>3.4300943</td>\n",
       "<td>0.0169137</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-12-11 20:57:23</td>\n",
       "<td> 3 min 27.842 sec</td>\n",
       "<td>20.0</td>\n",
       "<td>0.1502654</td>\n",
       "<td>0.1015057</td>\n",
       "<td>0.9972609</td>\n",
       "<td>0.8269213</td>\n",
       "<td>3.4858202</td>\n",
       "<td>0.0187077</td>\n",
       "<td>0.1376642</td>\n",
       "<td>0.0955218</td>\n",
       "<td>0.9983738</td>\n",
       "<td>0.9522312</td>\n",
       "<td>3.4300943</td>\n",
       "<td>0.0132680</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-12-11 20:57:27</td>\n",
       "<td> 3 min 31.979 sec</td>\n",
       "<td>31.0</td>\n",
       "<td>0.1450408</td>\n",
       "<td>0.0973989</td>\n",
       "<td>0.9980205</td>\n",
       "<td>0.8773195</td>\n",
       "<td>3.4887427</td>\n",
       "<td>0.0163495</td>\n",
       "<td>0.1371480</td>\n",
       "<td>0.0951007</td>\n",
       "<td>0.9984275</td>\n",
       "<td>0.9580318</td>\n",
       "<td>3.4300943</td>\n",
       "<td>0.0130887</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-12-11 20:57:32</td>\n",
       "<td> 3 min 37.002 sec</td>\n",
       "<td>44.0</td>\n",
       "<td>0.1427767</td>\n",
       "<td>0.0966466</td>\n",
       "<td>0.9982077</td>\n",
       "<td>0.9023397</td>\n",
       "<td>3.4887427</td>\n",
       "<td>0.0154665</td>\n",
       "<td>0.1372723</td>\n",
       "<td>0.0951708</td>\n",
       "<td>0.9984373</td>\n",
       "<td>0.9617304</td>\n",
       "<td>3.4300943</td>\n",
       "<td>0.0128795</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-12-11 20:57:35</td>\n",
       "<td> 3 min 39.588 sec</td>\n",
       "<td>50.0</td>\n",
       "<td>0.1422773</td>\n",
       "<td>0.0967380</td>\n",
       "<td>0.9982640</td>\n",
       "<td>0.9089612</td>\n",
       "<td>3.4887427</td>\n",
       "<td>0.0151080</td>\n",
       "<td>0.1374100</td>\n",
       "<td>0.0955319</td>\n",
       "<td>0.9984441</td>\n",
       "<td>0.9622318</td>\n",
       "<td>3.4300943</td>\n",
       "<td>0.0127600</td></tr></table></div>"
      ],
      "text/plain": [
       "    timestamp            duration          number_of_trees    training_rmse    training_logloss    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_auc    validation_pr_auc    validation_lift    validation_classification_error\n",
       "--  -------------------  ----------------  -----------------  ---------------  ------------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ----------------  -------------------  -----------------  ---------------------------------\n",
       "    2018-12-11 20:57:15  3 min 19.834 sec  0                  nan              nan                 nan             nan                nan              nan                              nan                nan                   nan               nan                  nan                nan\n",
       "    2018-12-11 20:57:16  3 min 20.186 sec  1                  0.227573         0.802349            0.964337        0.297342           3.28711          0.0678526                        0.227912           0.78452               0.964584          0.302125             3.24637            0.0692386\n",
       "    2018-12-11 20:57:16  3 min 20.516 sec  2                  0.194712         0.57555             0.975429        0.267453           3.35809          0.0477174                        0.163733           0.168288              0.991895          0.409038             3.40771            0.0301219\n",
       "    2018-12-11 20:57:16  3 min 20.899 sec  3                  0.213482         0.483062            0.974112        0.375321           3.37492          0.0549736                        0.168032           0.135255              0.99427           0.638148             3.4221             0.0240856\n",
       "    2018-12-11 20:57:17  3 min 21.359 sec  4                  0.206688         0.426271            0.976976        0.440188           3.38208          0.0500909                        0.161899           0.121442              0.995438          0.732965             3.42466            0.0223524\n",
       "    2018-12-11 20:57:17  3 min 21.859 sec  5                  0.193773         0.352854            0.98168         0.461965           3.40187          0.0430413                        0.150679           0.105699              0.997004          0.771341             3.42537            0.0180194\n",
       "    2018-12-11 20:57:18  3 min 22.433 sec  6                  0.186972         0.304241            0.984428        0.497487           3.41148          0.039322                         0.146787           0.0978622             0.997476          0.797699             3.43009            0.0173918\n",
       "    2018-12-11 20:57:18  3 min 23.078 sec  7                  0.185422         0.267486            0.986102        0.539132           3.42073          0.0376572                        0.149056           0.100738              0.997542          0.821622             3.43009            0.0170033\n",
       "    2018-12-11 20:57:19  3 min 23.758 sec  8                  0.187239         0.243233            0.986929        0.587094           3.42877          0.0383898                        0.154057           0.108468              0.997463          0.848792             3.43009            0.0169137\n",
       "    2018-12-11 20:57:23  3 min 27.842 sec  20                 0.150265         0.101506            0.997261        0.826921           3.48582          0.0187077                        0.137664           0.0955218             0.998374          0.952231             3.43009            0.013268\n",
       "    2018-12-11 20:57:27  3 min 31.979 sec  31                 0.145041         0.0973989           0.99802         0.87732            3.48874          0.0163495                        0.137148           0.0951007             0.998428          0.958032             3.43009            0.0130887\n",
       "    2018-12-11 20:57:32  3 min 37.002 sec  44                 0.142777         0.0966466           0.998208        0.90234            3.48874          0.0154665                        0.137272           0.0951708             0.998437          0.96173              3.43009            0.0128795\n",
       "    2018-12-11 20:57:35  3 min 39.588 sec  50                 0.142277         0.096738            0.998264        0.908961           3.48874          0.015108                         0.13741            0.0955319             0.998444          0.962232             3.43009            0.01276"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable Importances: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>variable</b></td>\n",
       "<td><b>relative_importance</b></td>\n",
       "<td><b>scaled_importance</b></td>\n",
       "<td><b>percentage</b></td></tr>\n",
       "<tr><td>city_id</td>\n",
       "<td>955775.3125000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.5581109</td></tr>\n",
       "<tr><td>state_id</td>\n",
       "<td>257751.2343750</td>\n",
       "<td>0.2696776</td>\n",
       "<td>0.1505100</td></tr>\n",
       "<tr><td>category_2</td>\n",
       "<td>160059.9062500</td>\n",
       "<td>0.1674660</td>\n",
       "<td>0.0934646</td></tr>\n",
       "<tr><td>category_1</td>\n",
       "<td>115193.4609375</td>\n",
       "<td>0.1205236</td>\n",
       "<td>0.0672655</td></tr>\n",
       "<tr><td>merchant_group_id</td>\n",
       "<td>70843.8906250</td>\n",
       "<td>0.0741219</td>\n",
       "<td>0.0413682</td></tr>\n",
       "<tr><td>subsector_id</td>\n",
       "<td>31761.3027344</td>\n",
       "<td>0.0332309</td>\n",
       "<td>0.0185465</td></tr>\n",
       "<tr><td>merchant_category_id</td>\n",
       "<td>19091.6308594</td>\n",
       "<td>0.0199750</td>\n",
       "<td>0.0111483</td></tr>\n",
       "<tr><td>most_recent_sales_range</td>\n",
       "<td>14489.4287109</td>\n",
       "<td>0.0151599</td>\n",
       "<td>0.0084609</td></tr>\n",
       "<tr><td>numerical_1</td>\n",
       "<td>11903.5019531</td>\n",
       "<td>0.0124543</td>\n",
       "<td>0.0069509</td></tr>\n",
       "<tr><td>most_recent_purchases_range</td>\n",
       "<td>10130.6972656</td>\n",
       "<td>0.0105995</td>\n",
       "<td>0.0059157</td></tr>\n",
       "<tr><td>numerical_2</td>\n",
       "<td>9703.4843750</td>\n",
       "<td>0.0101525</td>\n",
       "<td>0.0056662</td></tr>\n",
       "<tr><td>avg_purchases_lag3</td>\n",
       "<td>8831.2177734</td>\n",
       "<td>0.0092398</td>\n",
       "<td>0.0051569</td></tr>\n",
       "<tr><td>avg_purchases_lag6</td>\n",
       "<td>8387.1093750</td>\n",
       "<td>0.0087752</td>\n",
       "<td>0.0048975</td></tr>\n",
       "<tr><td>avg_purchases_lag12</td>\n",
       "<td>8357.7822266</td>\n",
       "<td>0.0087445</td>\n",
       "<td>0.0048804</td></tr>\n",
       "<tr><td>avg_sales_lag3</td>\n",
       "<td>8332.0605469</td>\n",
       "<td>0.0087176</td>\n",
       "<td>0.0048654</td></tr>\n",
       "<tr><td>avg_sales_lag12</td>\n",
       "<td>7839.9199219</td>\n",
       "<td>0.0082027</td>\n",
       "<td>0.0045780</td></tr>\n",
       "<tr><td>avg_sales_lag6</td>\n",
       "<td>7648.2841797</td>\n",
       "<td>0.0080022</td>\n",
       "<td>0.0044661</td></tr>\n",
       "<tr><td>active_months_lag12</td>\n",
       "<td>4748.7172852</td>\n",
       "<td>0.0049684</td>\n",
       "<td>0.0027729</td></tr>\n",
       "<tr><td>active_months_lag6</td>\n",
       "<td>1353.7655029</td>\n",
       "<td>0.0014164</td>\n",
       "<td>0.0007905</td></tr>\n",
       "<tr><td>active_months_lag3</td>\n",
       "<td>315.8672791</td>\n",
       "<td>0.0003305</td>\n",
       "<td>0.0001844</td></tr></table></div>"
      ],
      "text/plain": [
       "variable                     relative_importance    scaled_importance    percentage\n",
       "---------------------------  ---------------------  -------------------  ------------\n",
       "city_id                      955775                 1                    0.558111\n",
       "state_id                     257751                 0.269678             0.15051\n",
       "category_2                   160060                 0.167466             0.0934646\n",
       "category_1                   115193                 0.120524             0.0672655\n",
       "merchant_group_id            70843.9                0.0741219            0.0413682\n",
       "subsector_id                 31761.3                0.0332309            0.0185465\n",
       "merchant_category_id         19091.6                0.019975             0.0111483\n",
       "most_recent_sales_range      14489.4                0.0151599            0.00846089\n",
       "numerical_1                  11903.5                0.0124543            0.00695087\n",
       "most_recent_purchases_range  10130.7                0.0105995            0.00591567\n",
       "numerical_2                  9703.48                0.0101525            0.00566621\n",
       "avg_purchases_lag3           8831.22                0.00923985           0.00515686\n",
       "avg_purchases_lag6           8387.11                0.00877519           0.00489753\n",
       "avg_purchases_lag12          8357.78                0.00874451           0.0048804\n",
       "avg_sales_lag3               8332.06                0.00871759           0.00486538\n",
       "avg_sales_lag12              7839.92                0.00820268           0.00457801\n",
       "avg_sales_lag6               7648.28                0.00800218           0.0044661\n",
       "active_months_lag12          4748.72                0.00496845           0.00277294\n",
       "active_months_lag6           1353.77                0.00141641           0.000790511\n",
       "active_months_lag3           315.867                0.000330483          0.000184446"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<bound method H2OBinomialModel.tnr of >"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aml.leader.tnr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2ORandomForestEstimator :  Distributed Random Forest\n",
      "Model Key:  DRF_1_AutoML_20181211_205354\n",
      "\n",
      "\n",
      "ModelMetricsBinomial: drf\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.020242828646662245\n",
      "RMSE: 0.14227729490913948\n",
      "LogLoss: 0.09673799546133012\n",
      "Mean Per-Class Error: 0.01872350523172872\n",
      "AUC: 0.9982640258173935\n",
      "pr_auc: 0.9089612037582203\n",
      "Gini: 0.996528051634787\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.49174027253987507: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>N</b></td>\n",
       "<td><b>Y</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>N</td>\n",
       "<td>213435.0</td>\n",
       "<td>1453.0</td>\n",
       "<td>0.0068</td>\n",
       "<td> (1453.0/214888.0)</td></tr>\n",
       "<tr><td>Y</td>\n",
       "<td>3098.0</td>\n",
       "<td>83246.0</td>\n",
       "<td>0.0359</td>\n",
       "<td> (3098.0/86344.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>216533.0</td>\n",
       "<td>84699.0</td>\n",
       "<td>0.0151</td>\n",
       "<td> (4551.0/301232.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       N       Y      Error    Rate\n",
       "-----  ------  -----  -------  -----------------\n",
       "N      213435  1453   0.0068   (1453.0/214888.0)\n",
       "Y      3098    83246  0.0359   (3098.0/86344.0)\n",
       "Total  216533  84699  0.0151   (4551.0/301232.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.4917403</td>\n",
       "<td>0.9733927</td>\n",
       "<td>188.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.3549770</td>\n",
       "<td>0.9761585</td>\n",
       "<td>222.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.5960178</td>\n",
       "<td>0.9839807</td>\n",
       "<td>165.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.4917403</td>\n",
       "<td>0.9848920</td>\n",
       "<td>188.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9999810</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0000123</td>\n",
       "<td>1.0</td>\n",
       "<td>399.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9999810</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.4917403</td>\n",
       "<td>0.9629320</td>\n",
       "<td>188.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.3912923</td>\n",
       "<td>0.9810294</td>\n",
       "<td>212.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.4162169</td>\n",
       "<td>0.9812765</td>\n",
       "<td>206.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.49174      0.973393  188\n",
       "max f2                       0.354977     0.976159  222\n",
       "max f0point5                 0.596018     0.983981  165\n",
       "max accuracy                 0.49174      0.984892  188\n",
       "max precision                0.999981     1         0\n",
       "max recall                   1.23132e-05  1         399\n",
       "max specificity              0.999981     1         0\n",
       "max absolute_mcc             0.49174      0.962932  188\n",
       "max min_per_class_accuracy   0.391292     0.981029  212\n",
       "max mean_per_class_accuracy  0.416217     0.981276  206"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 28.66 %, avg score: 28.74 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>score</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>cumulative_score</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0245724</td>\n",
       "<td>1.0</td>\n",
       "<td>3.4887427</td>\n",
       "<td>3.4887427</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0857269</td>\n",
       "<td>0.0857269</td>\n",
       "<td>248.8742704</td>\n",
       "<td>248.8742704</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0300001</td>\n",
       "<td>0.9923801</td>\n",
       "<td>3.4887427</td>\n",
       "<td>3.4887427</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9960116</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9992784</td>\n",
       "<td>0.0189359</td>\n",
       "<td>0.1046627</td>\n",
       "<td>248.8742704</td>\n",
       "<td>248.8742704</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0400024</td>\n",
       "<td>0.9817353</td>\n",
       "<td>3.4887427</td>\n",
       "<td>3.4887427</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9873043</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9962844</td>\n",
       "<td>0.0348953</td>\n",
       "<td>0.1395580</td>\n",
       "<td>248.8742704</td>\n",
       "<td>248.8742704</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0500013</td>\n",
       "<td>0.9724944</td>\n",
       "<td>3.4887427</td>\n",
       "<td>3.4887427</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9772090</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9924698</td>\n",
       "<td>0.0348837</td>\n",
       "<td>0.1744418</td>\n",
       "<td>248.8742704</td>\n",
       "<td>248.8742704</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.1000060</td>\n",
       "<td>0.9298701</td>\n",
       "<td>3.4880479</td>\n",
       "<td>3.4883953</td>\n",
       "<td>0.9998008</td>\n",
       "<td>0.9503510</td>\n",
       "<td>0.9999004</td>\n",
       "<td>0.9714097</td>\n",
       "<td>0.1744186</td>\n",
       "<td>0.3488604</td>\n",
       "<td>248.8047873</td>\n",
       "<td>248.8395277</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1500007</td>\n",
       "<td>0.8884800</td>\n",
       "<td>3.4885110</td>\n",
       "<td>3.4884339</td>\n",
       "<td>0.9999336</td>\n",
       "<td>0.9095350</td>\n",
       "<td>0.9999115</td>\n",
       "<td>0.9507871</td>\n",
       "<td>0.1744070</td>\n",
       "<td>0.5232674</td>\n",
       "<td>248.8511047</td>\n",
       "<td>248.8433863</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.2000020</td>\n",
       "<td>0.8358737</td>\n",
       "<td>3.4873530</td>\n",
       "<td>3.4881636</td>\n",
       "<td>0.9996016</td>\n",
       "<td>0.8638037</td>\n",
       "<td>0.9998340</td>\n",
       "<td>0.9290409</td>\n",
       "<td>0.1743723</td>\n",
       "<td>0.6976397</td>\n",
       "<td>248.7352951</td>\n",
       "<td>248.8163630</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.3000013</td>\n",
       "<td>0.3581678</td>\n",
       "<td>2.8753781</td>\n",
       "<td>3.2839041</td>\n",
       "<td>0.8241875</td>\n",
       "<td>0.6756746</td>\n",
       "<td>0.9412858</td>\n",
       "<td>0.8445864</td>\n",
       "<td>0.2875359</td>\n",
       "<td>0.9851756</td>\n",
       "<td>187.5378120</td>\n",
       "<td>228.3904054</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.4000007</td>\n",
       "<td>0.1144822</td>\n",
       "<td>0.1351579</td>\n",
       "<td>2.4967241</td>\n",
       "<td>0.0387412</td>\n",
       "<td>0.2041120</td>\n",
       "<td>0.7156515</td>\n",
       "<td>0.6844691</td>\n",
       "<td>0.0135157</td>\n",
       "<td>0.9986913</td>\n",
       "<td>-86.4842056</td>\n",
       "<td>149.6724059</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0506433</td>\n",
       "<td>0.0044010</td>\n",
       "<td>1.9982628</td>\n",
       "<td>0.0012615</td>\n",
       "<td>0.0768782</td>\n",
       "<td>0.5727745</td>\n",
       "<td>0.5629517</td>\n",
       "<td>0.0004401</td>\n",
       "<td>0.9991314</td>\n",
       "<td>-99.5598970</td>\n",
       "<td>99.8262763</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.6000027</td>\n",
       "<td>0.0228758</td>\n",
       "<td>0.0026637</td>\n",
       "<td>1.6656556</td>\n",
       "<td>0.0007635</td>\n",
       "<td>0.0346323</td>\n",
       "<td>0.4774372</td>\n",
       "<td>0.4748965</td>\n",
       "<td>0.0002664</td>\n",
       "<td>0.9993978</td>\n",
       "<td>-99.7336307</td>\n",
       "<td>66.5655557</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.7000186</td>\n",
       "<td>0.0115814</td>\n",
       "<td>0.0020844</td>\n",
       "<td>1.4279710</td>\n",
       "<td>0.0005975</td>\n",
       "<td>0.0165641</td>\n",
       "<td>0.4093082</td>\n",
       "<td>0.4094118</td>\n",
       "<td>0.0002085</td>\n",
       "<td>0.9996062</td>\n",
       "<td>-99.7915648</td>\n",
       "<td>42.7970971</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.7999980</td>\n",
       "<td>0.0032095</td>\n",
       "<td>0.0028960</td>\n",
       "<td>1.2498728</td>\n",
       "<td>0.0008301</td>\n",
       "<td>0.0069621</td>\n",
       "<td>0.3582588</td>\n",
       "<td>0.3591158</td>\n",
       "<td>0.0002895</td>\n",
       "<td>0.9998958</td>\n",
       "<td>-99.7104009</td>\n",
       "<td>24.9872819</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0005212</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0001494</td>\n",
       "<td>0.0006021</td>\n",
       "<td>0.2866362</td>\n",
       "<td>0.2874123</td>\n",
       "<td>0.0001042</td>\n",
       "<td>1.0</td>\n",
       "<td>-99.9478834</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift         cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  -----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.0245724                   1                  3.48874      3.48874            1                1            1                           1                   0.0857269       0.0857269                  248.874   248.874\n",
       "    2        0.0300001                   0.99238            3.48874      3.48874            1                0.996012     1                           0.999278            0.0189359       0.104663                   248.874   248.874\n",
       "    3        0.0400024                   0.981735           3.48874      3.48874            1                0.987304     1                           0.996284            0.0348953       0.139558                   248.874   248.874\n",
       "    4        0.0500013                   0.972494           3.48874      3.48874            1                0.977209     1                           0.99247             0.0348837       0.174442                   248.874   248.874\n",
       "    5        0.100006                    0.92987            3.48805      3.4884             0.999801         0.950351     0.9999                      0.97141             0.174419        0.34886                    248.805   248.84\n",
       "    6        0.150001                    0.88848            3.48851      3.48843            0.999934         0.909535     0.999911                    0.950787            0.174407        0.523267                   248.851   248.843\n",
       "    7        0.200002                    0.835874           3.48735      3.48816            0.999602         0.863804     0.999834                    0.929041            0.174372        0.69764                    248.735   248.816\n",
       "    8        0.300001                    0.358168           2.87538      3.2839             0.824187         0.675675     0.941286                    0.844586            0.287536        0.985176                   187.538   228.39\n",
       "    9        0.400001                    0.114482           0.135158     2.49672            0.0387412        0.204112     0.715652                    0.684469            0.0135157       0.998691                   -86.4842  149.672\n",
       "    10       0.5                         0.0506433          0.00440103   1.99826            0.00126149       0.0768782    0.572774                    0.562952            0.0004401       0.999131                   -99.5599  99.8263\n",
       "    11       0.600003                    0.0228758          0.00266369   1.66566            0.000763511      0.0346323    0.477437                    0.474897            0.000266376     0.999398                   -99.7336  66.5656\n",
       "    12       0.700019                    0.0115814          0.00208435   1.42797            0.000597451      0.0165641    0.409308                    0.409412            0.000208468     0.999606                   -99.7916  42.7971\n",
       "    13       0.799998                    0.00320951         0.00289599   1.24987            0.000830096      0.00696211   0.358259                    0.359116            0.00028954      0.999896                   -99.7104  24.9873\n",
       "    14       1                           0                  0.000521166  1                  0.000149385      0.000602119  0.286636                    0.287412            0.000104234     1                          -99.9479  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: drf\n",
      "** Reported on validation data. **\n",
      "\n",
      "MSE: 0.018881497714415916\n",
      "RMSE: 0.1374099622094989\n",
      "LogLoss: 0.0955319096107168\n",
      "Mean Per-Class Error: 0.015262034263669788\n",
      "AUC: 0.9984440687687627\n",
      "pr_auc: 0.9622318205609467\n",
      "Gini: 0.9968881375375254\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4416887505133839: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>N</b></td>\n",
       "<td><b>Y</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>N</td>\n",
       "<td>23520.0</td>\n",
       "<td>188.0</td>\n",
       "<td>0.0079</td>\n",
       "<td> (188.0/23708.0)</td></tr>\n",
       "<tr><td>Y</td>\n",
       "<td>239.0</td>\n",
       "<td>9517.0</td>\n",
       "<td>0.0245</td>\n",
       "<td> (239.0/9756.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>23759.0</td>\n",
       "<td>9705.0</td>\n",
       "<td>0.0128</td>\n",
       "<td> (427.0/33464.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       N      Y     Error    Rate\n",
       "-----  -----  ----  -------  ---------------\n",
       "N      23520  188   0.0079   (188.0/23708.0)\n",
       "Y      239    9517  0.0245   (239.0/9756.0)\n",
       "Total  23759  9705  0.0128   (427.0/33464.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.4416888</td>\n",
       "<td>0.9780587</td>\n",
       "<td>195.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.3852141</td>\n",
       "<td>0.9802661</td>\n",
       "<td>210.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.6038533</td>\n",
       "<td>0.9869264</td>\n",
       "<td>161.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.4482769</td>\n",
       "<td>0.9872400</td>\n",
       "<td>193.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9999085</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0044250</td>\n",
       "<td>1.0</td>\n",
       "<td>394.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9999085</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.4416888</td>\n",
       "<td>0.9690697</td>\n",
       "<td>195.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.3852141</td>\n",
       "<td>0.9843513</td>\n",
       "<td>210.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.3914551</td>\n",
       "<td>0.9847380</td>\n",
       "<td>208.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.441689     0.978059  195\n",
       "max f2                       0.385214     0.980266  210\n",
       "max f0point5                 0.603853     0.986926  161\n",
       "max accuracy                 0.448277     0.98724   193\n",
       "max precision                0.999909     1         0\n",
       "max recall                   0.004425     1         394\n",
       "max specificity              0.999909     1         0\n",
       "max absolute_mcc             0.441689     0.96907   195\n",
       "max min_per_class_accuracy   0.385214     0.984351  210\n",
       "max mean_per_class_accuracy  0.391455     0.984738  208"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 29.15 %, avg score: 29.08 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>score</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>cumulative_score</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0100108</td>\n",
       "<td>0.9984228</td>\n",
       "<td>3.4300943</td>\n",
       "<td>3.4300943</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999521</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999521</td>\n",
       "<td>0.0343378</td>\n",
       "<td>0.0343378</td>\n",
       "<td>243.0094301</td>\n",
       "<td>243.0094301</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0200514</td>\n",
       "<td>0.9915056</td>\n",
       "<td>3.4300943</td>\n",
       "<td>3.4300943</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9932968</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9966195</td>\n",
       "<td>0.0344403</td>\n",
       "<td>0.0687782</td>\n",
       "<td>243.0094301</td>\n",
       "<td>243.0094301</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0307495</td>\n",
       "<td>0.9817939</td>\n",
       "<td>3.4300943</td>\n",
       "<td>3.4300943</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9859367</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9929028</td>\n",
       "<td>0.0366954</td>\n",
       "<td>0.1054736</td>\n",
       "<td>243.0094301</td>\n",
       "<td>243.0094301</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0400131</td>\n",
       "<td>0.9722330</td>\n",
       "<td>3.4300943</td>\n",
       "<td>3.4300943</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9778358</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9894146</td>\n",
       "<td>0.0317753</td>\n",
       "<td>0.1372489</td>\n",
       "<td>243.0094301</td>\n",
       "<td>243.0094301</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0500239</td>\n",
       "<td>0.9638823</td>\n",
       "<td>3.4300943</td>\n",
       "<td>3.4300943</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9674898</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9850270</td>\n",
       "<td>0.0343378</td>\n",
       "<td>0.1715867</td>\n",
       "<td>243.0094301</td>\n",
       "<td>243.0094301</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1000179</td>\n",
       "<td>0.9218599</td>\n",
       "<td>3.4300943</td>\n",
       "<td>3.4300943</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9416622</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9633511</td>\n",
       "<td>0.1714842</td>\n",
       "<td>0.3430709</td>\n",
       "<td>243.0094301</td>\n",
       "<td>243.0094301</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1500120</td>\n",
       "<td>0.8882195</td>\n",
       "<td>3.4300943</td>\n",
       "<td>3.4300943</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9053718</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9440285</td>\n",
       "<td>0.1714842</td>\n",
       "<td>0.5145551</td>\n",
       "<td>243.0094301</td>\n",
       "<td>243.0094301</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2000060</td>\n",
       "<td>0.8421777</td>\n",
       "<td>3.4280440</td>\n",
       "<td>3.4295818</td>\n",
       "<td>0.9994023</td>\n",
       "<td>0.8670677</td>\n",
       "<td>0.9998506</td>\n",
       "<td>0.9247912</td>\n",
       "<td>0.1713817</td>\n",
       "<td>0.6859369</td>\n",
       "<td>242.8044035</td>\n",
       "<td>242.9581811</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.2999940</td>\n",
       "<td>0.3708652</td>\n",
       "<td>2.9964631</td>\n",
       "<td>3.2852233</td>\n",
       "<td>0.8735804</td>\n",
       "<td>0.7020466</td>\n",
       "<td>0.9577647</td>\n",
       "<td>0.8505504</td>\n",
       "<td>0.2996105</td>\n",
       "<td>0.9855474</td>\n",
       "<td>199.6463133</td>\n",
       "<td>228.5223299</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4000120</td>\n",
       "<td>0.1124730</td>\n",
       "<td>0.1311778</td>\n",
       "<td>2.4965941</td>\n",
       "<td>0.0382432</td>\n",
       "<td>0.2071155</td>\n",
       "<td>0.7278500</td>\n",
       "<td>0.6896676</td>\n",
       "<td>0.0131201</td>\n",
       "<td>0.9986675</td>\n",
       "<td>-86.8822208</td>\n",
       "<td>149.6594111</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0486775</td>\n",
       "<td>0.0020503</td>\n",
       "<td>1.9977450</td>\n",
       "<td>0.0005977</td>\n",
       "<td>0.0752963</td>\n",
       "<td>0.5824169</td>\n",
       "<td>0.5668081</td>\n",
       "<td>0.0002050</td>\n",
       "<td>0.9988725</td>\n",
       "<td>-99.7949734</td>\n",
       "<td>99.7744977</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.6000179</td>\n",
       "<td>0.0250341</td>\n",
       "<td>0.0030745</td>\n",
       "<td>1.6652502</td>\n",
       "<td>0.0008963</td>\n",
       "<td>0.0353917</td>\n",
       "<td>0.4854823</td>\n",
       "<td>0.4782254</td>\n",
       "<td>0.0003075</td>\n",
       "<td>0.9991800</td>\n",
       "<td>-99.6925520</td>\n",
       "<td>66.5250224</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.7000060</td>\n",
       "<td>0.0144942</td>\n",
       "<td>0.0020503</td>\n",
       "<td>1.4276807</td>\n",
       "<td>0.0005977</td>\n",
       "<td>0.0190908</td>\n",
       "<td>0.4162220</td>\n",
       "<td>0.4126432</td>\n",
       "<td>0.0002050</td>\n",
       "<td>0.9993850</td>\n",
       "<td>-99.7949734</td>\n",
       "<td>42.7680659</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.8000239</td>\n",
       "<td>0.0087596</td>\n",
       "<td>0.0030745</td>\n",
       "<td>1.2495783</td>\n",
       "<td>0.0008963</td>\n",
       "<td>0.0113545</td>\n",
       "<td>0.3642985</td>\n",
       "<td>0.3624746</td>\n",
       "<td>0.0003075</td>\n",
       "<td>0.9996925</td>\n",
       "<td>-99.6925520</td>\n",
       "<td>24.9578280</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.8999821</td>\n",
       "<td>0.0040031</td>\n",
       "<td>0.0020509</td>\n",
       "<td>1.1110194</td>\n",
       "<td>0.0005979</td>\n",
       "<td>0.0063164</td>\n",
       "<td>0.3239034</td>\n",
       "<td>0.3229172</td>\n",
       "<td>0.0002050</td>\n",
       "<td>0.9998975</td>\n",
       "<td>-99.7949121</td>\n",
       "<td>11.1019355</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0010248</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0002988</td>\n",
       "<td>0.0016149</td>\n",
       "<td>0.2915372</td>\n",
       "<td>0.2907812</td>\n",
       "<td>0.0001025</td>\n",
       "<td>1.0</td>\n",
       "<td>-99.8975173</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.0100108                   0.998423           3.43009     3.43009            1                0.999952    1                           0.999952            0.0343378       0.0343378                  243.009   243.009\n",
       "    2        0.0200514                   0.991506           3.43009     3.43009            1                0.993297    1                           0.99662             0.0344403       0.0687782                  243.009   243.009\n",
       "    3        0.0307495                   0.981794           3.43009     3.43009            1                0.985937    1                           0.992903            0.0366954       0.105474                   243.009   243.009\n",
       "    4        0.0400131                   0.972233           3.43009     3.43009            1                0.977836    1                           0.989415            0.0317753       0.137249                   243.009   243.009\n",
       "    5        0.0500239                   0.963882           3.43009     3.43009            1                0.96749     1                           0.985027            0.0343378       0.171587                   243.009   243.009\n",
       "    6        0.100018                    0.92186            3.43009     3.43009            1                0.941662    1                           0.963351            0.171484        0.343071                   243.009   243.009\n",
       "    7        0.150012                    0.88822            3.43009     3.43009            1                0.905372    1                           0.944028            0.171484        0.514555                   243.009   243.009\n",
       "    8        0.200006                    0.842178           3.42804     3.42958            0.999402         0.867068    0.999851                    0.924791            0.171382        0.685937                   242.804   242.958\n",
       "    9        0.299994                    0.370865           2.99646     3.28522            0.87358          0.702047    0.957765                    0.85055             0.29961         0.985547                   199.646   228.522\n",
       "    10       0.400012                    0.112473           0.131178    2.49659            0.0382432        0.207116    0.72785                     0.689668            0.0131201       0.998667                   -86.8822  149.659\n",
       "    11       0.5                         0.0486775          0.00205027  1.99774            0.000597729      0.0752963   0.582417                    0.566808            0.000205002     0.998872                   -99.795   99.7745\n",
       "    12       0.600018                    0.0250341          0.00307448  1.66525            0.000896325      0.0353917   0.485482                    0.478225            0.000307503     0.99918                    -99.6926  66.525\n",
       "    13       0.700006                    0.0144942          0.00205027  1.42768            0.000597729      0.0190908   0.416222                    0.412643            0.000205002     0.999385                   -99.795   42.7681\n",
       "    14       0.800024                    0.00875963         0.00307448  1.24958            0.000896325      0.0113545   0.364299                    0.362475            0.000307503     0.999692                   -99.6926  24.9578\n",
       "    15       0.899982                    0.00400315         0.00205088  1.11102            0.000597907      0.0063164   0.323903                    0.322917            0.000205002     0.999897                   -99.7949  11.1019\n",
       "    16       1                           0                  0.00102483  1                  0.000298775      0.00161486  0.291537                    0.290781            0.000102501     1                          -99.8975  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: drf\n",
      "** Reported on cross-validation data. **\n",
      "\n",
      "MSE: 0.019838655136353946\n",
      "RMSE: 0.14084976086722314\n",
      "LogLoss: 0.09848448113892687\n",
      "Mean Per-Class Error: 0.01697642178512626\n",
      "AUC: 0.9984149199275788\n",
      "pr_auc: 0.9438620129204796\n",
      "Gini: 0.9968298398551576\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4721316665854305: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>N</b></td>\n",
       "<td><b>Y</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>N</td>\n",
       "<td>213304.0</td>\n",
       "<td>1584.0</td>\n",
       "<td>0.0074</td>\n",
       "<td> (1584.0/214888.0)</td></tr>\n",
       "<tr><td>Y</td>\n",
       "<td>2589.0</td>\n",
       "<td>83755.0</td>\n",
       "<td>0.03</td>\n",
       "<td> (2589.0/86344.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>215893.0</td>\n",
       "<td>85339.0</td>\n",
       "<td>0.0139</td>\n",
       "<td> (4173.0/301232.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       N       Y      Error    Rate\n",
       "-----  ------  -----  -------  -----------------\n",
       "N      213304  1584   0.0074   (1584.0/214888.0)\n",
       "Y      2589    83755  0.03     (2589.0/86344.0)\n",
       "Total  215893  85339  0.0139   (4173.0/301232.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.4721317</td>\n",
       "<td>0.9756936</td>\n",
       "<td>186.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.3610743</td>\n",
       "<td>0.9781708</td>\n",
       "<td>216.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.5859488</td>\n",
       "<td>0.9856473</td>\n",
       "<td>162.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.4721317</td>\n",
       "<td>0.9861469</td>\n",
       "<td>186.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9999495</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0013795</td>\n",
       "<td>1.0</td>\n",
       "<td>397.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9999495</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.4721317</td>\n",
       "<td>0.9660394</td>\n",
       "<td>186.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.3911902</td>\n",
       "<td>0.9824606</td>\n",
       "<td>207.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.4120424</td>\n",
       "<td>0.9830236</td>\n",
       "<td>201.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.472132     0.975694  186\n",
       "max f2                       0.361074     0.978171  216\n",
       "max f0point5                 0.585949     0.985647  162\n",
       "max accuracy                 0.472132     0.986147  186\n",
       "max precision                0.999949     1         0\n",
       "max recall                   0.00137952   1         397\n",
       "max specificity              0.999949     1         0\n",
       "max absolute_mcc             0.472132     0.966039  186\n",
       "max min_per_class_accuracy   0.39119      0.982461  207\n",
       "max mean_per_class_accuracy  0.412042     0.983024  201"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 28.66 %, avg score: 28.75 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>score</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>cumulative_score</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0140490</td>\n",
       "<td>1.0</td>\n",
       "<td>3.4887427</td>\n",
       "<td>3.4887427</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0490132</td>\n",
       "<td>0.0490132</td>\n",
       "<td>248.8742704</td>\n",
       "<td>248.8742704</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0200311</td>\n",
       "<td>0.9953594</td>\n",
       "<td>3.4887427</td>\n",
       "<td>3.4887427</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9974951</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9992519</td>\n",
       "<td>0.0208700</td>\n",
       "<td>0.0698833</td>\n",
       "<td>248.8742704</td>\n",
       "<td>248.8742704</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0301263</td>\n",
       "<td>0.9863092</td>\n",
       "<td>3.4887427</td>\n",
       "<td>3.4887427</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9906092</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9963558</td>\n",
       "<td>0.0352196</td>\n",
       "<td>0.1051028</td>\n",
       "<td>248.8742704</td>\n",
       "<td>248.8742704</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0400024</td>\n",
       "<td>0.9741634</td>\n",
       "<td>3.4887427</td>\n",
       "<td>3.4887427</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9807678</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9925073</td>\n",
       "<td>0.0344552</td>\n",
       "<td>0.1395580</td>\n",
       "<td>248.8742704</td>\n",
       "<td>248.8742704</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0500013</td>\n",
       "<td>0.9587926</td>\n",
       "<td>3.4887427</td>\n",
       "<td>3.4887427</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9660452</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9872156</td>\n",
       "<td>0.0348837</td>\n",
       "<td>0.1744418</td>\n",
       "<td>248.8742704</td>\n",
       "<td>248.8742704</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1000027</td>\n",
       "<td>0.9146654</td>\n",
       "<td>3.4887427</td>\n",
       "<td>3.4887427</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9343891</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9608024</td>\n",
       "<td>0.1744418</td>\n",
       "<td>0.3488835</td>\n",
       "<td>248.8742704</td>\n",
       "<td>248.8742704</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1500007</td>\n",
       "<td>0.8794678</td>\n",
       "<td>3.4885111</td>\n",
       "<td>3.4886655</td>\n",
       "<td>0.9999336</td>\n",
       "<td>0.8973287</td>\n",
       "<td>0.9999779</td>\n",
       "<td>0.9396454</td>\n",
       "<td>0.1744186</td>\n",
       "<td>0.5233021</td>\n",
       "<td>248.8511063</td>\n",
       "<td>248.8665493</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2000020</td>\n",
       "<td>0.8359674</td>\n",
       "<td>3.4882795</td>\n",
       "<td>3.4885690</td>\n",
       "<td>0.9998672</td>\n",
       "<td>0.8590832</td>\n",
       "<td>0.9999502</td>\n",
       "<td>0.9195045</td>\n",
       "<td>0.1744186</td>\n",
       "<td>0.6977207</td>\n",
       "<td>248.8279453</td>\n",
       "<td>248.8568982</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3000013</td>\n",
       "<td>0.3577441</td>\n",
       "<td>2.8957618</td>\n",
       "<td>3.2909688</td>\n",
       "<td>0.8300302</td>\n",
       "<td>0.6803003</td>\n",
       "<td>0.9433108</td>\n",
       "<td>0.8397707</td>\n",
       "<td>0.2895743</td>\n",
       "<td>0.9872950</td>\n",
       "<td>189.5761837</td>\n",
       "<td>229.0968787</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4000007</td>\n",
       "<td>0.1138118</td>\n",
       "<td>0.1148900</td>\n",
       "<td>2.4969557</td>\n",
       "<td>0.0329316</td>\n",
       "<td>0.2046500</td>\n",
       "<td>0.7157179</td>\n",
       "<td>0.6809918</td>\n",
       "<td>0.0114889</td>\n",
       "<td>0.9987839</td>\n",
       "<td>-88.5109957</td>\n",
       "<td>149.6955691</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0508306</td>\n",
       "<td>0.0033587</td>\n",
       "<td>1.9982396</td>\n",
       "<td>0.0009627</td>\n",
       "<td>0.0769064</td>\n",
       "<td>0.5727678</td>\n",
       "<td>0.5601755</td>\n",
       "<td>0.0003359</td>\n",
       "<td>0.9991198</td>\n",
       "<td>-99.6641319</td>\n",
       "<td>99.8239600</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.5999993</td>\n",
       "<td>0.0265169</td>\n",
       "<td>0.0013898</td>\n",
       "<td>1.6654331</td>\n",
       "<td>0.0003984</td>\n",
       "<td>0.0369419</td>\n",
       "<td>0.4773735</td>\n",
       "<td>0.4729704</td>\n",
       "<td>0.0001390</td>\n",
       "<td>0.9992588</td>\n",
       "<td>-99.8610201</td>\n",
       "<td>66.5433141</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.6999987</td>\n",
       "<td>0.0145751</td>\n",
       "<td>0.0019689</td>\n",
       "<td>1.4277965</td>\n",
       "<td>0.0005644</td>\n",
       "<td>0.0201392</td>\n",
       "<td>0.4092582</td>\n",
       "<td>0.4082805</td>\n",
       "<td>0.0001969</td>\n",
       "<td>0.9994557</td>\n",
       "<td>-99.8031118</td>\n",
       "<td>42.7796517</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.8001441</td>\n",
       "<td>0.0076869</td>\n",
       "<td>0.0028912</td>\n",
       "<td>1.2494565</td>\n",
       "<td>0.0008287</td>\n",
       "<td>0.0107899</td>\n",
       "<td>0.3581395</td>\n",
       "<td>0.3585309</td>\n",
       "<td>0.0002895</td>\n",
       "<td>0.9997452</td>\n",
       "<td>-99.7108809</td>\n",
       "<td>24.9456487</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.8999973</td>\n",
       "<td>0.0025570</td>\n",
       "<td>0.0020877</td>\n",
       "<td>1.1110629</td>\n",
       "<td>0.0005984</td>\n",
       "<td>0.0051052</td>\n",
       "<td>0.3184709</td>\n",
       "<td>0.3193189</td>\n",
       "<td>0.0002085</td>\n",
       "<td>0.9999537</td>\n",
       "<td>-99.7912252</td>\n",
       "<td>11.1062916</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0004633</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0001328</td>\n",
       "<td>0.0008872</td>\n",
       "<td>0.2866362</td>\n",
       "<td>0.2874749</td>\n",
       "<td>0.0000463</td>\n",
       "<td>1.0</td>\n",
       "<td>-99.9536749</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift         cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  -----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.014049                    1                  3.48874      3.48874            1                1            1                           1                   0.0490132       0.0490132                  248.874   248.874\n",
       "    2        0.0200311                   0.995359           3.48874      3.48874            1                0.997495     1                           0.999252            0.02087         0.0698833                  248.874   248.874\n",
       "    3        0.0301263                   0.986309           3.48874      3.48874            1                0.990609     1                           0.996356            0.0352196       0.105103                   248.874   248.874\n",
       "    4        0.0400024                   0.974163           3.48874      3.48874            1                0.980768     1                           0.992507            0.0344552       0.139558                   248.874   248.874\n",
       "    5        0.0500013                   0.958793           3.48874      3.48874            1                0.966045     1                           0.987216            0.0348837       0.174442                   248.874   248.874\n",
       "    6        0.100003                    0.914665           3.48874      3.48874            1                0.934389     1                           0.960802            0.174442        0.348884                   248.874   248.874\n",
       "    7        0.150001                    0.879468           3.48851      3.48867            0.999934         0.897329     0.999978                    0.939645            0.174419        0.523302                   248.851   248.867\n",
       "    8        0.200002                    0.835967           3.48828      3.48857            0.999867         0.859083     0.99995                     0.919505            0.174419        0.697721                   248.828   248.857\n",
       "    9        0.300001                    0.357744           2.89576      3.29097            0.83003          0.6803       0.943311                    0.839771            0.289574        0.987295                   189.576   229.097\n",
       "    10       0.400001                    0.113812           0.11489      2.49696            0.0329316        0.20465      0.715718                    0.680992            0.0114889       0.998784                   -88.511   149.696\n",
       "    11       0.5                         0.0508306          0.00335868   1.99824            0.00096272       0.0769064    0.572768                    0.560176            0.000335866     0.99912                    -99.6641  99.824\n",
       "    12       0.599999                    0.0265169          0.0013898    1.66543            0.000398367      0.0369419    0.477373                    0.47297             0.000138979     0.999259                   -99.861   66.5433\n",
       "    13       0.699999                    0.0145751          0.00196888   1.4278             0.000564353      0.0201392    0.409258                    0.408281            0.000196887     0.999456                   -99.8031  42.7797\n",
       "    14       0.800144                    0.00768693         0.00289119   1.24946            0.00082872       0.0107899    0.358139                    0.358531            0.00028954      0.999745                   -99.7109  24.9456\n",
       "    15       0.899997                    0.002557           0.00208775   1.11106            0.000598424      0.00510517   0.318471                    0.319319            0.000208468     0.999954                   -99.7912  11.1063\n",
       "    16       1                           0                  0.000463251  1                  0.000132784      0.000887211  0.286636                    0.287475            4.63263e-05     1                          -99.9537  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-Validation Metrics Summary: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>mean</b></td>\n",
       "<td><b>sd</b></td>\n",
       "<td><b>cv_1_valid</b></td>\n",
       "<td><b>cv_2_valid</b></td>\n",
       "<td><b>cv_3_valid</b></td>\n",
       "<td><b>cv_4_valid</b></td>\n",
       "<td><b>cv_5_valid</b></td></tr>\n",
       "<tr><td>accuracy</td>\n",
       "<td>0.9862399</td>\n",
       "<td>0.0003246</td>\n",
       "<td>0.9861902</td>\n",
       "<td>0.9866052</td>\n",
       "<td>0.9858912</td>\n",
       "<td>0.9868871</td>\n",
       "<td>0.9856256</td></tr>\n",
       "<tr><td>auc</td>\n",
       "<td>0.9984168</td>\n",
       "<td>0.0000323</td>\n",
       "<td>0.9984430</td>\n",
       "<td>0.9983832</td>\n",
       "<td>0.9983691</td>\n",
       "<td>0.9984936</td>\n",
       "<td>0.9983954</td></tr>\n",
       "<tr><td>err</td>\n",
       "<td>0.0137602</td>\n",
       "<td>0.0003246</td>\n",
       "<td>0.0138098</td>\n",
       "<td>0.0133949</td>\n",
       "<td>0.0141088</td>\n",
       "<td>0.0131129</td>\n",
       "<td>0.0143744</td></tr>\n",
       "<tr><td>err_count</td>\n",
       "<td>829.0</td>\n",
       "<td>19.55505</td>\n",
       "<td>832.0</td>\n",
       "<td>807.0</td>\n",
       "<td>850.0</td>\n",
       "<td>790.0</td>\n",
       "<td>866.0</td></tr>\n",
       "<tr><td>f0point5</td>\n",
       "<td>0.9792042</td>\n",
       "<td>0.0005735</td>\n",
       "<td>0.9803233</td>\n",
       "<td>0.9791669</td>\n",
       "<td>0.9783503</td>\n",
       "<td>0.9798901</td>\n",
       "<td>0.9782903</td></tr>\n",
       "<tr><td>f1</td>\n",
       "<td>0.9758602</td>\n",
       "<td>0.0005739</td>\n",
       "<td>0.9757661</td>\n",
       "<td>0.9764785</td>\n",
       "<td>0.9754321</td>\n",
       "<td>0.9769773</td>\n",
       "<td>0.9746472</td></tr>\n",
       "<tr><td>f2</td>\n",
       "<td>0.97254</td>\n",
       "<td>0.0008897</td>\n",
       "<td>0.9712509</td>\n",
       "<td>0.9738048</td>\n",
       "<td>0.9725312</td>\n",
       "<td>0.9740818</td>\n",
       "<td>0.9710313</td></tr>\n",
       "<tr><td>lift_top_group</td>\n",
       "<td>3.4887974</td>\n",
       "<td>0.0097586</td>\n",
       "<td>3.4826868</td>\n",
       "<td>3.496025</td>\n",
       "<td>3.4654012</td>\n",
       "<td>3.4941423</td>\n",
       "<td>3.5057318</td></tr>\n",
       "<tr><td>logloss</td>\n",
       "<td>0.0984845</td>\n",
       "<td>0.0005711</td>\n",
       "<td>0.0989524</td>\n",
       "<td>0.0975894</td>\n",
       "<td>0.0976437</td>\n",
       "<td>0.0985139</td>\n",
       "<td>0.0997231</td></tr>\n",
       "<tr><td>max_per_class_error</td>\n",
       "<td>0.0296604</td>\n",
       "<td>0.0011602</td>\n",
       "<td>0.0317359</td>\n",
       "<td>0.0279696</td>\n",
       "<td>0.0293932</td>\n",
       "<td>0.0278390</td>\n",
       "<td>0.0313646</td></tr>\n",
       "<tr><td>mcc</td>\n",
       "<td>0.9662698</td>\n",
       "<td>0.0007951</td>\n",
       "<td>0.9661673</td>\n",
       "<td>0.9671350</td>\n",
       "<td>0.96556</td>\n",
       "<td>0.9678338</td>\n",
       "<td>0.9646531</td></tr>\n",
       "<tr><td>mean_per_class_accuracy</td>\n",
       "<td>0.9814841</td>\n",
       "<td>0.0005400</td>\n",
       "<td>0.9808374</td>\n",
       "<td>0.9822373</td>\n",
       "<td>0.9813487</td>\n",
       "<td>0.9824762</td>\n",
       "<td>0.9805208</td></tr>\n",
       "<tr><td>mean_per_class_error</td>\n",
       "<td>0.0185159</td>\n",
       "<td>0.0005400</td>\n",
       "<td>0.0191627</td>\n",
       "<td>0.0177626</td>\n",
       "<td>0.0186512</td>\n",
       "<td>0.0175238</td>\n",
       "<td>0.0194792</td></tr>\n",
       "<tr><td>mse</td>\n",
       "<td>0.0198387</td>\n",
       "<td>0.0001794</td>\n",
       "<td>0.0200267</td>\n",
       "<td>0.0195677</td>\n",
       "<td>0.0197068</td>\n",
       "<td>0.0196522</td>\n",
       "<td>0.0202399</td></tr>\n",
       "<tr><td>precision</td>\n",
       "<td>0.9814468</td>\n",
       "<td>0.0007716</td>\n",
       "<td>0.9833852</td>\n",
       "<td>0.9809675</td>\n",
       "<td>0.9803056</td>\n",
       "<td>0.9818416</td>\n",
       "<td>0.9807341</td></tr>\n",
       "<tr><td>r2</td>\n",
       "<td>0.9029759</td>\n",
       "<td>0.0009448</td>\n",
       "<td>0.9021599</td>\n",
       "<td>0.9041837</td>\n",
       "<td>0.9040078</td>\n",
       "<td>0.9038008</td>\n",
       "<td>0.9007272</td></tr>\n",
       "<tr><td>recall</td>\n",
       "<td>0.9703395</td>\n",
       "<td>0.0011602</td>\n",
       "<td>0.9682640</td>\n",
       "<td>0.9720304</td>\n",
       "<td>0.9706069</td>\n",
       "<td>0.972161</td>\n",
       "<td>0.9686354</td></tr>\n",
       "<tr><td>rmse</td>\n",
       "<td>0.1408469</td>\n",
       "<td>0.0006359</td>\n",
       "<td>0.1415158</td>\n",
       "<td>0.1398845</td>\n",
       "<td>0.1403809</td>\n",
       "<td>0.1401864</td>\n",
       "<td>0.1422668</td></tr>\n",
       "<tr><td>specificity</td>\n",
       "<td>0.9926286</td>\n",
       "<td>0.0003179</td>\n",
       "<td>0.9934106</td>\n",
       "<td>0.9924443</td>\n",
       "<td>0.9920907</td>\n",
       "<td>0.9927913</td>\n",
       "<td>0.9924061</td></tr></table></div>"
      ],
      "text/plain": [
       "                         mean       sd           cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid\n",
       "-----------------------  ---------  -----------  ------------  ------------  ------------  ------------  ------------\n",
       "accuracy                 0.98624    0.000324608  0.98619       0.986605      0.985891      0.986887      0.985626\n",
       "auc                      0.998417   3.23065e-05  0.998443      0.998383      0.998369      0.998494      0.998395\n",
       "err                      0.0137602  0.000324608  0.0138098     0.0133949     0.0141088     0.0131129     0.0143744\n",
       "err_count                829        19.5551      832           807           850           790           866\n",
       "f0point5                 0.979204   0.000573461  0.980323      0.979167      0.97835       0.97989       0.97829\n",
       "f1                       0.97586    0.000573905  0.975766      0.976478      0.975432      0.976977      0.974647\n",
       "f2                       0.97254    0.000889657  0.971251      0.973805      0.972531      0.974082      0.971031\n",
       "lift_top_group           3.4888     0.00975858   3.48269       3.49602       3.4654        3.49414       3.50573\n",
       "logloss                  0.0984845  0.000571146  0.0989524     0.0975894     0.0976437     0.0985139     0.0997231\n",
       "max_per_class_error      0.0296604  0.00116016   0.0317359     0.0279696     0.0293932     0.027839      0.0313646\n",
       "mcc                      0.96627    0.000795138  0.966167      0.967135      0.96556       0.967834      0.964653\n",
       "mean_per_class_accuracy  0.981484   0.000540021  0.980837      0.982237      0.981349      0.982476      0.980521\n",
       "mean_per_class_error     0.0185159  0.000540021  0.0191627     0.0177626     0.0186512     0.0175238     0.0194792\n",
       "mse                      0.0198387  0.000179418  0.0200267     0.0195677     0.0197068     0.0196522     0.0202399\n",
       "precision                0.981447   0.000771579  0.983385      0.980967      0.980306      0.981842      0.980734\n",
       "r2                       0.902976   0.000944809  0.90216       0.904184      0.904008      0.903801      0.900727\n",
       "recall                   0.97034    0.00116016   0.968264      0.97203       0.970607      0.972161      0.968635\n",
       "rmse                     0.140847   0.000635873  0.141516      0.139884      0.140381      0.140186      0.142267\n",
       "specificity              0.992629   0.000317939  0.993411      0.992444      0.992091      0.992791      0.992406"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>timestamp</b></td>\n",
       "<td><b>duration</b></td>\n",
       "<td><b>number_of_trees</b></td>\n",
       "<td><b>training_rmse</b></td>\n",
       "<td><b>training_logloss</b></td>\n",
       "<td><b>training_auc</b></td>\n",
       "<td><b>training_pr_auc</b></td>\n",
       "<td><b>training_lift</b></td>\n",
       "<td><b>training_classification_error</b></td>\n",
       "<td><b>validation_rmse</b></td>\n",
       "<td><b>validation_logloss</b></td>\n",
       "<td><b>validation_auc</b></td>\n",
       "<td><b>validation_pr_auc</b></td>\n",
       "<td><b>validation_lift</b></td>\n",
       "<td><b>validation_classification_error</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-12-11 20:57:15</td>\n",
       "<td> 3 min 19.834 sec</td>\n",
       "<td>0.0</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-12-11 20:57:16</td>\n",
       "<td> 3 min 20.186 sec</td>\n",
       "<td>1.0</td>\n",
       "<td>0.2275729</td>\n",
       "<td>0.8023489</td>\n",
       "<td>0.9643373</td>\n",
       "<td>0.2973424</td>\n",
       "<td>3.2871077</td>\n",
       "<td>0.0678526</td>\n",
       "<td>0.2279121</td>\n",
       "<td>0.7845200</td>\n",
       "<td>0.9645842</td>\n",
       "<td>0.3021248</td>\n",
       "<td>3.2463666</td>\n",
       "<td>0.0692386</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-12-11 20:57:16</td>\n",
       "<td> 3 min 20.516 sec</td>\n",
       "<td>2.0</td>\n",
       "<td>0.1947116</td>\n",
       "<td>0.5755505</td>\n",
       "<td>0.9754294</td>\n",
       "<td>0.2674530</td>\n",
       "<td>3.3580941</td>\n",
       "<td>0.0477174</td>\n",
       "<td>0.1637330</td>\n",
       "<td>0.1682876</td>\n",
       "<td>0.9918950</td>\n",
       "<td>0.4090383</td>\n",
       "<td>3.4077110</td>\n",
       "<td>0.0301219</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-12-11 20:57:16</td>\n",
       "<td> 3 min 20.899 sec</td>\n",
       "<td>3.0</td>\n",
       "<td>0.2134816</td>\n",
       "<td>0.4830622</td>\n",
       "<td>0.9741121</td>\n",
       "<td>0.3753213</td>\n",
       "<td>3.3749162</td>\n",
       "<td>0.0549736</td>\n",
       "<td>0.1680320</td>\n",
       "<td>0.1352552</td>\n",
       "<td>0.9942703</td>\n",
       "<td>0.6381483</td>\n",
       "<td>3.4221034</td>\n",
       "<td>0.0240856</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-12-11 20:57:17</td>\n",
       "<td> 3 min 21.359 sec</td>\n",
       "<td>4.0</td>\n",
       "<td>0.2066882</td>\n",
       "<td>0.4262715</td>\n",
       "<td>0.9769762</td>\n",
       "<td>0.4401881</td>\n",
       "<td>3.3820812</td>\n",
       "<td>0.0500909</td>\n",
       "<td>0.1618993</td>\n",
       "<td>0.1214420</td>\n",
       "<td>0.9954384</td>\n",
       "<td>0.7329649</td>\n",
       "<td>3.4246605</td>\n",
       "<td>0.0223524</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-12-11 20:57:17</td>\n",
       "<td> 3 min 21.859 sec</td>\n",
       "<td>5.0</td>\n",
       "<td>0.1937728</td>\n",
       "<td>0.3528538</td>\n",
       "<td>0.9816797</td>\n",
       "<td>0.4619649</td>\n",
       "<td>3.4018667</td>\n",
       "<td>0.0430413</td>\n",
       "<td>0.1506791</td>\n",
       "<td>0.1056986</td>\n",
       "<td>0.9970041</td>\n",
       "<td>0.7713415</td>\n",
       "<td>3.4253653</td>\n",
       "<td>0.0180194</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-12-11 20:57:18</td>\n",
       "<td> 3 min 22.433 sec</td>\n",
       "<td>6.0</td>\n",
       "<td>0.1869723</td>\n",
       "<td>0.3042406</td>\n",
       "<td>0.9844282</td>\n",
       "<td>0.4974868</td>\n",
       "<td>3.4114792</td>\n",
       "<td>0.0393220</td>\n",
       "<td>0.1467868</td>\n",
       "<td>0.0978622</td>\n",
       "<td>0.9974764</td>\n",
       "<td>0.7976991</td>\n",
       "<td>3.4300943</td>\n",
       "<td>0.0173918</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-12-11 20:57:18</td>\n",
       "<td> 3 min 23.078 sec</td>\n",
       "<td>7.0</td>\n",
       "<td>0.1854219</td>\n",
       "<td>0.2674861</td>\n",
       "<td>0.9861019</td>\n",
       "<td>0.5391322</td>\n",
       "<td>3.4207316</td>\n",
       "<td>0.0376572</td>\n",
       "<td>0.1490559</td>\n",
       "<td>0.1007377</td>\n",
       "<td>0.9975420</td>\n",
       "<td>0.8216224</td>\n",
       "<td>3.4300943</td>\n",
       "<td>0.0170033</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-12-11 20:57:19</td>\n",
       "<td> 3 min 23.758 sec</td>\n",
       "<td>8.0</td>\n",
       "<td>0.1872386</td>\n",
       "<td>0.2432327</td>\n",
       "<td>0.9869286</td>\n",
       "<td>0.5870945</td>\n",
       "<td>3.4287745</td>\n",
       "<td>0.0383898</td>\n",
       "<td>0.1540573</td>\n",
       "<td>0.1084683</td>\n",
       "<td>0.9974627</td>\n",
       "<td>0.8487917</td>\n",
       "<td>3.4300943</td>\n",
       "<td>0.0169137</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-12-11 20:57:23</td>\n",
       "<td> 3 min 27.842 sec</td>\n",
       "<td>20.0</td>\n",
       "<td>0.1502654</td>\n",
       "<td>0.1015057</td>\n",
       "<td>0.9972609</td>\n",
       "<td>0.8269213</td>\n",
       "<td>3.4858202</td>\n",
       "<td>0.0187077</td>\n",
       "<td>0.1376642</td>\n",
       "<td>0.0955218</td>\n",
       "<td>0.9983738</td>\n",
       "<td>0.9522312</td>\n",
       "<td>3.4300943</td>\n",
       "<td>0.0132680</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-12-11 20:57:27</td>\n",
       "<td> 3 min 31.979 sec</td>\n",
       "<td>31.0</td>\n",
       "<td>0.1450408</td>\n",
       "<td>0.0973989</td>\n",
       "<td>0.9980205</td>\n",
       "<td>0.8773195</td>\n",
       "<td>3.4887427</td>\n",
       "<td>0.0163495</td>\n",
       "<td>0.1371480</td>\n",
       "<td>0.0951007</td>\n",
       "<td>0.9984275</td>\n",
       "<td>0.9580318</td>\n",
       "<td>3.4300943</td>\n",
       "<td>0.0130887</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-12-11 20:57:32</td>\n",
       "<td> 3 min 37.002 sec</td>\n",
       "<td>44.0</td>\n",
       "<td>0.1427767</td>\n",
       "<td>0.0966466</td>\n",
       "<td>0.9982077</td>\n",
       "<td>0.9023397</td>\n",
       "<td>3.4887427</td>\n",
       "<td>0.0154665</td>\n",
       "<td>0.1372723</td>\n",
       "<td>0.0951708</td>\n",
       "<td>0.9984373</td>\n",
       "<td>0.9617304</td>\n",
       "<td>3.4300943</td>\n",
       "<td>0.0128795</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-12-11 20:57:35</td>\n",
       "<td> 3 min 39.588 sec</td>\n",
       "<td>50.0</td>\n",
       "<td>0.1422773</td>\n",
       "<td>0.0967380</td>\n",
       "<td>0.9982640</td>\n",
       "<td>0.9089612</td>\n",
       "<td>3.4887427</td>\n",
       "<td>0.0151080</td>\n",
       "<td>0.1374100</td>\n",
       "<td>0.0955319</td>\n",
       "<td>0.9984441</td>\n",
       "<td>0.9622318</td>\n",
       "<td>3.4300943</td>\n",
       "<td>0.0127600</td></tr></table></div>"
      ],
      "text/plain": [
       "    timestamp            duration          number_of_trees    training_rmse    training_logloss    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_auc    validation_pr_auc    validation_lift    validation_classification_error\n",
       "--  -------------------  ----------------  -----------------  ---------------  ------------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ----------------  -------------------  -----------------  ---------------------------------\n",
       "    2018-12-11 20:57:15  3 min 19.834 sec  0                  nan              nan                 nan             nan                nan              nan                              nan                nan                   nan               nan                  nan                nan\n",
       "    2018-12-11 20:57:16  3 min 20.186 sec  1                  0.227573         0.802349            0.964337        0.297342           3.28711          0.0678526                        0.227912           0.78452               0.964584          0.302125             3.24637            0.0692386\n",
       "    2018-12-11 20:57:16  3 min 20.516 sec  2                  0.194712         0.57555             0.975429        0.267453           3.35809          0.0477174                        0.163733           0.168288              0.991895          0.409038             3.40771            0.0301219\n",
       "    2018-12-11 20:57:16  3 min 20.899 sec  3                  0.213482         0.483062            0.974112        0.375321           3.37492          0.0549736                        0.168032           0.135255              0.99427           0.638148             3.4221             0.0240856\n",
       "    2018-12-11 20:57:17  3 min 21.359 sec  4                  0.206688         0.426271            0.976976        0.440188           3.38208          0.0500909                        0.161899           0.121442              0.995438          0.732965             3.42466            0.0223524\n",
       "    2018-12-11 20:57:17  3 min 21.859 sec  5                  0.193773         0.352854            0.98168         0.461965           3.40187          0.0430413                        0.150679           0.105699              0.997004          0.771341             3.42537            0.0180194\n",
       "    2018-12-11 20:57:18  3 min 22.433 sec  6                  0.186972         0.304241            0.984428        0.497487           3.41148          0.039322                         0.146787           0.0978622             0.997476          0.797699             3.43009            0.0173918\n",
       "    2018-12-11 20:57:18  3 min 23.078 sec  7                  0.185422         0.267486            0.986102        0.539132           3.42073          0.0376572                        0.149056           0.100738              0.997542          0.821622             3.43009            0.0170033\n",
       "    2018-12-11 20:57:19  3 min 23.758 sec  8                  0.187239         0.243233            0.986929        0.587094           3.42877          0.0383898                        0.154057           0.108468              0.997463          0.848792             3.43009            0.0169137\n",
       "    2018-12-11 20:57:23  3 min 27.842 sec  20                 0.150265         0.101506            0.997261        0.826921           3.48582          0.0187077                        0.137664           0.0955218             0.998374          0.952231             3.43009            0.013268\n",
       "    2018-12-11 20:57:27  3 min 31.979 sec  31                 0.145041         0.0973989           0.99802         0.87732            3.48874          0.0163495                        0.137148           0.0951007             0.998428          0.958032             3.43009            0.0130887\n",
       "    2018-12-11 20:57:32  3 min 37.002 sec  44                 0.142777         0.0966466           0.998208        0.90234            3.48874          0.0154665                        0.137272           0.0951708             0.998437          0.96173              3.43009            0.0128795\n",
       "    2018-12-11 20:57:35  3 min 39.588 sec  50                 0.142277         0.096738            0.998264        0.908961           3.48874          0.015108                         0.13741            0.0955319             0.998444          0.962232             3.43009            0.01276"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable Importances: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>variable</b></td>\n",
       "<td><b>relative_importance</b></td>\n",
       "<td><b>scaled_importance</b></td>\n",
       "<td><b>percentage</b></td></tr>\n",
       "<tr><td>city_id</td>\n",
       "<td>955775.3125000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.5581109</td></tr>\n",
       "<tr><td>state_id</td>\n",
       "<td>257751.2343750</td>\n",
       "<td>0.2696776</td>\n",
       "<td>0.1505100</td></tr>\n",
       "<tr><td>category_2</td>\n",
       "<td>160059.9062500</td>\n",
       "<td>0.1674660</td>\n",
       "<td>0.0934646</td></tr>\n",
       "<tr><td>category_1</td>\n",
       "<td>115193.4609375</td>\n",
       "<td>0.1205236</td>\n",
       "<td>0.0672655</td></tr>\n",
       "<tr><td>merchant_group_id</td>\n",
       "<td>70843.8906250</td>\n",
       "<td>0.0741219</td>\n",
       "<td>0.0413682</td></tr>\n",
       "<tr><td>subsector_id</td>\n",
       "<td>31761.3027344</td>\n",
       "<td>0.0332309</td>\n",
       "<td>0.0185465</td></tr>\n",
       "<tr><td>merchant_category_id</td>\n",
       "<td>19091.6308594</td>\n",
       "<td>0.0199750</td>\n",
       "<td>0.0111483</td></tr>\n",
       "<tr><td>most_recent_sales_range</td>\n",
       "<td>14489.4287109</td>\n",
       "<td>0.0151599</td>\n",
       "<td>0.0084609</td></tr>\n",
       "<tr><td>numerical_1</td>\n",
       "<td>11903.5019531</td>\n",
       "<td>0.0124543</td>\n",
       "<td>0.0069509</td></tr>\n",
       "<tr><td>most_recent_purchases_range</td>\n",
       "<td>10130.6972656</td>\n",
       "<td>0.0105995</td>\n",
       "<td>0.0059157</td></tr>\n",
       "<tr><td>numerical_2</td>\n",
       "<td>9703.4843750</td>\n",
       "<td>0.0101525</td>\n",
       "<td>0.0056662</td></tr>\n",
       "<tr><td>avg_purchases_lag3</td>\n",
       "<td>8831.2177734</td>\n",
       "<td>0.0092398</td>\n",
       "<td>0.0051569</td></tr>\n",
       "<tr><td>avg_purchases_lag6</td>\n",
       "<td>8387.1093750</td>\n",
       "<td>0.0087752</td>\n",
       "<td>0.0048975</td></tr>\n",
       "<tr><td>avg_purchases_lag12</td>\n",
       "<td>8357.7822266</td>\n",
       "<td>0.0087445</td>\n",
       "<td>0.0048804</td></tr>\n",
       "<tr><td>avg_sales_lag3</td>\n",
       "<td>8332.0605469</td>\n",
       "<td>0.0087176</td>\n",
       "<td>0.0048654</td></tr>\n",
       "<tr><td>avg_sales_lag12</td>\n",
       "<td>7839.9199219</td>\n",
       "<td>0.0082027</td>\n",
       "<td>0.0045780</td></tr>\n",
       "<tr><td>avg_sales_lag6</td>\n",
       "<td>7648.2841797</td>\n",
       "<td>0.0080022</td>\n",
       "<td>0.0044661</td></tr>\n",
       "<tr><td>active_months_lag12</td>\n",
       "<td>4748.7172852</td>\n",
       "<td>0.0049684</td>\n",
       "<td>0.0027729</td></tr>\n",
       "<tr><td>active_months_lag6</td>\n",
       "<td>1353.7655029</td>\n",
       "<td>0.0014164</td>\n",
       "<td>0.0007905</td></tr>\n",
       "<tr><td>active_months_lag3</td>\n",
       "<td>315.8672791</td>\n",
       "<td>0.0003305</td>\n",
       "<td>0.0001844</td></tr></table></div>"
      ],
      "text/plain": [
       "variable                     relative_importance    scaled_importance    percentage\n",
       "---------------------------  ---------------------  -------------------  ------------\n",
       "city_id                      955775                 1                    0.558111\n",
       "state_id                     257751                 0.269678             0.15051\n",
       "category_2                   160060                 0.167466             0.0934646\n",
       "category_1                   115193                 0.120524             0.0672655\n",
       "merchant_group_id            70843.9                0.0741219            0.0413682\n",
       "subsector_id                 31761.3                0.0332309            0.0185465\n",
       "merchant_category_id         19091.6                0.019975             0.0111483\n",
       "most_recent_sales_range      14489.4                0.0151599            0.00846089\n",
       "numerical_1                  11903.5                0.0124543            0.00695087\n",
       "most_recent_purchases_range  10130.7                0.0105995            0.00591567\n",
       "numerical_2                  9703.48                0.0101525            0.00566621\n",
       "avg_purchases_lag3           8831.22                0.00923985           0.00515686\n",
       "avg_purchases_lag6           8387.11                0.00877519           0.00489753\n",
       "avg_purchases_lag12          8357.78                0.00874451           0.0048804\n",
       "avg_sales_lag3               8332.06                0.00871759           0.00486538\n",
       "avg_sales_lag12              7839.92                0.00820268           0.00457801\n",
       "avg_sales_lag6               7648.28                0.00800218           0.0044661\n",
       "active_months_lag12          4748.72                0.00496845           0.00277294\n",
       "active_months_lag6           1353.77                0.00141641           0.000790511\n",
       "active_months_lag3           315.867                0.000330483          0.000184446"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<bound method H2OBinomialModel.tpr of >"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aml.leader.tpr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2ORandomForestEstimator :  Distributed Random Forest\n",
      "Model Key:  DRF_1_AutoML_20181211_205354\n",
      "\n",
      "\n",
      "ModelMetricsBinomial: drf\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.020242828646662245\n",
      "RMSE: 0.14227729490913948\n",
      "LogLoss: 0.09673799546133012\n",
      "Mean Per-Class Error: 0.01872350523172872\n",
      "AUC: 0.9982640258173935\n",
      "pr_auc: 0.9089612037582203\n",
      "Gini: 0.996528051634787\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.49174027253987507: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>N</b></td>\n",
       "<td><b>Y</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>N</td>\n",
       "<td>213435.0</td>\n",
       "<td>1453.0</td>\n",
       "<td>0.0068</td>\n",
       "<td> (1453.0/214888.0)</td></tr>\n",
       "<tr><td>Y</td>\n",
       "<td>3098.0</td>\n",
       "<td>83246.0</td>\n",
       "<td>0.0359</td>\n",
       "<td> (3098.0/86344.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>216533.0</td>\n",
       "<td>84699.0</td>\n",
       "<td>0.0151</td>\n",
       "<td> (4551.0/301232.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       N       Y      Error    Rate\n",
       "-----  ------  -----  -------  -----------------\n",
       "N      213435  1453   0.0068   (1453.0/214888.0)\n",
       "Y      3098    83246  0.0359   (3098.0/86344.0)\n",
       "Total  216533  84699  0.0151   (4551.0/301232.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.4917403</td>\n",
       "<td>0.9733927</td>\n",
       "<td>188.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.3549770</td>\n",
       "<td>0.9761585</td>\n",
       "<td>222.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.5960178</td>\n",
       "<td>0.9839807</td>\n",
       "<td>165.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.4917403</td>\n",
       "<td>0.9848920</td>\n",
       "<td>188.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9999810</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0000123</td>\n",
       "<td>1.0</td>\n",
       "<td>399.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9999810</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.4917403</td>\n",
       "<td>0.9629320</td>\n",
       "<td>188.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.3912923</td>\n",
       "<td>0.9810294</td>\n",
       "<td>212.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.4162169</td>\n",
       "<td>0.9812765</td>\n",
       "<td>206.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.49174      0.973393  188\n",
       "max f2                       0.354977     0.976159  222\n",
       "max f0point5                 0.596018     0.983981  165\n",
       "max accuracy                 0.49174      0.984892  188\n",
       "max precision                0.999981     1         0\n",
       "max recall                   1.23132e-05  1         399\n",
       "max specificity              0.999981     1         0\n",
       "max absolute_mcc             0.49174      0.962932  188\n",
       "max min_per_class_accuracy   0.391292     0.981029  212\n",
       "max mean_per_class_accuracy  0.416217     0.981276  206"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 28.66 %, avg score: 28.74 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>score</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>cumulative_score</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0245724</td>\n",
       "<td>1.0</td>\n",
       "<td>3.4887427</td>\n",
       "<td>3.4887427</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0857269</td>\n",
       "<td>0.0857269</td>\n",
       "<td>248.8742704</td>\n",
       "<td>248.8742704</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0300001</td>\n",
       "<td>0.9923801</td>\n",
       "<td>3.4887427</td>\n",
       "<td>3.4887427</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9960116</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9992784</td>\n",
       "<td>0.0189359</td>\n",
       "<td>0.1046627</td>\n",
       "<td>248.8742704</td>\n",
       "<td>248.8742704</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0400024</td>\n",
       "<td>0.9817353</td>\n",
       "<td>3.4887427</td>\n",
       "<td>3.4887427</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9873043</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9962844</td>\n",
       "<td>0.0348953</td>\n",
       "<td>0.1395580</td>\n",
       "<td>248.8742704</td>\n",
       "<td>248.8742704</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0500013</td>\n",
       "<td>0.9724944</td>\n",
       "<td>3.4887427</td>\n",
       "<td>3.4887427</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9772090</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9924698</td>\n",
       "<td>0.0348837</td>\n",
       "<td>0.1744418</td>\n",
       "<td>248.8742704</td>\n",
       "<td>248.8742704</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.1000060</td>\n",
       "<td>0.9298701</td>\n",
       "<td>3.4880479</td>\n",
       "<td>3.4883953</td>\n",
       "<td>0.9998008</td>\n",
       "<td>0.9503510</td>\n",
       "<td>0.9999004</td>\n",
       "<td>0.9714097</td>\n",
       "<td>0.1744186</td>\n",
       "<td>0.3488604</td>\n",
       "<td>248.8047873</td>\n",
       "<td>248.8395277</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1500007</td>\n",
       "<td>0.8884800</td>\n",
       "<td>3.4885110</td>\n",
       "<td>3.4884339</td>\n",
       "<td>0.9999336</td>\n",
       "<td>0.9095350</td>\n",
       "<td>0.9999115</td>\n",
       "<td>0.9507871</td>\n",
       "<td>0.1744070</td>\n",
       "<td>0.5232674</td>\n",
       "<td>248.8511047</td>\n",
       "<td>248.8433863</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.2000020</td>\n",
       "<td>0.8358737</td>\n",
       "<td>3.4873530</td>\n",
       "<td>3.4881636</td>\n",
       "<td>0.9996016</td>\n",
       "<td>0.8638037</td>\n",
       "<td>0.9998340</td>\n",
       "<td>0.9290409</td>\n",
       "<td>0.1743723</td>\n",
       "<td>0.6976397</td>\n",
       "<td>248.7352951</td>\n",
       "<td>248.8163630</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.3000013</td>\n",
       "<td>0.3581678</td>\n",
       "<td>2.8753781</td>\n",
       "<td>3.2839041</td>\n",
       "<td>0.8241875</td>\n",
       "<td>0.6756746</td>\n",
       "<td>0.9412858</td>\n",
       "<td>0.8445864</td>\n",
       "<td>0.2875359</td>\n",
       "<td>0.9851756</td>\n",
       "<td>187.5378120</td>\n",
       "<td>228.3904054</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.4000007</td>\n",
       "<td>0.1144822</td>\n",
       "<td>0.1351579</td>\n",
       "<td>2.4967241</td>\n",
       "<td>0.0387412</td>\n",
       "<td>0.2041120</td>\n",
       "<td>0.7156515</td>\n",
       "<td>0.6844691</td>\n",
       "<td>0.0135157</td>\n",
       "<td>0.9986913</td>\n",
       "<td>-86.4842056</td>\n",
       "<td>149.6724059</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0506433</td>\n",
       "<td>0.0044010</td>\n",
       "<td>1.9982628</td>\n",
       "<td>0.0012615</td>\n",
       "<td>0.0768782</td>\n",
       "<td>0.5727745</td>\n",
       "<td>0.5629517</td>\n",
       "<td>0.0004401</td>\n",
       "<td>0.9991314</td>\n",
       "<td>-99.5598970</td>\n",
       "<td>99.8262763</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.6000027</td>\n",
       "<td>0.0228758</td>\n",
       "<td>0.0026637</td>\n",
       "<td>1.6656556</td>\n",
       "<td>0.0007635</td>\n",
       "<td>0.0346323</td>\n",
       "<td>0.4774372</td>\n",
       "<td>0.4748965</td>\n",
       "<td>0.0002664</td>\n",
       "<td>0.9993978</td>\n",
       "<td>-99.7336307</td>\n",
       "<td>66.5655557</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.7000186</td>\n",
       "<td>0.0115814</td>\n",
       "<td>0.0020844</td>\n",
       "<td>1.4279710</td>\n",
       "<td>0.0005975</td>\n",
       "<td>0.0165641</td>\n",
       "<td>0.4093082</td>\n",
       "<td>0.4094118</td>\n",
       "<td>0.0002085</td>\n",
       "<td>0.9996062</td>\n",
       "<td>-99.7915648</td>\n",
       "<td>42.7970971</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.7999980</td>\n",
       "<td>0.0032095</td>\n",
       "<td>0.0028960</td>\n",
       "<td>1.2498728</td>\n",
       "<td>0.0008301</td>\n",
       "<td>0.0069621</td>\n",
       "<td>0.3582588</td>\n",
       "<td>0.3591158</td>\n",
       "<td>0.0002895</td>\n",
       "<td>0.9998958</td>\n",
       "<td>-99.7104009</td>\n",
       "<td>24.9872819</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0005212</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0001494</td>\n",
       "<td>0.0006021</td>\n",
       "<td>0.2866362</td>\n",
       "<td>0.2874123</td>\n",
       "<td>0.0001042</td>\n",
       "<td>1.0</td>\n",
       "<td>-99.9478834</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift         cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  -----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.0245724                   1                  3.48874      3.48874            1                1            1                           1                   0.0857269       0.0857269                  248.874   248.874\n",
       "    2        0.0300001                   0.99238            3.48874      3.48874            1                0.996012     1                           0.999278            0.0189359       0.104663                   248.874   248.874\n",
       "    3        0.0400024                   0.981735           3.48874      3.48874            1                0.987304     1                           0.996284            0.0348953       0.139558                   248.874   248.874\n",
       "    4        0.0500013                   0.972494           3.48874      3.48874            1                0.977209     1                           0.99247             0.0348837       0.174442                   248.874   248.874\n",
       "    5        0.100006                    0.92987            3.48805      3.4884             0.999801         0.950351     0.9999                      0.97141             0.174419        0.34886                    248.805   248.84\n",
       "    6        0.150001                    0.88848            3.48851      3.48843            0.999934         0.909535     0.999911                    0.950787            0.174407        0.523267                   248.851   248.843\n",
       "    7        0.200002                    0.835874           3.48735      3.48816            0.999602         0.863804     0.999834                    0.929041            0.174372        0.69764                    248.735   248.816\n",
       "    8        0.300001                    0.358168           2.87538      3.2839             0.824187         0.675675     0.941286                    0.844586            0.287536        0.985176                   187.538   228.39\n",
       "    9        0.400001                    0.114482           0.135158     2.49672            0.0387412        0.204112     0.715652                    0.684469            0.0135157       0.998691                   -86.4842  149.672\n",
       "    10       0.5                         0.0506433          0.00440103   1.99826            0.00126149       0.0768782    0.572774                    0.562952            0.0004401       0.999131                   -99.5599  99.8263\n",
       "    11       0.600003                    0.0228758          0.00266369   1.66566            0.000763511      0.0346323    0.477437                    0.474897            0.000266376     0.999398                   -99.7336  66.5656\n",
       "    12       0.700019                    0.0115814          0.00208435   1.42797            0.000597451      0.0165641    0.409308                    0.409412            0.000208468     0.999606                   -99.7916  42.7971\n",
       "    13       0.799998                    0.00320951         0.00289599   1.24987            0.000830096      0.00696211   0.358259                    0.359116            0.00028954      0.999896                   -99.7104  24.9873\n",
       "    14       1                           0                  0.000521166  1                  0.000149385      0.000602119  0.286636                    0.287412            0.000104234     1                          -99.9479  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: drf\n",
      "** Reported on validation data. **\n",
      "\n",
      "MSE: 0.018881497714415916\n",
      "RMSE: 0.1374099622094989\n",
      "LogLoss: 0.0955319096107168\n",
      "Mean Per-Class Error: 0.015262034263669788\n",
      "AUC: 0.9984440687687627\n",
      "pr_auc: 0.9622318205609467\n",
      "Gini: 0.9968881375375254\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4416887505133839: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>N</b></td>\n",
       "<td><b>Y</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>N</td>\n",
       "<td>23520.0</td>\n",
       "<td>188.0</td>\n",
       "<td>0.0079</td>\n",
       "<td> (188.0/23708.0)</td></tr>\n",
       "<tr><td>Y</td>\n",
       "<td>239.0</td>\n",
       "<td>9517.0</td>\n",
       "<td>0.0245</td>\n",
       "<td> (239.0/9756.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>23759.0</td>\n",
       "<td>9705.0</td>\n",
       "<td>0.0128</td>\n",
       "<td> (427.0/33464.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       N      Y     Error    Rate\n",
       "-----  -----  ----  -------  ---------------\n",
       "N      23520  188   0.0079   (188.0/23708.0)\n",
       "Y      239    9517  0.0245   (239.0/9756.0)\n",
       "Total  23759  9705  0.0128   (427.0/33464.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.4416888</td>\n",
       "<td>0.9780587</td>\n",
       "<td>195.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.3852141</td>\n",
       "<td>0.9802661</td>\n",
       "<td>210.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.6038533</td>\n",
       "<td>0.9869264</td>\n",
       "<td>161.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.4482769</td>\n",
       "<td>0.9872400</td>\n",
       "<td>193.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9999085</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0044250</td>\n",
       "<td>1.0</td>\n",
       "<td>394.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9999085</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.4416888</td>\n",
       "<td>0.9690697</td>\n",
       "<td>195.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.3852141</td>\n",
       "<td>0.9843513</td>\n",
       "<td>210.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.3914551</td>\n",
       "<td>0.9847380</td>\n",
       "<td>208.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.441689     0.978059  195\n",
       "max f2                       0.385214     0.980266  210\n",
       "max f0point5                 0.603853     0.986926  161\n",
       "max accuracy                 0.448277     0.98724   193\n",
       "max precision                0.999909     1         0\n",
       "max recall                   0.004425     1         394\n",
       "max specificity              0.999909     1         0\n",
       "max absolute_mcc             0.441689     0.96907   195\n",
       "max min_per_class_accuracy   0.385214     0.984351  210\n",
       "max mean_per_class_accuracy  0.391455     0.984738  208"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 29.15 %, avg score: 29.08 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>score</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>cumulative_score</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0100108</td>\n",
       "<td>0.9984228</td>\n",
       "<td>3.4300943</td>\n",
       "<td>3.4300943</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999521</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999521</td>\n",
       "<td>0.0343378</td>\n",
       "<td>0.0343378</td>\n",
       "<td>243.0094301</td>\n",
       "<td>243.0094301</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0200514</td>\n",
       "<td>0.9915056</td>\n",
       "<td>3.4300943</td>\n",
       "<td>3.4300943</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9932968</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9966195</td>\n",
       "<td>0.0344403</td>\n",
       "<td>0.0687782</td>\n",
       "<td>243.0094301</td>\n",
       "<td>243.0094301</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0307495</td>\n",
       "<td>0.9817939</td>\n",
       "<td>3.4300943</td>\n",
       "<td>3.4300943</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9859367</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9929028</td>\n",
       "<td>0.0366954</td>\n",
       "<td>0.1054736</td>\n",
       "<td>243.0094301</td>\n",
       "<td>243.0094301</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0400131</td>\n",
       "<td>0.9722330</td>\n",
       "<td>3.4300943</td>\n",
       "<td>3.4300943</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9778358</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9894146</td>\n",
       "<td>0.0317753</td>\n",
       "<td>0.1372489</td>\n",
       "<td>243.0094301</td>\n",
       "<td>243.0094301</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0500239</td>\n",
       "<td>0.9638823</td>\n",
       "<td>3.4300943</td>\n",
       "<td>3.4300943</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9674898</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9850270</td>\n",
       "<td>0.0343378</td>\n",
       "<td>0.1715867</td>\n",
       "<td>243.0094301</td>\n",
       "<td>243.0094301</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1000179</td>\n",
       "<td>0.9218599</td>\n",
       "<td>3.4300943</td>\n",
       "<td>3.4300943</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9416622</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9633511</td>\n",
       "<td>0.1714842</td>\n",
       "<td>0.3430709</td>\n",
       "<td>243.0094301</td>\n",
       "<td>243.0094301</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1500120</td>\n",
       "<td>0.8882195</td>\n",
       "<td>3.4300943</td>\n",
       "<td>3.4300943</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9053718</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9440285</td>\n",
       "<td>0.1714842</td>\n",
       "<td>0.5145551</td>\n",
       "<td>243.0094301</td>\n",
       "<td>243.0094301</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2000060</td>\n",
       "<td>0.8421777</td>\n",
       "<td>3.4280440</td>\n",
       "<td>3.4295818</td>\n",
       "<td>0.9994023</td>\n",
       "<td>0.8670677</td>\n",
       "<td>0.9998506</td>\n",
       "<td>0.9247912</td>\n",
       "<td>0.1713817</td>\n",
       "<td>0.6859369</td>\n",
       "<td>242.8044035</td>\n",
       "<td>242.9581811</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.2999940</td>\n",
       "<td>0.3708652</td>\n",
       "<td>2.9964631</td>\n",
       "<td>3.2852233</td>\n",
       "<td>0.8735804</td>\n",
       "<td>0.7020466</td>\n",
       "<td>0.9577647</td>\n",
       "<td>0.8505504</td>\n",
       "<td>0.2996105</td>\n",
       "<td>0.9855474</td>\n",
       "<td>199.6463133</td>\n",
       "<td>228.5223299</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4000120</td>\n",
       "<td>0.1124730</td>\n",
       "<td>0.1311778</td>\n",
       "<td>2.4965941</td>\n",
       "<td>0.0382432</td>\n",
       "<td>0.2071155</td>\n",
       "<td>0.7278500</td>\n",
       "<td>0.6896676</td>\n",
       "<td>0.0131201</td>\n",
       "<td>0.9986675</td>\n",
       "<td>-86.8822208</td>\n",
       "<td>149.6594111</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0486775</td>\n",
       "<td>0.0020503</td>\n",
       "<td>1.9977450</td>\n",
       "<td>0.0005977</td>\n",
       "<td>0.0752963</td>\n",
       "<td>0.5824169</td>\n",
       "<td>0.5668081</td>\n",
       "<td>0.0002050</td>\n",
       "<td>0.9988725</td>\n",
       "<td>-99.7949734</td>\n",
       "<td>99.7744977</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.6000179</td>\n",
       "<td>0.0250341</td>\n",
       "<td>0.0030745</td>\n",
       "<td>1.6652502</td>\n",
       "<td>0.0008963</td>\n",
       "<td>0.0353917</td>\n",
       "<td>0.4854823</td>\n",
       "<td>0.4782254</td>\n",
       "<td>0.0003075</td>\n",
       "<td>0.9991800</td>\n",
       "<td>-99.6925520</td>\n",
       "<td>66.5250224</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.7000060</td>\n",
       "<td>0.0144942</td>\n",
       "<td>0.0020503</td>\n",
       "<td>1.4276807</td>\n",
       "<td>0.0005977</td>\n",
       "<td>0.0190908</td>\n",
       "<td>0.4162220</td>\n",
       "<td>0.4126432</td>\n",
       "<td>0.0002050</td>\n",
       "<td>0.9993850</td>\n",
       "<td>-99.7949734</td>\n",
       "<td>42.7680659</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.8000239</td>\n",
       "<td>0.0087596</td>\n",
       "<td>0.0030745</td>\n",
       "<td>1.2495783</td>\n",
       "<td>0.0008963</td>\n",
       "<td>0.0113545</td>\n",
       "<td>0.3642985</td>\n",
       "<td>0.3624746</td>\n",
       "<td>0.0003075</td>\n",
       "<td>0.9996925</td>\n",
       "<td>-99.6925520</td>\n",
       "<td>24.9578280</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.8999821</td>\n",
       "<td>0.0040031</td>\n",
       "<td>0.0020509</td>\n",
       "<td>1.1110194</td>\n",
       "<td>0.0005979</td>\n",
       "<td>0.0063164</td>\n",
       "<td>0.3239034</td>\n",
       "<td>0.3229172</td>\n",
       "<td>0.0002050</td>\n",
       "<td>0.9998975</td>\n",
       "<td>-99.7949121</td>\n",
       "<td>11.1019355</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0010248</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0002988</td>\n",
       "<td>0.0016149</td>\n",
       "<td>0.2915372</td>\n",
       "<td>0.2907812</td>\n",
       "<td>0.0001025</td>\n",
       "<td>1.0</td>\n",
       "<td>-99.8975173</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.0100108                   0.998423           3.43009     3.43009            1                0.999952    1                           0.999952            0.0343378       0.0343378                  243.009   243.009\n",
       "    2        0.0200514                   0.991506           3.43009     3.43009            1                0.993297    1                           0.99662             0.0344403       0.0687782                  243.009   243.009\n",
       "    3        0.0307495                   0.981794           3.43009     3.43009            1                0.985937    1                           0.992903            0.0366954       0.105474                   243.009   243.009\n",
       "    4        0.0400131                   0.972233           3.43009     3.43009            1                0.977836    1                           0.989415            0.0317753       0.137249                   243.009   243.009\n",
       "    5        0.0500239                   0.963882           3.43009     3.43009            1                0.96749     1                           0.985027            0.0343378       0.171587                   243.009   243.009\n",
       "    6        0.100018                    0.92186            3.43009     3.43009            1                0.941662    1                           0.963351            0.171484        0.343071                   243.009   243.009\n",
       "    7        0.150012                    0.88822            3.43009     3.43009            1                0.905372    1                           0.944028            0.171484        0.514555                   243.009   243.009\n",
       "    8        0.200006                    0.842178           3.42804     3.42958            0.999402         0.867068    0.999851                    0.924791            0.171382        0.685937                   242.804   242.958\n",
       "    9        0.299994                    0.370865           2.99646     3.28522            0.87358          0.702047    0.957765                    0.85055             0.29961         0.985547                   199.646   228.522\n",
       "    10       0.400012                    0.112473           0.131178    2.49659            0.0382432        0.207116    0.72785                     0.689668            0.0131201       0.998667                   -86.8822  149.659\n",
       "    11       0.5                         0.0486775          0.00205027  1.99774            0.000597729      0.0752963   0.582417                    0.566808            0.000205002     0.998872                   -99.795   99.7745\n",
       "    12       0.600018                    0.0250341          0.00307448  1.66525            0.000896325      0.0353917   0.485482                    0.478225            0.000307503     0.99918                    -99.6926  66.525\n",
       "    13       0.700006                    0.0144942          0.00205027  1.42768            0.000597729      0.0190908   0.416222                    0.412643            0.000205002     0.999385                   -99.795   42.7681\n",
       "    14       0.800024                    0.00875963         0.00307448  1.24958            0.000896325      0.0113545   0.364299                    0.362475            0.000307503     0.999692                   -99.6926  24.9578\n",
       "    15       0.899982                    0.00400315         0.00205088  1.11102            0.000597907      0.0063164   0.323903                    0.322917            0.000205002     0.999897                   -99.7949  11.1019\n",
       "    16       1                           0                  0.00102483  1                  0.000298775      0.00161486  0.291537                    0.290781            0.000102501     1                          -99.8975  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: drf\n",
      "** Reported on cross-validation data. **\n",
      "\n",
      "MSE: 0.019838655136353946\n",
      "RMSE: 0.14084976086722314\n",
      "LogLoss: 0.09848448113892687\n",
      "Mean Per-Class Error: 0.01697642178512626\n",
      "AUC: 0.9984149199275788\n",
      "pr_auc: 0.9438620129204796\n",
      "Gini: 0.9968298398551576\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4721316665854305: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>N</b></td>\n",
       "<td><b>Y</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>N</td>\n",
       "<td>213304.0</td>\n",
       "<td>1584.0</td>\n",
       "<td>0.0074</td>\n",
       "<td> (1584.0/214888.0)</td></tr>\n",
       "<tr><td>Y</td>\n",
       "<td>2589.0</td>\n",
       "<td>83755.0</td>\n",
       "<td>0.03</td>\n",
       "<td> (2589.0/86344.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>215893.0</td>\n",
       "<td>85339.0</td>\n",
       "<td>0.0139</td>\n",
       "<td> (4173.0/301232.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       N       Y      Error    Rate\n",
       "-----  ------  -----  -------  -----------------\n",
       "N      213304  1584   0.0074   (1584.0/214888.0)\n",
       "Y      2589    83755  0.03     (2589.0/86344.0)\n",
       "Total  215893  85339  0.0139   (4173.0/301232.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.4721317</td>\n",
       "<td>0.9756936</td>\n",
       "<td>186.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.3610743</td>\n",
       "<td>0.9781708</td>\n",
       "<td>216.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.5859488</td>\n",
       "<td>0.9856473</td>\n",
       "<td>162.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.4721317</td>\n",
       "<td>0.9861469</td>\n",
       "<td>186.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9999495</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0013795</td>\n",
       "<td>1.0</td>\n",
       "<td>397.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9999495</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.4721317</td>\n",
       "<td>0.9660394</td>\n",
       "<td>186.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.3911902</td>\n",
       "<td>0.9824606</td>\n",
       "<td>207.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.4120424</td>\n",
       "<td>0.9830236</td>\n",
       "<td>201.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.472132     0.975694  186\n",
       "max f2                       0.361074     0.978171  216\n",
       "max f0point5                 0.585949     0.985647  162\n",
       "max accuracy                 0.472132     0.986147  186\n",
       "max precision                0.999949     1         0\n",
       "max recall                   0.00137952   1         397\n",
       "max specificity              0.999949     1         0\n",
       "max absolute_mcc             0.472132     0.966039  186\n",
       "max min_per_class_accuracy   0.39119      0.982461  207\n",
       "max mean_per_class_accuracy  0.412042     0.983024  201"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 28.66 %, avg score: 28.75 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>score</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>cumulative_score</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0140490</td>\n",
       "<td>1.0</td>\n",
       "<td>3.4887427</td>\n",
       "<td>3.4887427</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0490132</td>\n",
       "<td>0.0490132</td>\n",
       "<td>248.8742704</td>\n",
       "<td>248.8742704</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0200311</td>\n",
       "<td>0.9953594</td>\n",
       "<td>3.4887427</td>\n",
       "<td>3.4887427</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9974951</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9992519</td>\n",
       "<td>0.0208700</td>\n",
       "<td>0.0698833</td>\n",
       "<td>248.8742704</td>\n",
       "<td>248.8742704</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0301263</td>\n",
       "<td>0.9863092</td>\n",
       "<td>3.4887427</td>\n",
       "<td>3.4887427</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9906092</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9963558</td>\n",
       "<td>0.0352196</td>\n",
       "<td>0.1051028</td>\n",
       "<td>248.8742704</td>\n",
       "<td>248.8742704</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0400024</td>\n",
       "<td>0.9741634</td>\n",
       "<td>3.4887427</td>\n",
       "<td>3.4887427</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9807678</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9925073</td>\n",
       "<td>0.0344552</td>\n",
       "<td>0.1395580</td>\n",
       "<td>248.8742704</td>\n",
       "<td>248.8742704</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0500013</td>\n",
       "<td>0.9587926</td>\n",
       "<td>3.4887427</td>\n",
       "<td>3.4887427</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9660452</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9872156</td>\n",
       "<td>0.0348837</td>\n",
       "<td>0.1744418</td>\n",
       "<td>248.8742704</td>\n",
       "<td>248.8742704</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1000027</td>\n",
       "<td>0.9146654</td>\n",
       "<td>3.4887427</td>\n",
       "<td>3.4887427</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9343891</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9608024</td>\n",
       "<td>0.1744418</td>\n",
       "<td>0.3488835</td>\n",
       "<td>248.8742704</td>\n",
       "<td>248.8742704</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1500007</td>\n",
       "<td>0.8794678</td>\n",
       "<td>3.4885111</td>\n",
       "<td>3.4886655</td>\n",
       "<td>0.9999336</td>\n",
       "<td>0.8973287</td>\n",
       "<td>0.9999779</td>\n",
       "<td>0.9396454</td>\n",
       "<td>0.1744186</td>\n",
       "<td>0.5233021</td>\n",
       "<td>248.8511063</td>\n",
       "<td>248.8665493</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2000020</td>\n",
       "<td>0.8359674</td>\n",
       "<td>3.4882795</td>\n",
       "<td>3.4885690</td>\n",
       "<td>0.9998672</td>\n",
       "<td>0.8590832</td>\n",
       "<td>0.9999502</td>\n",
       "<td>0.9195045</td>\n",
       "<td>0.1744186</td>\n",
       "<td>0.6977207</td>\n",
       "<td>248.8279453</td>\n",
       "<td>248.8568982</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3000013</td>\n",
       "<td>0.3577441</td>\n",
       "<td>2.8957618</td>\n",
       "<td>3.2909688</td>\n",
       "<td>0.8300302</td>\n",
       "<td>0.6803003</td>\n",
       "<td>0.9433108</td>\n",
       "<td>0.8397707</td>\n",
       "<td>0.2895743</td>\n",
       "<td>0.9872950</td>\n",
       "<td>189.5761837</td>\n",
       "<td>229.0968787</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4000007</td>\n",
       "<td>0.1138118</td>\n",
       "<td>0.1148900</td>\n",
       "<td>2.4969557</td>\n",
       "<td>0.0329316</td>\n",
       "<td>0.2046500</td>\n",
       "<td>0.7157179</td>\n",
       "<td>0.6809918</td>\n",
       "<td>0.0114889</td>\n",
       "<td>0.9987839</td>\n",
       "<td>-88.5109957</td>\n",
       "<td>149.6955691</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0508306</td>\n",
       "<td>0.0033587</td>\n",
       "<td>1.9982396</td>\n",
       "<td>0.0009627</td>\n",
       "<td>0.0769064</td>\n",
       "<td>0.5727678</td>\n",
       "<td>0.5601755</td>\n",
       "<td>0.0003359</td>\n",
       "<td>0.9991198</td>\n",
       "<td>-99.6641319</td>\n",
       "<td>99.8239600</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.5999993</td>\n",
       "<td>0.0265169</td>\n",
       "<td>0.0013898</td>\n",
       "<td>1.6654331</td>\n",
       "<td>0.0003984</td>\n",
       "<td>0.0369419</td>\n",
       "<td>0.4773735</td>\n",
       "<td>0.4729704</td>\n",
       "<td>0.0001390</td>\n",
       "<td>0.9992588</td>\n",
       "<td>-99.8610201</td>\n",
       "<td>66.5433141</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.6999987</td>\n",
       "<td>0.0145751</td>\n",
       "<td>0.0019689</td>\n",
       "<td>1.4277965</td>\n",
       "<td>0.0005644</td>\n",
       "<td>0.0201392</td>\n",
       "<td>0.4092582</td>\n",
       "<td>0.4082805</td>\n",
       "<td>0.0001969</td>\n",
       "<td>0.9994557</td>\n",
       "<td>-99.8031118</td>\n",
       "<td>42.7796517</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.8001441</td>\n",
       "<td>0.0076869</td>\n",
       "<td>0.0028912</td>\n",
       "<td>1.2494565</td>\n",
       "<td>0.0008287</td>\n",
       "<td>0.0107899</td>\n",
       "<td>0.3581395</td>\n",
       "<td>0.3585309</td>\n",
       "<td>0.0002895</td>\n",
       "<td>0.9997452</td>\n",
       "<td>-99.7108809</td>\n",
       "<td>24.9456487</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.8999973</td>\n",
       "<td>0.0025570</td>\n",
       "<td>0.0020877</td>\n",
       "<td>1.1110629</td>\n",
       "<td>0.0005984</td>\n",
       "<td>0.0051052</td>\n",
       "<td>0.3184709</td>\n",
       "<td>0.3193189</td>\n",
       "<td>0.0002085</td>\n",
       "<td>0.9999537</td>\n",
       "<td>-99.7912252</td>\n",
       "<td>11.1062916</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0004633</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0001328</td>\n",
       "<td>0.0008872</td>\n",
       "<td>0.2866362</td>\n",
       "<td>0.2874749</td>\n",
       "<td>0.0000463</td>\n",
       "<td>1.0</td>\n",
       "<td>-99.9536749</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift         cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  -----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.014049                    1                  3.48874      3.48874            1                1            1                           1                   0.0490132       0.0490132                  248.874   248.874\n",
       "    2        0.0200311                   0.995359           3.48874      3.48874            1                0.997495     1                           0.999252            0.02087         0.0698833                  248.874   248.874\n",
       "    3        0.0301263                   0.986309           3.48874      3.48874            1                0.990609     1                           0.996356            0.0352196       0.105103                   248.874   248.874\n",
       "    4        0.0400024                   0.974163           3.48874      3.48874            1                0.980768     1                           0.992507            0.0344552       0.139558                   248.874   248.874\n",
       "    5        0.0500013                   0.958793           3.48874      3.48874            1                0.966045     1                           0.987216            0.0348837       0.174442                   248.874   248.874\n",
       "    6        0.100003                    0.914665           3.48874      3.48874            1                0.934389     1                           0.960802            0.174442        0.348884                   248.874   248.874\n",
       "    7        0.150001                    0.879468           3.48851      3.48867            0.999934         0.897329     0.999978                    0.939645            0.174419        0.523302                   248.851   248.867\n",
       "    8        0.200002                    0.835967           3.48828      3.48857            0.999867         0.859083     0.99995                     0.919505            0.174419        0.697721                   248.828   248.857\n",
       "    9        0.300001                    0.357744           2.89576      3.29097            0.83003          0.6803       0.943311                    0.839771            0.289574        0.987295                   189.576   229.097\n",
       "    10       0.400001                    0.113812           0.11489      2.49696            0.0329316        0.20465      0.715718                    0.680992            0.0114889       0.998784                   -88.511   149.696\n",
       "    11       0.5                         0.0508306          0.00335868   1.99824            0.00096272       0.0769064    0.572768                    0.560176            0.000335866     0.99912                    -99.6641  99.824\n",
       "    12       0.599999                    0.0265169          0.0013898    1.66543            0.000398367      0.0369419    0.477373                    0.47297             0.000138979     0.999259                   -99.861   66.5433\n",
       "    13       0.699999                    0.0145751          0.00196888   1.4278             0.000564353      0.0201392    0.409258                    0.408281            0.000196887     0.999456                   -99.8031  42.7797\n",
       "    14       0.800144                    0.00768693         0.00289119   1.24946            0.00082872       0.0107899    0.358139                    0.358531            0.00028954      0.999745                   -99.7109  24.9456\n",
       "    15       0.899997                    0.002557           0.00208775   1.11106            0.000598424      0.00510517   0.318471                    0.319319            0.000208468     0.999954                   -99.7912  11.1063\n",
       "    16       1                           0                  0.000463251  1                  0.000132784      0.000887211  0.286636                    0.287475            4.63263e-05     1                          -99.9537  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-Validation Metrics Summary: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>mean</b></td>\n",
       "<td><b>sd</b></td>\n",
       "<td><b>cv_1_valid</b></td>\n",
       "<td><b>cv_2_valid</b></td>\n",
       "<td><b>cv_3_valid</b></td>\n",
       "<td><b>cv_4_valid</b></td>\n",
       "<td><b>cv_5_valid</b></td></tr>\n",
       "<tr><td>accuracy</td>\n",
       "<td>0.9862399</td>\n",
       "<td>0.0003246</td>\n",
       "<td>0.9861902</td>\n",
       "<td>0.9866052</td>\n",
       "<td>0.9858912</td>\n",
       "<td>0.9868871</td>\n",
       "<td>0.9856256</td></tr>\n",
       "<tr><td>auc</td>\n",
       "<td>0.9984168</td>\n",
       "<td>0.0000323</td>\n",
       "<td>0.9984430</td>\n",
       "<td>0.9983832</td>\n",
       "<td>0.9983691</td>\n",
       "<td>0.9984936</td>\n",
       "<td>0.9983954</td></tr>\n",
       "<tr><td>err</td>\n",
       "<td>0.0137602</td>\n",
       "<td>0.0003246</td>\n",
       "<td>0.0138098</td>\n",
       "<td>0.0133949</td>\n",
       "<td>0.0141088</td>\n",
       "<td>0.0131129</td>\n",
       "<td>0.0143744</td></tr>\n",
       "<tr><td>err_count</td>\n",
       "<td>829.0</td>\n",
       "<td>19.55505</td>\n",
       "<td>832.0</td>\n",
       "<td>807.0</td>\n",
       "<td>850.0</td>\n",
       "<td>790.0</td>\n",
       "<td>866.0</td></tr>\n",
       "<tr><td>f0point5</td>\n",
       "<td>0.9792042</td>\n",
       "<td>0.0005735</td>\n",
       "<td>0.9803233</td>\n",
       "<td>0.9791669</td>\n",
       "<td>0.9783503</td>\n",
       "<td>0.9798901</td>\n",
       "<td>0.9782903</td></tr>\n",
       "<tr><td>f1</td>\n",
       "<td>0.9758602</td>\n",
       "<td>0.0005739</td>\n",
       "<td>0.9757661</td>\n",
       "<td>0.9764785</td>\n",
       "<td>0.9754321</td>\n",
       "<td>0.9769773</td>\n",
       "<td>0.9746472</td></tr>\n",
       "<tr><td>f2</td>\n",
       "<td>0.97254</td>\n",
       "<td>0.0008897</td>\n",
       "<td>0.9712509</td>\n",
       "<td>0.9738048</td>\n",
       "<td>0.9725312</td>\n",
       "<td>0.9740818</td>\n",
       "<td>0.9710313</td></tr>\n",
       "<tr><td>lift_top_group</td>\n",
       "<td>3.4887974</td>\n",
       "<td>0.0097586</td>\n",
       "<td>3.4826868</td>\n",
       "<td>3.496025</td>\n",
       "<td>3.4654012</td>\n",
       "<td>3.4941423</td>\n",
       "<td>3.5057318</td></tr>\n",
       "<tr><td>logloss</td>\n",
       "<td>0.0984845</td>\n",
       "<td>0.0005711</td>\n",
       "<td>0.0989524</td>\n",
       "<td>0.0975894</td>\n",
       "<td>0.0976437</td>\n",
       "<td>0.0985139</td>\n",
       "<td>0.0997231</td></tr>\n",
       "<tr><td>max_per_class_error</td>\n",
       "<td>0.0296604</td>\n",
       "<td>0.0011602</td>\n",
       "<td>0.0317359</td>\n",
       "<td>0.0279696</td>\n",
       "<td>0.0293932</td>\n",
       "<td>0.0278390</td>\n",
       "<td>0.0313646</td></tr>\n",
       "<tr><td>mcc</td>\n",
       "<td>0.9662698</td>\n",
       "<td>0.0007951</td>\n",
       "<td>0.9661673</td>\n",
       "<td>0.9671350</td>\n",
       "<td>0.96556</td>\n",
       "<td>0.9678338</td>\n",
       "<td>0.9646531</td></tr>\n",
       "<tr><td>mean_per_class_accuracy</td>\n",
       "<td>0.9814841</td>\n",
       "<td>0.0005400</td>\n",
       "<td>0.9808374</td>\n",
       "<td>0.9822373</td>\n",
       "<td>0.9813487</td>\n",
       "<td>0.9824762</td>\n",
       "<td>0.9805208</td></tr>\n",
       "<tr><td>mean_per_class_error</td>\n",
       "<td>0.0185159</td>\n",
       "<td>0.0005400</td>\n",
       "<td>0.0191627</td>\n",
       "<td>0.0177626</td>\n",
       "<td>0.0186512</td>\n",
       "<td>0.0175238</td>\n",
       "<td>0.0194792</td></tr>\n",
       "<tr><td>mse</td>\n",
       "<td>0.0198387</td>\n",
       "<td>0.0001794</td>\n",
       "<td>0.0200267</td>\n",
       "<td>0.0195677</td>\n",
       "<td>0.0197068</td>\n",
       "<td>0.0196522</td>\n",
       "<td>0.0202399</td></tr>\n",
       "<tr><td>precision</td>\n",
       "<td>0.9814468</td>\n",
       "<td>0.0007716</td>\n",
       "<td>0.9833852</td>\n",
       "<td>0.9809675</td>\n",
       "<td>0.9803056</td>\n",
       "<td>0.9818416</td>\n",
       "<td>0.9807341</td></tr>\n",
       "<tr><td>r2</td>\n",
       "<td>0.9029759</td>\n",
       "<td>0.0009448</td>\n",
       "<td>0.9021599</td>\n",
       "<td>0.9041837</td>\n",
       "<td>0.9040078</td>\n",
       "<td>0.9038008</td>\n",
       "<td>0.9007272</td></tr>\n",
       "<tr><td>recall</td>\n",
       "<td>0.9703395</td>\n",
       "<td>0.0011602</td>\n",
       "<td>0.9682640</td>\n",
       "<td>0.9720304</td>\n",
       "<td>0.9706069</td>\n",
       "<td>0.972161</td>\n",
       "<td>0.9686354</td></tr>\n",
       "<tr><td>rmse</td>\n",
       "<td>0.1408469</td>\n",
       "<td>0.0006359</td>\n",
       "<td>0.1415158</td>\n",
       "<td>0.1398845</td>\n",
       "<td>0.1403809</td>\n",
       "<td>0.1401864</td>\n",
       "<td>0.1422668</td></tr>\n",
       "<tr><td>specificity</td>\n",
       "<td>0.9926286</td>\n",
       "<td>0.0003179</td>\n",
       "<td>0.9934106</td>\n",
       "<td>0.9924443</td>\n",
       "<td>0.9920907</td>\n",
       "<td>0.9927913</td>\n",
       "<td>0.9924061</td></tr></table></div>"
      ],
      "text/plain": [
       "                         mean       sd           cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid\n",
       "-----------------------  ---------  -----------  ------------  ------------  ------------  ------------  ------------\n",
       "accuracy                 0.98624    0.000324608  0.98619       0.986605      0.985891      0.986887      0.985626\n",
       "auc                      0.998417   3.23065e-05  0.998443      0.998383      0.998369      0.998494      0.998395\n",
       "err                      0.0137602  0.000324608  0.0138098     0.0133949     0.0141088     0.0131129     0.0143744\n",
       "err_count                829        19.5551      832           807           850           790           866\n",
       "f0point5                 0.979204   0.000573461  0.980323      0.979167      0.97835       0.97989       0.97829\n",
       "f1                       0.97586    0.000573905  0.975766      0.976478      0.975432      0.976977      0.974647\n",
       "f2                       0.97254    0.000889657  0.971251      0.973805      0.972531      0.974082      0.971031\n",
       "lift_top_group           3.4888     0.00975858   3.48269       3.49602       3.4654        3.49414       3.50573\n",
       "logloss                  0.0984845  0.000571146  0.0989524     0.0975894     0.0976437     0.0985139     0.0997231\n",
       "max_per_class_error      0.0296604  0.00116016   0.0317359     0.0279696     0.0293932     0.027839      0.0313646\n",
       "mcc                      0.96627    0.000795138  0.966167      0.967135      0.96556       0.967834      0.964653\n",
       "mean_per_class_accuracy  0.981484   0.000540021  0.980837      0.982237      0.981349      0.982476      0.980521\n",
       "mean_per_class_error     0.0185159  0.000540021  0.0191627     0.0177626     0.0186512     0.0175238     0.0194792\n",
       "mse                      0.0198387  0.000179418  0.0200267     0.0195677     0.0197068     0.0196522     0.0202399\n",
       "precision                0.981447   0.000771579  0.983385      0.980967      0.980306      0.981842      0.980734\n",
       "r2                       0.902976   0.000944809  0.90216       0.904184      0.904008      0.903801      0.900727\n",
       "recall                   0.97034    0.00116016   0.968264      0.97203       0.970607      0.972161      0.968635\n",
       "rmse                     0.140847   0.000635873  0.141516      0.139884      0.140381      0.140186      0.142267\n",
       "specificity              0.992629   0.000317939  0.993411      0.992444      0.992091      0.992791      0.992406"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>timestamp</b></td>\n",
       "<td><b>duration</b></td>\n",
       "<td><b>number_of_trees</b></td>\n",
       "<td><b>training_rmse</b></td>\n",
       "<td><b>training_logloss</b></td>\n",
       "<td><b>training_auc</b></td>\n",
       "<td><b>training_pr_auc</b></td>\n",
       "<td><b>training_lift</b></td>\n",
       "<td><b>training_classification_error</b></td>\n",
       "<td><b>validation_rmse</b></td>\n",
       "<td><b>validation_logloss</b></td>\n",
       "<td><b>validation_auc</b></td>\n",
       "<td><b>validation_pr_auc</b></td>\n",
       "<td><b>validation_lift</b></td>\n",
       "<td><b>validation_classification_error</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-12-11 20:57:15</td>\n",
       "<td> 3 min 19.834 sec</td>\n",
       "<td>0.0</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-12-11 20:57:16</td>\n",
       "<td> 3 min 20.186 sec</td>\n",
       "<td>1.0</td>\n",
       "<td>0.2275729</td>\n",
       "<td>0.8023489</td>\n",
       "<td>0.9643373</td>\n",
       "<td>0.2973424</td>\n",
       "<td>3.2871077</td>\n",
       "<td>0.0678526</td>\n",
       "<td>0.2279121</td>\n",
       "<td>0.7845200</td>\n",
       "<td>0.9645842</td>\n",
       "<td>0.3021248</td>\n",
       "<td>3.2463666</td>\n",
       "<td>0.0692386</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-12-11 20:57:16</td>\n",
       "<td> 3 min 20.516 sec</td>\n",
       "<td>2.0</td>\n",
       "<td>0.1947116</td>\n",
       "<td>0.5755505</td>\n",
       "<td>0.9754294</td>\n",
       "<td>0.2674530</td>\n",
       "<td>3.3580941</td>\n",
       "<td>0.0477174</td>\n",
       "<td>0.1637330</td>\n",
       "<td>0.1682876</td>\n",
       "<td>0.9918950</td>\n",
       "<td>0.4090383</td>\n",
       "<td>3.4077110</td>\n",
       "<td>0.0301219</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-12-11 20:57:16</td>\n",
       "<td> 3 min 20.899 sec</td>\n",
       "<td>3.0</td>\n",
       "<td>0.2134816</td>\n",
       "<td>0.4830622</td>\n",
       "<td>0.9741121</td>\n",
       "<td>0.3753213</td>\n",
       "<td>3.3749162</td>\n",
       "<td>0.0549736</td>\n",
       "<td>0.1680320</td>\n",
       "<td>0.1352552</td>\n",
       "<td>0.9942703</td>\n",
       "<td>0.6381483</td>\n",
       "<td>3.4221034</td>\n",
       "<td>0.0240856</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-12-11 20:57:17</td>\n",
       "<td> 3 min 21.359 sec</td>\n",
       "<td>4.0</td>\n",
       "<td>0.2066882</td>\n",
       "<td>0.4262715</td>\n",
       "<td>0.9769762</td>\n",
       "<td>0.4401881</td>\n",
       "<td>3.3820812</td>\n",
       "<td>0.0500909</td>\n",
       "<td>0.1618993</td>\n",
       "<td>0.1214420</td>\n",
       "<td>0.9954384</td>\n",
       "<td>0.7329649</td>\n",
       "<td>3.4246605</td>\n",
       "<td>0.0223524</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-12-11 20:57:17</td>\n",
       "<td> 3 min 21.859 sec</td>\n",
       "<td>5.0</td>\n",
       "<td>0.1937728</td>\n",
       "<td>0.3528538</td>\n",
       "<td>0.9816797</td>\n",
       "<td>0.4619649</td>\n",
       "<td>3.4018667</td>\n",
       "<td>0.0430413</td>\n",
       "<td>0.1506791</td>\n",
       "<td>0.1056986</td>\n",
       "<td>0.9970041</td>\n",
       "<td>0.7713415</td>\n",
       "<td>3.4253653</td>\n",
       "<td>0.0180194</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-12-11 20:57:18</td>\n",
       "<td> 3 min 22.433 sec</td>\n",
       "<td>6.0</td>\n",
       "<td>0.1869723</td>\n",
       "<td>0.3042406</td>\n",
       "<td>0.9844282</td>\n",
       "<td>0.4974868</td>\n",
       "<td>3.4114792</td>\n",
       "<td>0.0393220</td>\n",
       "<td>0.1467868</td>\n",
       "<td>0.0978622</td>\n",
       "<td>0.9974764</td>\n",
       "<td>0.7976991</td>\n",
       "<td>3.4300943</td>\n",
       "<td>0.0173918</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-12-11 20:57:18</td>\n",
       "<td> 3 min 23.078 sec</td>\n",
       "<td>7.0</td>\n",
       "<td>0.1854219</td>\n",
       "<td>0.2674861</td>\n",
       "<td>0.9861019</td>\n",
       "<td>0.5391322</td>\n",
       "<td>3.4207316</td>\n",
       "<td>0.0376572</td>\n",
       "<td>0.1490559</td>\n",
       "<td>0.1007377</td>\n",
       "<td>0.9975420</td>\n",
       "<td>0.8216224</td>\n",
       "<td>3.4300943</td>\n",
       "<td>0.0170033</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-12-11 20:57:19</td>\n",
       "<td> 3 min 23.758 sec</td>\n",
       "<td>8.0</td>\n",
       "<td>0.1872386</td>\n",
       "<td>0.2432327</td>\n",
       "<td>0.9869286</td>\n",
       "<td>0.5870945</td>\n",
       "<td>3.4287745</td>\n",
       "<td>0.0383898</td>\n",
       "<td>0.1540573</td>\n",
       "<td>0.1084683</td>\n",
       "<td>0.9974627</td>\n",
       "<td>0.8487917</td>\n",
       "<td>3.4300943</td>\n",
       "<td>0.0169137</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-12-11 20:57:23</td>\n",
       "<td> 3 min 27.842 sec</td>\n",
       "<td>20.0</td>\n",
       "<td>0.1502654</td>\n",
       "<td>0.1015057</td>\n",
       "<td>0.9972609</td>\n",
       "<td>0.8269213</td>\n",
       "<td>3.4858202</td>\n",
       "<td>0.0187077</td>\n",
       "<td>0.1376642</td>\n",
       "<td>0.0955218</td>\n",
       "<td>0.9983738</td>\n",
       "<td>0.9522312</td>\n",
       "<td>3.4300943</td>\n",
       "<td>0.0132680</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-12-11 20:57:27</td>\n",
       "<td> 3 min 31.979 sec</td>\n",
       "<td>31.0</td>\n",
       "<td>0.1450408</td>\n",
       "<td>0.0973989</td>\n",
       "<td>0.9980205</td>\n",
       "<td>0.8773195</td>\n",
       "<td>3.4887427</td>\n",
       "<td>0.0163495</td>\n",
       "<td>0.1371480</td>\n",
       "<td>0.0951007</td>\n",
       "<td>0.9984275</td>\n",
       "<td>0.9580318</td>\n",
       "<td>3.4300943</td>\n",
       "<td>0.0130887</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-12-11 20:57:32</td>\n",
       "<td> 3 min 37.002 sec</td>\n",
       "<td>44.0</td>\n",
       "<td>0.1427767</td>\n",
       "<td>0.0966466</td>\n",
       "<td>0.9982077</td>\n",
       "<td>0.9023397</td>\n",
       "<td>3.4887427</td>\n",
       "<td>0.0154665</td>\n",
       "<td>0.1372723</td>\n",
       "<td>0.0951708</td>\n",
       "<td>0.9984373</td>\n",
       "<td>0.9617304</td>\n",
       "<td>3.4300943</td>\n",
       "<td>0.0128795</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-12-11 20:57:35</td>\n",
       "<td> 3 min 39.588 sec</td>\n",
       "<td>50.0</td>\n",
       "<td>0.1422773</td>\n",
       "<td>0.0967380</td>\n",
       "<td>0.9982640</td>\n",
       "<td>0.9089612</td>\n",
       "<td>3.4887427</td>\n",
       "<td>0.0151080</td>\n",
       "<td>0.1374100</td>\n",
       "<td>0.0955319</td>\n",
       "<td>0.9984441</td>\n",
       "<td>0.9622318</td>\n",
       "<td>3.4300943</td>\n",
       "<td>0.0127600</td></tr></table></div>"
      ],
      "text/plain": [
       "    timestamp            duration          number_of_trees    training_rmse    training_logloss    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_auc    validation_pr_auc    validation_lift    validation_classification_error\n",
       "--  -------------------  ----------------  -----------------  ---------------  ------------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ----------------  -------------------  -----------------  ---------------------------------\n",
       "    2018-12-11 20:57:15  3 min 19.834 sec  0                  nan              nan                 nan             nan                nan              nan                              nan                nan                   nan               nan                  nan                nan\n",
       "    2018-12-11 20:57:16  3 min 20.186 sec  1                  0.227573         0.802349            0.964337        0.297342           3.28711          0.0678526                        0.227912           0.78452               0.964584          0.302125             3.24637            0.0692386\n",
       "    2018-12-11 20:57:16  3 min 20.516 sec  2                  0.194712         0.57555             0.975429        0.267453           3.35809          0.0477174                        0.163733           0.168288              0.991895          0.409038             3.40771            0.0301219\n",
       "    2018-12-11 20:57:16  3 min 20.899 sec  3                  0.213482         0.483062            0.974112        0.375321           3.37492          0.0549736                        0.168032           0.135255              0.99427           0.638148             3.4221             0.0240856\n",
       "    2018-12-11 20:57:17  3 min 21.359 sec  4                  0.206688         0.426271            0.976976        0.440188           3.38208          0.0500909                        0.161899           0.121442              0.995438          0.732965             3.42466            0.0223524\n",
       "    2018-12-11 20:57:17  3 min 21.859 sec  5                  0.193773         0.352854            0.98168         0.461965           3.40187          0.0430413                        0.150679           0.105699              0.997004          0.771341             3.42537            0.0180194\n",
       "    2018-12-11 20:57:18  3 min 22.433 sec  6                  0.186972         0.304241            0.984428        0.497487           3.41148          0.039322                         0.146787           0.0978622             0.997476          0.797699             3.43009            0.0173918\n",
       "    2018-12-11 20:57:18  3 min 23.078 sec  7                  0.185422         0.267486            0.986102        0.539132           3.42073          0.0376572                        0.149056           0.100738              0.997542          0.821622             3.43009            0.0170033\n",
       "    2018-12-11 20:57:19  3 min 23.758 sec  8                  0.187239         0.243233            0.986929        0.587094           3.42877          0.0383898                        0.154057           0.108468              0.997463          0.848792             3.43009            0.0169137\n",
       "    2018-12-11 20:57:23  3 min 27.842 sec  20                 0.150265         0.101506            0.997261        0.826921           3.48582          0.0187077                        0.137664           0.0955218             0.998374          0.952231             3.43009            0.013268\n",
       "    2018-12-11 20:57:27  3 min 31.979 sec  31                 0.145041         0.0973989           0.99802         0.87732            3.48874          0.0163495                        0.137148           0.0951007             0.998428          0.958032             3.43009            0.0130887\n",
       "    2018-12-11 20:57:32  3 min 37.002 sec  44                 0.142777         0.0966466           0.998208        0.90234            3.48874          0.0154665                        0.137272           0.0951708             0.998437          0.96173              3.43009            0.0128795\n",
       "    2018-12-11 20:57:35  3 min 39.588 sec  50                 0.142277         0.096738            0.998264        0.908961           3.48874          0.015108                         0.13741            0.0955319             0.998444          0.962232             3.43009            0.01276"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable Importances: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>variable</b></td>\n",
       "<td><b>relative_importance</b></td>\n",
       "<td><b>scaled_importance</b></td>\n",
       "<td><b>percentage</b></td></tr>\n",
       "<tr><td>city_id</td>\n",
       "<td>955775.3125000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.5581109</td></tr>\n",
       "<tr><td>state_id</td>\n",
       "<td>257751.2343750</td>\n",
       "<td>0.2696776</td>\n",
       "<td>0.1505100</td></tr>\n",
       "<tr><td>category_2</td>\n",
       "<td>160059.9062500</td>\n",
       "<td>0.1674660</td>\n",
       "<td>0.0934646</td></tr>\n",
       "<tr><td>category_1</td>\n",
       "<td>115193.4609375</td>\n",
       "<td>0.1205236</td>\n",
       "<td>0.0672655</td></tr>\n",
       "<tr><td>merchant_group_id</td>\n",
       "<td>70843.8906250</td>\n",
       "<td>0.0741219</td>\n",
       "<td>0.0413682</td></tr>\n",
       "<tr><td>subsector_id</td>\n",
       "<td>31761.3027344</td>\n",
       "<td>0.0332309</td>\n",
       "<td>0.0185465</td></tr>\n",
       "<tr><td>merchant_category_id</td>\n",
       "<td>19091.6308594</td>\n",
       "<td>0.0199750</td>\n",
       "<td>0.0111483</td></tr>\n",
       "<tr><td>most_recent_sales_range</td>\n",
       "<td>14489.4287109</td>\n",
       "<td>0.0151599</td>\n",
       "<td>0.0084609</td></tr>\n",
       "<tr><td>numerical_1</td>\n",
       "<td>11903.5019531</td>\n",
       "<td>0.0124543</td>\n",
       "<td>0.0069509</td></tr>\n",
       "<tr><td>most_recent_purchases_range</td>\n",
       "<td>10130.6972656</td>\n",
       "<td>0.0105995</td>\n",
       "<td>0.0059157</td></tr>\n",
       "<tr><td>numerical_2</td>\n",
       "<td>9703.4843750</td>\n",
       "<td>0.0101525</td>\n",
       "<td>0.0056662</td></tr>\n",
       "<tr><td>avg_purchases_lag3</td>\n",
       "<td>8831.2177734</td>\n",
       "<td>0.0092398</td>\n",
       "<td>0.0051569</td></tr>\n",
       "<tr><td>avg_purchases_lag6</td>\n",
       "<td>8387.1093750</td>\n",
       "<td>0.0087752</td>\n",
       "<td>0.0048975</td></tr>\n",
       "<tr><td>avg_purchases_lag12</td>\n",
       "<td>8357.7822266</td>\n",
       "<td>0.0087445</td>\n",
       "<td>0.0048804</td></tr>\n",
       "<tr><td>avg_sales_lag3</td>\n",
       "<td>8332.0605469</td>\n",
       "<td>0.0087176</td>\n",
       "<td>0.0048654</td></tr>\n",
       "<tr><td>avg_sales_lag12</td>\n",
       "<td>7839.9199219</td>\n",
       "<td>0.0082027</td>\n",
       "<td>0.0045780</td></tr>\n",
       "<tr><td>avg_sales_lag6</td>\n",
       "<td>7648.2841797</td>\n",
       "<td>0.0080022</td>\n",
       "<td>0.0044661</td></tr>\n",
       "<tr><td>active_months_lag12</td>\n",
       "<td>4748.7172852</td>\n",
       "<td>0.0049684</td>\n",
       "<td>0.0027729</td></tr>\n",
       "<tr><td>active_months_lag6</td>\n",
       "<td>1353.7655029</td>\n",
       "<td>0.0014164</td>\n",
       "<td>0.0007905</td></tr>\n",
       "<tr><td>active_months_lag3</td>\n",
       "<td>315.8672791</td>\n",
       "<td>0.0003305</td>\n",
       "<td>0.0001844</td></tr></table></div>"
      ],
      "text/plain": [
       "variable                     relative_importance    scaled_importance    percentage\n",
       "---------------------------  ---------------------  -------------------  ------------\n",
       "city_id                      955775                 1                    0.558111\n",
       "state_id                     257751                 0.269678             0.15051\n",
       "category_2                   160060                 0.167466             0.0934646\n",
       "category_1                   115193                 0.120524             0.0672655\n",
       "merchant_group_id            70843.9                0.0741219            0.0413682\n",
       "subsector_id                 31761.3                0.0332309            0.0185465\n",
       "merchant_category_id         19091.6                0.019975             0.0111483\n",
       "most_recent_sales_range      14489.4                0.0151599            0.00846089\n",
       "numerical_1                  11903.5                0.0124543            0.00695087\n",
       "most_recent_purchases_range  10130.7                0.0105995            0.00591567\n",
       "numerical_2                  9703.48                0.0101525            0.00566621\n",
       "avg_purchases_lag3           8831.22                0.00923985           0.00515686\n",
       "avg_purchases_lag6           8387.11                0.00877519           0.00489753\n",
       "avg_purchases_lag12          8357.78                0.00874451           0.0048804\n",
       "avg_sales_lag3               8332.06                0.00871759           0.00486538\n",
       "avg_sales_lag12              7839.92                0.00820268           0.00457801\n",
       "avg_sales_lag6               7648.28                0.00800218           0.0044661\n",
       "active_months_lag12          4748.72                0.00496845           0.00277294\n",
       "active_months_lag6           1353.77                0.00141641           0.000790511\n",
       "active_months_lag3           315.867                0.000330483          0.000184446"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<bound method ModelBase.weights of >"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aml.leader.weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume the following are passed by the user from the web interface\n",
    "\n",
    "'''\n",
    "Need a user id and project id?\n",
    "\n",
    "'''\n",
    "target='category_4' \n",
    "output='avg_purchases_lag6' \n",
    "\n",
    "data_file='merchants.csv'\n",
    "run_time=500\n",
    "run_id='SOME_ID_20180617_221529' # Just some arbitrary ID\n",
    "server_path='/Users/Suprita Ganesh/Desktop/ML3'\n",
    "classification=True\n",
    "scale=False\n",
    "max_models=None\n",
    "balance_y=False # balance_classes=balance_y\n",
    "balance_threshold=0.2\n",
    "project =\"automl_test\"  # project_name = project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/Suprita Ganesh/Desktop/ML3\\\\merchants.csv'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "data_path=os.path.join(server_path,data_file)\n",
    "data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "# Load data into H2O\n",
    "df = h2o.import_file(data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows:334696\n",
      "Cols:22\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>       </th><th>merchant_id    </th><th>merchant_group_id  </th><th>merchant_category_id  </th><th>subsector_id     </th><th>numerical_1         </th><th>numerical_2         </th><th>category_1  </th><th>most_recent_sales_range  </th><th>most_recent_purchases_range  </th><th>avg_sales_lag3    </th><th>avg_purchases_lag3  </th><th>active_months_lag3  </th><th>avg_sales_lag6    </th><th>avg_purchases_lag6  </th><th>active_months_lag6  </th><th>avg_sales_lag12   </th><th>avg_purchases_lag12  </th><th>active_months_lag12  </th><th>category_4  </th><th>city_id           </th><th>state_id         </th><th>category_2        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>type   </td><td>string         </td><td>int                </td><td>int                   </td><td>int              </td><td>real                </td><td>real                </td><td>enum        </td><td>enum                     </td><td>enum                         </td><td>real              </td><td>real                </td><td>int                 </td><td>real              </td><td>real                </td><td>int                 </td><td>real              </td><td>real                 </td><td>int                  </td><td>enum        </td><td>int               </td><td>int              </td><td>int               </td></tr>\n",
       "<tr><td>mins   </td><td>NaN            </td><td>1.0                </td><td>-1.0                  </td><td>-1.0             </td><td>-0.05747065         </td><td>-0.05747065         </td><td>            </td><td>                         </td><td>                             </td><td>-82.13            </td><td>0.33349533          </td><td>1.0                 </td><td>-82.13            </td><td>0.16704466          </td><td>1.0                 </td><td>-82.13            </td><td>0.09832954           </td><td>1.0                  </td><td>            </td><td>-1.0              </td><td>-1.0             </td><td>1.0               </td></tr>\n",
       "<tr><td>mean   </td><td>NaN            </td><td>31028.736142648864 </td><td>423.1316627626265     </td><td>25.11640413987618</td><td>0.011476379786761658</td><td>0.008103109673703913</td><td>            </td><td>                         </td><td>                             </td><td>13.832992503353953</td><td>1.5907620965243703  </td><td>2.9941080861438434  </td><td>21.65078713289889 </td><td>1.8875678157761608  </td><td>5.947397040896815   </td><td>25.227708876757905</td><td>2.0791954108497923   </td><td>11.599334918851728   </td><td>            </td><td>102.91792552047231</td><td>11.86094246719412</td><td>2.3800017967280946</td></tr>\n",
       "<tr><td>maxs   </td><td>NaN            </td><td>112586.0           </td><td>891.0                 </td><td>41.0             </td><td>183.73511137        </td><td>182.07932234        </td><td>            </td><td>                         </td><td>                             </td><td>851844.64         </td><td>61851.33333333      </td><td>3.0                 </td><td>1513959.0         </td><td>56077.5             </td><td>6.0                 </td><td>2567408.0         </td><td>50215.55555556       </td><td>12.0                 </td><td>            </td><td>347.0             </td><td>24.0             </td><td>5.0               </td></tr>\n",
       "<tr><td>sigma  </td><td>NaN            </td><td>31623.04342585761  </td><td>252.89804640741087    </td><td>9.807371150499078</td><td>1.0981535340747228  </td><td>1.070497129139856   </td><td>            </td><td>                         </td><td>                             </td><td>2395.4899987266786</td><td>107.18705938009496  </td><td>0.0952474880224711  </td><td>3947.1080986745974</td><td>97.86279027368853   </td><td>0.3949360216945969  </td><td>5251.842164947328 </td><td>88.44238392934712    </td><td>1.5201376720923252   </td><td>            </td><td>107.0906729099498 </td><td>6.176888783729171</td><td>1.562661049268994 </td></tr>\n",
       "<tr><td>zeros  </td><td>0              </td><td>0                  </td><td>0                     </td><td>0                </td><td>0                   </td><td>0                   </td><td>            </td><td>                         </td><td>                             </td><td>0                 </td><td>0                   </td><td>0                   </td><td>0                 </td><td>0                   </td><td>0                   </td><td>0                 </td><td>0                    </td><td>0                    </td><td>            </td><td>0                 </td><td>0                </td><td>0                 </td></tr>\n",
       "<tr><td>missing</td><td>0              </td><td>0                  </td><td>0                     </td><td>0                </td><td>0                   </td><td>0                   </td><td>0           </td><td>0                        </td><td>0                            </td><td>13                </td><td>3                   </td><td>0                   </td><td>13                </td><td>3                   </td><td>0                   </td><td>13                </td><td>3                    </td><td>0                    </td><td>0           </td><td>0                 </td><td>0                </td><td>11887             </td></tr>\n",
       "<tr><td>0      </td><td>M_ID_838061e48c</td><td>8353.0             </td><td>792.0                 </td><td>9.0              </td><td>-0.05747065         </td><td>-0.05747065         </td><td>N           </td><td>E                        </td><td>E                            </td><td>-0.4              </td><td>9.66666667          </td><td>3.0                 </td><td>-2.25             </td><td>18.66666667         </td><td>6.0                 </td><td>-2.32             </td><td>13.91666667          </td><td>12.0                 </td><td>N           </td><td>242.0             </td><td>9.0              </td><td>1.0               </td></tr>\n",
       "<tr><td>1      </td><td>M_ID_9339d880ad</td><td>3184.0             </td><td>840.0                 </td><td>20.0             </td><td>-0.05747065         </td><td>-0.05747065         </td><td>N           </td><td>E                        </td><td>E                            </td><td>-0.72             </td><td>1.75                </td><td>3.0                 </td><td>-0.74             </td><td>1.29166667          </td><td>6.0                 </td><td>-0.57             </td><td>1.6875               </td><td>12.0                 </td><td>N           </td><td>22.0              </td><td>16.0             </td><td>1.0               </td></tr>\n",
       "<tr><td>2      </td><td>M_ID_e726bbae1e</td><td>447.0              </td><td>690.0                 </td><td>1.0              </td><td>-0.05747065         </td><td>-0.05747065         </td><td>N           </td><td>E                        </td><td>E                            </td><td>-82.13            </td><td>260.0               </td><td>2.0                 </td><td>-82.13            </td><td>260.0               </td><td>2.0                 </td><td>-82.13            </td><td>260.0                </td><td>2.0                  </td><td>N           </td><td>-1.0              </td><td>5.0              </td><td>5.0               </td></tr>\n",
       "<tr><td>3      </td><td>M_ID_a70e9c5f81</td><td>5026.0             </td><td>792.0                 </td><td>9.0              </td><td>-0.05747065         </td><td>-0.05747065         </td><td>Y           </td><td>E                        </td><td>E                            </td><td>nan               </td><td>1.66666667          </td><td>3.0                 </td><td>nan               </td><td>4.66666667          </td><td>6.0                 </td><td>nan               </td><td>3.83333333           </td><td>12.0                 </td><td>Y           </td><td>-1.0              </td><td>-1.0             </td><td>nan               </td></tr>\n",
       "<tr><td>4      </td><td>M_ID_64456c37ce</td><td>2228.0             </td><td>222.0                 </td><td>21.0             </td><td>-0.05747065         </td><td>-0.05747065         </td><td>Y           </td><td>E                        </td><td>E                            </td><td>nan               </td><td>0.5                 </td><td>3.0                 </td><td>nan               </td><td>0.36111111          </td><td>6.0                 </td><td>nan               </td><td>0.34722222           </td><td>12.0                 </td><td>Y           </td><td>-1.0              </td><td>-1.0             </td><td>nan               </td></tr>\n",
       "<tr><td>5      </td><td>M_ID_a0915f62b5</td><td>20201.0            </td><td>87.0                  </td><td>27.0             </td><td>-0.05747065         </td><td>-0.05747065         </td><td>N           </td><td>E                        </td><td>E                            </td><td>nan               </td><td>1.0                 </td><td>3.0                 </td><td>nan               </td><td>3.66666667          </td><td>6.0                 </td><td>nan               </td><td>3.83333333           </td><td>12.0                 </td><td>Y           </td><td>160.0             </td><td>21.0             </td><td>5.0               </td></tr>\n",
       "<tr><td>6      </td><td>M_ID_bfd41933db</td><td>33861.0            </td><td>792.0                 </td><td>9.0              </td><td>-0.05747065         </td><td>-0.05747065         </td><td>N           </td><td>E                        </td><td>E                            </td><td>nan               </td><td>2.83333333          </td><td>3.0                 </td><td>nan               </td><td>4.83333333          </td><td>6.0                 </td><td>nan               </td><td>6.33333333           </td><td>12.0                 </td><td>N           </td><td>60.0              </td><td>16.0             </td><td>1.0               </td></tr>\n",
       "<tr><td>7      </td><td>M_ID_d8ff08219e</td><td>16430.0            </td><td>529.0                 </td><td>20.0             </td><td>-0.05747065         </td><td>-0.05747065         </td><td>Y           </td><td>E                        </td><td>E                            </td><td>nan               </td><td>1.0                 </td><td>3.0                 </td><td>nan               </td><td>1.66666667          </td><td>6.0                 </td><td>nan               </td><td>1.5                  </td><td>11.0                 </td><td>Y           </td><td>-1.0              </td><td>-1.0             </td><td>nan               </td></tr>\n",
       "<tr><td>8      </td><td>M_ID_c5b389236d</td><td>37179.0            </td><td>813.0                 </td><td>29.0             </td><td>-0.05747065         </td><td>-0.05747065         </td><td>N           </td><td>E                        </td><td>E                            </td><td>nan               </td><td>115.0               </td><td>3.0                 </td><td>nan               </td><td>189.91666667        </td><td>6.0                 </td><td>nan               </td><td>197.0                </td><td>7.0                  </td><td>N           </td><td>248.0             </td><td>15.0             </td><td>1.0               </td></tr>\n",
       "<tr><td>9      </td><td>M_ID_d2162ed113</td><td>112122.0           </td><td>81.0                  </td><td>29.0             </td><td>-0.05747065         </td><td>-0.05747065         </td><td>Y           </td><td>E                        </td><td>E                            </td><td>nan               </td><td>1.0                 </td><td>2.0                 </td><td>nan               </td><td>1.0                 </td><td>2.0                 </td><td>nan               </td><td>1.0                  </td><td>2.0                  </td><td>Y           </td><td>-1.0              </td><td>-1.0             </td><td>nan               </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category_4\n",
      "['merchant_id', 'merchant_group_id', 'merchant_category_id', 'subsector_id', 'numerical_1', 'numerical_2', 'category_1', 'most_recent_sales_range', 'most_recent_purchases_range', 'avg_sales_lag3', 'avg_purchases_lag3', 'active_months_lag3', 'avg_sales_lag6', 'avg_purchases_lag6', 'active_months_lag6', 'avg_sales_lag12', 'avg_purchases_lag12', 'active_months_lag12', 'city_id', 'state_id', 'category_2']\n"
     ]
    }
   ],
   "source": [
    "# assign target and inputs for logistic regression\n",
    "y = target\n",
    "X = [name for name in df.columns if name != y]\n",
    "print(y)\n",
    "print(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category_4\n",
      "['merchant_id', 'merchant_group_id', 'merchant_category_id', 'subsector_id', 'numerical_1', 'numerical_2', 'category_1', 'most_recent_sales_range', 'most_recent_purchases_range', 'avg_sales_lag3', 'avg_purchases_lag3', 'active_months_lag3', 'avg_sales_lag6', 'avg_purchases_lag6', 'active_months_lag6', 'avg_sales_lag12', 'avg_purchases_lag12', 'active_months_lag12', 'city_id', 'state_id', 'category_2']\n"
     ]
    }
   ],
   "source": [
    "# assign target and inputs for logistic regression\n",
    "y1 = output\n",
    "X1= [name for name in df.columns if name != y]\n",
    "print(y)\n",
    "print(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['merchant_group_id', 'merchant_category_id', 'subsector_id', 'active_months_lag3', 'active_months_lag6', 'active_months_lag12', 'city_id', 'state_id', 'category_2']\n",
      "['category_1', 'most_recent_sales_range', 'most_recent_purchases_range']\n",
      "['merchant_id', 'numerical_1', 'numerical_2', 'avg_sales_lag3', 'avg_purchases_lag3', 'avg_sales_lag6', 'avg_purchases_lag6', 'avg_sales_lag12', 'avg_purchases_lag12']\n"
     ]
    }
   ],
   "source": [
    "# determine column types\n",
    "ints, reals, enums = [], [], []\n",
    "for key, val in df.types.items():\n",
    "    if key in X1:\n",
    "        if val == 'enum':\n",
    "            enums.append(key)\n",
    "        elif val == 'int':\n",
    "            ints.append(key)            \n",
    "        else: \n",
    "            reals.append(key)\n",
    "\n",
    "print(ints)\n",
    "print(enums)\n",
    "print(reals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute missing values\n",
    "_=df[reals].impute(method='mean')\n",
    "_=df[ints].impute(method='median')\n",
    "\n",
    "if scale:\n",
    "    df[reals] = df[reals].scale()\n",
    "    df[ints] = df[ints].scale()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows:334696\n",
      "Cols:22\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>       </th><th>merchant_id    </th><th>merchant_group_id  </th><th>merchant_category_id  </th><th>subsector_id     </th><th>numerical_1         </th><th>numerical_2         </th><th>category_1  </th><th>most_recent_sales_range  </th><th>most_recent_purchases_range  </th><th>avg_sales_lag3    </th><th>avg_purchases_lag3  </th><th>active_months_lag3  </th><th>avg_sales_lag6    </th><th>avg_purchases_lag6  </th><th>active_months_lag6  </th><th>avg_sales_lag12   </th><th>avg_purchases_lag12  </th><th>active_months_lag12  </th><th>category_4  </th><th>city_id           </th><th>state_id         </th><th>category_2        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>type   </td><td>string         </td><td>int                </td><td>int                   </td><td>int              </td><td>real                </td><td>real                </td><td>enum        </td><td>enum                     </td><td>enum                         </td><td>real              </td><td>real                </td><td>int                 </td><td>real              </td><td>real                </td><td>int                 </td><td>real              </td><td>real                 </td><td>int                  </td><td>enum        </td><td>int               </td><td>int              </td><td>real              </td></tr>\n",
       "<tr><td>mins   </td><td>NaN            </td><td>1.0                </td><td>-1.0                  </td><td>-1.0             </td><td>-0.05747065         </td><td>-0.05747065         </td><td>            </td><td>                         </td><td>                             </td><td>-82.13            </td><td>0.33349533          </td><td>1.0                 </td><td>-82.13            </td><td>0.16704466          </td><td>1.0                 </td><td>-82.13            </td><td>0.09832954           </td><td>1.0                  </td><td>            </td><td>-1.0              </td><td>-1.0             </td><td>1.0               </td></tr>\n",
       "<tr><td>mean   </td><td>NaN            </td><td>31028.736142648864 </td><td>423.1316627626265     </td><td>25.11640413987618</td><td>0.011476379786761658</td><td>0.008103109673703913</td><td>            </td><td>                         </td><td>                             </td><td>13.832992503353958</td><td>1.5907620965243676  </td><td>2.9941080861438434  </td><td>21.650787132898987</td><td>1.8875678157761566  </td><td>5.947397040896815   </td><td>25.227708876757813</td><td>2.079195410849794    </td><td>11.599334918851728   </td><td>            </td><td>102.91792552047231</td><td>11.86094246719412</td><td>2.380001796728098 </td></tr>\n",
       "<tr><td>maxs   </td><td>NaN            </td><td>112586.0           </td><td>891.0                 </td><td>41.0             </td><td>183.73511137        </td><td>182.07932234        </td><td>            </td><td>                         </td><td>                             </td><td>851844.64         </td><td>61851.33333333      </td><td>3.0                 </td><td>1513959.0         </td><td>56077.5             </td><td>6.0                 </td><td>2567408.0         </td><td>50215.55555556       </td><td>12.0                 </td><td>            </td><td>347.0             </td><td>24.0             </td><td>5.0               </td></tr>\n",
       "<tr><td>sigma  </td><td>NaN            </td><td>31623.04342585761  </td><td>252.89804640741087    </td><td>9.807371150499078</td><td>1.0981535340747228  </td><td>1.070497129139856   </td><td>            </td><td>                         </td><td>                             </td><td>2395.4434762623737</td><td>107.18657899960115  </td><td>0.0952474880224711  </td><td>3947.031442459927 </td><td>97.86235168179363   </td><td>0.3949360216945969  </td><td>5251.74016968131  </td><td>88.44198755690937    </td><td>1.5201376720923252   </td><td>            </td><td>107.0906729099498 </td><td>6.176888783729171</td><td>1.5346605151185726</td></tr>\n",
       "<tr><td>zeros  </td><td>0              </td><td>0                  </td><td>0                     </td><td>0                </td><td>0                   </td><td>0                   </td><td>            </td><td>                         </td><td>                             </td><td>0                 </td><td>0                   </td><td>0                   </td><td>0                 </td><td>0                   </td><td>0                   </td><td>0                 </td><td>0                    </td><td>0                    </td><td>            </td><td>0                 </td><td>0                </td><td>0                 </td></tr>\n",
       "<tr><td>missing</td><td>0              </td><td>0                  </td><td>0                     </td><td>0                </td><td>0                   </td><td>0                   </td><td>0           </td><td>0                        </td><td>0                            </td><td>0                 </td><td>0                   </td><td>0                   </td><td>0                 </td><td>0                   </td><td>0                   </td><td>0                 </td><td>0                    </td><td>0                    </td><td>0           </td><td>0                 </td><td>0                </td><td>0                 </td></tr>\n",
       "<tr><td>0      </td><td>M_ID_838061e48c</td><td>8353.0             </td><td>792.0                 </td><td>9.0              </td><td>-0.05747065         </td><td>-0.05747065         </td><td>N           </td><td>E                        </td><td>E                            </td><td>-0.4              </td><td>9.66666667          </td><td>3.0                 </td><td>-2.25             </td><td>18.66666667         </td><td>6.0                 </td><td>-2.32             </td><td>13.91666667          </td><td>12.0                 </td><td>N           </td><td>242.0             </td><td>9.0              </td><td>1.0               </td></tr>\n",
       "<tr><td>1      </td><td>M_ID_9339d880ad</td><td>3184.0             </td><td>840.0                 </td><td>20.0             </td><td>-0.05747065         </td><td>-0.05747065         </td><td>N           </td><td>E                        </td><td>E                            </td><td>-0.72             </td><td>1.75                </td><td>3.0                 </td><td>-0.74             </td><td>1.29166667          </td><td>6.0                 </td><td>-0.57             </td><td>1.6875               </td><td>12.0                 </td><td>N           </td><td>22.0              </td><td>16.0             </td><td>1.0               </td></tr>\n",
       "<tr><td>2      </td><td>M_ID_e726bbae1e</td><td>447.0              </td><td>690.0                 </td><td>1.0              </td><td>-0.05747065         </td><td>-0.05747065         </td><td>N           </td><td>E                        </td><td>E                            </td><td>-82.13            </td><td>260.0               </td><td>2.0                 </td><td>-82.13            </td><td>260.0               </td><td>2.0                 </td><td>-82.13            </td><td>260.0                </td><td>2.0                  </td><td>N           </td><td>-1.0              </td><td>5.0              </td><td>5.0               </td></tr>\n",
       "<tr><td>3      </td><td>M_ID_a70e9c5f81</td><td>5026.0             </td><td>792.0                 </td><td>9.0              </td><td>-0.05747065         </td><td>-0.05747065         </td><td>Y           </td><td>E                        </td><td>E                            </td><td>13.832992503353953</td><td>1.66666667          </td><td>3.0                 </td><td>21.65078713289889 </td><td>4.66666667          </td><td>6.0                 </td><td>25.227708876757905</td><td>3.83333333           </td><td>12.0                 </td><td>Y           </td><td>-1.0              </td><td>-1.0             </td><td>2.3800017967280946</td></tr>\n",
       "<tr><td>4      </td><td>M_ID_64456c37ce</td><td>2228.0             </td><td>222.0                 </td><td>21.0             </td><td>-0.05747065         </td><td>-0.05747065         </td><td>Y           </td><td>E                        </td><td>E                            </td><td>13.832992503353953</td><td>0.5                 </td><td>3.0                 </td><td>21.65078713289889 </td><td>0.36111111          </td><td>6.0                 </td><td>25.227708876757905</td><td>0.34722222           </td><td>12.0                 </td><td>Y           </td><td>-1.0              </td><td>-1.0             </td><td>2.3800017967280946</td></tr>\n",
       "<tr><td>5      </td><td>M_ID_a0915f62b5</td><td>20201.0            </td><td>87.0                  </td><td>27.0             </td><td>-0.05747065         </td><td>-0.05747065         </td><td>N           </td><td>E                        </td><td>E                            </td><td>13.832992503353953</td><td>1.0                 </td><td>3.0                 </td><td>21.65078713289889 </td><td>3.66666667          </td><td>6.0                 </td><td>25.227708876757905</td><td>3.83333333           </td><td>12.0                 </td><td>Y           </td><td>160.0             </td><td>21.0             </td><td>5.0               </td></tr>\n",
       "<tr><td>6      </td><td>M_ID_bfd41933db</td><td>33861.0            </td><td>792.0                 </td><td>9.0              </td><td>-0.05747065         </td><td>-0.05747065         </td><td>N           </td><td>E                        </td><td>E                            </td><td>13.832992503353953</td><td>2.83333333          </td><td>3.0                 </td><td>21.65078713289889 </td><td>4.83333333          </td><td>6.0                 </td><td>25.227708876757905</td><td>6.33333333           </td><td>12.0                 </td><td>N           </td><td>60.0              </td><td>16.0             </td><td>1.0               </td></tr>\n",
       "<tr><td>7      </td><td>M_ID_d8ff08219e</td><td>16430.0            </td><td>529.0                 </td><td>20.0             </td><td>-0.05747065         </td><td>-0.05747065         </td><td>Y           </td><td>E                        </td><td>E                            </td><td>13.832992503353953</td><td>1.0                 </td><td>3.0                 </td><td>21.65078713289889 </td><td>1.66666667          </td><td>6.0                 </td><td>25.227708876757905</td><td>1.5                  </td><td>11.0                 </td><td>Y           </td><td>-1.0              </td><td>-1.0             </td><td>2.3800017967280946</td></tr>\n",
       "<tr><td>8      </td><td>M_ID_c5b389236d</td><td>37179.0            </td><td>813.0                 </td><td>29.0             </td><td>-0.05747065         </td><td>-0.05747065         </td><td>N           </td><td>E                        </td><td>E                            </td><td>13.832992503353953</td><td>115.0               </td><td>3.0                 </td><td>21.65078713289889 </td><td>189.91666667        </td><td>6.0                 </td><td>25.227708876757905</td><td>197.0                </td><td>7.0                  </td><td>N           </td><td>248.0             </td><td>15.0             </td><td>1.0               </td></tr>\n",
       "<tr><td>9      </td><td>M_ID_d2162ed113</td><td>112122.0           </td><td>81.0                  </td><td>29.0             </td><td>-0.05747065         </td><td>-0.05747065         </td><td>Y           </td><td>E                        </td><td>E                            </td><td>13.832992503353953</td><td>1.0                 </td><td>2.0                 </td><td>21.65078713289889 </td><td>1.0                 </td><td>2.0                 </td><td>25.227708876757905</td><td>1.0                  </td><td>2.0                  </td><td>Y           </td><td>-1.0              </td><td>-1.0             </td><td>2.3800017967280946</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "    df[y] = df[y].asfactor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'H2OGeneralizedLinearEstimator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-56-c628283a629b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mglm_model1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mH2OGeneralizedLinearEstimator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfamily\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;34m\"gaussian\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlambda_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompute_p_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mremove_collinear_columns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mglm_model1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_frame\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'H2OGeneralizedLinearEstimator' is not defined"
     ]
    }
   ],
   "source": [
    "glm_model1 = H2OGeneralizedLinearEstimator(family= \"gaussian\", lambda_ = 0, compute_p_values = True,remove_collinear_columns=False)\n",
    "glm_model1.train(X1, y1, training_frame= df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glm_model._model_json['output']['coefficients_table'].as_data_frame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from h2o.estimators.glm import H2OGeneralizedLinearEstimator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glm_model1.std_coef_plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(glm_model.coef())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(glm_model.coef_norm())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glm_model._model_json['output']['coefficients_table'].as_data_frame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(glm_model._model_json['output']['coefficients_table']['std_error'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glm_model.std_coef_plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h2o\n",
    "import numpy as np\n",
    "import math\n",
    "from h2o.estimators.gbm import H2OGradientBoostingEstimator\n",
    "from h2o.grid.grid_search import H2OGridSearch\n",
    "h2o.init(nthreads=-1, strict_version_check=True)\n",
    "## optional: connect to a running H2O cluster\n",
    "#h2o.init(ip=\"mycluster\", port=55555)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid, test = df.split_frame(\n",
    "    ratios=[0.6,0.2], \n",
    "    seed=1234, \n",
    "    destination_frames=['train.hex','valid.hex','test.hex']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We only provide the required parameters, everything else is default\n",
    "gbm = H2OGradientBoostingEstimator()\n",
    "gbm.train(x=X, y=y, training_frame=train)\n",
    "\n",
    "## Show a detailed model summary\n",
    "print(gbm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the AUC on the validation set\n",
    "perf = gbm.model_performance(valid)\n",
    "print(perf.auc())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_gbm = H2OGradientBoostingEstimator(nfolds = 4)\n",
    "cv_gbm.train(x = X, y = y, training_frame = train.rbind(valid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Show a detailed summary of the cross validation metrics\n",
    "## This gives you an idea of the variance between the folds\n",
    "cv_summary = cv_gbm.cross_validation_metrics_summary().as_data_frame()\n",
    "#print(cv_summary) ## Full summary of all metrics\n",
    "#print(cv_summary.iloc[4]) ## get the row with just the AUCs\n",
    "\n",
    "cv_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the cross-validated AUC by scoring the combined holdout predictions.\n",
    "## (Instead of taking the average of the metrics across the folds)\n",
    "perf_cv = cv_gbm.model_performance(xval=True)\n",
    "print(perf_cv.auc())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll do real hyper-parameter optimization to see if we can beat the best AUC so far (around 94%).\n",
    "\n",
    "The key here is to start tuning some key parameters first (i.e., those that we expect to have the biggest impact on the results). From experience with gradient boosted trees across many datasets, we can state the following \"rules\":\n",
    "\n",
    "Build as many trees (ntrees) as it takes until the validation set error starts increasing.\n",
    "A lower learning rate (learn_rate) is generally better, but will require more trees. Using learn_rate=0.02and learn_rate_annealing=0.995 (reduction of learning rate with each additional tree) can help speed up convergence without sacrificing accuracy too much, and is great to hyper-parameter searches. For faster scans, use values of 0.05 and 0.99 instead.\n",
    "The optimum maximum allowed depth for the trees (max_depth) is data dependent, deeper trees take longer to train, especially at depths greater than 10.\n",
    "Row and column sampling (sample_rate and col_sample_rate) can improve generalization and lead to lower validation and test set errors. Good general values for large datasets are around 0.7 to 0.8 (sampling 70-80 percent of the data) for both parameters. Column sampling per tree (col_sample_rate_per_tree) can also be tuned. Note that it is multiplicative with col_sample_rate, so setting both parameters to 0.8 results in 64% of columns being considered at any given node to split.\n",
    "For highly imbalanced classification datasets (e.g., fewer buyers than non-buyers), stratified row sampling based on response class membership can help improve predictive accuracy. It is configured with sample_rate_per_class (array of ratios, one per response class in lexicographic order).\n",
    "Most other options only have a small impact on the model performance, but are worth tuning with a Random hyper-parameter search nonetheless, if highest performance is critical.\n",
    "First we want to know what value of max_depth to use because it has a big impact on the model training time and optimal values depend strongly on the dataset. We'll do a quick Cartesian grid search to get a rough idea of good candidate max_depth values. Each model in the grid search will use early stopping to tune the number of trees using the validation set AUC, as before. We'll use learning rate annealing to speed up convergence without sacrificing too much accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from h2o.grid.grid_search import H2OGridSearch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = df.split_frame(seed = 1)\n",
    "train = ss[0]\n",
    "valid = ss[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GBM hyperparameters\n",
    "\n",
    "gbm_params1 = {'learn_rate': [0.01, 0.1],\n",
    "                'max_depth': [3, 5, 9],\n",
    "                'sample_rate': [0.8, 1.0],\n",
    "                'col_sample_rate': [0.2, 0.5, 1.0]}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_grid1 = H2OGridSearch(model=H2OGradientBoostingEstimator,\n",
    "                          grid_id='gbm_grid1',\n",
    "                          hyper_params=gbm_params1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_grid1.train(x=X, y=y,\n",
    "                training_frame=train,\n",
    "                validation_frame=valid,\n",
    "                ntrees=100,\n",
    "                seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_gridperf1 = gbm_grid1.get_grid(sort_by='auc', decreasing=True)\n",
    "gbm_gridperf1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the top GBM model, chosen by validation AUC\n",
    "best_gbm1 = gbm_gridperf1.models[0]\n",
    "\n",
    "# Now let's evaluate the model performance on a test set\n",
    "# so we get an honest estimate of top model performance\n",
    "best_gbm_perf1 = best_gbm1.model_performance(test)\n",
    "\n",
    "best_gbm_perf1.auc()  # 0.7781932261061573\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from h2o.estimators.random_forest import H2ORandomForestEstimator\n",
    "\n",
    "\n",
    "rf_v1 = H2ORandomForestEstimator(\n",
    "    model_id=\"rf_covType_v1\",\n",
    "    ntrees=200,\n",
    "    stopping_rounds=2,\n",
    "    score_each_iteration=True,\n",
    "    seed=1000000)\n",
    "\n",
    "\n",
    "rf_v1.train(X, y, training_frame=train, validation_frame=valid)\n",
    "\n",
    "\n",
    "rf_v1\n",
    "\n",
    "rf_v1.score_history()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
